{"files":{"frontend/messages/pl.json":"{%- if cookiecutter.enable_i18n %}\n{\n  \"common\": {\n    \"loading\": \"≈Åadowanie...\",\n    \"error\": \"B≈ÇƒÖd\",\n    \"success\": \"Sukces\",\n    \"save\": \"Zapisz\",\n    \"cancel\": \"Anuluj\",\n    \"delete\": \"Usu≈Ñ\",\n    \"edit\": \"Edytuj\",\n    \"create\": \"Utw√≥rz\",\n    \"search\": \"Szukaj\",\n    \"back\": \"Wstecz\",\n    \"next\": \"Dalej\",\n    \"previous\": \"Wstecz\",\n    \"submit\": \"Wy≈õlij\",\n    \"close\": \"Zamknij\",\n    \"confirm\": \"Potwierd≈∫\",\n    \"yes\": \"Tak\",\n    \"no\": \"Nie\"\n  },\n  \"navigation\": {\n    \"home\": \"Strona g≈Ç√≥wna\",\n    \"dashboard\": \"Panel\",\n    \"profile\": \"Profil\",\n    \"settings\": \"Ustawienia\",\n    \"logout\": \"Wyloguj\"\n  },\n  \"auth\": {\n    \"login\": \"Zaloguj siƒô\",\n    \"register\": \"Zarejestruj siƒô\",\n    \"email\": \"Email\",\n    \"password\": \"Has≈Ço\",\n    \"confirmPassword\": \"Potwierd≈∫ has≈Ço\",\n    \"forgotPassword\": \"Zapomnia≈Çe≈õ has≈Ça?\",\n    \"noAccount\": \"Nie masz konta?\",\n    \"hasAccount\": \"Masz ju≈º konto?\",\n    \"loginSuccess\": \"Zalogowano pomy≈õlnie\",\n    \"registerSuccess\": \"Konto utworzone pomy≈õlnie\",\n    \"logoutSuccess\": \"Wylogowano pomy≈õlnie\",\n    \"invalidCredentials\": \"Nieprawid≈Çowy email lub has≈Ço\",\n    \"emailRequired\": \"Email jest wymagany\",\n    \"passwordRequired\": \"Has≈Ço jest wymagane\",\n    \"passwordMismatch\": \"Has≈Ça nie sƒÖ takie same\",\n    \"continueWithGoogle\": \"Kontynuuj z Google\"\n  },\n  \"profile\": {\n    \"title\": \"Profil\",\n    \"personalInfo\": \"Dane osobowe\",\n    \"name\": \"Imiƒô\",\n    \"email\": \"Email\",\n    \"changePassword\": \"Zmie≈Ñ has≈Ço\",\n    \"currentPassword\": \"Obecne has≈Ço\",\n    \"newPassword\": \"Nowe has≈Ço\",\n    \"updateProfile\": \"Zaktualizuj profil\",\n    \"deleteAccount\": \"Usu≈Ñ konto\",\n    \"deleteAccountWarning\": \"Tej akcji nie mo≈ºna cofnƒÖƒá. Wszystkie Twoje dane zostanƒÖ trwale usuniƒôte.\"\n  },\n  \"chat\": {\n    \"title\": \"Czat\",\n    \"newChat\": \"Nowy czat\",\n    \"sendMessage\": \"Napisz wiadomo≈õƒá...\",\n    \"thinking\": \"My≈õlƒô...\",\n    \"noConversations\": \"Brak konwersacji\",\n    \"startNewChat\": \"Rozpocznij nowy czat\",\n    \"deleteConversation\": \"Usu≈Ñ konwersacjƒô\",\n    \"archiveConversation\": \"Archiwizuj konwersacjƒô\",\n    \"renameConversation\": \"Zmie≈Ñ nazwƒô konwersacji\"\n  },\n  \"errors\": {\n    \"generic\": \"Co≈õ posz≈Ço nie tak\",\n    \"notFound\": \"Strona nie znaleziona\",\n    \"unauthorized\": \"Nie masz uprawnie≈Ñ do wy≈õwietlenia tej strony\",\n    \"forbidden\": \"Dostƒôp zabroniony\",\n    \"serverError\": \"B≈ÇƒÖd serwera. Spr√≥buj ponownie p√≥≈∫niej.\",\n    \"networkError\": \"B≈ÇƒÖd sieci. Sprawd≈∫ po≈ÇƒÖczenie.\"\n  },\n  \"footer\": {\n    \"copyright\": \"Wszelkie prawa zastrze≈ºone\"\n  }\n}\n{%- else %}\n{}\n{%- endif %}\n","frontend/messages/en.json":"{%- if cookiecutter.enable_i18n %}\n{\n  \"common\": {\n    \"loading\": \"Loading...\",\n    \"error\": \"Error\",\n    \"success\": \"Success\",\n    \"save\": \"Save\",\n    \"cancel\": \"Cancel\",\n    \"delete\": \"Delete\",\n    \"edit\": \"Edit\",\n    \"create\": \"Create\",\n    \"search\": \"Search\",\n    \"back\": \"Back\",\n    \"next\": \"Next\",\n    \"previous\": \"Previous\",\n    \"submit\": \"Submit\",\n    \"close\": \"Close\",\n    \"confirm\": \"Confirm\",\n    \"yes\": \"Yes\",\n    \"no\": \"No\"\n  },\n  \"navigation\": {\n    \"home\": \"Home\",\n    \"dashboard\": \"Dashboard\",\n    \"profile\": \"Profile\",\n    \"settings\": \"Settings\",\n    \"logout\": \"Logout\"\n  },\n  \"auth\": {\n    \"login\": \"Login\",\n    \"register\": \"Register\",\n    \"email\": \"Email\",\n    \"password\": \"Password\",\n    \"confirmPassword\": \"Confirm Password\",\n    \"forgotPassword\": \"Forgot Password?\",\n    \"noAccount\": \"Don't have an account?\",\n    \"hasAccount\": \"Already have an account?\",\n    \"loginSuccess\": \"Successfully logged in\",\n    \"registerSuccess\": \"Account created successfully\",\n    \"logoutSuccess\": \"Successfully logged out\",\n    \"invalidCredentials\": \"Invalid email or password\",\n    \"emailRequired\": \"Email is required\",\n    \"passwordRequired\": \"Password is required\",\n    \"passwordMismatch\": \"Passwords do not match\",\n    \"continueWithGoogle\": \"Continue with Google\"\n  },\n  \"profile\": {\n    \"title\": \"Profile\",\n    \"personalInfo\": \"Personal Information\",\n    \"name\": \"Name\",\n    \"email\": \"Email\",\n    \"changePassword\": \"Change Password\",\n    \"currentPassword\": \"Current Password\",\n    \"newPassword\": \"New Password\",\n    \"updateProfile\": \"Update Profile\",\n    \"deleteAccount\": \"Delete Account\",\n    \"deleteAccountWarning\": \"This action cannot be undone. All your data will be permanently deleted.\"\n  },\n  \"chat\": {\n    \"title\": \"Chat\",\n    \"newChat\": \"New Chat\",\n    \"sendMessage\": \"Send a message...\",\n    \"thinking\": \"Thinking...\",\n    \"noConversations\": \"No conversations yet\",\n    \"startNewChat\": \"Start a new chat\",\n    \"deleteConversation\": \"Delete conversation\",\n    \"archiveConversation\": \"Archive conversation\",\n    \"renameConversation\": \"Rename conversation\"\n  },\n  \"errors\": {\n    \"generic\": \"Something went wrong\",\n    \"notFound\": \"Page not found\",\n    \"unauthorized\": \"You are not authorized to view this page\",\n    \"forbidden\": \"Access forbidden\",\n    \"serverError\": \"Server error. Please try again later.\",\n    \"networkError\": \"Network error. Please check your connection.\"\n  },\n  \"footer\": {\n    \"copyright\": \"All rights reserved\"\n  }\n}\n{%- else %}\n{}\n{%- endif %}\n","frontend/.env.local":"{%- if cookiecutter.generate_env -%}\n# {{ cookiecutter.project_name }} Frontend Environment Variables\n# Generated automatically - ready for local development\n\n# Backend API URL (server-side only - not exposed to browser)\nBACKEND_URL=http://localhost:{{ cookiecutter.backend_port }}\n\n# WebSocket URL for real-time features\nBACKEND_WS_URL=ws://localhost:{{ cookiecutter.backend_port }}\n{%- if cookiecutter.enable_oauth %}\n\n# Public API URL for OAuth redirects (exposed to browser)\nNEXT_PUBLIC_API_URL=http://localhost:{{ cookiecutter.backend_port }}\n{%- endif %}\n{%- if cookiecutter.enable_logfire %}\n\n# Logfire/OpenTelemetry (server-side instrumentation)\n# Get your write token from: https://logfire.pydantic.dev\n# OTEL_EXPORTER_OTLP_ENDPOINT=https://logfire-api.pydantic.dev\n# OTEL_EXPORTER_OTLP_HEADERS=Authorization=your-logfire-write-token\n{%- endif %}\n{% else -%}\n# .env.local file not generated - copy from .env.example\n# cp .env.example .env.local\n{%- endif %}\n","frontend/postcss.config.mjs":"const config = {\n  plugins: {\n    \"@tailwindcss/postcss\": {},\n  },\n};\n\nexport default config;\n","frontend/Dockerfile":"FROM oven/bun:1 AS base\n\n# Install dependencies only when needed\nFROM base AS deps\nWORKDIR /app\n\n# Copy package files\nCOPY package.json bun.lockb* ./\n\n# Install dependencies\nRUN bun install --frozen-lockfile\n\n# Rebuild the source code only when needed\nFROM base AS builder\nWORKDIR /app\n\nCOPY --from=deps /app/node_modules ./node_modules\nCOPY . .\n\n# Build the application\nENV NEXT_TELEMETRY_DISABLED=1\nRUN bun run build\n\n# Production image\nFROM base AS runner\nWORKDIR /app\n\nENV NODE_ENV=production\nENV NEXT_TELEMETRY_DISABLED=1\n\nRUN useradd --system --uid 1001 nextjs\n\nCOPY --from=builder /app/public ./public\nCOPY --from=builder --chown=nextjs:bun /app/.next/standalone ./\nCOPY --from=builder --chown=nextjs:bun /app/.next/static ./.next/static\n\nUSER nextjs\n\nEXPOSE {{ cookiecutter.frontend_port }}\n\nENV PORT={{ cookiecutter.frontend_port }}\nENV HOSTNAME=\"0.0.0.0\"\n\nCMD [\"bun\", \"server.js\"]\n","frontend/.prettierignore":"# Dependencies\nnode_modules/\n\n# Build output\n.next/\nout/\ndist/\n\n# Cache\n.cache/\n\n# Misc\n*.log\n.DS_Store\n\n# Lock files\npackage-lock.json\nyarn.lock\npnpm-lock.yaml\n","frontend/README.md":"# Full-Stack FastAPI + Next.js Template for AI/LLM Applications\n\n<p align=\"center\">\n  <a href=\"https://github.com/vstorm-co/full-stack-ai-agent-template/stargazers\"><img src=\"https://img.shields.io/github/stars/vstorm-co/full-stack-ai-agent-template?style=flat&logo=github&color=yellow\" alt=\"GitHub Stars\"></a>\n  <a href=\"https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/vstorm-co/full-stack-ai-agent-template?color=blue\" alt=\"License\"></a>\n  <a href=\"https://www.python.org/\"><img src=\"https://img.shields.io/badge/python-3.11%20%7C%203.12%20%7C%203.13-blue?logo=python&logoColor=white\" alt=\"Python\"></a>\n  <a href=\"https://pypi.org/project/fastapi-fullstack/\"><img src=\"https://img.shields.io/pypi/v/fastapi-fullstack?color=green&logo=pypi&logoColor=white\" alt=\"PyPI\"></a>\n  <img src=\"https://img.shields.io/badge/coverage-100%25-brightgreen\" alt=\"Coverage\">\n  <img src=\"https://img.shields.io/badge/integrations-20%2B-brightgreen\" alt=\"20+ Integrations\">\n</p>\n\n<p align=\"center\">\n  <b>Production-ready project generator for AI/LLM applications with 20+ enterprise integrations.</b><br>\n  <sub>Built with FastAPI, Next.js 15, PydanticAI/LangChain, and everything you need for professional business applications.</sub>\n</p>\n\n<p align=\"center\">\n  <a href=\"#-why-this-template\">Why This Template</a> ‚Ä¢\n  <a href=\"#-features\">Features</a> ‚Ä¢\n  <a href=\"#-demo\">Demo</a> ‚Ä¢\n  <a href=\"#-quick-start\">Quick Start</a> ‚Ä¢\n  <a href=\"#-architecture\">Architecture</a> ‚Ä¢\n  <a href=\"#-ai-agent\">AI Agent</a> ‚Ä¢\n  <a href=\"#-observability-with-logfire\">Logfire</a> ‚Ä¢\n  <a href=\"#-documentation\">Documentation</a>\n</p>\n\n## Related Projects\n\n> **Building advanced AI agents?** Check out [pydantic-deep](https://github.com/vstorm-co/pydantic-deepagents) - a deep agent framework built on pydantic-ai with planning, filesystem, and subagent capabilities.\n\n---\n\n## üéØ Why This Template\n\nBuilding AI/LLM applications requires more than just an API wrapper. You need:\n\n- **Type-safe AI agents** with tool/function calling\n- **Real-time streaming** responses via WebSocket\n- **Conversation persistence** and history management\n- **Production infrastructure** - auth, rate limiting, observability\n- **Enterprise integrations** - background tasks, webhooks, admin panels\n\nThis template gives you all of that out of the box, with **20+ configurable integrations** so you can focus on building your AI product, not boilerplate.\n\n### Perfect For\n\n- ü§ñ **AI Chatbots & Assistants** - PydanticAI or LangChain agents with streaming responses\n- üìä **ML Applications** - Background task processing with Celery/Taskiq\n- üè¢ **Enterprise SaaS** - Full auth, admin panel, webhooks, and more\n- üöÄ **Startups** - Ship fast with production-ready infrastructure\n\n---\n\n## ‚ú® Features\n\n### ü§ñ AI/LLM First\n\n- **[PydanticAI](https://ai.pydantic.dev)** or **[LangChain](https://python.langchain.com)** - Choose your preferred AI framework\n- **WebSocket Streaming** - Real-time responses with full event access\n- **Conversation Persistence** - Save chat history to database\n- **Custom Tools** - Easily extend agent capabilities\n- **Multi-model Support** - OpenAI, Anthropic, and more\n- **Observability** - Logfire for PydanticAI, LangSmith for LangChain\n\n### ‚ö° Backend (FastAPI)\n\n- **[FastAPI](https://fastapi.tiangolo.com)** + **[Pydantic v2](https://docs.pydantic.dev)** - High-performance async API\n- **Multiple Databases** - PostgreSQL (async), MongoDB (async), SQLite\n- **Authentication** - JWT + Refresh tokens, API Keys, OAuth2 (Google)\n- **Background Tasks** - Celery, Taskiq, or ARQ\n- **Django-style CLI** - Custom management commands with auto-discovery\n\n### üé® Frontend (Next.js 15)\n\n- **React 19** + **TypeScript** + **Tailwind CSS v4**\n- **AI Chat Interface** - WebSocket streaming, tool call visualization\n- **Authentication** - HTTP-only cookies, auto-refresh\n- **Dark Mode** + **i18n** (optional)\n\n### üîå 20+ Enterprise Integrations\n\n| Category | Integrations |\n|----------|-------------|\n| **AI Frameworks** | PydanticAI, LangChain |\n| **Caching & State** | Redis, fastapi-cache2 |\n| **Security** | Rate limiting, CORS, CSRF protection |\n| **Observability** | Logfire, LangSmith, Sentry, Prometheus |\n| **Admin** | SQLAdmin panel with auth |\n| **Events** | Webhooks, WebSockets |\n| **DevOps** | Docker, GitHub Actions, GitLab CI, Kubernetes |\n\n---\n\n## üé¨ Demo\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/app_start.gif\" alt=\"FastAPI Fullstack Generator Demo\">\n</p>\n\n---\n\n## üöÄ Quick Start\n\n### Installation\n\n```bash\n# pip\npip install fastapi-fullstack\n\n# uv (recommended)\nuv tool install fastapi-fullstack\n\n# pipx\npipx install fastapi-fullstack\n```\n\n### Create Your Project\n\n```bash\n# Interactive wizard (recommended)\nfastapi-fullstack new\n\n# Quick mode with options\nfastapi-fullstack create my_ai_app \\\n  --database postgresql \\\n  --auth jwt \\\n  --frontend nextjs\n\n# Use presets for common setups\nfastapi-fullstack create my_ai_app --preset production   # Full production setup\nfastapi-fullstack create my_ai_app --preset ai-agent     # AI agent with streaming\n\n# Minimal project (no extras)\nfastapi-fullstack create my_ai_app --minimal\n```\n\n### Start Development\n\n```bash\ncd my_ai_app\n\n# Backend\ncd backend\nuv sync\n# .env is pre-configured for development - just add your API keys\nalembic upgrade head\n\n# Create admin user\nuv run my_ai_app user create --email admin@example.com --password secret123 --superuser\n\n# Start server\nuv run uvicorn app.main:app --reload\n\n# Frontend (new terminal)\ncd frontend\nbun install\nbun dev\n```\n\n> **Note:** The admin user is required to access the SQLAdmin panel at `/admin`. Use the `--superuser` flag to grant full admin privileges.\n\n**Access:**\n- API: http://localhost:8000\n- Docs: http://localhost:8000/docs\n- Admin Panel: http://localhost:8000/admin\n- Frontend: http://localhost:3000\n\n---\n\n## üì∏ Screenshots\n\n### Chat Interface\n| Light Mode | Dark Mode |\n|:---:|:---:|\n| ![Chat Light](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/new_chat_light.png) | ![Chat Dark](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/new_chat_dark.png) |\n\n### Authentication\n| Register | Login |\n|:---:|:---:|\n| ![Register](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/new_register.png) | ![Login](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/new_login.png) |\n\n### Observability\n| Logfire (PydanticAI) | LangSmith (LangChain) |\n|:---:|:---:|\n| ![Logfire](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/logfire.png) | ![LangSmith](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/langsmith.png) |\n\n### Admin, Monitoring & API\n| Celery Flower | SQLAdmin Panel |\n|:---:|:---:|\n| ![Flower](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/flower.png) | ![Admin](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/admin.png) |\n\n| API Documentation |\n|:---:|\n| ![API Docs](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/docs_2.png) |\n\n---\n\n## üèóÔ∏è Architecture\n\n```mermaid\ngraph TB\n    subgraph Frontend[\"Frontend (Next.js 15)\"]\n        UI[React Components]\n        WS[WebSocket Client]\n        Store[Zustand Stores]\n    end\n\n    subgraph Backend[\"Backend (FastAPI)\"]\n        API[API Routes]\n        Services[Services Layer]\n        Repos[Repositories]\n        Agent[AI Agent]\n    end\n\n    subgraph Infrastructure\n        DB[(PostgreSQL/MongoDB)]\n        Redis[(Redis)]\n        Queue[Celery/Taskiq]\n    end\n\n    subgraph External\n        LLM[OpenAI/Anthropic]\n        Webhook[Webhook Endpoints]\n    end\n\n    UI --> API\n    WS <--> Agent\n    API --> Services\n    Services --> Repos\n    Services --> Agent\n    Repos --> DB\n    Agent --> LLM\n    Services --> Redis\n    Services --> Queue\n    Services --> Webhook\n```\n\n### Layered Architecture\n\nThe backend follows a clean **Repository + Service** pattern:\n\n```mermaid\ngraph LR\n    A[API Routes] --> B[Services]\n    B --> C[Repositories]\n    C --> D[(Database)]\n\n    B --> E[External APIs]\n    B --> F[AI Agents]\n```\n\n| Layer | Responsibility |\n|-------|---------------|\n| **Routes** | HTTP handling, validation, auth |\n| **Services** | Business logic, orchestration |\n| **Repositories** | Data access, queries |\n\nSee [Architecture Documentation](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/architecture.md) for details.\n\n---\n\n## ü§ñ AI Agent\n\nChoose between **PydanticAI** or **LangChain** when generating your project, with support for multiple LLM providers:\n\n```bash\n# PydanticAI with OpenAI (default)\nfastapi-fullstack create my_app --ai-agent --ai-framework pydantic_ai\n\n# PydanticAI with Anthropic\nfastapi-fullstack create my_app --ai-agent --ai-framework pydantic_ai --llm-provider anthropic\n\n# PydanticAI with OpenRouter\nfastapi-fullstack create my_app --ai-agent --ai-framework pydantic_ai --llm-provider openrouter\n\n# LangChain with OpenAI\nfastapi-fullstack create my_app --ai-agent --ai-framework langchain\n\n# LangChain with Anthropic\nfastapi-fullstack create my_app --ai-agent --ai-framework langchain --llm-provider anthropic\n```\n\n### Supported LLM Providers\n\n| Framework | OpenAI | Anthropic | OpenRouter |\n|-----------|:------:|:---------:|:----------:|\n| **PydanticAI** | ‚úì | ‚úì | ‚úì |\n| **LangChain** | ‚úì | ‚úì | - |\n\n### PydanticAI Integration\n\nType-safe agents with full dependency injection:\n\n```python\n# app/agents/assistant.py\nfrom pydantic_ai import Agent, RunContext\n\n@dataclass\nclass Deps:\n    user_id: str | None = None\n    db: AsyncSession | None = None\n\nagent = Agent[Deps, str](\n    model=\"openai:gpt-4o-mini\",\n    system_prompt=\"You are a helpful assistant.\",\n)\n\n@agent.tool\nasync def search_database(ctx: RunContext[Deps], query: str) -> list[dict]:\n    \"\"\"Search the database for relevant information.\"\"\"\n    # Access user context and database via ctx.deps\n    ...\n```\n\n### LangChain Integration\n\nFlexible agents with LangGraph:\n\n```python\n# app/agents/langchain_assistant.py\nfrom langchain.tools import tool\nfrom langgraph.prebuilt import create_react_agent\n\n@tool\ndef search_database(query: str) -> list[dict]:\n    \"\"\"Search the database for relevant information.\"\"\"\n    ...\n\nagent = create_react_agent(\n    model=ChatOpenAI(model=\"gpt-4o-mini\"),\n    tools=[search_database],\n    prompt=\"You are a helpful assistant.\",\n)\n```\n\n### WebSocket Streaming\n\nBoth frameworks use the same WebSocket endpoint with real-time streaming:\n\n```python\n@router.websocket(\"/ws\")\nasync def agent_ws(websocket: WebSocket):\n    await websocket.accept()\n\n    # Works with both PydanticAI and LangChain\n    async for event in agent.stream(user_input):\n        await websocket.send_json({\n            \"type\": \"text_delta\",\n            \"content\": event.content\n        })\n```\n\n### Observability\n\nEach framework has its own observability solution:\n\n| Framework | Observability | Dashboard |\n|-----------|--------------|-----------|\n| **PydanticAI** | [Logfire](https://logfire.pydantic.dev) | Agent runs, tool calls, token usage |\n| **LangChain** | [LangSmith](https://smith.langchain.com) | Traces, feedback, datasets |\n\nSee [AI Agent Documentation](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/ai-agent.md) for more.\n\n---\n\n## üìä Observability\n\n### Logfire (for PydanticAI)\n\n[Logfire](https://logfire.pydantic.dev) provides complete observability for your application - from AI agents to database queries. Built by the Pydantic team, it offers first-class support for the entire Python ecosystem.\n\n```mermaid\ngraph LR\n    subgraph Your App\n        API[FastAPI]\n        Agent[PydanticAI]\n        DB[(Database)]\n        Cache[(Redis)]\n        Queue[Celery/Taskiq]\n        HTTP[HTTPX]\n    end\n\n    subgraph Logfire\n        Traces[Traces]\n        Metrics[Metrics]\n        Logs[Logs]\n    end\n\n    API --> Traces\n    Agent --> Traces\n    DB --> Traces\n    Cache --> Traces\n    Queue --> Traces\n    HTTP --> Traces\n```\n\n| Component | What You See |\n|-----------|-------------|\n| **PydanticAI** | Agent runs, tool calls, LLM requests, token usage, streaming events |\n| **FastAPI** | Request/response traces, latency, status codes, route performance |\n| **PostgreSQL/MongoDB** | Query execution time, slow queries, connection pool stats |\n| **Redis** | Cache hits/misses, command latency, key patterns |\n| **Celery/Taskiq** | Task execution, queue depth, worker performance |\n| **HTTPX** | External API calls, response times, error rates |\n\n### LangSmith (for LangChain)\n\n[LangSmith](https://smith.langchain.com) provides observability specifically designed for LangChain applications:\n\n| Feature | Description |\n|---------|-------------|\n| **Traces** | Full execution traces for agent runs and chains |\n| **Feedback** | Collect user feedback on agent responses |\n| **Datasets** | Build evaluation datasets from production data |\n| **Monitoring** | Track latency, errors, and token usage |\n\nLangSmith is automatically configured when you choose LangChain:\n\n```bash\n# .env\nLANGCHAIN_TRACING_V2=true\nLANGCHAIN_API_KEY=your-api-key\nLANGCHAIN_PROJECT=my_project\n```\n\n### Configuration\n\nEnable Logfire and select which components to instrument:\n\n```bash\nfastapi-fullstack new\n# ‚úì Enable Logfire observability\n#   ‚úì Instrument FastAPI\n#   ‚úì Instrument Database\n#   ‚úì Instrument Redis\n#   ‚úì Instrument Celery\n#   ‚úì Instrument HTTPX\n```\n\n### Usage\n\n```python\n# Automatic instrumentation in app/main.py\nimport logfire\n\nlogfire.configure()\nlogfire.instrument_fastapi(app)\nlogfire.instrument_asyncpg()\nlogfire.instrument_redis()\nlogfire.instrument_httpx()\n```\n\n```python\n# Manual spans for custom logic\nwith logfire.span(\"process_order\", order_id=order.id):\n    await validate_order(order)\n    await charge_payment(order)\n    await send_confirmation(order)\n```\n\nFor more details, see [Logfire Documentation](https://logfire.pydantic.dev/docs/integrations/).\n\n---\n\n## üõ†Ô∏è Django-style CLI\n\nEach generated project includes a powerful CLI inspired by Django's management commands:\n\n### Built-in Commands\n\n```bash\n# Server\nmy_app server run --reload\nmy_app server routes\n\n# Database (Alembic wrapper)\nmy_app db init\nmy_app db migrate -m \"Add users\"\nmy_app db upgrade\n\n# Users\nmy_app user create --email admin@example.com --superuser\nmy_app user list\n```\n\n### Custom Commands\n\nCreate your own commands with auto-discovery:\n\n```python\n# app/commands/seed.py\nfrom app.commands import command, success, error\nimport click\n\n@command(\"seed\", help=\"Seed database with test data\")\n@click.option(\"--count\", \"-c\", default=10, type=int)\n@click.option(\"--dry-run\", is_flag=True)\ndef seed_database(count: int, dry_run: bool):\n    \"\"\"Seed the database with sample data.\"\"\"\n    if dry_run:\n        info(f\"[DRY RUN] Would create {count} records\")\n        return\n\n    # Your logic here\n    success(f\"Created {count} records!\")\n```\n\nCommands are **automatically discovered** from `app/commands/` - just create a file and use the `@command` decorator.\n\n```bash\nmy_app cmd seed --count 100\nmy_app cmd seed --dry-run\n```\n\n---\n\n## üìÅ Generated Project Structure\n\n```\nmy_project/\n‚îú‚îÄ‚îÄ backend/\n‚îÇ   ‚îú‚îÄ‚îÄ app/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI app with lifespan\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/v1/       # Versioned API endpoints\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deps.py          # Dependency injection\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ router.py        # Route aggregation\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/                # Config, security, middleware\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db/models/           # SQLAlchemy/MongoDB models\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/             # Pydantic schemas\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repositories/        # Data access layer\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/            # Business logic\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agents/              # AI agents with centralized prompts\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commands/            # Django-style CLI commands\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ worker/              # Background tasks\n‚îÇ   ‚îú‚îÄ‚îÄ cli/                     # Project CLI\n‚îÇ   ‚îú‚îÄ‚îÄ tests/                   # pytest test suite\n‚îÇ   ‚îî‚îÄ‚îÄ alembic/                 # Database migrations\n‚îú‚îÄ‚îÄ frontend/\n‚îÇ   ‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/                 # Next.js App Router\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/          # React components\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/               # useChat, useWebSocket, etc.\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stores/              # Zustand state management\n‚îÇ   ‚îî‚îÄ‚îÄ e2e/                     # Playwright tests\n‚îú‚îÄ‚îÄ docker-compose.yml\n‚îú‚îÄ‚îÄ Makefile\n‚îî‚îÄ‚îÄ README.md\n```\n\nGenerated projects include version metadata in `pyproject.toml` for tracking:\n\n```toml\n[tool.fastapi-fullstack]\ngenerator_version = \"0.1.5\"\ngenerated_at = \"2024-12-21T10:30:00+00:00\"\n```\n\n---\n\n## ‚öôÔ∏è Configuration Options\n\n### Core Options\n\n| Option | Values | Description |\n|--------|--------|-------------|\n| **Database** | `postgresql`, `mongodb`, `sqlite`, `none` | Async by default |\n| **Auth** | `jwt`, `api_key`, `both`, `none` | JWT includes user management |\n| **OAuth** | `none`, `google` | Social login |\n| **AI Framework** | `pydantic_ai`, `langchain` | Choose your AI agent framework |\n| **LLM Provider** | `openai`, `anthropic`, `openrouter` | OpenRouter only with PydanticAI |\n| **Background Tasks** | `none`, `celery`, `taskiq`, `arq` | Distributed queues |\n| **Frontend** | `none`, `nextjs` | Next.js 15 + React 19 |\n\n### Presets\n\n| Preset | Description |\n|--------|-------------|\n| `--preset production` | Full production setup with Redis, Sentry, Kubernetes, Prometheus |\n| `--preset ai-agent` | AI agent with WebSocket streaming and conversation persistence |\n| `--minimal` | Minimal project with no extras |\n\n### Integrations\n\nSelect what you need:\n\n```bash\nfastapi-fullstack new\n# ‚úì Redis (caching/sessions)\n# ‚úì Rate limiting (slowapi)\n# ‚úì Pagination (fastapi-pagination)\n# ‚úì Admin Panel (SQLAdmin)\n# ‚úì AI Agent (PydanticAI or LangChain)\n# ‚úì Webhooks\n# ‚úì Sentry\n# ‚úì Logfire / LangSmith\n# ‚úì Prometheus\n# ... and more\n```\n\n---\n\n## üìö Documentation\n\n| Document | Description |\n|----------|-------------|\n| [Architecture](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/architecture.md) | Repository + Service pattern, layered design |\n| [Frontend](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/frontend.md) | Next.js setup, auth, state management |\n| [AI Agent](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/ai-agent.md) | PydanticAI, tools, WebSocket streaming |\n| [Observability](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/observability.md) | Logfire integration, tracing, metrics |\n| [Deployment](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/deployment.md) | Docker, Kubernetes, production setup |\n| [Development](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/development.md) | Local setup, testing, debugging |\n\n---\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=vstorm-co/full-stack-ai-agent-template&type=date&legend=top-left)](https://www.star-history.com/#vstorm-co/full-stack-ai-agent-template&type=date&legend=top-left)\n\n---\n\n## üôè Inspiration\n\nThis project is inspired by:\n\n- [full-stack-fastapi-template](https://github.com/fastapi/full-stack-fastapi-template) by @tiangolo\n- [fastapi-template](https://github.com/s3rius/fastapi-template) by @s3rius\n- [FastAPI Best Practices](https://github.com/zhanymkanov/fastapi-best-practices) by @zhanymkanov\n- Django's management commands system\n\n---\n\n## ü§ù Contributing\n\nContributions are welcome! Please read our [Contributing Guide](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/CONTRIBUTING.md) for details.\n\n---\n\n## üìÑ License\n\nMIT License - see [LICENSE](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/LICENSE) for details.\n\n---\n\n<p align=\"center\">\n  Made with ‚ù§Ô∏è by <a href=\"https://github.com/vstorm-co\">VStorm</a>\n</p>\n","frontend/.dockerignore":"# Dependencies\nnode_modules\n.pnp\n.pnp.js\n\n# Build outputs\n.next\nout\nbuild\ndist\n\n# Testing\ncoverage\n.nyc_output\n\n# Debug\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\n\n# Local env files\n.env\n.env.local\n.env.development.local\n.env.test.local\n.env.production.local\n\n# IDE\n.idea\n.vscode\n*.swp\n*.swo\n\n# OS\n.DS_Store\nThumbs.db\n\n# Misc\n*.log\n.turbo\n","frontend/.gitignore":"# Dependencies\nnode_modules\n.pnp\n.pnp.js\n\n# Testing\ncoverage\n\n# Playwright\n/test-results/\n/playwright-report/\n/blob-report/\n/playwright/.cache/\n.playwright/\n\n# Next.js\n.next/\nout/\nbuild\n\n# Misc\n.DS_Store\n*.pem\n\n# Debug\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\n\n# Local env files\n.env\n.env.local\n.env.development.local\n.env.test.local\n.env.production.local\n\n# Vercel\n.vercel\n\n# TypeScript\n*.tsbuildinfo\nnext-env.d.ts\n\n# Bun\nbun.lockb\n","frontend/package.json":"{\n  \"name\": \"{{ cookiecutter.project_slug }}-frontend\",\n  \"version\": \"0.1.0\",\n  \"private\": true,\n  \"scripts\": {\n    \"dev\": \"next dev -p {{ cookiecutter.frontend_port }}\",\n    \"build\": \"next build\",\n    \"start\": \"next start -p {{ cookiecutter.frontend_port }}\",\n    \"lint\": \"next lint\",\n    \"lint:fix\": \"next lint --fix\",\n    \"format\": \"prettier --write .\",\n    \"format:check\": \"prettier --check .\",\n    \"type-check\": \"tsc --noEmit\",\n    \"test:e2e\": \"playwright test\",\n    \"test:e2e:ui\": \"playwright test --ui\",\n    \"test:e2e:headed\": \"playwright test --headed\",\n    \"test:e2e:debug\": \"playwright test --debug\",\n    \"test:e2e:report\": \"playwright show-report\",\n    \"test\": \"vitest\",\n    \"test:run\": \"vitest run\",\n    \"test:coverage\": \"vitest run --coverage\",\n    \"test:ui\": \"vitest --ui\"\n  },\n  \"dependencies\": {\n    \"next\": \"^15.1.0\",\n    \"react\": \"^19.0.0\",\n    \"react-dom\": \"^19.0.0\",\n    \"@tanstack/react-query\": \"^5.62.0\",\n    \"zustand\": \"^5.0.2\",\n    \"nanoid\": \"^5.0.9\",\n    \"lucide-react\": \"^0.468.0\",\n    \"clsx\": \"^2.1.1\",\n    \"tailwind-merge\": \"^2.6.0\",\n{%- if cookiecutter.enable_logfire %}\n    \"@vercel/otel\": \"^1.10.0\",\n    \"@opentelemetry/api\": \"^1.9.0\",\n{%- endif %}\n{%- if cookiecutter.enable_i18n %}\n    \"next-intl\": \"^3.25.3\",\n{%- endif %}\n    \"class-variance-authority\": \"^0.7.1\",\n    \"react-markdown\": \"^9.0.1\",\n    \"remark-gfm\": \"^4.0.0\",\n    \"rehype-highlight\": \"^7.0.0\"\n  },\n  \"devDependencies\": {\n    \"typescript\": \"^5.7.2\",\n    \"@types/node\": \"^22.10.2\",\n    \"@types/react\": \"^19.0.1\",\n    \"@types/react-dom\": \"^19.0.2\",\n    \"tailwindcss\": \"^4.0.0-beta.8\",\n    \"@tailwindcss/postcss\": \"^4.0.0-beta.8\",\n    \"postcss\": \"^8.4.49\",\n    \"eslint\": \"^9.17.0\",\n    \"eslint-config-next\": \"^15.1.0\",\n    \"eslint-config-prettier\": \"^9.1.0\",\n    \"prettier\": \"^3.4.2\",\n    \"prettier-plugin-tailwindcss\": \"^0.6.9\",\n    \"@playwright/test\": \"^1.49.1\",\n    \"vitest\": \"^2.1.8\",\n    \"@vitejs/plugin-react\": \"^4.3.4\",\n    \"@testing-library/react\": \"^16.1.0\",\n    \"@testing-library/jest-dom\": \"^6.6.3\",\n    \"@testing-library/user-event\": \"^14.5.2\",\n    \"jsdom\": \"^25.0.1\",\n    \"@vitest/coverage-v8\": \"^2.1.8\",\n    \"@vitest/ui\": \"^2.1.8\"\n  }\n}\n","frontend/.prettierrc":"{\n  \"semi\": true,\n  \"singleQuote\": false,\n  \"tabWidth\": 2,\n  \"trailingComma\": \"es5\",\n  \"printWidth\": 100,\n  \"bracketSpacing\": true,\n  \"arrowParens\": \"always\",\n  \"endOfLine\": \"lf\",\n  \"plugins\": [\"prettier-plugin-tailwindcss\"]\n}\n","frontend/tsconfig.json":"{\n  \"compilerOptions\": {\n    \"target\": \"ES2017\",\n    \"lib\": [\"dom\", \"dom.iterable\", \"esnext\"],\n    \"allowJs\": true,\n    \"skipLibCheck\": true,\n    \"strict\": true,\n    \"noEmit\": true,\n    \"esModuleInterop\": true,\n    \"module\": \"esnext\",\n    \"moduleResolution\": \"bundler\",\n    \"resolveJsonModule\": true,\n    \"isolatedModules\": true,\n    \"jsx\": \"preserve\",\n    \"incremental\": true,\n    \"plugins\": [\n      {\n        \"name\": \"next\"\n      }\n    ],\n    \"baseUrl\": \".\",\n    \"paths\": {\n      \"@/*\": [\"./src/*\"]\n    }\n  },\n  \"include\": [\"next-env.d.ts\", \"**/*.ts\", \"**/*.tsx\", \".next/types/**/*.ts\"],\n  \"exclude\": [\"node_modules\"]\n}\n","frontend/playwright.config.ts":"{%- if cookiecutter.use_frontend %}\nimport { defineConfig, devices } from \"@playwright/test\";\n\n/**\n * Playwright E2E test configuration.\n *\n * See https://playwright.dev/docs/test-configuration.\n */\nexport default defineConfig({\n  testDir: \"./e2e\",\n  /* Run tests in files in parallel */\n  fullyParallel: true,\n  /* Fail the build on CI if you accidentally left test.only in the source code. */\n  forbidOnly: !!process.env.CI,\n  /* Retry on CI only */\n  retries: process.env.CI ? 2 : 0,\n  /* Opt out of parallel tests on CI. */\n  workers: process.env.CI ? 1 : undefined,\n  /* Reporter to use. See https://playwright.dev/docs/test-reporters */\n  reporter: [\n    [\"list\"],\n    [\"html\", { outputFolder: \"playwright-report\" }],\n  ],\n  /* Shared settings for all the projects below. See https://playwright.dev/docs/api/class-testoptions. */\n  use: {\n    /* Base URL to use in actions like `await page.goto('/')`. */\n    baseURL: process.env.PLAYWRIGHT_BASE_URL || \"http://localhost:{{ cookiecutter.frontend_port }}\",\n\n    /* Collect trace when retrying the failed test. See https://playwright.dev/docs/trace-viewer */\n    trace: \"on-first-retry\",\n\n    /* Capture screenshot on failure */\n    screenshot: \"only-on-failure\",\n\n    /* Video recording on failure */\n    video: \"on-first-retry\",\n  },\n\n  /* Configure projects for major browsers */\n  projects: [\n    /* Authentication setup - runs first */\n    {\n      name: \"setup\",\n      testMatch: /.*\\.setup\\.ts/,\n    },\n\n    {\n      name: \"chromium\",\n      use: {\n        ...devices[\"Desktop Chrome\"],\n      },\n      dependencies: [\"setup\"],\n    },\n\n    {\n      name: \"firefox\",\n      use: {\n        ...devices[\"Desktop Firefox\"],\n      },\n      dependencies: [\"setup\"],\n    },\n\n    {\n      name: \"webkit\",\n      use: {\n        ...devices[\"Desktop Safari\"],\n      },\n      dependencies: [\"setup\"],\n    },\n\n    /* Test against mobile viewports. */\n    {\n      name: \"Mobile Chrome\",\n      use: {\n        ...devices[\"Pixel 5\"],\n      },\n      dependencies: [\"setup\"],\n    },\n    {\n      name: \"Mobile Safari\",\n      use: {\n        ...devices[\"iPhone 12\"],\n      },\n      dependencies: [\"setup\"],\n    },\n  ],\n\n  /* Run your local dev server before starting the tests */\n  webServer: process.env.CI\n    ? undefined\n    : {\n        command: \"bun run dev\",\n        url: \"http://localhost:{{ cookiecutter.frontend_port }}\",\n        reuseExistingServer: !process.env.CI,\n        timeout: 120 * 1000,\n      },\n});\n{%- else %}\n/* Playwright config - frontend not configured */\nexport {};\n{%- endif %}\n","frontend/.env.example":"# Backend API URL (server-side only - not exposed to browser)\nBACKEND_URL=http://localhost:{{ cookiecutter.backend_port }}\n\n# WebSocket URL for real-time features\nBACKEND_WS_URL=ws://localhost:{{ cookiecutter.backend_port }}\n{%- if cookiecutter.enable_oauth %}\n\n# Public API URL for OAuth redirects (exposed to browser)\nNEXT_PUBLIC_API_URL=http://localhost:{{ cookiecutter.backend_port }}\n{%- endif %}\n{%- if cookiecutter.enable_logfire %}\n\n# Logfire/OpenTelemetry (server-side instrumentation)\n# Get your write token from: https://logfire.pydantic.dev\nOTEL_EXPORTER_OTLP_ENDPOINT=https://logfire-api.pydantic.dev\nOTEL_EXPORTER_OTLP_HEADERS=Authorization=your-logfire-write-token\n{%- endif %}\n","frontend/vitest.config.ts":"{%- if cookiecutter.use_frontend %}\nimport { defineConfig } from \"vitest/config\";\nimport react from \"@vitejs/plugin-react\";\nimport path from \"path\";\n\nexport default defineConfig({\n  plugins: [react()],\n  test: {\n    environment: \"jsdom\",\n    globals: true,\n    setupFiles: [\"./vitest.setup.ts\"],\n    include: [\"**/*.{test,spec}.{ts,tsx}\"],\n    exclude: [\"node_modules\", \".next\", \"e2e\"],\n    coverage: {\n      provider: \"v8\",\n      reporter: [\"text\", \"json\", \"html\"],\n      exclude: [\n        \"node_modules\",\n        \".next\",\n        \"e2e\",\n        \"**/*.d.ts\",\n        \"**/*.config.*\",\n        \"vitest.setup.ts\",\n      ],\n    },\n  },\n  resolve: {\n    alias: {\n      \"@\": path.resolve(__dirname, \"./src\"),\n    },\n  },\n});\n{%- else %}\n/* Vitest config - frontend not configured */\nexport {};\n{%- endif %}\n","frontend/e2e/auth.spec.ts":"{%- if cookiecutter.use_frontend and cookiecutter.use_jwt %}\nimport { test, expect } from \"@playwright/test\";\n\ntest.describe(\"Authentication\", () => {\n  test.describe(\"Login Page\", () => {\n    test(\"should display login form\", async ({ page }) => {\n      await page.goto(\"/login\");\n\n      // Check for login form elements\n      await expect(page.getByRole(\"heading\", { name: /sign in|log in/i })).toBeVisible();\n      await expect(page.getByLabel(/email/i)).toBeVisible();\n      await expect(page.getByLabel(/password/i)).toBeVisible();\n      await expect(page.getByRole(\"button\", { name: /sign in|log in/i })).toBeVisible();\n    });\n\n    test(\"should show validation errors for empty form\", async ({ page }) => {\n      await page.goto(\"/login\");\n\n      // Submit empty form\n      await page.getByRole(\"button\", { name: /sign in|log in/i }).click();\n\n      // Should show validation errors\n      await expect(page.getByText(/required|invalid/i)).toBeVisible();\n    });\n\n    test(\"should show error for invalid credentials\", async ({ page }) => {\n      await page.goto(\"/login\");\n\n      // Fill in invalid credentials\n      await page.getByLabel(/email/i).fill(\"invalid@example.com\");\n      await page.getByLabel(/password/i).fill(\"wrongpassword\");\n      await page.getByRole(\"button\", { name: /sign in|log in/i }).click();\n\n      // Should show error message\n      await expect(\n        page.getByText(/invalid|incorrect|failed|error/i)\n      ).toBeVisible({ timeout: 5000 });\n    });\n\n    test(\"should have link to registration\", async ({ page }) => {\n      await page.goto(\"/login\");\n\n      // Should have link to register page\n      const registerLink = page.getByRole(\"link\", { name: /sign up|register|create account/i });\n      await expect(registerLink).toBeVisible();\n    });\n  });\n\n  test.describe(\"Registration Page\", () => {\n    test(\"should display registration form\", async ({ page }) => {\n      await page.goto(\"/register\");\n\n      // Check for registration form elements\n      await expect(page.getByRole(\"heading\", { name: /sign up|register|create/i })).toBeVisible();\n      await expect(page.getByLabel(/email/i)).toBeVisible();\n      await expect(page.getByLabel(/password/i).first()).toBeVisible();\n      await expect(page.getByRole(\"button\", { name: /sign up|register|create/i })).toBeVisible();\n    });\n\n    test(\"should validate password requirements\", async ({ page }) => {\n      await page.goto(\"/register\");\n\n      // Fill in weak password\n      await page.getByLabel(/email/i).fill(\"newuser@example.com\");\n      await page.getByLabel(/password/i).first().fill(\"weak\");\n\n      // Should show password requirements error\n      await page.getByRole(\"button\", { name: /sign up|register|create/i }).click();\n      await expect(page.getByText(/password|characters|strong/i)).toBeVisible();\n    });\n\n    test(\"should have link to login\", async ({ page }) => {\n      await page.goto(\"/register\");\n\n      // Should have link to login page\n      const loginLink = page.getByRole(\"link\", { name: /sign in|log in|already have/i });\n      await expect(loginLink).toBeVisible();\n    });\n  });\n\n  test.describe(\"Authenticated User\", () => {\n    // Use authenticated state from setup\n    test.use({\n      storageState: \".playwright/.auth/user.json\",\n    });\n\n    test(\"should redirect to dashboard after login\", async ({ page }) => {\n      await page.goto(\"/\");\n\n      // Should be redirected to dashboard or see dashboard content\n      await expect(page).toHaveURL(/dashboard|home/i);\n    });\n\n    test(\"should show user menu or profile\", async ({ page }) => {\n      await page.goto(\"/dashboard\");\n\n      // Should have user profile/menu element\n      await expect(\n        page.getByRole(\"button\", { name: /profile|account|user/i }).or(\n          page.getByText(/@|user/i)\n        )\n      ).toBeVisible();\n    });\n\n    test(\"should be able to logout\", async ({ page }) => {\n      await page.goto(\"/dashboard\");\n\n      // Find and click logout button\n      const logoutButton = page.getByRole(\"button\", { name: /log out|sign out/i }).or(\n        page.getByRole(\"link\", { name: /log out|sign out/i })\n      );\n\n      if (await logoutButton.isVisible()) {\n        await logoutButton.click();\n\n        // Should be redirected to login or home\n        await expect(page).toHaveURL(/login|\\/$/);\n      }\n    });\n  });\n});\n{%- elif cookiecutter.use_frontend %}\nimport { test, expect } from \"@playwright/test\";\n\ntest.describe(\"Public Access\", () => {\n  test(\"should allow public access to main page\", async ({ page }) => {\n    await page.goto(\"/\");\n    await expect(page.getByRole(\"main\")).toBeVisible();\n  });\n});\n{%- else %}\n/* Auth tests - frontend not configured */\nexport {};\n{%- endif %}\n","frontend/e2e/auth.setup.ts":"{%- if cookiecutter.use_frontend and cookiecutter.use_jwt %}\nimport { test as setup, expect } from \"@playwright/test\";\nimport path from \"path\";\n\nconst authFile = path.join(__dirname, \"../.playwright/.auth/user.json\");\n\n/**\n * Authentication setup - runs before all tests.\n *\n * This creates an authenticated session that other tests can reuse.\n */\nsetup(\"authenticate\", async ({ page }) => {\n  // Test credentials - adjust for your environment\n  const testEmail = process.env.TEST_USER_EMAIL || \"test@example.com\";\n  const testPassword = process.env.TEST_USER_PASSWORD || \"TestPassword123!\";\n\n  // Navigate to login page\n  await page.goto(\"/login\");\n\n  // Fill in login form\n  await page.getByLabel(/email/i).fill(testEmail);\n  await page.getByLabel(/password/i).fill(testPassword);\n\n  // Submit and wait for redirect\n  await page.getByRole(\"button\", { name: /sign in|log in|login/i }).click();\n\n  // Wait for authentication to complete - adjust selector based on your app\n  await expect(\n    page.getByRole(\"link\", { name: /dashboard|home/i }).or(\n      page.getByText(/welcome/i)\n    )\n  ).toBeVisible({ timeout: 10000 });\n\n  // Save authentication state\n  await page.context().storageState({ path: authFile });\n});\n{%- elif cookiecutter.use_frontend %}\nimport { test as setup } from \"@playwright/test\";\n\n/**\n * Setup - no authentication required.\n */\nsetup(\"setup\", async () => {\n  // No authentication needed\n});\n{%- else %}\n/* Auth setup - frontend not configured */\nexport {};\n{%- endif %}\n","frontend/e2e/home.spec.ts":"{%- if cookiecutter.use_frontend %}\nimport { test, expect } from \"@playwright/test\";\n\ntest.describe(\"Home Page\", () => {\n  test(\"should load the home page\", async ({ page }) => {\n    await page.goto(\"/\");\n    await expect(page).toHaveTitle(/{{ cookiecutter.project_name }}/i);\n  });\n\n  test(\"should have navigation elements\", async ({ page }) => {\n    await page.goto(\"/\");\n\n    // Check for main navigation elements\n    const nav = page.getByRole(\"navigation\");\n    await expect(nav).toBeVisible();\n  });\n\n  test(\"should be accessible\", async ({ page }) => {\n    await page.goto(\"/\");\n\n    // Basic accessibility checks\n    // Main landmark should exist\n    await expect(page.getByRole(\"main\")).toBeVisible();\n\n    // Page should have a heading\n    const heading = page.getByRole(\"heading\", { level: 1 });\n    await expect(heading).toBeVisible();\n  });\n});\n\ntest.describe(\"Navigation\", () => {\n{%- if cookiecutter.use_jwt %}\n  test(\"unauthenticated user should see login link\", async ({ page }) => {\n    // Clear any stored auth state\n    await page.context().clearCookies();\n    await page.goto(\"/\");\n\n    // Should have login/sign in link\n    const loginLink = page.getByRole(\"link\", { name: /log in|sign in/i });\n    await expect(loginLink).toBeVisible();\n  });\n{%- endif %}\n\n  test(\"should navigate between pages\", async ({ page }) => {\n    await page.goto(\"/\");\n\n    // Test navigation to different sections\n    const links = await page.getByRole(\"link\").all();\n    expect(links.length).toBeGreaterThan(0);\n  });\n});\n\ntest.describe(\"Responsive Design\", () => {\n  test(\"should work on mobile viewport\", async ({ page }) => {\n    await page.setViewportSize({ width: 375, height: 667 });\n    await page.goto(\"/\");\n\n    // Page should still be functional\n    await expect(page.getByRole(\"main\")).toBeVisible();\n  });\n\n  test(\"should work on tablet viewport\", async ({ page }) => {\n    await page.setViewportSize({ width: 768, height: 1024 });\n    await page.goto(\"/\");\n\n    // Page should still be functional\n    await expect(page.getByRole(\"main\")).toBeVisible();\n  });\n});\n{%- else %}\n/* Home tests - frontend not configured */\nexport {};\n{%- endif %}\n","frontend/e2e/chat.spec.ts":"{%- if cookiecutter.use_frontend and cookiecutter.enable_ai_agent %}\nimport { test, expect } from \"@playwright/test\";\n\ntest.describe(\"AI Chat\", () => {\n{%- if cookiecutter.use_jwt %}\n  // Use authenticated state\n  test.use({\n    storageState: \".playwright/.auth/user.json\",\n  });\n{%- endif %}\n\n  test.beforeEach(async ({ page }) => {\n    await page.goto(\"/chat\");\n  });\n\n  test.describe(\"Chat Interface\", () => {\n    test(\"should display chat container\", async ({ page }) => {\n      // Chat container should be visible\n      await expect(page.getByRole(\"main\")).toBeVisible();\n\n      // Input should be present\n      const input = page.getByRole(\"textbox\", { name: /message|type|ask/i }).or(\n        page.getByPlaceholder(/message|type|ask/i)\n      );\n      await expect(input).toBeVisible();\n    });\n\n    test(\"should have send button\", async ({ page }) => {\n      const sendButton = page.getByRole(\"button\", { name: /send|submit/i }).or(\n        page.locator('button[type=\"submit\"]')\n      );\n      await expect(sendButton).toBeVisible();\n    });\n\n    test(\"should allow typing a message\", async ({ page }) => {\n      const input = page.getByRole(\"textbox\").first();\n      await input.fill(\"Hello, AI assistant!\");\n      await expect(input).toHaveValue(\"Hello, AI assistant!\");\n    });\n  });\n\n  test.describe(\"Chat Functionality\", () => {\n    test(\"should send message and receive response\", async ({ page }) => {\n      const input = page.getByRole(\"textbox\").first();\n      const sendButton = page.getByRole(\"button\", { name: /send|submit/i }).or(\n        page.locator('button[type=\"submit\"]')\n      );\n\n      // Send a message\n      await input.fill(\"Hello!\");\n      await sendButton.click();\n\n      // User message should appear in chat\n      await expect(page.getByText(\"Hello!\")).toBeVisible();\n\n      // Wait for AI response (with reasonable timeout)\n      await expect(\n        page.locator(\"[data-role='assistant']\").or(\n          page.getByText(/thinking|processing/i)\n        )\n      ).toBeVisible({ timeout: 30000 });\n    });\n\n    test(\"should show loading state while waiting for response\", async ({ page }) => {\n      const input = page.getByRole(\"textbox\").first();\n      const sendButton = page.getByRole(\"button\", { name: /send|submit/i }).or(\n        page.locator('button[type=\"submit\"]')\n      );\n\n      // Send a message\n      await input.fill(\"What is 2 + 2?\");\n      await sendButton.click();\n\n      // Should show some loading indicator\n      await expect(\n        page.getByText(/thinking|loading|processing/i).or(\n          page.locator(\".animate-pulse, .animate-spin\")\n        )\n      ).toBeVisible();\n    });\n\n    test(\"should clear input after sending\", async ({ page }) => {\n      const input = page.getByRole(\"textbox\").first();\n      const sendButton = page.getByRole(\"button\", { name: /send|submit/i }).or(\n        page.locator('button[type=\"submit\"]')\n      );\n\n      await input.fill(\"Test message\");\n      await sendButton.click();\n\n      // Input should be cleared\n      await expect(input).toHaveValue(\"\");\n    });\n  });\n\n  test.describe(\"Message Display\", () => {\n    test(\"should display user messages correctly\", async ({ page }) => {\n      const input = page.getByRole(\"textbox\").first();\n      const sendButton = page.getByRole(\"button\", { name: /send|submit/i }).or(\n        page.locator('button[type=\"submit\"]')\n      );\n\n      await input.fill(\"My test message\");\n      await sendButton.click();\n\n      // Message should be styled as user message\n      const userMessage = page.locator(\"[data-role='user']\").or(\n        page.getByText(\"My test message\")\n      );\n      await expect(userMessage).toBeVisible();\n    });\n\n    test(\"should support multiple messages\", async ({ page }) => {\n      const input = page.getByRole(\"textbox\").first();\n      const sendButton = page.getByRole(\"button\", { name: /send|submit/i }).or(\n        page.locator('button[type=\"submit\"]')\n      );\n\n      // Send first message\n      await input.fill(\"First message\");\n      await sendButton.click();\n      await expect(page.getByText(\"First message\")).toBeVisible();\n\n      // Wait for response\n      await page.waitForTimeout(1000);\n\n      // Send second message\n      await input.fill(\"Second message\");\n      await sendButton.click();\n      await expect(page.getByText(\"Second message\")).toBeVisible();\n\n      // Both messages should be visible\n      await expect(page.getByText(\"First message\")).toBeVisible();\n      await expect(page.getByText(\"Second message\")).toBeVisible();\n    });\n  });\n\n  test.describe(\"Keyboard Navigation\", () => {\n    test(\"should send message on Enter key\", async ({ page }) => {\n      const input = page.getByRole(\"textbox\").first();\n\n      await input.fill(\"Keyboard test\");\n      await input.press(\"Enter\");\n\n      // Message should be sent\n      await expect(page.getByText(\"Keyboard test\")).toBeVisible();\n    });\n\n    test(\"should support Shift+Enter for new line\", async ({ page }) => {\n      const input = page.getByRole(\"textbox\").first();\n\n      await input.fill(\"Line 1\");\n      await input.press(\"Shift+Enter\");\n      await input.type(\"Line 2\");\n\n      // Should contain multiline text (behavior may vary)\n      const value = await input.inputValue();\n      expect(value).toContain(\"Line 1\");\n    });\n  });\n});\n\n{%- if cookiecutter.enable_conversation_persistence %}\ntest.describe(\"Conversation Persistence\", () => {\n{%- if cookiecutter.use_jwt %}\n  test.use({\n    storageState: \".playwright/.auth/user.json\",\n  });\n{%- endif %}\n\n  test(\"should show conversation list\", async ({ page }) => {\n    await page.goto(\"/chat\");\n\n    // Should have some way to view conversation history\n    const conversationList = page.getByRole(\"list\").or(\n      page.locator(\"[data-testid='conversation-list']\")\n    );\n    // List may or may not be visible depending on UI\n  });\n\n  test(\"should create new conversation\", async ({ page }) => {\n    await page.goto(\"/chat\");\n\n    // Find new conversation button\n    const newChatButton = page.getByRole(\"button\", { name: /new|create/i }).or(\n      page.getByText(/new chat/i)\n    );\n\n    if (await newChatButton.isVisible()) {\n      await newChatButton.click();\n      // Should start a new conversation\n    }\n  });\n});\n{%- endif %}\n{%- elif cookiecutter.use_frontend %}\nimport { test, expect } from \"@playwright/test\";\n\ntest.describe(\"Chat\", () => {\n  test.skip(\"AI agent not enabled\", async () => {\n    // Skip chat tests when AI agent is not configured\n  });\n});\n{%- else %}\n/* Chat tests - frontend not configured */\nexport {};\n{%- endif %}\n","frontend/instrumentation.ts":"{%- if cookiecutter.enable_logfire %}\nimport { registerOTel } from \"@vercel/otel\";\n\nexport function register() {\n  registerOTel({\n    serviceName: \"{{ cookiecutter.project_slug }}-frontend\",\n  });\n}\n{%- else %}\n// Logfire/OpenTelemetry instrumentation is disabled\nexport function register() {\n  // No-op when Logfire is disabled\n}\n{%- endif %}\n","frontend/vitest.setup.ts":"{%- if cookiecutter.use_frontend %}\nimport \"@testing-library/jest-dom/vitest\";\nimport { cleanup } from \"@testing-library/react\";\nimport { afterEach, vi } from \"vitest\";\n\n// Cleanup after each test\nafterEach(() => {\n  cleanup();\n});\n\n// Mock Next.js router\nvi.mock(\"next/navigation\", () => ({\n  useRouter: () => ({\n    push: vi.fn(),\n    replace: vi.fn(),\n    prefetch: vi.fn(),\n    back: vi.fn(),\n    forward: vi.fn(),\n  }),\n  useSearchParams: () => new URLSearchParams(),\n  usePathname: () => \"/\",\n  useParams: () => ({}),\n}));\n\n// Mock matchMedia for responsive components\nObject.defineProperty(window, \"matchMedia\", {\n  writable: true,\n  value: vi.fn().mockImplementation((query: string) => ({\n    matches: false,\n    media: query,\n    onchange: null,\n    addListener: vi.fn(),\n    removeListener: vi.fn(),\n    addEventListener: vi.fn(),\n    removeEventListener: vi.fn(),\n    dispatchEvent: vi.fn(),\n  })),\n});\n\n// Mock ResizeObserver\nglobal.ResizeObserver = vi.fn().mockImplementation(() => ({\n  observe: vi.fn(),\n  unobserve: vi.fn(),\n  disconnect: vi.fn(),\n}));\n\n// Mock IntersectionObserver\nglobal.IntersectionObserver = vi.fn().mockImplementation(() => ({\n  observe: vi.fn(),\n  unobserve: vi.fn(),\n  disconnect: vi.fn(),\n}));\n{%- else %}\n/* Vitest setup - frontend not configured */\nexport {};\n{%- endif %}\n","frontend/next.config.ts":"import type { NextConfig } from \"next\";\n{%- if cookiecutter.enable_i18n %}\nimport createNextIntlPlugin from 'next-intl/plugin';\n\nconst withNextIntl = createNextIntlPlugin('./src/i18n.ts');\n{%- endif %}\n\n// Content Security Policy directives\nconst ContentSecurityPolicy = `\n  default-src 'self';\n  script-src 'self' 'unsafe-eval' 'unsafe-inline';\n  style-src 'self' 'unsafe-inline';\n  img-src 'self' blob: data: https:;\n  font-src 'self' data:;\n  connect-src 'self' ws: wss: http://localhost:* https://localhost:*;\n  frame-ancestors 'none';\n  base-uri 'self';\n  form-action 'self';\n`.replace(/\\n/g, \" \").trim();\n\nconst securityHeaders = [\n  {\n    key: \"Content-Security-Policy\",\n    value: ContentSecurityPolicy,\n  },\n  {\n    key: \"X-Content-Type-Options\",\n    value: \"nosniff\",\n  },\n  {\n    key: \"X-Frame-Options\",\n    value: \"DENY\",\n  },\n  {\n    key: \"X-XSS-Protection\",\n    value: \"1; mode=block\",\n  },\n  {\n    key: \"Referrer-Policy\",\n    value: \"strict-origin-when-cross-origin\",\n  },\n  {\n    key: \"Permissions-Policy\",\n    value: \"camera=(), microphone=(), geolocation=()\",\n  },\n];\n\nconst nextConfig: NextConfig = {\n  output: \"standalone\",\n\n  // Security headers\n  async headers() {\n    return [\n      {\n        source: \"/(.*)\",\n        headers: securityHeaders,\n      },\n    ];\n  },\n\n  // Environment variables available on the server side only\n  serverRuntimeConfig: {\n    apiUrl: process.env.BACKEND_URL || \"http://localhost:{{ cookiecutter.backend_port }}\",\n  },\n\n  // Environment variables available on both server and client\n  publicRuntimeConfig: {\n    appName: \"{{ cookiecutter.project_name }}\",\n  },\n};\n\n{%- if cookiecutter.enable_i18n %}\nexport default withNextIntl(nextConfig);\n{%- else %}\nexport default nextConfig;\n{%- endif %}\n","frontend/src/middleware.ts":"{%- if cookiecutter.enable_i18n %}\nimport createMiddleware from \"next-intl/middleware\";\nimport { locales, defaultLocale } from \"./i18n\";\n\nexport default createMiddleware({\n  // A list of all locales that are supported\n  locales,\n\n  // Used when no locale matches\n  defaultLocale,\n\n  // Don't prefix the default locale (e.g., /about instead of /en/about)\n  localePrefix: \"as-needed\",\n});\n\nexport const config = {\n  // Match only internationalized pathnames\n  matcher: [\n    // Match all pathnames except for:\n    // - /api (API routes)\n    // - /_next (Next.js internals)\n    // - /static (inside /public)\n    // - /_vercel (Vercel internals)\n    // - All root files like favicon.ico, robots.txt, etc.\n    \"/((?!api|_next|_vercel|static|.*\\\\..*).*)\",\n  ],\n};\n{%- else %}\n// Middleware is disabled when i18n is not enabled\nexport {};\n{%- endif %}\n","frontend/src/types/chat.ts":"/**\n * Chat and AI Agent types.\n */\n\nexport type MessageRole = \"user\" | \"assistant\" | \"system\";\n\nexport interface ChatMessage {\n  id: string;\n  role: MessageRole;\n  content: string;\n  timestamp: Date;\n  toolCalls?: ToolCall[];\n  isStreaming?: boolean;\n  /** Group ID for related messages (e.g., CrewAI agent chain) */\n  groupId?: string;\n}\n\nexport interface ToolCall {\n  id: string;\n  name: string;\n  args: Record<string, unknown>;\n  result?: unknown;\n  status: \"pending\" | \"running\" | \"completed\" | \"error\";\n}\n\n// WebSocket event types from backend\nexport type WSEventType =\n  // PydanticAI / LangChain / LangGraph events\n  | \"user_prompt\"\n  | \"user_prompt_processed\"\n  | \"model_request_start\"\n  | \"part_start\"\n  | \"text_delta\"\n  | \"tool_call_delta\"\n  | \"call_tools_start\"\n  | \"tool_call\"\n  | \"tool_result\"\n  | \"final_result_start\"\n  | \"final_result\"\n  | \"complete\"\n  | \"error\"\n  | \"conversation_created\"\n  | \"message_saved\"\n  // DeepAgents Human-in-the-Loop event\n  | \"tool_approval_required\"\n  // CrewAI-specific events\n  | \"crew_start\"\n  | \"crew_started\"\n  | \"crew_complete\"\n  | \"agent_started\"\n  | \"agent_completed\"\n  | \"task_started\"\n  | \"task_completed\"\n  | \"tool_started\"\n  | \"tool_finished\"\n  | \"llm_started\"\n  | \"llm_completed\";\n\nexport interface WSEvent {\n  type: WSEventType;\n  data?: unknown;\n  timestamp?: string;\n}\n\nexport interface TextDeltaEvent {\n  type: \"text_delta\";\n  data: {\n    delta: string;\n  };\n}\n\nexport interface ToolCallEvent {\n  type: \"tool_call\";\n  data: {\n    tool_name: string;\n    args: Record<string, unknown>;\n  };\n}\n\nexport interface ToolResultEvent {\n  type: \"tool_result\";\n  data: {\n    tool_name: string;\n    result: unknown;\n  };\n}\n\nexport interface FinalResultEvent {\n  type: \"final_result\";\n  data: {\n    output: string;\n    tool_events: ToolCall[];\n  };\n}\n\nexport interface ChatState {\n  messages: ChatMessage[];\n  isConnected: boolean;\n  isProcessing: boolean;\n}\n\n// Human-in-the-Loop (HITL) types for DeepAgents\nexport interface ActionRequest {\n  id: string;\n  tool_name: string;\n  args: Record<string, unknown>;\n}\n\nexport interface ReviewConfig {\n  tool_name: string;\n  /** Whether to allow editing the tool arguments */\n  allow_edit?: boolean;\n  /** Maximum time to wait for decision (seconds) */\n  timeout?: number;\n}\n\nexport interface PendingApproval {\n  actionRequests: ActionRequest[];\n  reviewConfigs: ReviewConfig[];\n}\n\nexport type DecisionType = \"approve\" | \"edit\" | \"reject\";\n\nexport interface Decision {\n  type: DecisionType;\n  editedAction?: {\n    id: string;\n    tool_name: string;\n    args: Record<string, unknown>;\n  };\n}\n\nexport interface ToolApprovalRequiredEvent {\n  type: \"tool_approval_required\";\n  data: {\n    action_requests: ActionRequest[];\n    review_configs: ReviewConfig[];\n  };\n}\n","frontend/src/types/api.ts":"/**\n * API response types.\n */\n\nexport interface ApiResponse<T> {\n  data: T;\n  message?: string;\n}\n\nexport interface PaginatedResponse<T> {\n  items: T[];\n  total: number;\n  page: number;\n  size: number;\n  pages: number;\n}\n\nexport interface HealthResponse {\n  status: string;\n  version?: string;\n  database?: string;\n}\n\nexport interface ErrorResponse {\n  detail: string;\n  status_code?: number;\n}\n","frontend/src/types/conversation.ts":"{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n/**\n * Conversation types for AI chat persistence.\n */\n\nexport interface Conversation {\n  id: string;\n  user_id?: string;\n  title?: string;\n  created_at: string;\n  updated_at: string;\n  is_archived: boolean;\n}\n\nexport interface ConversationMessage {\n  id: string;\n  conversation_id: string;\n  role: \"user\" | \"assistant\" | \"system\";\n  content: string;\n  created_at: string;\n  model_name?: string;\n  tokens_used?: number;\n  tool_calls?: ConversationToolCall[];\n}\n\nexport interface ConversationToolCall {\n  id: string;\n  message_id: string;\n  tool_call_id: string;\n  tool_name: string;\n  args: Record<string, unknown>;\n  result?: string;\n  status: \"pending\" | \"running\" | \"completed\" | \"failed\";\n  started_at: string;\n  completed_at?: string;\n  duration_ms?: number;\n}\n\nexport interface ConversationListResponse {\n  items: Conversation[];\n  total: number;\n}\n\nexport interface ConversationWithMessages extends Conversation {\n  messages: ConversationMessage[];\n}\n{%- else %}\n// Conversation types - not configured (enable_conversation_persistence is false)\n{%- endif %}\n","frontend/src/types/index.ts":"/**\n * Re-export all types.\n */\n\nexport * from \"./api\";\nexport * from \"./auth\";\nexport * from \"./chat\";\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nexport * from \"./conversation\";\n{%- endif %}\n","frontend/src/types/auth.ts":"/**\n * Authentication types.\n */\n\nexport interface User {\n  id: string;\n  email: string;\n  name?: string;\n  is_active: boolean;\n  is_superuser?: boolean;\n  created_at: string;\n}\n\nexport interface LoginRequest {\n  email: string;\n  password: string;\n}\n\nexport interface LoginResponse {\n  access_token: string;\n  refresh_token: string;\n  token_type: string;\n  user: User;\n}\n\nexport interface RegisterRequest {\n  email: string;\n  password: string;\n  name?: string;\n}\n\nexport interface RegisterResponse {\n  id: string;\n  email: string;\n  name?: string;\n}\n\nexport interface RefreshTokenRequest {\n  refresh_token: string;\n}\n\nexport interface RefreshTokenResponse {\n  access_token: string;\n  token_type: string;\n}\n\nexport interface AuthState {\n  user: User | null;\n  accessToken: string | null;\n  isAuthenticated: boolean;\n  isLoading: boolean;\n}\n","frontend/src/app/[locale]/auth/callback/page.tsx":"{%- if cookiecutter.enable_oauth %}\n\"use client\";\n\nimport { Suspense, useEffect, useState } from \"react\";\nimport { useRouter, useSearchParams } from \"next/navigation\";\nimport { useAuthStore } from \"@/stores/auth-store\";\nimport { Card, CardContent } from \"@/components/ui\";\nimport { ROUTES } from \"@/lib/constants\";\n\nfunction AuthCallbackContent() {\n  const router = useRouter();\n  const searchParams = useSearchParams();\n  const [error, setError] = useState<string | null>(null);\n  const { checkAuth } = useAuthStore();\n\n  useEffect(() => {\n    const handleCallback = async () => {\n      const accessToken = searchParams.get(\"access_token\");\n      const refreshToken = searchParams.get(\"refresh_token\");\n      const errorParam = searchParams.get(\"error\");\n\n      if (errorParam) {\n        setError(errorParam);\n        setTimeout(() => {\n          router.push(ROUTES.LOGIN);\n        }, 3000);\n        return;\n      }\n\n      if (accessToken && refreshToken) {\n        // Store tokens - the API route will handle this\n        try {\n          const response = await fetch(\"/api/auth/oauth-callback\", {\n            method: \"POST\",\n            headers: {\n              \"Content-Type\": \"application/json\",\n            },\n            body: JSON.stringify({ accessToken, refreshToken }),\n          });\n\n          if (response.ok) {\n            // Refresh auth state\n            await checkAuth();\n            router.push(ROUTES.DASHBOARD);\n          } else {\n            setError(\"Failed to complete authentication\");\n            setTimeout(() => {\n              router.push(ROUTES.LOGIN);\n            }, 3000);\n          }\n        } catch {\n          setError(\"Authentication error\");\n          setTimeout(() => {\n            router.push(ROUTES.LOGIN);\n          }, 3000);\n        }\n      } else {\n        setError(\"Missing authentication tokens\");\n        setTimeout(() => {\n          router.push(ROUTES.LOGIN);\n        }, 3000);\n      }\n    };\n\n    handleCallback();\n  }, [searchParams, router, checkAuth]);\n\n  return (\n    <Card className=\"w-full max-w-md\">\n      <CardContent className=\"pt-6\">\n        {error ? (\n          <div className=\"text-center\">\n            <p className=\"text-destructive mb-2\">{error}</p>\n            <p className=\"text-muted-foreground text-sm\">Redirecting to login...</p>\n          </div>\n        ) : (\n          <div className=\"text-center\">\n            <div className=\"border-primary mx-auto mb-4 h-8 w-8 animate-spin rounded-full border-b-2\" />\n            <p className=\"text-muted-foreground\">Completing authentication...</p>\n          </div>\n        )}\n      </CardContent>\n    </Card>\n  );\n}\n\nfunction LoadingFallback() {\n  return (\n    <Card className=\"w-full max-w-md\">\n      <CardContent className=\"pt-6\">\n        <div className=\"text-center\">\n          <div className=\"border-primary mx-auto mb-4 h-8 w-8 animate-spin rounded-full border-b-2\" />\n          <p className=\"text-muted-foreground\">Loading...</p>\n        </div>\n      </CardContent>\n    </Card>\n  );\n}\n\nexport default function AuthCallbackPage() {\n  return (\n    <div className=\"flex min-h-screen items-center justify-center\">\n      <Suspense fallback={<LoadingFallback />}>\n        <AuthCallbackContent />\n      </Suspense>\n    </div>\n  );\n}\n{%- else %}\nexport default function AuthCallbackPage() {\n  return <div>OAuth not enabled</div>;\n}\n{%- endif %}\n","frontend/src/app/[locale]/layout.tsx":"{%- if cookiecutter.enable_i18n %}\nimport { NextIntlClientProvider } from \"next-intl\";\nimport { getMessages } from \"next-intl/server\";\n{%- endif %}\nimport { notFound } from \"next/navigation\";\nimport { Providers } from \"../providers\";\n{%- if cookiecutter.enable_i18n %}\nimport { locales, type Locale } from \"@/i18n\";\n{%- endif %}\n\n{%- if cookiecutter.enable_i18n %}\nexport function generateStaticParams() {\n  return locales.map((locale) => ({ locale }));\n}\n{%- endif %}\n\nexport default async function LocaleLayout({\n  children,\n  params,\n}: {\n  children: React.ReactNode;\n  params: Promise<{ locale: string }>;\n}) {\n  const { locale } = await params;\n\n{%- if cookiecutter.enable_i18n %}\n  // Validate locale\n  if (!locales.includes(locale as Locale)) {\n    notFound();\n  }\n\n  // Get messages for the current locale\n  const messages = await getMessages();\n\n  return (\n    <Providers>\n      <NextIntlClientProvider messages={messages}>\n        {children}\n      </NextIntlClientProvider>\n    </Providers>\n  );\n{%- else %}\n  // i18n disabled - just render with providers\n  return <Providers>{children}</Providers>;\n{%- endif %}\n}\n","frontend/src/app/[locale]/(auth)/register/page.tsx":"import { RegisterForm } from \"@/components/auth\";\n\nexport default function RegisterPage() {\n  return <RegisterForm />;\n}\n","frontend/src/app/[locale]/(auth)/layout.tsx":"export default function AuthLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <div className=\"min-h-screen flex items-center justify-center bg-background px-4\">\n      {children}\n    </div>\n  );\n}\n","frontend/src/app/[locale]/(auth)/login/page.tsx":"import { LoginForm } from \"@/components/auth\";\n\nexport default function LoginPage() {\n  return <LoginForm />;\n}\n","frontend/src/app/[locale]/(dashboard)/chat/page.tsx":"{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n\"use client\";\n\nimport { ChatContainer, ConversationSidebar, LocalConversationSidebar, ChatSidebarToggle } from \"@/components/chat\";\nimport { useAuthStore } from \"@/stores\";\n\nexport default function ChatPage() {\n  const { isAuthenticated } = useAuthStore();\n\n  const Sidebar = isAuthenticated ? ConversationSidebar : LocalConversationSidebar;\n\n  return (\n    <div className=\"flex h-full -m-3 sm:-m-6\">\n      <Sidebar />\n      <div className=\"flex-1 min-w-0 flex flex-col\">\n        <div className=\"flex items-center gap-2 p-2 border-b md:hidden\">\n          <ChatSidebarToggle />\n          <span className=\"text-sm font-medium\">Chat</span>\n        </div>\n        <div className=\"flex-1 min-h-0\">\n          <ChatContainer />\n        </div>\n      </div>\n    </div>\n  );\n}\n{%- else %}\n\"use client\";\n\nimport { ChatContainer, LocalConversationSidebar, ChatSidebarToggle } from \"@/components/chat\";\n\nexport default function ChatPage() {\n  return (\n    <div className=\"flex h-full -m-3 sm:-m-6\">\n      <LocalConversationSidebar />\n      <div className=\"flex-1 min-w-0 flex flex-col\">\n        <div className=\"flex items-center gap-2 p-2 border-b md:hidden\">\n          <ChatSidebarToggle />\n          <span className=\"text-sm font-medium\">Chat</span>\n        </div>\n        <div className=\"flex-1 min-h-0\">\n          <ChatContainer />\n        </div>\n      </div>\n    </div>\n  );\n}\n{%- endif %}\n","frontend/src/app/[locale]/(dashboard)/dashboard/page.tsx":"\"use client\";\n\nimport { useEffect, useState } from \"react\";\nimport { Card, CardHeader, CardTitle, CardContent } from \"@/components/ui\";\nimport { apiClient } from \"@/lib/api-client\";\nimport { useAuth } from \"@/hooks\";\nimport type { HealthResponse } from \"@/types\";\nimport { CheckCircle, XCircle, Loader2 } from \"lucide-react\";\n\nexport default function DashboardPage() {\n  const { user } = useAuth();\n  const [health, setHealth] = useState<HealthResponse | null>(null);\n  const [healthLoading, setHealthLoading] = useState(true);\n  const [healthError, setHealthError] = useState(false);\n\n  useEffect(() => {\n    const checkHealth = async () => {\n      try {\n        const data = await apiClient.get<HealthResponse>(\"/health\");\n        setHealth(data);\n        setHealthError(false);\n      } catch {\n        setHealthError(true);\n      } finally {\n        setHealthLoading(false);\n      }\n    };\n\n    checkHealth();\n  }, []);\n\n  return (\n    <div className=\"space-y-4 sm:space-y-6\">\n      <div>\n        <h1 className=\"text-2xl sm:text-3xl font-bold\">Dashboard</h1>\n        <p className=\"text-sm sm:text-base text-muted-foreground\">\n          Welcome back{user?.name ? `, ${user.name}` : \"\"}!\n        </p>\n      </div>\n\n      <div className=\"grid gap-4 sm:gap-6 md:grid-cols-2 lg:grid-cols-3\">\n        <Card>\n          <CardHeader className=\"pb-2 sm:pb-4\">\n            <CardTitle className=\"flex items-center gap-2 text-base sm:text-lg\">\n              API Status\n              {healthLoading ? (\n                <Loader2 className=\"h-4 w-4 animate-spin\" />\n              ) : healthError ? (\n                <XCircle className=\"h-4 w-4 text-destructive\" />\n              ) : (\n                <CheckCircle className=\"h-4 w-4 text-green-500\" />\n              )}\n            </CardTitle>\n          </CardHeader>\n          <CardContent>\n            {healthLoading ? (\n              <p className=\"text-muted-foreground text-sm\">Checking...</p>\n            ) : healthError ? (\n              <p className=\"text-destructive text-sm\">Backend unavailable</p>\n            ) : (\n              <div className=\"space-y-1\">\n                <p className=\"text-sm\">\n                  Status: <span className=\"font-medium\">{health?.status}</span>\n                </p>\n                {health?.version && (\n                  <p className=\"text-xs sm:text-sm text-muted-foreground\">\n                    Version: {health.version}\n                  </p>\n                )}\n              </div>\n            )}\n          </CardContent>\n        </Card>\n\n        <Card>\n          <CardHeader className=\"pb-2 sm:pb-4\">\n            <CardTitle className=\"text-base sm:text-lg\">Your Account</CardTitle>\n          </CardHeader>\n          <CardContent>\n            {user ? (\n              <div className=\"space-y-1\">\n                <p className=\"text-sm break-all\">\n                  Email: <span className=\"font-medium\">{user.email}</span>\n                </p>\n                {user.name && (\n                  <p className=\"text-sm\">\n                    Name: <span className=\"font-medium\">{user.name}</span>\n                  </p>\n                )}\n              </div>\n            ) : (\n              <p className=\"text-muted-foreground text-sm\">Loading...</p>\n            )}\n          </CardContent>\n        </Card>\n      </div>\n    </div>\n  );\n}\n","frontend/src/app/[locale]/(dashboard)/profile/page.tsx":"{%- if cookiecutter.use_frontend and cookiecutter.use_jwt %}\n\"use client\";\n\nimport { useState } from \"react\";\nimport { useAuth } from \"@/hooks\";\nimport { Button, Card, Input, Label, Badge } from \"@/components/ui\";\nimport { ThemeToggle } from \"@/components/theme\";\nimport { User, Mail, Calendar, Shield, Settings } from \"lucide-react\";\n\nexport default function ProfilePage() {\n  const { user, isAuthenticated, logout } = useAuth();\n  const [isEditing, setIsEditing] = useState(false);\n\n  if (!isAuthenticated || !user) {\n    return (\n      <div className=\"flex min-h-[50vh] items-center justify-center\">\n        <Card className=\"p-6 sm:p-8 text-center mx-4\">\n          <p className=\"text-muted-foreground\">Please log in to view your profile.</p>\n        </Card>\n      </div>\n    );\n  }\n\n  return (\n    <div className=\"container mx-auto max-w-4xl\">\n      <div className=\"mb-6 sm:mb-8\">\n        <h1 className=\"text-2xl sm:text-3xl font-bold tracking-tight\">Profile</h1>\n        <p className=\"text-sm sm:text-base text-muted-foreground\">\n          Manage your account settings and preferences\n        </p>\n      </div>\n\n      <div className=\"grid gap-4 sm:gap-6\">\n        <Card className=\"p-4 sm:p-6\">\n          <div className=\"flex flex-col sm:flex-row sm:items-start sm:justify-between gap-4\">\n            <div className=\"flex items-center gap-3 sm:gap-4\">\n              <div className=\"flex h-12 w-12 sm:h-16 sm:w-16 items-center justify-center rounded-full bg-primary/10 shrink-0\">\n                <User className=\"h-6 w-6 sm:h-8 sm:w-8 text-primary\" />\n              </div>\n              <div className=\"min-w-0\">\n                <h2 className=\"text-lg sm:text-xl font-semibold truncate\">{user.email}</h2>\n                <div className=\"mt-1 flex flex-wrap items-center gap-2\">\n                  {user.is_superuser && (\n                    <Badge variant=\"secondary\">\n                      <Shield className=\"mr-1 h-3 w-3\" />\n                      Admin\n                    </Badge>\n                  )}\n                  {user.is_active && (\n                    <Badge variant=\"outline\" className=\"text-green-600\">\n                      Active\n                    </Badge>\n                  )}\n                </div>\n              </div>\n            </div>\n            <Button\n              variant=\"outline\"\n              size=\"sm\"\n              onClick={() => setIsEditing(!isEditing)}\n              className=\"self-start h-10\"\n            >\n              <Settings className=\"mr-2 h-4 w-4\" />\n              {isEditing ? \"Cancel\" : \"Edit\"}\n            </Button>\n          </div>\n        </Card>\n\n        <Card className=\"p-4 sm:p-6\">\n          <h3 className=\"mb-4 text-base sm:text-lg font-semibold\">Account Information</h3>\n          <div className=\"grid gap-4\">\n            <div className=\"grid gap-2\">\n              <Label htmlFor=\"email\" className=\"flex items-center gap-2 text-sm\">\n                <Mail className=\"h-4 w-4 text-muted-foreground\" />\n                Email Address\n              </Label>\n              <Input\n                id=\"email\"\n                type=\"email\"\n                value={user.email}\n                disabled={!isEditing}\n                className={!isEditing ? \"bg-muted\" : \"\"}\n              />\n            </div>\n\n            {user.created_at && (\n              <div className=\"flex items-center gap-2 text-xs sm:text-sm text-muted-foreground\">\n                <Calendar className=\"h-4 w-4 shrink-0\" />\n                <span>Member since {new Date(user.created_at).toLocaleDateString()}</span>\n              </div>\n            )}\n          </div>\n\n          {isEditing && (\n            <div className=\"mt-4 flex flex-col sm:flex-row justify-end gap-2\">\n              <Button variant=\"outline\" onClick={() => setIsEditing(false)} className=\"h-10\">\n                Cancel\n              </Button>\n              <Button className=\"h-10\">Save Changes</Button>\n            </div>\n          )}\n        </Card>\n\n        <Card className=\"p-4 sm:p-6\">\n          <h3 className=\"mb-4 text-base sm:text-lg font-semibold\">Preferences</h3>\n          <div className=\"flex items-center justify-between gap-4\">\n            <div className=\"min-w-0\">\n              <p className=\"font-medium text-sm sm:text-base\">Theme</p>\n              <p className=\"text-xs sm:text-sm text-muted-foreground\">\n                Choose your preferred color scheme\n              </p>\n            </div>\n            <ThemeToggle variant=\"dropdown\" />\n          </div>\n        </Card>\n\n        <Card className=\"border-destructive/50 p-4 sm:p-6\">\n          <h3 className=\"mb-4 text-base sm:text-lg font-semibold text-destructive\">\n            Danger Zone\n          </h3>\n          <div className=\"flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4\">\n            <div>\n              <p className=\"font-medium text-sm sm:text-base\">Sign out</p>\n              <p className=\"text-xs sm:text-sm text-muted-foreground\">\n                Sign out from your account on this device\n              </p>\n            </div>\n            <Button variant=\"destructive\" onClick={logout} className=\"h-10 self-start sm:self-auto\">\n              Sign Out\n            </Button>\n          </div>\n        </Card>\n      </div>\n    </div>\n  );\n}\n{%- elif cookiecutter.use_frontend %}\nexport default function ProfilePage() {\n  return (\n    <div className=\"container mx-auto\">\n      <h1 className=\"text-2xl sm:text-3xl font-bold\">Profile</h1>\n      <p className=\"mt-4 text-sm sm:text-base text-muted-foreground\">\n        User authentication is not enabled.\n      </p>\n    </div>\n  );\n}\n{%- else %}\nexport default function ProfilePage() {\n  return null;\n}\n{%- endif %}\n","frontend/src/app/[locale]/(dashboard)/layout.tsx":"import { Header, Sidebar } from \"@/components/layout\";\n\nexport default function DashboardLayout({\n  children,\n}: {\n  children: React.ReactNode;\n}) {\n  return (\n    <div className=\"flex h-screen overflow-hidden\">\n      <Sidebar />\n      <div className=\"flex min-w-0 flex-1 flex-col\">\n        <Header />\n        <main className=\"flex-1 overflow-auto p-3 sm:p-6\">{children}</main>\n      </div>\n    </div>\n  );\n}\n","frontend/src/app/[locale]/page.tsx":"import Link from \"next/link\";\nimport { Button, Card, CardHeader, CardTitle, CardContent } from \"@/components/ui\";\nimport { ROUTES } from \"@/lib/constants\";\n\nexport default function HomePage() {\n  return (\n    <div className=\"min-h-screen bg-background\">\n      <div className=\"container mx-auto py-16 px-4\">\n        <div className=\"text-center mb-12\">\n          <h1 className=\"text-4xl font-bold mb-4\">\n            {{ cookiecutter.project_name }}\n          </h1>\n          <p className=\"text-xl text-muted-foreground max-w-2xl mx-auto\">\n            {{ cookiecutter.project_description }}\n          </p>\n        </div>\n\n        <div className=\"grid gap-6 md:grid-cols-2 lg:grid-cols-3 max-w-5xl mx-auto\">\n          {% if cookiecutter.use_jwt %}\n          <Card>\n            <CardHeader>\n              <CardTitle>Authentication</CardTitle>\n            </CardHeader>\n            <CardContent>\n              <p className=\"mb-4 text-muted-foreground\">\n                Secure JWT-based authentication system\n              </p>\n              <div className=\"flex gap-2\">\n                <Button asChild>\n                  <Link href={ROUTES.LOGIN}>Login</Link>\n                </Button>\n                <Button variant=\"outline\" asChild>\n                  <Link href={ROUTES.REGISTER}>Register</Link>\n                </Button>\n              </div>\n            </CardContent>\n          </Card>\n          {% endif %}\n\n          {% if cookiecutter.enable_ai_agent %}\n          <Card>\n            <CardHeader>\n              <CardTitle>AI Assistant</CardTitle>\n            </CardHeader>\n            <CardContent>\n              <p className=\"mb-4 text-muted-foreground\">\n                Chat with our AI assistant powered by PydanticAI\n              </p>\n              <Button asChild>\n                <Link href={ROUTES.CHAT}>Start Chat</Link>\n              </Button>\n            </CardContent>\n          </Card>\n          {% endif %}\n\n          <Card>\n            <CardHeader>\n              <CardTitle>Dashboard</CardTitle>\n            </CardHeader>\n            <CardContent>\n              <p className=\"mb-4 text-muted-foreground\">\n                View your dashboard and manage your account\n              </p>\n              <Button variant=\"outline\" asChild>\n                <Link href={ROUTES.DASHBOARD}>Go to Dashboard</Link>\n              </Button>\n            </CardContent>\n          </Card>\n        </div>\n      </div>\n    </div>\n  );\n}\n","frontend/src/app/layout.tsx":"import type { Metadata } from \"next\";\nimport { Inter } from \"next/font/google\";\nimport \"./globals.css\";\n\nconst inter = Inter({ subsets: [\"latin\"] });\n\nexport const metadata: Metadata = {\n  title: \"{{ cookiecutter.project_name }}\",\n  description: \"{{ cookiecutter.project_description }}\",\n};\n\nexport default function RootLayout({\n  children,\n}: Readonly<{\n  children: React.ReactNode;\n}>) {\n  return (\n    <html lang=\"en\" suppressHydrationWarning>\n      <body className={inter.className}>{children}</body>\n    </html>\n  );\n}\n","frontend/src/app/api/auth/refresh/route.ts":"{% raw %}import { NextRequest, NextResponse } from \"next/server\";\nimport { backendFetch, BackendApiError } from \"@/lib/server-api\";\nimport type { RefreshTokenResponse } from \"@/types\";\n\nexport async function POST(request: NextRequest) {\n  try {\n    const refreshToken = request.cookies.get(\"refresh_token\")?.value;\n\n    if (!refreshToken) {\n      return NextResponse.json(\n        { detail: \"No refresh token\" },\n        { status: 401 }\n      );\n    }\n\n    const data = await backendFetch<RefreshTokenResponse>(\n      \"/api/v1/auth/refresh\",\n      {\n        method: \"POST\",\n        body: JSON.stringify({ refresh_token: refreshToken }),\n      }\n    );\n\n    const response = NextResponse.json({ message: \"Token refreshed\" });\n\n    // Update access token cookie\n    response.cookies.set(\"access_token\", data.access_token, {\n      httpOnly: true,\n      secure: process.env.NODE_ENV === \"production\",\n      sameSite: \"lax\",\n      maxAge: 60 * 15, // 15 minutes\n      path: \"/\",\n    });\n\n    return response;\n  } catch (error) {\n    if (error instanceof BackendApiError) {\n      // Clear cookies on refresh failure\n      const response = NextResponse.json(\n        { detail: \"Session expired\" },\n        { status: 401 }\n      );\n\n      response.cookies.set(\"access_token\", \"\", { maxAge: 0, path: \"/\" });\n      response.cookies.set(\"refresh_token\", \"\", { maxAge: 0, path: \"/\" });\n\n      return response;\n    }\n    return NextResponse.json(\n      { detail: \"Internal server error\" },\n      { status: 500 }\n    );\n  }\n}{% endraw %}\n","frontend/src/app/api/auth/logout/route.ts":"import { NextResponse } from \"next/server\";\n\nexport async function POST() {\n  const response = NextResponse.json({ message: \"Logged out successfully\" });\n\n  // Clear auth cookies\n  response.cookies.set(\"access_token\", \"\", {\n    httpOnly: true,\n    secure: process.env.NODE_ENV === \"production\",\n    sameSite: \"lax\",\n    maxAge: 0,\n    path: \"/\",\n  });\n\n  response.cookies.set(\"refresh_token\", \"\", {\n    httpOnly: true,\n    secure: process.env.NODE_ENV === \"production\",\n    sameSite: \"lax\",\n    maxAge: 0,\n    path: \"/\",\n  });\n\n  return response;\n}\n","frontend/src/app/api/auth/register/route.ts":"{% raw %}import { NextRequest, NextResponse } from \"next/server\";\nimport { backendFetch, BackendApiError } from \"@/lib/server-api\";\nimport type { RegisterResponse } from \"@/types\";\n\nexport async function POST(request: NextRequest) {\n  try {\n    const body = await request.json();\n\n    const data = await backendFetch<RegisterResponse>(\"/api/v1/auth/register\", {\n      method: \"POST\",\n      body: JSON.stringify(body),\n    });\n\n    return NextResponse.json(data, { status: 201 });\n  } catch (error) {\n    if (error instanceof BackendApiError) {\n      const detail =\n        (error.data as { detail?: string })?.detail || \"Registration failed\";\n      return NextResponse.json({ detail }, { status: error.status });\n    }\n    return NextResponse.json(\n      { detail: \"Internal server error\" },\n      { status: 500 }\n    );\n  }\n}{% endraw %}\n","frontend/src/app/api/auth/me/route.ts":"{% raw %}import { NextRequest, NextResponse } from \"next/server\";\nimport { backendFetch, BackendApiError } from \"@/lib/server-api\";\nimport type { User } from \"@/types\";\n\nexport async function GET(request: NextRequest) {\n  try {\n    const accessToken = request.cookies.get(\"access_token\")?.value;\n\n    if (!accessToken) {\n      return NextResponse.json({ detail: \"Not authenticated\" }, { status: 401 });\n    }\n\n    const data = await backendFetch<User>(\"/api/v1/auth/me\", {\n      headers: {\n        Authorization: `Bearer ${accessToken}`,\n      },\n    });\n\n    return NextResponse.json(data);\n  } catch (error) {\n    if (error instanceof BackendApiError) {\n      if (error.status === 401) {\n        // Token expired, try to refresh\n        return NextResponse.json(\n          { detail: \"Token expired\" },\n          { status: 401 }\n        );\n      }\n      return NextResponse.json(\n        { detail: \"Failed to get user\" },\n        { status: error.status }\n      );\n    }\n    return NextResponse.json(\n      { detail: \"Internal server error\" },\n      { status: 500 }\n    );\n  }\n}{% endraw %}\n","frontend/src/app/api/auth/oauth-callback/route.ts":"{%- if cookiecutter.enable_oauth %}\nimport { cookies } from \"next/headers\";\nimport { NextRequest, NextResponse } from \"next/server\";\n\nexport async function POST(request: NextRequest) {\n  try {\n    const { accessToken, refreshToken } = await request.json();\n\n    if (!accessToken || !refreshToken) {\n      return NextResponse.json(\n        { error: \"Missing tokens\" },\n        { status: 400 }\n      );\n    }\n\n    const cookieStore = await cookies();\n\n    // Set access token cookie\n    cookieStore.set(\"access_token\", accessToken, {\n      httpOnly: true,\n      secure: process.env.NODE_ENV === \"production\",\n      sameSite: \"lax\",\n      maxAge: 60 * 60 * 24, // 24 hours\n      path: \"/\",\n    });\n\n    // Set refresh token cookie\n    cookieStore.set(\"refresh_token\", refreshToken, {\n      httpOnly: true,\n      secure: process.env.NODE_ENV === \"production\",\n      sameSite: \"lax\",\n      maxAge: 60 * 60 * 24 * 7, // 7 days\n      path: \"/\",\n    });\n\n    return NextResponse.json({ success: true });\n  } catch {\n    return NextResponse.json(\n      { error: \"Failed to process OAuth callback\" },\n      { status: 500 }\n    );\n  }\n}\n{%- else %}\nimport { NextResponse } from \"next/server\";\n\nexport async function POST() {\n  return NextResponse.json({ error: \"OAuth not enabled\" }, { status: 404 });\n}\n{%- endif %}\n","frontend/src/app/api/auth/login/route.ts":"{% raw %}import { NextRequest, NextResponse } from \"next/server\";\nimport { backendFetch, BackendApiError } from \"@/lib/server-api\";\nimport type { LoginResponse } from \"@/types\";\n\nexport async function POST(request: NextRequest) {\n  try {\n    const body = await request.json();\n\n    // Backend expects OAuth2 form data format\n    const formData = new URLSearchParams();\n    formData.append(\"username\", body.email);\n    formData.append(\"password\", body.password);\n\n    const data = await backendFetch<LoginResponse>(\"/api/v1/auth/login\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/x-www-form-urlencoded\",\n      },\n      body: formData.toString(),\n    });\n\n    // Set HTTP-only cookies for tokens\n    const response = NextResponse.json({\n      user: data.user,\n      message: \"Login successful\",\n    });\n\n    // Set access token cookie (short-lived)\n    response.cookies.set(\"access_token\", data.access_token, {\n      httpOnly: true,\n      secure: process.env.NODE_ENV === \"production\",\n      sameSite: \"lax\",\n      maxAge: 60 * 15, // 15 minutes\n      path: \"/\",\n    });\n\n    // Set refresh token cookie (long-lived)\n    response.cookies.set(\"refresh_token\", data.refresh_token, {\n      httpOnly: true,\n      secure: process.env.NODE_ENV === \"production\",\n      sameSite: \"lax\",\n      maxAge: 60 * 60 * 24 * 7, // 7 days\n      path: \"/\",\n    });\n\n    return response;\n  } catch (error) {\n    if (error instanceof BackendApiError) {\n      const detail =\n        (error.data as { detail?: string })?.detail || \"Login failed\";\n      return NextResponse.json({ detail }, { status: error.status });\n    }\n    return NextResponse.json(\n      { detail: \"Internal server error\" },\n      { status: 500 }\n    );\n  }\n}{% endraw %}\n","frontend/src/app/api/health/route.ts":"import { NextResponse } from \"next/server\";\nimport { backendFetch, BackendApiError } from \"@/lib/server-api\";\nimport type { HealthResponse } from \"@/types\";\n\nexport async function GET() {\n  try {\n    const data = await backendFetch<HealthResponse>(\"/api/v1/health\");\n    return NextResponse.json(data);\n  } catch (error) {\n    if (error instanceof BackendApiError) {\n      return NextResponse.json(\n        { detail: \"Backend service unavailable\" },\n        { status: error.status }\n      );\n    }\n    return NextResponse.json(\n      { detail: \"Internal server error\" },\n      { status: 500 }\n    );\n  }\n}\n","frontend/src/app/api/conversations/route.ts":"{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n{% raw %}import { NextRequest, NextResponse } from \"next/server\";\nimport { backendFetch, BackendApiError } from \"@/lib/server-api\";\n\nexport async function GET(request: NextRequest) {\n  try {\n    const accessToken = request.cookies.get(\"access_token\")?.value;\n\n    if (!accessToken) {\n      return NextResponse.json({ detail: \"Not authenticated\" }, { status: 401 });\n    }\n\n    const searchParams = request.nextUrl.searchParams;\n    const skip = searchParams.get(\"skip\") || \"0\";\n    const limit = searchParams.get(\"limit\") || \"50\";\n\n    const data = await backendFetch(`/api/v1/conversations?skip=${skip}&limit=${limit}`, {\n      headers: {\n        Authorization: `Bearer ${accessToken}`,\n      },\n    });\n\n    return NextResponse.json(data);\n  } catch (error) {\n    if (error instanceof BackendApiError) {\n      return NextResponse.json(\n        { detail: error.message || \"Failed to fetch conversations\" },\n        { status: error.status }\n      );\n    }\n    return NextResponse.json(\n      { detail: \"Internal server error\" },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function POST(request: NextRequest) {\n  try {\n    const accessToken = request.cookies.get(\"access_token\")?.value;\n\n    if (!accessToken) {\n      return NextResponse.json({ detail: \"Not authenticated\" }, { status: 401 });\n    }\n\n    const body = await request.json();\n\n    const data = await backendFetch(\"/api/v1/conversations\", {\n      method: \"POST\",\n      headers: {\n        Authorization: `Bearer ${accessToken}`,\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify(body),\n    });\n\n    return NextResponse.json(data, { status: 201 });\n  } catch (error) {\n    if (error instanceof BackendApiError) {\n      return NextResponse.json(\n        { detail: error.message || \"Failed to create conversation\" },\n        { status: error.status }\n      );\n    }\n    return NextResponse.json(\n      { detail: \"Internal server error\" },\n      { status: 500 }\n    );\n  }\n}{% endraw %}\n{%- else %}\n// Conversations API route - not configured (enable_conversation_persistence is false)\n{%- endif %}\n","frontend/src/app/api/conversations/[id]/messages/route.ts":"{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n{% raw %}import { NextRequest, NextResponse } from \"next/server\";\nimport { backendFetch, BackendApiError } from \"@/lib/server-api\";\n\ninterface RouteParams {\n  params: Promise<{ id: string }>;\n}\n\nexport async function GET(request: NextRequest, { params }: RouteParams) {\n  try {\n    const accessToken = request.cookies.get(\"access_token\")?.value;\n\n    if (!accessToken) {\n      return NextResponse.json({ detail: \"Not authenticated\" }, { status: 401 });\n    }\n\n    const { id } = await params;\n\n    const data = await backendFetch(`/api/v1/conversations/${id}/messages`, {\n      headers: {\n        Authorization: `Bearer ${accessToken}`,\n      },\n    });\n\n    return NextResponse.json(data);\n  } catch (error) {\n    if (error instanceof BackendApiError) {\n      return NextResponse.json(\n        { detail: error.message || \"Failed to fetch messages\" },\n        { status: error.status }\n      );\n    }\n    return NextResponse.json(\n      { detail: \"Internal server error\" },\n      { status: 500 }\n    );\n  }\n}{% endraw %}\n{%- else %}\n// Conversation messages API route - not configured (enable_conversation_persistence is false)\n{%- endif %}\n","frontend/src/app/api/conversations/[id]/route.ts":"{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n{% raw %}import { NextRequest, NextResponse } from \"next/server\";\nimport { backendFetch, BackendApiError } from \"@/lib/server-api\";\n\ninterface RouteParams {\n  params: Promise<{ id: string }>;\n}\n\nexport async function GET(request: NextRequest, { params }: RouteParams) {\n  try {\n    const accessToken = request.cookies.get(\"access_token\")?.value;\n\n    if (!accessToken) {\n      return NextResponse.json({ detail: \"Not authenticated\" }, { status: 401 });\n    }\n\n    const { id } = await params;\n\n    const data = await backendFetch(`/api/v1/conversations/${id}`, {\n      headers: {\n        Authorization: `Bearer ${accessToken}`,\n      },\n    });\n\n    return NextResponse.json(data);\n  } catch (error) {\n    if (error instanceof BackendApiError) {\n      return NextResponse.json(\n        { detail: error.message || \"Failed to fetch conversation\" },\n        { status: error.status }\n      );\n    }\n    return NextResponse.json(\n      { detail: \"Internal server error\" },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function PATCH(request: NextRequest, { params }: RouteParams) {\n  try {\n    const accessToken = request.cookies.get(\"access_token\")?.value;\n\n    if (!accessToken) {\n      return NextResponse.json({ detail: \"Not authenticated\" }, { status: 401 });\n    }\n\n    const { id } = await params;\n    const body = await request.json();\n\n    const data = await backendFetch(`/api/v1/conversations/${id}`, {\n      method: \"PATCH\",\n      headers: {\n        Authorization: `Bearer ${accessToken}`,\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify(body),\n    });\n\n    return NextResponse.json(data);\n  } catch (error) {\n    if (error instanceof BackendApiError) {\n      return NextResponse.json(\n        { detail: error.message || \"Failed to update conversation\" },\n        { status: error.status }\n      );\n    }\n    return NextResponse.json(\n      { detail: \"Internal server error\" },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function DELETE(request: NextRequest, { params }: RouteParams) {\n  try {\n    const accessToken = request.cookies.get(\"access_token\")?.value;\n\n    if (!accessToken) {\n      return NextResponse.json({ detail: \"Not authenticated\" }, { status: 401 });\n    }\n\n    const { id } = await params;\n\n    await backendFetch(`/api/v1/conversations/${id}`, {\n      method: \"DELETE\",\n      headers: {\n        Authorization: `Bearer ${accessToken}`,\n      },\n    });\n\n    return new NextResponse(null, { status: 204 });\n  } catch (error) {\n    if (error instanceof BackendApiError) {\n      return NextResponse.json(\n        { detail: error.message || \"Failed to delete conversation\" },\n        { status: error.status }\n      );\n    }\n    return NextResponse.json(\n      { detail: \"Internal server error\" },\n      { status: 500 }\n    );\n  }\n}{% endraw %}\n{%- else %}\n// Conversation detail API route - not configured (enable_conversation_persistence is false)\n{%- endif %}\n","frontend/src/app/globals.css":"@import \"tailwindcss\";\n\n@theme {\n  /* Light theme - neutral grays with better contrast */\n  --color-background: oklch(97% 0 0);\n  --color-foreground: oklch(15% 0 0);\n  --color-card: oklch(100% 0 0);\n  --color-card-foreground: oklch(15% 0 0);\n  --color-popover: oklch(100% 0 0);\n  --color-popover-foreground: oklch(15% 0 0);\n  --color-primary: oklch(25% 0 0);\n  --color-primary-foreground: oklch(98% 0 0);\n  --color-secondary: oklch(93% 0 0);\n  --color-secondary-foreground: oklch(20% 0 0);\n  --color-muted: oklch(93% 0 0);\n  --color-muted-foreground: oklch(45% 0 0);\n  --color-accent: oklch(93% 0 0);\n  --color-accent-foreground: oklch(20% 0 0);\n  --color-destructive: oklch(57.7% 0.245 27.325);\n  --color-destructive-foreground: oklch(98.5% 0 0);\n  --color-border: oklch(88% 0 0);\n  --color-input: oklch(88% 0 0);\n  --color-ring: oklch(25% 0 0);\n  --radius: 0.5rem;\n}\n\n/* Dark theme - triggered by system preference or .dark class */\n@media (prefers-color-scheme: dark) {\n  :root:not(.light) {\n    /* Dark theme - neutral with better contrast between sections */\n    --color-background: oklch(12% 0 0);\n    --color-foreground: oklch(95% 0 0);\n    --color-card: oklch(18% 0 0);\n    --color-card-foreground: oklch(95% 0 0);\n    --color-popover: oklch(18% 0 0);\n    --color-popover-foreground: oklch(95% 0 0);\n    --color-primary: oklch(95% 0 0);\n    --color-primary-foreground: oklch(12% 0 0);\n    --color-secondary: oklch(22% 0 0);\n    --color-secondary-foreground: oklch(95% 0 0);\n    --color-muted: oklch(22% 0 0);\n    --color-muted-foreground: oklch(60% 0 0);\n    --color-accent: oklch(25% 0 0);\n    --color-accent-foreground: oklch(95% 0 0);\n    --color-destructive: oklch(57.7% 0.245 27.325);\n    --color-destructive-foreground: oklch(98.5% 0 0);\n    --color-border: oklch(28% 0 0);\n    --color-input: oklch(28% 0 0);\n    --color-ring: oklch(80% 0 0);\n  }\n}\n\n/* Manual dark mode via .dark class */\n:root.dark {\n  /* Dark theme - neutral with better contrast between sections */\n  --color-background: oklch(12% 0 0);\n  --color-foreground: oklch(95% 0 0);\n  --color-card: oklch(18% 0 0);\n  --color-card-foreground: oklch(95% 0 0);\n  --color-popover: oklch(18% 0 0);\n  --color-popover-foreground: oklch(95% 0 0);\n  --color-primary: oklch(95% 0 0);\n  --color-primary-foreground: oklch(12% 0 0);\n  --color-secondary: oklch(22% 0 0);\n  --color-secondary-foreground: oklch(95% 0 0);\n  --color-muted: oklch(22% 0 0);\n  --color-muted-foreground: oklch(60% 0 0);\n  --color-accent: oklch(25% 0 0);\n  --color-accent-foreground: oklch(95% 0 0);\n  --color-destructive: oklch(57.7% 0.245 27.325);\n  --color-destructive-foreground: oklch(98.5% 0 0);\n  --color-border: oklch(28% 0 0);\n  --color-input: oklch(28% 0 0);\n  --color-ring: oklch(80% 0 0);\n}\n\n@layer base {\n  * {\n    @apply border-border;\n  }\n  body {\n    @apply bg-background text-foreground;\n  }\n}\n\n/* Custom scrollbar */\n@layer utilities {\n  .scrollbar-thin {\n    scrollbar-width: thin;\n    scrollbar-color: oklch(50% 0 0 / 0.3) transparent;\n  }\n\n  .scrollbar-thin::-webkit-scrollbar {\n    width: 6px;\n    height: 6px;\n  }\n\n  .scrollbar-thin::-webkit-scrollbar-track {\n    background: transparent;\n    border-radius: 3px;\n  }\n\n  .scrollbar-thin::-webkit-scrollbar-thumb {\n    background: oklch(50% 0 0 / 0.3);\n    border-radius: 3px;\n  }\n\n  .scrollbar-thin::-webkit-scrollbar-thumb:hover {\n    background: oklch(50% 0 0 / 0.5);\n  }\n}\n\n/* Code syntax highlighting for markdown */\n@layer base {\n  /* Light theme code highlighting */\n  pre code.hljs {\n    display: block;\n    overflow-x: auto;\n    padding: 0;\n    background: transparent;\n  }\n\n  code.hljs {\n    padding: 3px 5px;\n  }\n\n  .hljs {\n    color: #24292e;\n  }\n\n  .hljs-comment,\n  .hljs-quote {\n    color: #6a737d;\n    font-style: italic;\n  }\n\n  .hljs-keyword,\n  .hljs-selector-tag,\n  .hljs-literal {\n    color: #d73a49;\n  }\n\n  .hljs-name,\n  .hljs-tag {\n    color: #22863a;\n  }\n\n  .hljs-attr,\n  .hljs-attribute {\n    color: #6f42c1;\n  }\n\n  .hljs-variable,\n  .hljs-template-variable,\n  .hljs-regexp,\n  .hljs-link {\n    color: #005cc5;\n  }\n\n  .hljs-string,\n  .hljs-symbol,\n  .hljs-bullet {\n    color: #032f62;\n  }\n\n  .hljs-number {\n    color: #005cc5;\n  }\n\n  .hljs-meta,\n  .hljs-built_in,\n  .hljs-builtin-name,\n  .hljs-type,\n  .hljs-params {\n    color: #e36209;\n  }\n\n  .hljs-function .hljs-title {\n    color: #6f42c1;\n  }\n\n  .hljs-addition {\n    color: #22863a;\n    background-color: #f0fff4;\n  }\n\n  .hljs-deletion {\n    color: #b31d28;\n    background-color: #ffeef0;\n  }\n\n  /* Dark theme code highlighting */\n  .dark .hljs,\n  @media (prefers-color-scheme: dark) {\n    :root:not(.light) .hljs {\n      color: #e1e4e8;\n    }\n\n    :root:not(.light) .hljs-comment,\n    :root:not(.light) .hljs-quote {\n      color: #6a737d;\n    }\n\n    :root:not(.light) .hljs-keyword,\n    :root:not(.light) .hljs-selector-tag,\n    :root:not(.light) .hljs-literal {\n      color: #ff7b72;\n    }\n\n    :root:not(.light) .hljs-name,\n    :root:not(.light) .hljs-tag {\n      color: #7ee787;\n    }\n\n    :root:not(.light) .hljs-attr,\n    :root:not(.light) .hljs-attribute {\n      color: #d2a8ff;\n    }\n\n    :root:not(.light) .hljs-variable,\n    :root:not(.light) .hljs-template-variable,\n    :root:not(.light) .hljs-regexp,\n    :root:not(.light) .hljs-link {\n      color: #79c0ff;\n    }\n\n    :root:not(.light) .hljs-string,\n    :root:not(.light) .hljs-symbol,\n    :root:not(.light) .hljs-bullet {\n      color: #a5d6ff;\n    }\n\n    :root:not(.light) .hljs-number {\n      color: #79c0ff;\n    }\n\n    :root:not(.light) .hljs-meta,\n    :root:not(.light) .hljs-built_in,\n    :root:not(.light) .hljs-builtin-name,\n    :root:not(.light) .hljs-type,\n    :root:not(.light) .hljs-params {\n      color: #ffa657;\n    }\n\n    :root:not(.light) .hljs-function .hljs-title {\n      color: #d2a8ff;\n    }\n\n    :root:not(.light) .hljs-addition {\n      color: #aff5b4;\n      background-color: #033a16;\n    }\n\n    :root:not(.light) .hljs-deletion {\n      color: #ffdcd7;\n      background-color: #67060c;\n    }\n  }\n\n  .dark .hljs {\n    color: #e1e4e8;\n  }\n\n  .dark .hljs-comment,\n  .dark .hljs-quote {\n    color: #6a737d;\n  }\n\n  .dark .hljs-keyword,\n  .dark .hljs-selector-tag,\n  .dark .hljs-literal {\n    color: #ff7b72;\n  }\n\n  .dark .hljs-name,\n  .dark .hljs-tag {\n    color: #7ee787;\n  }\n\n  .dark .hljs-attr,\n  .dark .hljs-attribute {\n    color: #d2a8ff;\n  }\n\n  .dark .hljs-variable,\n  .dark .hljs-template-variable,\n  .dark .hljs-regexp,\n  .dark .hljs-link {\n    color: #79c0ff;\n  }\n\n  .dark .hljs-string,\n  .dark .hljs-symbol,\n  .dark .hljs-bullet {\n    color: #a5d6ff;\n  }\n\n  .dark .hljs-number {\n    color: #79c0ff;\n  }\n\n  .dark .hljs-meta,\n  .dark .hljs-built_in,\n  .dark .hljs-builtin-name,\n  .dark .hljs-type,\n  .dark .hljs-params {\n    color: #ffa657;\n  }\n\n  .dark .hljs-function .hljs-title {\n    color: #d2a8ff;\n  }\n\n  .dark .hljs-addition {\n    color: #aff5b4;\n    background-color: #033a16;\n  }\n\n  .dark .hljs-deletion {\n    color: #ffdcd7;\n    background-color: #67060c;\n  }\n}\n","frontend/src/app/providers.tsx":"\"use client\";\n\nimport { QueryClient, QueryClientProvider } from \"@tanstack/react-query\";\nimport { useState, type ReactNode } from \"react\";\nimport { ThemeProvider } from \"@/components/theme\";\n\ninterface ProvidersProps {\n  children: ReactNode;\n}\n\nexport function Providers({ children }: ProvidersProps) {\n  const [queryClient] = useState(\n    () =>\n      new QueryClient({\n        defaultOptions: {\n          queries: {\n            staleTime: 60 * 1000, // 1 minute\n            retry: 1,\n          },\n        },\n      })\n  );\n\n  return (\n    <QueryClientProvider client={queryClient}>\n      <ThemeProvider>{children}</ThemeProvider>\n    </QueryClientProvider>\n  );\n}\n","frontend/src/i18n.ts":"{%- if cookiecutter.enable_i18n %}\nimport { getRequestConfig } from \"next-intl/server\";\n\n// Supported locales\nexport const locales = [\"en\", \"pl\"] as const;\nexport type Locale = (typeof locales)[number];\n\nexport const defaultLocale: Locale = \"en\";\n\nexport default getRequestConfig(async ({ requestLocale }) => {\n  // This typically corresponds to the `[locale]` segment\n  let locale = await requestLocale;\n\n  // Ensure that a valid locale is used\n  if (!locale || !locales.includes(locale as Locale)) {\n    locale = defaultLocale;\n  }\n\n  return {\n    locale,\n    messages: (await import(`../messages/${locale}.json`)).default,\n  };\n});\n\nexport function getLocaleLabel(locale: Locale): string {\n  const labels: Record<Locale, string> = {\n    en: \"English\",\n    pl: \"Polski\",\n  };\n  return labels[locale];\n}\n{%- else %}\n// i18n is disabled\nexport const locales = [\"en\"] as const;\nexport type Locale = (typeof locales)[number];\nexport const defaultLocale: Locale = \"en\";\n{%- endif %}\n","frontend/src/stores/auth-store.test.ts":"{%- if cookiecutter.use_frontend and cookiecutter.use_jwt %}\nimport { describe, it, expect, beforeEach } from \"vitest\";\nimport { useAuthStore } from \"./auth-store\";\nimport type { User } from \"@/types\";\n\nconst createMockUser = (overrides?: Partial<User>): User => ({\n  id: \"test-id\",\n  email: \"test@example.com\",\n  is_active: true,\n  created_at: new Date().toISOString(),\n  ...overrides,\n});\n\ndescribe(\"Auth Store\", () => {\n  beforeEach(() => {\n    // Reset store before each test\n    useAuthStore.setState({\n      user: null,\n      isAuthenticated: false,\n      isLoading: false,\n    });\n  });\n\n  it(\"should have initial state\", () => {\n    const state = useAuthStore.getState();\n    expect(state.user).toBeNull();\n    expect(state.isAuthenticated).toBe(false);\n    expect(state.isLoading).toBe(false);\n  });\n\n  it(\"should set user on setUser\", () => {\n    const testUser = createMockUser();\n\n    useAuthStore.getState().setUser(testUser);\n\n    const state = useAuthStore.getState();\n    expect(state.user).toEqual(testUser);\n    expect(state.isAuthenticated).toBe(true);\n  });\n\n  it(\"should clear user on logout\", () => {\n    // First set a user\n    useAuthStore.getState().setUser(createMockUser());\n\n    // Then logout\n    useAuthStore.getState().logout();\n\n    const state = useAuthStore.getState();\n    expect(state.user).toBeNull();\n    expect(state.isAuthenticated).toBe(false);\n  });\n\n  it(\"should set loading state\", () => {\n    useAuthStore.getState().setLoading(true);\n    expect(useAuthStore.getState().isLoading).toBe(true);\n\n    useAuthStore.getState().setLoading(false);\n    expect(useAuthStore.getState().isLoading).toBe(false);\n  });\n});\n{%- elif cookiecutter.use_frontend %}\nimport { describe, it, expect } from \"vitest\";\n\ndescribe(\"Auth Store\", () => {\n  it.skip(\"JWT authentication not enabled\", () => {\n    // Skip auth store tests when JWT is not configured\n  });\n});\n{%- else %}\n/* Auth store tests - frontend not configured */\nexport {};\n{%- endif %}\n","frontend/src/stores/local-chat-store.ts":"\"use client\";\n\nimport { create } from \"zustand\";\nimport { persist } from \"zustand/middleware\";\nimport { nanoid } from \"nanoid\";\nimport type { ChatMessage, ToolCall } from \"@/types\";\n\nconst STORAGE_KEY = \"{{ cookiecutter.project_slug }}-local-chats\";\n\nexport interface LocalConversation {\n  id: string;\n  title: string | null;\n  messages: ChatMessage[];\n  createdAt: string;\n  updatedAt: string;\n}\n\ninterface LocalChatState {\n  conversations: LocalConversation[];\n  currentConversationId: string | null;\n\n  createConversation: () => string;\n  selectConversation: (id: string | null) => void;\n  deleteConversation: (id: string) => void;\n  renameConversation: (id: string, title: string) => void;\n  getCurrentConversation: () => LocalConversation | null;\n  getCurrentMessages: () => ChatMessage[];\n\n  addMessage: (message: ChatMessage) => void;\n  updateMessage: (\n    id: string,\n    updater: (msg: ChatMessage) => ChatMessage\n  ) => void;\n  addToolCall: (messageId: string, toolCall: ToolCall) => void;\n  updateToolCall: (\n    messageId: string,\n    toolCallId: string,\n    update: Partial<ToolCall>\n  ) => void;\n  clearCurrentMessages: () => void;\n\n  reset: () => void;\n}\n\nconst initialState = {\n  conversations: [] as LocalConversation[],\n  currentConversationId: null as string | null,\n};\n\nexport const useLocalChatStore = create<LocalChatState>()(\n  persist(\n    (set, get) => ({\n      ...initialState,\n\n      createConversation: () => {\n        const id = nanoid();\n        const now = new Date().toISOString();\n        const newConversation: LocalConversation = {\n          id,\n          title: null,\n          messages: [],\n          createdAt: now,\n          updatedAt: now,\n        };\n        set((state) => ({\n          conversations: [newConversation, ...state.conversations],\n          currentConversationId: id,\n        }));\n        return id;\n      },\n\n      selectConversation: (id) => {\n        set({ currentConversationId: id });\n      },\n\n      deleteConversation: (id) => {\n        set((state) => ({\n          conversations: state.conversations.filter((c) => c.id !== id),\n          currentConversationId:\n            state.currentConversationId === id\n              ? null\n              : state.currentConversationId,\n        }));\n      },\n\n      renameConversation: (id, title) => {\n        set((state) => ({\n          conversations: state.conversations.map((c) =>\n            c.id === id ? { ...c, title, updatedAt: new Date().toISOString() } : c\n          ),\n        }));\n      },\n\n      getCurrentConversation: () => {\n        const state = get();\n        return (\n          state.conversations.find((c) => c.id === state.currentConversationId) ||\n          null\n        );\n      },\n\n      getCurrentMessages: () => {\n        const state = get();\n        const conversation = state.conversations.find(\n          (c) => c.id === state.currentConversationId\n        );\n        return conversation?.messages || [];\n      },\n\n      addMessage: (message) => {\n        set((state) => {\n          const convId = state.currentConversationId;\n          if (!convId) return state;\n\n          return {\n            conversations: state.conversations.map((c) =>\n              c.id === convId\n                ? {\n                    ...c,\n                    messages: [...c.messages, message],\n                    updatedAt: new Date().toISOString(),\n                    title:\n                      c.title ||\n                      (message.role === \"user\"\n                        ? message.content.slice(0, 50) +\n                          (message.content.length > 50 ? \"...\" : \"\")\n                        : null),\n                  }\n                : c\n            ),\n          };\n        });\n      },\n\n      updateMessage: (id, updater) => {\n        set((state) => {\n          const convId = state.currentConversationId;\n          if (!convId) return state;\n\n          return {\n            conversations: state.conversations.map((c) =>\n              c.id === convId\n                ? {\n                    ...c,\n                    messages: c.messages.map((msg) =>\n                      msg.id === id ? updater(msg) : msg\n                    ),\n                    updatedAt: new Date().toISOString(),\n                  }\n                : c\n            ),\n          };\n        });\n      },\n\n      addToolCall: (messageId, toolCall) => {\n        set((state) => {\n          const convId = state.currentConversationId;\n          if (!convId) return state;\n\n          return {\n            conversations: state.conversations.map((c) =>\n              c.id === convId\n                ? {\n                    ...c,\n                    messages: c.messages.map((msg) =>\n                      msg.id === messageId\n                        ? {\n                            ...msg,\n                            toolCalls: [...(msg.toolCalls || []), toolCall],\n                          }\n                        : msg\n                    ),\n                    updatedAt: new Date().toISOString(),\n                  }\n                : c\n            ),\n          };\n        });\n      },\n\n      updateToolCall: (messageId, toolCallId, update) => {\n        set((state) => {\n          const convId = state.currentConversationId;\n          if (!convId) return state;\n\n          return {\n            conversations: state.conversations.map((c) =>\n              c.id === convId\n                ? {\n                    ...c,\n                    messages: c.messages.map((msg) =>\n                      msg.id === messageId\n                        ? {\n                            ...msg,\n                            toolCalls: msg.toolCalls?.map((tc) =>\n                              tc.id === toolCallId ? { ...tc, ...update } : tc\n                            ),\n                          }\n                        : msg\n                    ),\n                    updatedAt: new Date().toISOString(),\n                  }\n                : c\n            ),\n          };\n        });\n      },\n\n      clearCurrentMessages: () => {\n        set((state) => {\n          const convId = state.currentConversationId;\n          if (!convId) return state;\n\n          return {\n            conversations: state.conversations.map((c) =>\n              c.id === convId\n                ? { ...c, messages: [], updatedAt: new Date().toISOString() }\n                : c\n            ),\n          };\n        });\n      },\n\n      reset: () => set(initialState),\n    }),\n    {\n      name: STORAGE_KEY,\n      partialize: (state) => ({\n        conversations: state.conversations.map((c) => ({\n          ...c,\n          messages: c.messages.map((m) => ({\n            ...m,\n            timestamp:\n              m.timestamp instanceof Date\n                ? m.timestamp.toISOString()\n                : m.timestamp,\n          })),\n        })),\n        currentConversationId: state.currentConversationId,\n      }),\n      onRehydrateStorage: () => (state) => {\n        if (state) {\n          state.conversations = state.conversations.map((c) => ({\n            ...c,\n            messages: c.messages.map((m) => ({\n              ...m,\n              timestamp: new Date(m.timestamp as unknown as string),\n            })),\n          }));\n        }\n      },\n    }\n  )\n);\n","frontend/src/stores/conversation-store.ts":"{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n\"use client\";\n\nimport { create } from \"zustand\";\nimport type { Conversation, ConversationMessage } from \"@/types\";\n\ninterface ConversationState {\n  conversations: Conversation[];\n  currentConversationId: string | null;\n  currentMessages: ConversationMessage[];\n  isLoading: boolean;\n  error: string | null;\n\n  // Actions\n  setConversations: (conversations: Conversation[]) => void;\n  addConversation: (conversation: Conversation) => void;\n  updateConversation: (id: string, updates: Partial<Conversation>) => void;\n  removeConversation: (id: string) => void;\n  setCurrentConversationId: (id: string | null) => void;\n  setCurrentMessages: (messages: ConversationMessage[]) => void;\n  addMessage: (message: ConversationMessage) => void;\n  setLoading: (loading: boolean) => void;\n  setError: (error: string | null) => void;\n  reset: () => void;\n}\n\nconst initialState = {\n  conversations: [],\n  currentConversationId: null,\n  currentMessages: [],\n  isLoading: false,\n  error: null,\n};\n\nexport const useConversationStore = create<ConversationState>((set) => ({\n  ...initialState,\n\n  setConversations: (conversations) => set({ conversations }),\n\n  addConversation: (conversation) =>\n    set((state) => ({\n      conversations: [conversation, ...(state.conversations || [])],\n    })),\n\n  updateConversation: (id, updates) =>\n    set((state) => ({\n      conversations: (state.conversations || []).map((conv) =>\n        conv.id === id ? { ...conv, ...updates } : conv\n      ),\n    })),\n\n  removeConversation: (id) =>\n    set((state) => ({\n      conversations: (state.conversations || []).filter((conv) => conv.id !== id),\n      currentConversationId:\n        state.currentConversationId === id ? null : state.currentConversationId,\n    })),\n\n  setCurrentConversationId: (id) => set({ currentConversationId: id }),\n\n  setCurrentMessages: (messages) => set({ currentMessages: messages }),\n\n  addMessage: (message) =>\n    set((state) => ({\n      currentMessages: [...(state.currentMessages || []), message],\n    })),\n\n  setLoading: (loading) => set({ isLoading: loading }),\n\n  setError: (error) => set({ error }),\n\n  reset: () => set(initialState),\n}));\n{%- else %}\n// Conversation store - not configured (enable_conversation_persistence is false)\n{%- endif %}\n","frontend/src/stores/sidebar-store.ts":"\"use client\";\n\nimport { create } from \"zustand\";\n\ninterface SidebarState {\n  isOpen: boolean;\n  open: () => void;\n  close: () => void;\n  toggle: () => void;\n}\n\nexport const useSidebarStore = create<SidebarState>((set) => ({\n  isOpen: false,\n  open: () => set({ isOpen: true }),\n  close: () => set({ isOpen: false }),\n  toggle: () => set((state) => ({ isOpen: !state.isOpen })),\n}));\n","frontend/src/stores/chat-store.ts":"\"use client\";\n\nimport { create } from \"zustand\";\nimport type { ChatMessage, ToolCall } from \"@/types\";\n\ninterface ChatState {\n  messages: ChatMessage[];\n  isStreaming: boolean;\n\n  addMessage: (message: ChatMessage) => void;\n  updateMessage: (\n    id: string,\n    updater: (msg: ChatMessage) => ChatMessage\n  ) => void;\n  addToolCall: (messageId: string, toolCall: ToolCall) => void;\n  updateToolCall: (\n    messageId: string,\n    toolCallId: string,\n    update: Partial<ToolCall>\n  ) => void;\n  setStreaming: (streaming: boolean) => void;\n  clearMessages: () => void;\n}\n\nexport const useChatStore = create<ChatState>((set) => ({\n  messages: [],\n  isStreaming: false,\n\n  addMessage: (message) =>\n    set((state) => ({\n      messages: [...state.messages, message],\n    })),\n\n  updateMessage: (id, updater) =>\n    set((state) => ({\n      messages: state.messages.map((msg) => (msg.id === id ? updater(msg) : msg)),\n    })),\n\n  addToolCall: (messageId, toolCall) =>\n    set((state) => ({\n      messages: state.messages.map((msg) =>\n        msg.id === messageId\n          ? { ...msg, toolCalls: [...(msg.toolCalls || []), toolCall] }\n          : msg\n      ),\n    })),\n\n  updateToolCall: (messageId, toolCallId, update) =>\n    set((state) => ({\n      messages: state.messages.map((msg) =>\n        msg.id === messageId\n          ? {\n              ...msg,\n              toolCalls: msg.toolCalls?.map((tc) =>\n                tc.id === toolCallId ? { ...tc, ...update } : tc\n              ),\n            }\n          : msg\n      ),\n    })),\n\n  setStreaming: (streaming) => set({ isStreaming: streaming }),\n\n  clearMessages: () => set({ messages: [] }),\n}));\n","frontend/src/stores/auth-store.ts":"\"use client\";\n\nimport { create } from \"zustand\";\nimport { persist } from \"zustand/middleware\";\nimport type { User } from \"@/types\";\n\ninterface AuthState {\n  user: User | null;\n  isAuthenticated: boolean;\n  isLoading: boolean;\n\n  setUser: (user: User | null) => void;\n  setLoading: (loading: boolean) => void;\n  checkAuth: () => Promise<void>;\n  logout: () => void;\n}\n\nexport const useAuthStore = create<AuthState>()(\n  persist(\n    (set) => ({\n      user: null,\n      isAuthenticated: false,\n      isLoading: true,\n\n      setUser: (user) =>\n        set({\n          user,\n          isAuthenticated: user !== null,\n          isLoading: false,\n        }),\n\n      setLoading: (loading) => set({ isLoading: loading }),\n\n      checkAuth: async () => {\n        try {\n          set({ isLoading: true });\n          const response = await fetch(\"/api/auth/me\");\n          if (response.ok) {\n            const user = await response.json();\n            set({ user, isAuthenticated: true, isLoading: false });\n          } else {\n            set({ user: null, isAuthenticated: false, isLoading: false });\n          }\n        } catch {\n          set({ user: null, isAuthenticated: false, isLoading: false });\n        }\n      },\n\n      logout: () =>\n        set({\n          user: null,\n          isAuthenticated: false,\n          isLoading: false,\n        }),\n    }),\n    {\n      name: \"auth-storage\",\n      partialize: (state) => ({\n        user: state.user,\n        isAuthenticated: state.isAuthenticated,\n      }),\n    }\n  )\n);\n","frontend/src/stores/chat-sidebar-store.ts":"\"use client\";\n\nimport { create } from \"zustand\";\n\ninterface ChatSidebarState {\n  isOpen: boolean;\n  open: () => void;\n  close: () => void;\n  toggle: () => void;\n}\n\nexport const useChatSidebarStore = create<ChatSidebarState>((set) => ({\n  isOpen: false,\n  open: () => set({ isOpen: true }),\n  close: () => set({ isOpen: false }),\n  toggle: () => set((state) => ({ isOpen: !state.isOpen })),\n}));\n","frontend/src/stores/theme-store.ts":"{%- if cookiecutter.use_frontend %}\n\"use client\";\n\nimport { create } from \"zustand\";\nimport { persist } from \"zustand/middleware\";\n\nexport type Theme = \"light\" | \"dark\" | \"system\";\n\ninterface ThemeState {\n  theme: Theme;\n  setTheme: (theme: Theme) => void;\n}\n\nexport const useThemeStore = create<ThemeState>()(\n  persist(\n    (set) => ({\n      theme: \"system\",\n      setTheme: (theme) => set({ theme }),\n    }),\n    {\n      name: \"theme-storage\",\n    }\n  )\n);\n\n/**\n * Get the resolved theme (light or dark) based on the current theme setting.\n * When theme is \"system\", it checks the user's system preference.\n */\nexport function getResolvedTheme(theme: Theme): \"light\" | \"dark\" {\n  if (theme === \"system\") {\n    if (typeof window !== \"undefined\") {\n      return window.matchMedia(\"(prefers-color-scheme: dark)\").matches\n        ? \"dark\"\n        : \"light\";\n    }\n    return \"light\";\n  }\n  return theme;\n}\n{%- else %}\n/* Theme store - frontend not configured */\nexport {};\n{%- endif %}\n","frontend/src/stores/index.ts":"export { useAuthStore } from \"./auth-store\";\nexport { useChatStore } from \"./chat-store\";\nexport { useThemeStore } from \"./theme-store\";\nexport { useLocalChatStore } from \"./local-chat-store\";\nexport { useSidebarStore } from \"./sidebar-store\";\nexport { useChatSidebarStore } from \"./chat-sidebar-store\";\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nexport { useConversationStore } from \"./conversation-store\";\n{%- endif %}\n","frontend/src/components/ui/button.test.tsx":"{%- if cookiecutter.use_frontend %}\nimport { describe, it, expect, vi } from \"vitest\";\nimport { render, screen, fireEvent } from \"@testing-library/react\";\nimport { Button } from \"./button\";\n\ndescribe(\"Button component\", () => {\n  it(\"should render with children\", () => {\n    render(<Button>Click me</Button>);\n    expect(screen.getByRole(\"button\", { name: /click me/i })).toBeInTheDocument();\n  });\n\n  it(\"should handle click events\", () => {\n    const handleClick = vi.fn();\n    render(<Button onClick={handleClick}>Click me</Button>);\n\n    fireEvent.click(screen.getByRole(\"button\"));\n    expect(handleClick).toHaveBeenCalledTimes(1);\n  });\n\n  it(\"should apply variant classes\", () => {\n    render(<Button variant=\"destructive\">Delete</Button>);\n    const button = screen.getByRole(\"button\");\n    expect(button.className).toMatch(/destructive|red|danger/i);\n  });\n\n  it(\"should apply size classes\", () => {\n    render(<Button size=\"lg\">Large Button</Button>);\n    const button = screen.getByRole(\"button\");\n    // Check that the button has appropriate size styling\n    expect(button).toBeInTheDocument();\n  });\n\n  it(\"should be disabled when disabled prop is true\", () => {\n    render(<Button disabled>Disabled</Button>);\n    const button = screen.getByRole(\"button\");\n    expect(button).toBeDisabled();\n  });\n\n  it(\"should not trigger click when disabled\", () => {\n    const handleClick = vi.fn();\n    render(\n      <Button disabled onClick={handleClick}>\n        Disabled\n      </Button>\n    );\n\n    fireEvent.click(screen.getByRole(\"button\"));\n    expect(handleClick).not.toHaveBeenCalled();\n  });\n\n  it(\"should support custom className\", () => {\n    render(<Button className=\"custom-class\">Custom</Button>);\n    const button = screen.getByRole(\"button\");\n    expect(button.className).toContain(\"custom-class\");\n  });\n\n  it(\"should render as a link when asChild is used\", () => {\n    render(\n      <Button asChild>\n        <a href=\"/test\">Link Button</a>\n      </Button>\n    );\n    expect(screen.getByRole(\"link\")).toBeInTheDocument();\n  });\n\n  it(\"should support different button types\", () => {\n    render(<Button type=\"submit\">Submit</Button>);\n    const button = screen.getByRole(\"button\");\n    expect(button).toHaveAttribute(\"type\", \"submit\");\n  });\n});\n{%- else %}\n/* Button tests - frontend not configured */\nexport {};\n{%- endif %}\n","frontend/src/components/ui/card.tsx":"import * as React from \"react\";\nimport { cn } from \"@/lib/utils\";\n\nconst Card = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\n      \"rounded-xl border bg-card text-card-foreground shadow\",\n      className\n    )}\n    {...props}\n  />\n));\nCard.displayName = \"Card\";\n\nconst CardHeader = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\"flex flex-col space-y-1.5 p-6\", className)}\n    {...props}\n  />\n));\nCardHeader.displayName = \"CardHeader\";\n\nconst CardTitle = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\"font-semibold leading-none tracking-tight\", className)}\n    {...props}\n  />\n));\nCardTitle.displayName = \"CardTitle\";\n\nconst CardDescription = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\"text-sm text-muted-foreground\", className)}\n    {...props}\n  />\n));\nCardDescription.displayName = \"CardDescription\";\n\nconst CardContent = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div ref={ref} className={cn(\"p-6 pt-0\", className)} {...props} />\n));\nCardContent.displayName = \"CardContent\";\n\nconst CardFooter = React.forwardRef<\n  HTMLDivElement,\n  React.HTMLAttributes<HTMLDivElement>\n>(({ className, ...props }, ref) => (\n  <div\n    ref={ref}\n    className={cn(\"flex items-center p-6 pt-0\", className)}\n    {...props}\n  />\n));\nCardFooter.displayName = \"CardFooter\";\n\nexport {\n  Card,\n  CardHeader,\n  CardFooter,\n  CardTitle,\n  CardDescription,\n  CardContent,\n};\n","frontend/src/components/ui/sheet.tsx":"\"use client\";\n\nimport * as React from \"react\";\nimport { cn } from \"@/lib/utils\";\nimport { X } from \"lucide-react\";\n\ninterface SheetProps {\n  open: boolean;\n  onOpenChange: (open: boolean) => void;\n  children: React.ReactNode;\n}\n\ninterface SheetContentProps {\n  children: React.ReactNode;\n  className?: string;\n  side?: \"left\" | \"right\";\n}\n\nexport function Sheet({ open, onOpenChange, children }: SheetProps) {\n  React.useEffect(() => {\n    if (open) {\n      document.body.style.overflow = \"hidden\";\n    } else {\n      document.body.style.overflow = \"\";\n    }\n    return () => {\n      document.body.style.overflow = \"\";\n    };\n  }, [open]);\n\n  if (!open) return null;\n\n  return (\n    <div className=\"fixed inset-0 z-50\">\n      <div\n        className=\"fixed inset-0 bg-black/50 backdrop-blur-sm\"\n        onClick={() => onOpenChange(false)}\n        aria-hidden=\"true\"\n      />\n      {children}\n    </div>\n  );\n}\n\nexport function SheetContent({\n  children,\n  className,\n  side = \"left\",\n}: SheetContentProps) {\n  return (\n    <div\n      className={cn(\n        \"fixed inset-y-0 z-50 flex w-72 flex-col bg-background shadow-lg\",\n        \"animate-in duration-300\",\n        side === \"left\" ? \"left-0 slide-in-from-left\" : \"right-0 slide-in-from-right\",\n        className\n      )}\n    >\n      {children}\n    </div>\n  );\n}\n\nexport function SheetHeader({\n  children,\n  className,\n}: {\n  children: React.ReactNode;\n  className?: string;\n}) {\n  return (\n    <div className={cn(\"flex items-center justify-between border-b p-4\", className)}>\n      {children}\n    </div>\n  );\n}\n\nexport function SheetTitle({\n  children,\n  className,\n}: {\n  children: React.ReactNode;\n  className?: string;\n}) {\n  return <h2 className={cn(\"text-lg font-semibold\", className)}>{children}</h2>;\n}\n\nexport function SheetClose({\n  onClick,\n  className,\n}: {\n  onClick: () => void;\n  className?: string;\n}) {\n  return (\n    <button\n      onClick={onClick}\n      className={cn(\n        \"rounded-sm opacity-70 ring-offset-background transition-opacity\",\n        \"hover:opacity-100 focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2\",\n        \"h-10 w-10 flex items-center justify-center\",\n        className\n      )}\n    >\n      <X className=\"h-5 w-5\" />\n      <span className=\"sr-only\">Close</span>\n    </button>\n  );\n}\n","frontend/src/components/ui/label.tsx":"import * as React from \"react\";\nimport { cn } from \"@/lib/utils\";\n\nconst Label = React.forwardRef<\n  HTMLLabelElement,\n  React.LabelHTMLAttributes<HTMLLabelElement>\n>(({ className, ...props }, ref) => {\n  return (\n    <label\n      ref={ref}\n      className={cn(\n        \"text-sm font-medium leading-none peer-disabled:cursor-not-allowed peer-disabled:opacity-70\",\n        className\n      )}\n      {...props}\n    />\n  );\n});\nLabel.displayName = \"Label\";\n\nexport { Label };\n","frontend/src/components/ui/badge.tsx":"import * as React from \"react\";\nimport { cva, type VariantProps } from \"class-variance-authority\";\nimport { cn } from \"@/lib/utils\";\n\nconst badgeVariants = cva(\n  \"inline-flex items-center rounded-md border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2\",\n  {\n    variants: {\n      variant: {\n        default:\n          \"border-transparent bg-primary text-primary-foreground shadow hover:bg-primary/80\",\n        secondary:\n          \"border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80\",\n        destructive:\n          \"border-transparent bg-destructive text-destructive-foreground shadow hover:bg-destructive/80\",\n        outline: \"text-foreground\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n    },\n  }\n);\n\nexport interface BadgeProps\n  extends React.HTMLAttributes<HTMLDivElement>,\n    VariantProps<typeof badgeVariants> {}\n\nfunction Badge({ className, variant, ...props }: BadgeProps) {\n  return (\n    <div className={cn(badgeVariants({ variant }), className)} {...props} />\n  );\n}\n\nexport { Badge, badgeVariants };\n","frontend/src/components/ui/index.ts":"export { Button, buttonVariants } from \"./button\";\nexport { Input } from \"./input\";\nexport { Label } from \"./label\";\nexport {\n  Card,\n  CardHeader,\n  CardFooter,\n  CardTitle,\n  CardDescription,\n  CardContent,\n} from \"./card\";\nexport { Badge, badgeVariants } from \"./badge\";\nexport { Sheet, SheetContent, SheetHeader, SheetTitle, SheetClose } from \"./sheet\";\n","frontend/src/components/ui/button.tsx":"import * as React from \"react\";\nimport { cva, type VariantProps } from \"class-variance-authority\";\nimport { cn } from \"@/lib/utils\";\n\nconst buttonVariants = cva(\n  \"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0\",\n  {\n    variants: {\n      variant: {\n        default:\n          \"bg-primary text-primary-foreground shadow hover:bg-primary/90\",\n        destructive:\n          \"bg-destructive text-destructive-foreground shadow-sm hover:bg-destructive/90\",\n        outline:\n          \"border border-input bg-background shadow-sm hover:bg-accent hover:text-accent-foreground\",\n        secondary:\n          \"bg-secondary text-secondary-foreground shadow-sm hover:bg-secondary/80\",\n        ghost: \"hover:bg-accent hover:text-accent-foreground\",\n        link: \"text-primary underline-offset-4 hover:underline\",\n      },\n      size: {\n        default: \"h-9 px-4 py-2\",\n        sm: \"h-8 rounded-md px-3 text-xs\",\n        lg: \"h-10 rounded-md px-8\",\n        icon: \"h-9 w-9\",\n      },\n    },\n    defaultVariants: {\n      variant: \"default\",\n      size: \"default\",\n    },\n  }\n);\n\nexport interface ButtonProps\n  extends React.ButtonHTMLAttributes<HTMLButtonElement>,\n    VariantProps<typeof buttonVariants> {\n  asChild?: boolean;\n}\n\nconst Button = React.forwardRef<HTMLButtonElement, ButtonProps>(\n  ({ className, variant, size, asChild: _asChild, ...props }, ref) => {\n    // Note: asChild is extracted but not used - this component doesn't support Slot rendering\n    // If you need asChild support, install @radix-ui/react-slot and use Slot component\n    return (\n      <button\n        className={cn(buttonVariants({ variant, size, className }))}\n        ref={ref}\n        {...props}\n      />\n    );\n  }\n);\nButton.displayName = \"Button\";\n\nexport { Button, buttonVariants };\n","frontend/src/components/ui/input.tsx":"import * as React from \"react\";\nimport { cn } from \"@/lib/utils\";\n\nconst Input = React.forwardRef<HTMLInputElement, React.ComponentProps<\"input\">>(\n  ({ className, type, ...props }, ref) => {\n    return (\n      <input\n        type={type}\n        className={cn(\n          \"flex h-9 w-full rounded-md border border-input bg-transparent px-3 py-1 text-base shadow-sm transition-colors file:border-0 file:bg-transparent file:text-sm file:font-medium file:text-foreground placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:cursor-not-allowed disabled:opacity-50 md:text-sm\",\n          className\n        )}\n        ref={ref}\n        {...props}\n      />\n    );\n  }\n);\nInput.displayName = \"Input\";\n\nexport { Input };\n","frontend/src/components/chat/chat-container.tsx":"\"use client\";\n\nimport { useEffect, useRef, useCallback } from \"react\";\nimport { useChat, useLocalChat } from \"@/hooks\";\nimport { MessageList } from \"./message-list\";\nimport { ChatInput } from \"./chat-input\";\nimport { ToolApprovalDialog } from \"./tool-approval-dialog\";\nimport { Button } from \"@/components/ui\";\nimport { Wifi, WifiOff, RotateCcw, Bot } from \"lucide-react\";\nimport type { PendingApproval, Decision } from \"@/types\";\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nimport { useConversationStore, useChatStore, useAuthStore } from \"@/stores\";\nimport { useConversations } from \"@/hooks\";\n{%- endif %}\n\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\ninterface ChatContainerProps {\n  useLocalStorage?: boolean;\n}\n\nexport function ChatContainer({ useLocalStorage = false }: ChatContainerProps) {\n  const { isAuthenticated } = useAuthStore();\n\n  const shouldUseLocal = useLocalStorage || !isAuthenticated;\n\n  if (shouldUseLocal) {\n    return <LocalChatContainer />;\n  }\n\n  return <AuthenticatedChatContainer />;\n}\n\nfunction AuthenticatedChatContainer() {\n  const { currentConversationId, currentMessages } = useConversationStore();\n  const { addMessage: addChatMessage } = useChatStore();\n  const { fetchConversations } = useConversations();\n  const prevConversationIdRef = useRef<string | null | undefined>(undefined);\n\n  const handleConversationCreated = useCallback((conversationId: string) => {\n    fetchConversations();\n  }, [fetchConversations]);\n\n  const {\n    messages,\n    isConnected,\n    isProcessing,\n    connect,\n    disconnect,\n    sendMessage,\n    clearMessages,\n    pendingApproval,\n    sendResumeDecisions,\n  } = useChat({\n    conversationId: currentConversationId,\n    onConversationCreated: handleConversationCreated,\n  });\n\n  const messagesEndRef = useRef<HTMLDivElement>(null);\n\n  // Clear messages when conversation changes, but NOT when going from null to a new ID\n  // (that happens when a new chat is saved - we want to keep the messages)\n  useEffect(() => {\n    const prevId = prevConversationIdRef.current;\n    const currId = currentConversationId;\n\n    // Skip initial mount\n    if (prevId === undefined) {\n      prevConversationIdRef.current = currId;\n      return;\n    }\n\n    // Clear messages when:\n    // 1. Going from a conversation to null (new chat)\n    // 2. Switching between two different conversations\n    // Do NOT clear when going from null to a conversation (new chat being saved)\n    const shouldClear =\n      currId === null || // Going to new chat\n      (prevId !== null && prevId !== currId); // Switching between conversations\n\n    if (shouldClear) {\n      clearMessages();\n    }\n\n    prevConversationIdRef.current = currId;\n  }, [currentConversationId, clearMessages]);\n\n  // Load messages from conversation store when switching to a saved conversation\n  useEffect(() => {\n    if (currentMessages.length > 0) {\n      currentMessages.forEach((msg) => {\n        addChatMessage({\n          id: msg.id,\n          role: msg.role,\n          content: msg.content,\n          timestamp: new Date(msg.created_at),\n          toolCalls: msg.tool_calls?.map((tc) => ({\n            id: tc.tool_call_id,\n            name: tc.tool_name,\n            args: tc.args,\n            result: tc.result,\n            status: tc.status === \"failed\" ? \"error\" : tc.status,\n          })),\n        });\n      });\n    }\n  }, [currentMessages, addChatMessage]);\n\n  useEffect(() => {\n    connect();\n    return () => disconnect();\n  }, [connect, disconnect]);\n\n  useEffect(() => {\n    messagesEndRef.current?.scrollIntoView({ behavior: \"smooth\" });\n  }, [messages]);\n\n  return (\n    <ChatUI\n      messages={messages}\n      isConnected={isConnected}\n      isProcessing={isProcessing}\n      sendMessage={sendMessage}\n      clearMessages={clearMessages}\n      messagesEndRef={messagesEndRef}\n      pendingApproval={pendingApproval}\n      onResumeDecisions={sendResumeDecisions}\n    />\n  );\n}\n{%- endif %}\n\nfunction LocalChatContainer() {\n  const {\n    messages,\n    isConnected,\n    isProcessing,\n    connect,\n    disconnect,\n    sendMessage,\n    clearMessages,\n    pendingApproval,\n    sendResumeDecisions,\n  } = useLocalChat();\n\n  const messagesEndRef = useRef<HTMLDivElement>(null);\n\n  useEffect(() => {\n    connect();\n    return () => disconnect();\n  }, [connect, disconnect]);\n\n  useEffect(() => {\n    messagesEndRef.current?.scrollIntoView({ behavior: \"smooth\" });\n  }, [messages]);\n\n  return (\n    <ChatUI\n      messages={messages}\n      isConnected={isConnected}\n      isProcessing={isProcessing}\n      sendMessage={sendMessage}\n      clearMessages={clearMessages}\n      messagesEndRef={messagesEndRef}\n      pendingApproval={pendingApproval}\n      onResumeDecisions={sendResumeDecisions}\n    />\n  );\n}\n\n{%- if not (cookiecutter.enable_conversation_persistence and cookiecutter.use_database) %}\nexport function ChatContainer() {\n  return <LocalChatContainer />;\n}\n{%- endif %}\n\ninterface ChatUIProps {\n  messages: import(\"@/types\").ChatMessage[];\n  isConnected: boolean;\n  isProcessing: boolean;\n  sendMessage: (content: string) => void;\n  clearMessages: () => void;\n  messagesEndRef: React.RefObject<HTMLDivElement | null>;\n  // Human-in-the-Loop support\n  pendingApproval?: PendingApproval | null;\n  onResumeDecisions?: (decisions: Decision[]) => void;\n}\n\nfunction ChatUI({\n  messages,\n  isConnected,\n  isProcessing,\n  sendMessage,\n  clearMessages,\n  messagesEndRef,\n  pendingApproval,\n  onResumeDecisions,\n}: ChatUIProps) {\n  return (\n    <div className=\"flex flex-col h-full max-w-4xl mx-auto w-full\">\n      <div className=\"flex-1 overflow-y-auto px-2 py-4 sm:px-4 sm:py-6 scrollbar-thin\">\n        {messages.length === 0 ? (\n          <div className=\"flex flex-col items-center justify-center h-full text-muted-foreground gap-4\">\n            <div className=\"w-14 h-14 sm:w-16 sm:h-16 rounded-full bg-secondary flex items-center justify-center\">\n              <Bot className=\"h-7 w-7 sm:h-8 sm:w-8\" />\n            </div>\n            <div className=\"text-center px-4\">\n              <p className=\"text-base sm:text-lg font-medium text-foreground\">AI Assistant</p>\n              <p className=\"text-sm\">Start a conversation to get help</p>\n            </div>\n          </div>\n        ) : (\n          <MessageList messages={messages} />\n        )}\n        <div ref={messagesEndRef} />\n      </div>\n\n      {/* Human-in-the-Loop: Tool Approval Dialog */}\n      {pendingApproval && onResumeDecisions && (\n        <div className=\"px-2 pb-2 sm:px-4 sm:pb-2\">\n          <ToolApprovalDialog\n            actionRequests={pendingApproval.actionRequests}\n            reviewConfigs={pendingApproval.reviewConfigs}\n            onDecisions={onResumeDecisions}\n            disabled={!isConnected}\n          />\n        </div>\n      )}\n\n      <div className=\"px-2 pb-2 sm:px-4 sm:pb-4\">\n        <div className=\"rounded-xl border bg-card shadow-sm p-3 sm:p-4\">\n          <ChatInput\n            onSend={sendMessage}\n            disabled={!isConnected || isProcessing || !!pendingApproval}\n            isProcessing={isProcessing}\n          />\n          <div className=\"flex items-center justify-between mt-3 pt-3 border-t\">\n            <div className=\"flex items-center gap-2\">\n              {isConnected ? (\n                <Wifi className=\"h-3.5 w-3.5 text-green-500\" />\n              ) : (\n                <WifiOff className=\"h-3.5 w-3.5 text-red-500\" />\n              )}\n              <span className=\"text-xs text-muted-foreground\">\n                {isConnected ? \"Connected\" : \"Disconnected\"}\n              </span>\n            </div>\n            <Button\n              variant=\"ghost\"\n              size=\"sm\"\n              onClick={clearMessages}\n              className=\"text-xs h-8 px-3\"\n            >\n              <RotateCcw className=\"h-3.5 w-3.5 mr-1.5\" />\n              Reset\n            </Button>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n","frontend/src/components/chat/markdown-content.tsx":"\"use client\";\n\nimport ReactMarkdown from \"react-markdown\";\nimport remarkGfm from \"remark-gfm\";\nimport rehypeHighlight from \"rehype-highlight\";\nimport { CopyButton } from \"./copy-button\";\n\ninterface MarkdownContentProps {\n  content: string;\n}\n\nexport function MarkdownContent({ content }: MarkdownContentProps) {\n  return (\n    <ReactMarkdown\n      remarkPlugins={[remarkGfm]}\n      rehypePlugins={[rehypeHighlight]}\n      components={% raw %}{{{% endraw %}\n        pre({ children, ...props }) {\n          const codeElement = children as React.ReactElement<{\n            children?: string;\n          }>;\n          const codeContent =\n            typeof codeElement?.props?.children === \"string\"\n              ? codeElement.props.children\n              : \"\";\n\n          return (\n            <div className=\"group relative\">\n              <pre\n                className=\"overflow-x-auto rounded-lg bg-muted/50 p-3 text-xs\"\n                {...props}\n              >\n                {children}\n              </pre>\n              {codeContent && (\n                <div className=\"absolute right-2 top-2\">\n                  <CopyButton text={codeContent} className=\"opacity-100\" />\n                </div>\n              )}\n            </div>\n          );\n        },\n        code({ className, children, ...props }) {\n          const isInline = !className;\n          if (isInline) {\n            return (\n              <code\n                className=\"rounded bg-muted px-1.5 py-0.5 text-xs font-mono\"\n                {...props}\n              >\n                {children}\n              </code>\n            );\n          }\n          return (\n            <code className={className} {...props}>\n              {children}\n            </code>\n          );\n        },\n        a({ href, children, ...props }) {\n          return (\n            <a\n              href={href}\n              target=\"_blank\"\n              rel=\"noopener noreferrer\"\n              className=\"text-primary underline hover:text-primary/80\"\n              {...props}\n            >\n              {children}\n            </a>\n          );\n        },\n        p({ children, ...props }) {\n          return (\n            <p className=\"mb-2 last:mb-0\" {...props}>\n              {children}\n            </p>\n          );\n        },\n        ul({ children, ...props }) {\n          return (\n            <ul className=\"mb-2 ml-4 list-disc last:mb-0\" {...props}>\n              {children}\n            </ul>\n          );\n        },\n        ol({ children, ...props }) {\n          return (\n            <ol className=\"mb-2 ml-4 list-decimal last:mb-0\" {...props}>\n              {children}\n            </ol>\n          );\n        },\n        li({ children, ...props }) {\n          return (\n            <li className=\"mb-1\" {...props}>\n              {children}\n            </li>\n          );\n        },\n        h1({ children, ...props }) {\n          return (\n            <h1 className=\"mb-2 text-lg font-bold\" {...props}>\n              {children}\n            </h1>\n          );\n        },\n        h2({ children, ...props }) {\n          return (\n            <h2 className=\"mb-2 text-base font-bold\" {...props}>\n              {children}\n            </h2>\n          );\n        },\n        h3({ children, ...props }) {\n          return (\n            <h3 className=\"mb-2 text-sm font-bold\" {...props}>\n              {children}\n            </h3>\n          );\n        },\n        blockquote({ children, ...props }) {\n          return (\n            <blockquote\n              className=\"mb-2 border-l-2 border-muted-foreground/50 pl-3 italic\"\n              {...props}\n            >\n              {children}\n            </blockquote>\n          );\n        },\n        table({ children, ...props }) {\n          return (\n            <div className=\"mb-2 overflow-x-auto\">\n              <table className=\"min-w-full text-sm\" {...props}>\n                {children}\n              </table>\n            </div>\n          );\n        },\n        th({ children, ...props }) {\n          return (\n            <th\n              className=\"border-b border-muted px-2 py-1 text-left font-semibold\"\n              {...props}\n            >\n              {children}\n            </th>\n          );\n        },\n        td({ children, ...props }) {\n          return (\n            <td className=\"border-b border-muted/50 px-2 py-1\" {...props}>\n              {children}\n            </td>\n          );\n        },\n        hr({ ...props }) {\n          return <hr className=\"my-3 border-muted\" {...props} />;\n        },\n      {% raw %}}}{% endraw %}\n    >\n      {content}\n    </ReactMarkdown>\n  );\n}\n","frontend/src/components/chat/tool-approval-dialog.tsx":"\"use client\";\n\nimport { useState } from \"react\";\nimport { Button } from \"@/components/ui\";\nimport type { ActionRequest, ReviewConfig, Decision } from \"@/types\";\nimport { Wrench, AlertTriangle } from \"lucide-react\";\nimport { cn } from \"@/lib/utils\";\n\ninterface ToolApprovalDialogProps {\n  actionRequests: ActionRequest[];\n  reviewConfigs: ReviewConfig[];\n  onDecisions: (decisions: Decision[]) => void;\n  disabled?: boolean;\n}\n\nexport function ToolApprovalDialog({\n  actionRequests,\n  reviewConfigs,\n  onDecisions,\n  disabled = false,\n}: ToolApprovalDialogProps) {\n  // Store edited args for each action\n  const [editedArgs, setEditedArgs] = useState<Record<string, string>>(() =>\n    Object.fromEntries(\n      actionRequests.map((a) => [a.id, JSON.stringify(a.args, null, 2)])\n    )\n  );\n  const [hasChanges, setHasChanges] = useState(false);\n\n  const handleArgsChange = (id: string, text: string) => {\n    setEditedArgs((prev) => ({ ...prev, [id]: text }));\n    setHasChanges(true);\n  };\n\n  const handleCancel = () => {\n    // Reset to original args\n    setEditedArgs(\n      Object.fromEntries(\n        actionRequests.map((a) => [a.id, JSON.stringify(a.args, null, 2)])\n      )\n    );\n    setHasChanges(false);\n  };\n\n  const handleSave = () => {\n    // Validate all JSON\n    for (const id of Object.keys(editedArgs)) {\n      try {\n        JSON.parse(editedArgs[id]);\n      } catch {\n        return; // Invalid JSON, don't save\n      }\n    }\n    setHasChanges(false);\n  };\n\n  const handleSubmit = () => {\n    const decisions: Decision[] = actionRequests.map((a) => {\n      try {\n        const parsed = JSON.parse(editedArgs[a.id]);\n        const original = JSON.stringify(a.args);\n        const edited = JSON.stringify(parsed);\n\n        if (original !== edited) {\n          return {\n            type: \"edit\" as const,\n            editedAction: { id: a.id, tool_name: a.tool_name, args: parsed },\n          };\n        }\n        return { type: \"approve\" as const };\n      } catch {\n        return { type: \"reject\" as const };\n      }\n    });\n    onDecisions(decisions);\n  };\n\n  return (\n    <div className=\"rounded-lg border border-yellow-500/50 bg-yellow-50/5 p-3 space-y-3\">\n      <div className=\"flex items-center gap-2 text-sm text-yellow-600\">\n        <AlertTriangle className=\"h-4 w-4\" />\n        <span className=\"font-medium\">Tool approval required</span>\n      </div>\n\n      {actionRequests.map((action) => (\n        <div key={action.id} className=\"space-y-1.5\">\n          <div className=\"flex items-center gap-2\">\n            <Wrench className=\"h-3.5 w-3.5 text-muted-foreground\" />\n            <code className=\"text-xs font-semibold\">{action.tool_name}</code>\n          </div>\n          <textarea\n            className={cn(\n              \"w-full p-2 text-xs font-mono bg-background border rounded resize-none\",\n              \"min-h-[80px] max-h-[200px]\"\n            )}\n            value={editedArgs[action.id]}\n            onChange={(e) => handleArgsChange(action.id, e.target.value)}\n            disabled={disabled}\n            rows={Math.min(10, (editedArgs[action.id]?.split(\"\\n\").length || 3) + 1)}\n          />\n        </div>\n      ))}\n\n      <div className=\"flex justify-end gap-2 pt-1 border-t\">\n        {hasChanges && (\n          <>\n            <Button\n              size=\"sm\"\n              variant=\"ghost\"\n              className=\"h-7 text-xs\"\n              onClick={handleCancel}\n              disabled={disabled}\n            >\n              Cancel\n            </Button>\n            <Button\n              size=\"sm\"\n              variant=\"outline\"\n              className=\"h-7 text-xs\"\n              onClick={handleSave}\n              disabled={disabled}\n            >\n              Save\n            </Button>\n          </>\n        )}\n        <Button\n          size=\"sm\"\n          className=\"h-7 text-xs\"\n          onClick={handleSubmit}\n          disabled={disabled}\n        >\n          Submit ({actionRequests.length})\n        </Button>\n      </div>\n    </div>\n  );\n}\n","frontend/src/components/chat/conversation-sidebar.tsx":"{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n\"use client\";\n\nimport { useEffect, useState } from \"react\";\nimport { useConversations } from \"@/hooks\";\nimport { Button } from \"@/components/ui\";\nimport { Sheet, SheetContent, SheetHeader, SheetTitle, SheetClose } from \"@/components/ui\";\nimport { cn } from \"@/lib/utils\";\nimport { useChatSidebarStore } from \"@/stores\";\nimport {\n  MessageSquarePlus,\n  MessageSquare,\n  Trash2,\n  Archive,\n  MoreVertical,\n  Pencil,\n  ChevronLeft,\n  ChevronRight,\n} from \"lucide-react\";\nimport type { Conversation } from \"@/types\";\n\ninterface ConversationItemProps {\n  conversation: Conversation;\n  isActive: boolean;\n  onSelect: () => void;\n  onDelete: () => void;\n  onArchive: () => void;\n  onRename: (title: string) => void;\n}\n\nfunction ConversationItem({\n  conversation,\n  isActive,\n  onSelect,\n  onDelete,\n  onArchive,\n  onRename,\n}: ConversationItemProps) {\n  const [showMenu, setShowMenu] = useState(false);\n  const [isEditing, setIsEditing] = useState(false);\n  const [editTitle, setEditTitle] = useState(conversation.title || \"\");\n\n  const handleRename = () => {\n    if (editTitle.trim()) {\n      onRename(editTitle.trim());\n    }\n    setIsEditing(false);\n  };\n\n  const displayTitle =\n    conversation.title ||\n    `Chat ${new Date(conversation.created_at).toLocaleDateString()}`;\n\n  return (\n    <div\n      className={cn(\n        \"group relative flex items-center gap-2 rounded-lg px-3 py-3 text-sm transition-colors cursor-pointer min-h-[44px]\",\n        isActive\n          ? \"bg-secondary text-secondary-foreground\"\n          : \"text-muted-foreground hover:bg-secondary/50 hover:text-secondary-foreground\"\n      )}\n      onClick={onSelect}\n    >\n      <MessageSquare className=\"h-4 w-4 shrink-0\" />\n      {isEditing ? (\n        <input\n          type=\"text\"\n          value={editTitle}\n          onChange={(e) => setEditTitle(e.target.value)}\n          onBlur={handleRename}\n          onKeyDown={(e) => {\n            if (e.key === \"Enter\") handleRename();\n            if (e.key === \"Escape\") setIsEditing(false);\n          }}\n          className=\"flex-1 bg-transparent outline-none text-foreground\"\n          autoFocus\n          onClick={(e) => e.stopPropagation()}\n        />\n      ) : (\n        <span className=\"flex-1 truncate\">{displayTitle}</span>\n      )}\n\n      <div className=\"relative\">\n        <Button\n          variant=\"ghost\"\n          size=\"sm\"\n          className={cn(\n            \"h-8 w-8 p-0 opacity-0 group-hover:opacity-100 touch:opacity-100\",\n            showMenu && \"opacity-100\"\n          )}\n          onClick={(e) => {\n            e.stopPropagation();\n            setShowMenu(!showMenu);\n          }}\n        >\n          <MoreVertical className=\"h-4 w-4\" />\n        </Button>\n\n        {showMenu && (\n          <>\n            <div\n              className=\"fixed inset-0 z-10\"\n              onClick={() => setShowMenu(false)}\n            />\n            <div className=\"absolute right-0 top-8 z-20 w-40 rounded-md border bg-popover shadow-lg\">\n              <button\n                className=\"flex w-full items-center gap-2 px-3 py-3 text-sm hover:bg-secondary min-h-[44px]\"\n                onClick={(e) => {\n                  e.stopPropagation();\n                  setIsEditing(true);\n                  setShowMenu(false);\n                }}\n              >\n                <Pencil className=\"h-4 w-4\" />\n                Rename\n              </button>\n              <button\n                className=\"flex w-full items-center gap-2 px-3 py-3 text-sm hover:bg-secondary min-h-[44px]\"\n                onClick={(e) => {\n                  e.stopPropagation();\n                  onArchive();\n                  setShowMenu(false);\n                }}\n              >\n                <Archive className=\"h-4 w-4\" />\n                Archive\n              </button>\n              <button\n                className=\"flex w-full items-center gap-2 px-3 py-3 text-sm text-destructive hover:bg-destructive/10 min-h-[44px]\"\n                onClick={(e) => {\n                  e.stopPropagation();\n                  onDelete();\n                  setShowMenu(false);\n                }}\n              >\n                <Trash2 className=\"h-4 w-4\" />\n                Delete\n              </button>\n            </div>\n          </>\n        )}\n      </div>\n    </div>\n  );\n}\n\ninterface ConversationListProps {\n  conversations: Conversation[];\n  currentConversationId: string | null;\n  isLoading: boolean;\n  onSelect: (id: string) => void;\n  onDelete: (id: string) => void;\n  onArchive: (id: string) => void;\n  onRename: (id: string, title: string) => void;\n  onNewChat: () => void;\n  onNavigate?: () => void;\n}\n\nfunction ConversationList({\n  conversations = [],\n  currentConversationId,\n  isLoading,\n  onSelect,\n  onDelete,\n  onArchive,\n  onRename,\n  onNewChat,\n  onNavigate,\n}: ConversationListProps) {\n  const activeConversations = (conversations ?? []).filter((c) => !c.is_archived);\n\n  const handleSelect = (id: string) => {\n    onSelect(id);\n    onNavigate?.();\n  };\n\n  const handleNewChat = () => {\n    onNewChat();\n    onNavigate?.();\n  };\n\n  return (\n    <>\n      <div className=\"p-3\">\n        <Button\n          variant=\"outline\"\n          size=\"sm\"\n          className=\"w-full justify-start gap-2 h-10\"\n          onClick={handleNewChat}\n        >\n          <MessageSquarePlus className=\"h-4 w-4\" />\n          New Chat\n        </Button>\n      </div>\n\n      <div className=\"flex-1 overflow-y-auto px-3 pb-3 scrollbar-thin\">\n        {isLoading && conversations.length === 0 ? (\n          <div className=\"flex items-center justify-center py-8 text-sm text-muted-foreground\">\n            Loading...\n          </div>\n        ) : activeConversations.length === 0 ? (\n          <div className=\"flex flex-col items-center justify-center py-8 text-center text-sm text-muted-foreground\">\n            <MessageSquare className=\"h-8 w-8 mb-2 opacity-50\" />\n            <p>No conversations yet</p>\n            <p className=\"text-xs mt-1\">Start a new chat to begin</p>\n          </div>\n        ) : (\n          <div className=\"space-y-1\">\n            {activeConversations.map((conversation) => (\n              <ConversationItem\n                key={conversation.id}\n                conversation={conversation}\n                isActive={conversation.id === currentConversationId}\n                onSelect={() => handleSelect(conversation.id)}\n                onDelete={() => onDelete(conversation.id)}\n                onArchive={() => onArchive(conversation.id)}\n                onRename={(title) => onRename(conversation.id, title)}\n              />\n            ))}\n          </div>\n        )}\n      </div>\n    </>\n  );\n}\n\ninterface ConversationSidebarProps {\n  className?: string;\n}\n\nexport function ConversationSidebar({ className }: ConversationSidebarProps) {\n  const [isCollapsed, setIsCollapsed] = useState(false);\n  const { isOpen, close } = useChatSidebarStore();\n  const {\n    conversations,\n    currentConversationId,\n    isLoading,\n    fetchConversations,\n    selectConversation,\n    deleteConversation,\n    archiveConversation,\n    renameConversation,\n    startNewChat,\n  } = useConversations();\n\n  useEffect(() => {\n    fetchConversations();\n  }, [fetchConversations]);\n\n  const listProps = {\n    conversations,\n    currentConversationId,\n    isLoading,\n    onSelect: selectConversation,\n    onDelete: deleteConversation,\n    onArchive: archiveConversation,\n    onRename: renameConversation,\n    onNewChat: startNewChat,\n  };\n\n  if (isCollapsed) {\n    return (\n      <div\n        className={cn(\n          \"hidden md:flex flex-col items-center border-r bg-background py-4 w-12\",\n          className\n        )}\n      >\n        <Button\n          variant=\"ghost\"\n          size=\"sm\"\n          className=\"h-10 w-10 p-0 mb-4\"\n          onClick={() => setIsCollapsed(false)}\n        >\n          <ChevronRight className=\"h-4 w-4\" />\n        </Button>\n        <Button\n          variant=\"ghost\"\n          size=\"sm\"\n          className=\"h-10 w-10 p-0\"\n          onClick={startNewChat}\n          title=\"New Chat\"\n        >\n          <MessageSquarePlus className=\"h-4 w-4\" />\n        </Button>\n      </div>\n    );\n  }\n\n  return (\n    <>\n      <aside\n        className={cn(\n          \"hidden md:flex w-64 shrink-0 flex-col border-r bg-background\",\n          className\n        )}\n      >\n        <div className=\"flex items-center justify-between border-b px-4 py-3 h-12\">\n          <h2 className=\"font-semibold text-sm\">Conversations</h2>\n          <Button\n            variant=\"ghost\"\n            size=\"sm\"\n            className=\"h-8 w-8 p-0\"\n            onClick={() => setIsCollapsed(true)}\n          >\n            <ChevronLeft className=\"h-4 w-4\" />\n          </Button>\n        </div>\n        <ConversationList {...listProps} />\n      </aside>\n\n      <Sheet open={isOpen} onOpenChange={close}>\n        <SheetContent side=\"left\" className=\"w-80 p-0\">\n          <SheetHeader className=\"h-12 px-4\">\n            <SheetTitle>Conversations</SheetTitle>\n            <SheetClose onClick={close} />\n          </SheetHeader>\n          <div className=\"flex flex-col h-[calc(100%-48px)]\">\n            <ConversationList {...listProps} onNavigate={close} />\n          </div>\n        </SheetContent>\n      </Sheet>\n    </>\n  );\n}\n{%- else %}\nexport {};\n{%- endif %}\n","frontend/src/components/chat/copy-button.tsx":"\"use client\";\n\nimport { useState } from \"react\";\nimport { Button } from \"@/components/ui\";\nimport { Check, Copy } from \"lucide-react\";\nimport { cn } from \"@/lib/utils\";\n\ninterface CopyButtonProps {\n  text: string;\n  className?: string;\n  size?: \"sm\" | \"default\";\n}\n\nexport function CopyButton({ text, className, size = \"sm\" }: CopyButtonProps) {\n  const [copied, setCopied] = useState(false);\n\n  const handleCopy = async (e: React.MouseEvent) => {\n    e.stopPropagation();\n    try {\n      await navigator.clipboard.writeText(text);\n      setCopied(true);\n      setTimeout(() => setCopied(false), 2000);\n    } catch {\n      console.error(\"Failed to copy text\");\n    }\n  };\n\n  return (\n    <Button\n      variant=\"ghost\"\n      size={size}\n      className={cn(\n        \"h-6 w-6 p-0 opacity-0 group-hover:opacity-100 transition-opacity\",\n        className\n      )}\n      onClick={handleCopy}\n      title={copied ? \"Copied!\" : \"Copy\"}\n    >\n      {copied ? (\n        <Check className=\"h-3.5 w-3.5 text-green-500\" />\n      ) : (\n        <Copy className=\"h-3.5 w-3.5\" />\n      )}\n    </Button>\n  );\n}\n","frontend/src/components/chat/message-list.tsx":"\"use client\";\n\nimport type { ChatMessage } from \"@/types\";\nimport { MessageItem } from \"./message-item\";\n\ninterface MessageListProps {\n  messages: ChatMessage[];\n}\n\nexport function MessageList({ messages }: MessageListProps) {\n  // Calculate group positions for timeline connector\n  const getGroupPosition = (\n    message: ChatMessage,\n    index: number\n  ): \"first\" | \"middle\" | \"last\" | \"single\" | undefined => {\n    if (!message.groupId) return undefined;\n\n    const groupMessages = messages.filter((m) => m.groupId === message.groupId);\n    if (groupMessages.length <= 1) return \"single\";\n\n    const groupIndex = groupMessages.findIndex((m) => m.id === message.id);\n    if (groupIndex === 0) return \"first\";\n    if (groupIndex === groupMessages.length - 1) return \"last\";\n    return \"middle\";\n  };\n\n  return (\n    <div className=\"space-y-0\">\n      {messages.map((message, index) => (\n        <MessageItem\n          key={message.id}\n          message={message}\n          groupPosition={getGroupPosition(message, index)}\n        />\n      ))}\n    </div>\n  );\n}\n","frontend/src/components/chat/tool-call-card.tsx":"\"use client\";\n\nimport { Card, CardContent, CardHeader, CardTitle } from \"@/components/ui\";\nimport type { ToolCall } from \"@/types\";\nimport { Wrench, CheckCircle, Loader2, AlertCircle } from \"lucide-react\";\nimport { cn } from \"@/lib/utils\";\nimport { CopyButton } from \"./copy-button\";\n\ninterface ToolCallCardProps {\n  toolCall: ToolCall;\n}\n\nexport function ToolCallCard({ toolCall }: ToolCallCardProps) {\n  const statusConfig = {\n    pending: { icon: Loader2, color: \"text-muted-foreground\", animate: true },\n    running: { icon: Loader2, color: \"text-blue-500\", animate: true },\n    completed: { icon: CheckCircle, color: \"text-green-500\", animate: false },\n    error: { icon: AlertCircle, color: \"text-red-500\", animate: false },\n  };\n\n  const { icon: StatusIcon, color, animate } = statusConfig[toolCall.status];\n\n  const argsText = JSON.stringify(toolCall.args, null, 2);\n  const resultText =\n    toolCall.result !== undefined\n      ? typeof toolCall.result === \"string\"\n        ? toolCall.result\n        : JSON.stringify(toolCall.result, null, 2)\n      : \"\";\n\n  return (\n    <Card className=\"bg-muted/50\">\n      <CardHeader className=\"py-2 px-3\">\n        <div className=\"flex items-center justify-between\">\n          <div className=\"flex items-center gap-2\">\n            <Wrench className=\"h-4 w-4 text-muted-foreground\" />\n            <CardTitle className=\"text-sm font-medium\">\n              {toolCall.name}\n            </CardTitle>\n          </div>\n          <StatusIcon\n            className={cn(\"h-4 w-4\", color, animate && \"animate-spin\")}\n          />\n        </div>\n      </CardHeader>\n      <CardContent className=\"py-2 px-3 space-y-2\">\n        {/* Arguments */}\n        <div className=\"group relative\">\n          <div className=\"flex items-center justify-between mb-1\">\n            <p className=\"text-xs text-muted-foreground\">Arguments:</p>\n            <CopyButton\n              text={argsText}\n              className=\"opacity-0 group-hover:opacity-100\"\n            />\n          </div>\n          <pre className=\"text-xs bg-background p-2 rounded overflow-x-auto\">\n            {argsText}\n          </pre>\n        </div>\n\n        {/* Result */}\n        {toolCall.result !== undefined && (\n          <div className=\"group relative\">\n            <div className=\"flex items-center justify-between mb-1\">\n              <p className=\"text-xs text-muted-foreground\">Result:</p>\n              <CopyButton\n                text={resultText}\n                className=\"opacity-0 group-hover:opacity-100\"\n              />\n            </div>\n            <pre className=\"text-xs bg-background p-2 rounded overflow-x-auto max-h-48 overflow-y-auto\">\n              {resultText}\n            </pre>\n          </div>\n        )}\n      </CardContent>\n    </Card>\n  );\n}\n","frontend/src/components/chat/message-item.tsx":"\"use client\";\n\nimport { cn } from \"@/lib/utils\";\nimport type { ChatMessage } from \"@/types\";\nimport { ToolCallCard } from \"./tool-call-card\";\nimport { MarkdownContent } from \"./markdown-content\";\nimport { CopyButton } from \"./copy-button\";\nimport { User, Bot } from \"lucide-react\";\n\ninterface MessageItemProps {\n  message: ChatMessage;\n  groupPosition?: \"first\" | \"middle\" | \"last\" | \"single\";\n}\n\nexport function MessageItem({ message, groupPosition }: MessageItemProps) {\n  const isUser = message.role === \"user\";\n  const isGrouped = groupPosition && groupPosition !== \"single\";\n\n  return (\n    <div\n      className={cn(\n        \"group flex gap-2 sm:gap-4 relative overflow-visible\",\n        isGrouped ? \"py-2 sm:py-3\" : \"py-3 sm:py-4\",\n        isUser && \"flex-row-reverse\"\n      )}\n    >\n      {/* Timeline connector line for grouped messages */}\n      {isGrouped && !isUser && (\n        <div\n          className=\"absolute left-[15px] sm:left-[17px] w-0.5 bg-orange-500/40\"\n          style={\n            groupPosition === \"first\"\n              ? { top: \"24px\", bottom: \"0\" }\n              : groupPosition === \"last\"\n                ? { top: \"0\", height: \"24px\" }\n                : { top: \"0\", bottom: \"0\" }\n          }\n        />\n      )}\n\n      <div\n        className={cn(\n          \"flex-shrink-0 w-8 h-8 sm:w-9 sm:h-9 rounded-full flex items-center justify-center z-10\",\n          isUser ? \"bg-primary text-primary-foreground\" : \"bg-orange-500/10 text-orange-500\",\n          isGrouped && !isUser && \"ring-2 ring-background\"\n        )}\n      >\n        {isUser ? <User className=\"h-4 w-4\" /> : <Bot className=\"h-4 w-4 sm:h-5 sm:w-5\" />}\n      </div>\n\n      <div className={cn(\n        \"flex-1 space-y-2 overflow-hidden max-w-[88%] sm:max-w-[85%]\",\n        isUser && \"flex flex-col items-end\"\n      )}>\n        {/* Only show message bubble if there's content or if it's streaming without tool calls */}\n        {(message.content || (message.isStreaming && (!message.toolCalls || message.toolCalls.length === 0))) && (\n          <div className={cn(\n            \"relative rounded-2xl px-3 py-2 sm:px-4 sm:py-2.5\",\n            isUser\n              ? \"bg-primary text-primary-foreground rounded-tr-sm\"\n              : \"bg-muted rounded-tl-sm\"\n          )}>\n            {isUser ? (\n              <p className=\"whitespace-pre-wrap break-words text-sm\">\n                {message.content}\n              </p>\n            ) : (\n              <div className=\"text-sm prose-sm max-w-none\">\n                <MarkdownContent content={message.content} />\n                {message.isStreaming && (\n                  <span className=\"inline-block w-1.5 h-4 ml-1 bg-current animate-pulse rounded-full\" />\n                )}\n              </div>\n            )}\n\n            {!isUser && message.content && !message.isStreaming && (\n              <div className=\"absolute -right-1 -top-1 sm:opacity-0 sm:group-hover:opacity-100\">\n                <CopyButton\n                  text={message.content}\n                  className=\"bg-background/80 hover:bg-background shadow-sm\"\n                />\n              </div>\n            )}\n          </div>\n        )}\n\n        {message.toolCalls && message.toolCalls.length > 0 && (\n          <div className=\"space-y-2 w-full\">\n            {message.toolCalls.map((toolCall) => (\n              <ToolCallCard key={toolCall.id} toolCall={toolCall} />\n            ))}\n          </div>\n        )}\n      </div>\n    </div>\n  );\n}\n","frontend/src/components/chat/index.ts":"export { ChatContainer } from \"./chat-container\";\nexport { MessageList } from \"./message-list\";\nexport { MessageItem } from \"./message-item\";\nexport { ToolCallCard } from \"./tool-call-card\";\nexport { ToolApprovalDialog } from \"./tool-approval-dialog\";\nexport { ChatInput } from \"./chat-input\";\nexport { LocalConversationSidebar, ChatSidebarToggle } from \"./local-conversation-sidebar\";\nexport { CopyButton } from \"./copy-button\";\nexport { MarkdownContent } from \"./markdown-content\";\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nexport { ConversationSidebar } from \"./conversation-sidebar\";\n{%- endif %}\n","frontend/src/components/chat/local-conversation-sidebar.tsx":"\"use client\";\n\nimport { useState } from \"react\";\nimport { Button } from \"@/components/ui\";\nimport { Sheet, SheetContent, SheetHeader, SheetTitle, SheetClose } from \"@/components/ui\";\nimport { cn } from \"@/lib/utils\";\nimport { useLocalChatStore, useChatSidebarStore } from \"@/stores\";\nimport type { LocalConversation } from \"@/stores/local-chat-store\";\nimport {\n  MessageSquarePlus,\n  MessageSquare,\n  Trash2,\n  MoreVertical,\n  Pencil,\n  ChevronLeft,\n  ChevronRight,\n  PanelLeftClose,\n  PanelLeft,\n} from \"lucide-react\";\n\ninterface LocalConversationItemProps {\n  conversation: LocalConversation;\n  isActive: boolean;\n  onSelect: () => void;\n  onDelete: () => void;\n  onRename: (title: string) => void;\n}\n\nfunction LocalConversationItem({\n  conversation,\n  isActive,\n  onSelect,\n  onDelete,\n  onRename,\n}: LocalConversationItemProps) {\n  const [showMenu, setShowMenu] = useState(false);\n  const [isEditing, setIsEditing] = useState(false);\n  const [editTitle, setEditTitle] = useState(conversation.title || \"\");\n\n  const handleRename = () => {\n    if (editTitle.trim()) {\n      onRename(editTitle.trim());\n    }\n    setIsEditing(false);\n  };\n\n  const displayTitle =\n    conversation.title ||\n    `Chat ${new Date(conversation.createdAt).toLocaleDateString()}`;\n\n  return (\n    <div\n      className={cn(\n        \"group relative flex items-center gap-2 rounded-lg px-3 py-3 text-sm transition-colors cursor-pointer min-h-[44px]\",\n        isActive\n          ? \"bg-secondary text-secondary-foreground\"\n          : \"text-muted-foreground hover:bg-secondary/50 hover:text-secondary-foreground\"\n      )}\n      onClick={onSelect}\n    >\n      <MessageSquare className=\"h-4 w-4 shrink-0\" />\n      {isEditing ? (\n        <input\n          type=\"text\"\n          value={editTitle}\n          onChange={(e) => setEditTitle(e.target.value)}\n          onBlur={handleRename}\n          onKeyDown={(e) => {\n            if (e.key === \"Enter\") handleRename();\n            if (e.key === \"Escape\") setIsEditing(false);\n          }}\n          className=\"flex-1 bg-transparent outline-none text-foreground\"\n          autoFocus\n          onClick={(e) => e.stopPropagation()}\n        />\n      ) : (\n        <span className=\"flex-1 truncate\">{displayTitle}</span>\n      )}\n\n      <div className=\"relative\">\n        <Button\n          variant=\"ghost\"\n          size=\"sm\"\n          className={cn(\n            \"h-8 w-8 p-0 opacity-0 group-hover:opacity-100 touch:opacity-100\",\n            showMenu && \"opacity-100\"\n          )}\n          onClick={(e) => {\n            e.stopPropagation();\n            setShowMenu(!showMenu);\n          }}\n        >\n          <MoreVertical className=\"h-4 w-4\" />\n        </Button>\n\n        {showMenu && (\n          <>\n            <div\n              className=\"fixed inset-0 z-10\"\n              onClick={() => setShowMenu(false)}\n            />\n            <div className=\"absolute right-0 top-8 z-20 w-40 rounded-md border bg-popover shadow-lg\">\n              <button\n                className=\"flex w-full items-center gap-2 px-3 py-3 text-sm hover:bg-secondary min-h-[44px]\"\n                onClick={(e) => {\n                  e.stopPropagation();\n                  setIsEditing(true);\n                  setShowMenu(false);\n                }}\n              >\n                <Pencil className=\"h-4 w-4\" />\n                Rename\n              </button>\n              <button\n                className=\"flex w-full items-center gap-2 px-3 py-3 text-sm text-destructive hover:bg-destructive/10 min-h-[44px]\"\n                onClick={(e) => {\n                  e.stopPropagation();\n                  onDelete();\n                  setShowMenu(false);\n                }}\n              >\n                <Trash2 className=\"h-4 w-4\" />\n                Delete\n              </button>\n            </div>\n          </>\n        )}\n      </div>\n    </div>\n  );\n}\n\nfunction ConversationList({ onNavigate }: { onNavigate?: () => void }) {\n  const {\n    conversations,\n    currentConversationId,\n    selectConversation,\n    deleteConversation,\n    renameConversation,\n    createConversation,\n  } = useLocalChatStore();\n\n  const handleSelect = (id: string) => {\n    selectConversation(id);\n    onNavigate?.();\n  };\n\n  const handleNewChat = () => {\n    createConversation();\n    onNavigate?.();\n  };\n\n  return (\n    <>\n      <div className=\"p-3\">\n        <Button\n          variant=\"outline\"\n          size=\"sm\"\n          className=\"w-full justify-start gap-2 h-10\"\n          onClick={handleNewChat}\n        >\n          <MessageSquarePlus className=\"h-4 w-4\" />\n          New Chat\n        </Button>\n      </div>\n\n      <div className=\"flex-1 overflow-y-auto px-3 pb-3 scrollbar-thin\">\n        {conversations.length === 0 ? (\n          <div className=\"flex flex-col items-center justify-center py-8 text-center text-sm text-muted-foreground\">\n            <MessageSquare className=\"h-8 w-8 mb-2 opacity-50\" />\n            <p>No conversations yet</p>\n            <p className=\"text-xs mt-1\">Start a new chat to begin</p>\n          </div>\n        ) : (\n          <div className=\"space-y-1\">\n            {conversations.map((conversation) => (\n              <LocalConversationItem\n                key={conversation.id}\n                conversation={conversation}\n                isActive={conversation.id === currentConversationId}\n                onSelect={() => handleSelect(conversation.id)}\n                onDelete={() => deleteConversation(conversation.id)}\n                onRename={(title) => renameConversation(conversation.id, title)}\n              />\n            ))}\n          </div>\n        )}\n      </div>\n\n      <div className=\"border-t px-3 py-2\">\n        <p className=\"text-xs text-muted-foreground text-center\">\n          Stored in browser\n        </p>\n      </div>\n    </>\n  );\n}\n\ninterface LocalConversationSidebarProps {\n  className?: string;\n}\n\nexport function LocalConversationSidebar({\n  className,\n}: LocalConversationSidebarProps) {\n  const [isCollapsed, setIsCollapsed] = useState(false);\n  const { isOpen, close } = useChatSidebarStore();\n\n  if (isCollapsed) {\n    return (\n      <div\n        className={cn(\n          \"hidden md:flex flex-col items-center border-r bg-background py-4 w-12\",\n          className\n        )}\n      >\n        <Button\n          variant=\"ghost\"\n          size=\"sm\"\n          className=\"h-10 w-10 p-0 mb-4\"\n          onClick={() => setIsCollapsed(false)}\n        >\n          <ChevronRight className=\"h-4 w-4\" />\n        </Button>\n        <Button\n          variant=\"ghost\"\n          size=\"sm\"\n          className=\"h-10 w-10 p-0\"\n          onClick={() => {\n            useLocalChatStore.getState().createConversation();\n          }}\n          title=\"New Chat\"\n        >\n          <MessageSquarePlus className=\"h-4 w-4\" />\n        </Button>\n      </div>\n    );\n  }\n\n  return (\n    <>\n      <aside\n        className={cn(\n          \"hidden md:flex w-64 shrink-0 flex-col border-r bg-background\",\n          className\n        )}\n      >\n        <div className=\"flex items-center justify-between border-b px-4 py-3 h-12\">\n          <h2 className=\"font-semibold text-sm\">Local Chats</h2>\n          <Button\n            variant=\"ghost\"\n            size=\"sm\"\n            className=\"h-8 w-8 p-0\"\n            onClick={() => setIsCollapsed(true)}\n          >\n            <ChevronLeft className=\"h-4 w-4\" />\n          </Button>\n        </div>\n        <ConversationList />\n      </aside>\n\n      <Sheet open={isOpen} onOpenChange={close}>\n        <SheetContent side=\"left\" className=\"w-80 p-0\">\n          <SheetHeader className=\"h-12 px-4\">\n            <SheetTitle>Local Chats</SheetTitle>\n            <SheetClose onClick={close} />\n          </SheetHeader>\n          <div className=\"flex flex-col h-[calc(100%-48px)]\">\n            <ConversationList onNavigate={close} />\n          </div>\n        </SheetContent>\n      </Sheet>\n    </>\n  );\n}\n\nexport function ChatSidebarToggle() {\n  const { toggle, isOpen } = useChatSidebarStore();\n\n  return (\n    <Button\n      variant=\"ghost\"\n      size=\"sm\"\n      className=\"h-10 w-10 p-0 md:hidden\"\n      onClick={toggle}\n    >\n      {isOpen ? (\n        <PanelLeftClose className=\"h-5 w-5\" />\n      ) : (\n        <PanelLeft className=\"h-5 w-5\" />\n      )}\n      <span className=\"sr-only\">Toggle chat list</span>\n    </Button>\n  );\n}\n","frontend/src/components/chat/chat-input.tsx":"\"use client\";\n\nimport { useState, useRef, useEffect } from \"react\";\nimport { Button } from \"@/components/ui\";\nimport { Send, Loader2 } from \"lucide-react\";\n\ninterface ChatInputProps {\n  onSend: (message: string) => void;\n  disabled?: boolean;\n  isProcessing?: boolean;\n}\n\nexport function ChatInput({ onSend, disabled, isProcessing }: ChatInputProps) {\n  const [message, setMessage] = useState(\"\");\n  const textareaRef = useRef<HTMLTextAreaElement>(null);\n\n  useEffect(() => {\n    if (!isProcessing && textareaRef.current) {\n      textareaRef.current.focus();\n    }\n  }, [isProcessing]);\n\n  useEffect(() => {\n    if (textareaRef.current) {\n      textareaRef.current.style.height = \"auto\";\n      textareaRef.current.style.height = `${Math.min(textareaRef.current.scrollHeight, 200)}px`;\n    }\n  }, [message]);\n\n  const handleSubmit = (e: React.FormEvent) => {\n    e.preventDefault();\n    if (message.trim() && !disabled) {\n      onSend(message.trim());\n      setMessage(\"\");\n    }\n  };\n\n  const handleKeyDown = (e: React.KeyboardEvent) => {\n    if (e.key === \"Enter\" && !e.shiftKey) {\n      e.preventDefault();\n      handleSubmit(e);\n    }\n  };\n\n  return (\n    <form onSubmit={handleSubmit} className=\"relative\">\n      <textarea\n        ref={textareaRef}\n        value={message}\n        onChange={(e) => setMessage(e.target.value)}\n        onKeyDown={handleKeyDown}\n        placeholder=\"Type a message...\"\n        disabled={disabled}\n        rows={1}\n        className=\"w-full resize-none bg-transparent pr-14 text-sm sm:text-base placeholder:text-muted-foreground focus:outline-none disabled:cursor-not-allowed disabled:opacity-50\"\n      />\n      <Button\n        type=\"submit\"\n        size=\"icon\"\n        disabled={disabled || !message.trim()}\n        className=\"absolute right-0 top-0 h-10 w-10 rounded-lg\"\n      >\n        {isProcessing ? (\n          <Loader2 className=\"h-5 w-5 animate-spin\" />\n        ) : (\n          <Send className=\"h-5 w-5\" />\n        )}\n        <span className=\"sr-only\">Send message</span>\n      </Button>\n    </form>\n  );\n}\n","frontend/src/components/auth/register-form.tsx":"\"use client\";\n\nimport { useState } from \"react\";\nimport Link from \"next/link\";\nimport { useRouter } from \"next/navigation\";\nimport { useAuth } from \"@/hooks\";\nimport { Button, Input, Label, Card, CardHeader, CardTitle, CardContent, CardFooter } from \"@/components/ui\";\nimport { ApiError } from \"@/lib/api-client\";\nimport { ROUTES } from \"@/lib/constants\";\n{%- if cookiecutter.enable_oauth_google %}\nimport { GoogleIcon } from \"@/components/icons/google-icon\";\n{%- endif %}\n\nexport function RegisterForm() {\n  const router = useRouter();\n  const { register } = useAuth();\n  const [email, setEmail] = useState(\"\");\n  const [password, setPassword] = useState(\"\");\n  const [confirmPassword, setConfirmPassword] = useState(\"\");\n  const [name, setName] = useState(\"\");\n  const [error, setError] = useState(\"\");\n  const [isLoading, setIsLoading] = useState(false);\n{%- if cookiecutter.enable_oauth_google %}\n  const [isOAuthLoading, setIsOAuthLoading] = useState(false);\n{%- endif %}\n\n  const handleSubmit = async (e: React.FormEvent) => {\n    e.preventDefault();\n    setError(\"\");\n\n    if (password !== confirmPassword) {\n      setError(\"Passwords do not match\");\n      return;\n    }\n\n    setIsLoading(true);\n\n    try {\n      await register({ email, password, name: name || undefined });\n      router.push(ROUTES.LOGIN + \"?registered=true\");\n    } catch (err) {\n      if (err instanceof ApiError) {\n        setError(err.message);\n      } else {\n        setError(\"Registration failed. Please try again.\");\n      }\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n{%- if cookiecutter.enable_oauth_google %}\n\n  const handleGoogleSignUp = () => {\n    setIsOAuthLoading(true);\n    // Redirect to backend OAuth endpoint\n    window.location.href = `${process.env.NEXT_PUBLIC_API_URL}/api/v1/oauth/google/login`;\n  };\n{%- endif %}\n\n  return (\n    <Card className=\"w-full max-w-md mx-auto\">\n      <CardHeader>\n        <CardTitle className=\"text-2xl text-center\">Create Account</CardTitle>\n      </CardHeader>\n      <CardContent>\n{%- if cookiecutter.enable_oauth_google %}\n        <Button\n          type=\"button\"\n          variant=\"outline\"\n          className=\"w-full mb-6\"\n          onClick={handleGoogleSignUp}\n          disabled={isOAuthLoading || isLoading}\n        >\n          <GoogleIcon className=\"mr-2 h-4 w-4\" />\n          {isOAuthLoading ? \"Redirecting...\" : \"Sign up with Google\"}\n        </Button>\n\n        <div className=\"relative mb-6\">\n          <div className=\"absolute inset-0 flex items-center\">\n            <span className=\"w-full border-t\" />\n          </div>\n          <div className=\"relative flex justify-center text-xs uppercase\">\n            <span className=\"bg-card px-2 text-muted-foreground\">Or register with email</span>\n          </div>\n        </div>\n{%- endif %}\n\n        <form onSubmit={handleSubmit} className=\"space-y-4\">\n          <div className=\"space-y-2\">\n            <Label htmlFor=\"name\">Name (optional)</Label>\n            <Input\n              id=\"name\"\n              type=\"text\"\n              placeholder=\"John Doe\"\n              value={name}\n              onChange={(e) => setName(e.target.value)}\n              disabled={isLoading}\n            />\n          </div>\n          <div className=\"space-y-2\">\n            <Label htmlFor=\"email\">Email</Label>\n            <Input\n              id=\"email\"\n              type=\"email\"\n              placeholder=\"you@example.com\"\n              value={email}\n              onChange={(e) => setEmail(e.target.value)}\n              required\n              disabled={isLoading}\n            />\n          </div>\n          <div className=\"space-y-2\">\n            <Label htmlFor=\"password\">Password</Label>\n            <Input\n              id=\"password\"\n              type=\"password\"\n              value={password}\n              onChange={(e) => setPassword(e.target.value)}\n              required\n              disabled={isLoading}\n            />\n          </div>\n          <div className=\"space-y-2\">\n            <Label htmlFor=\"confirmPassword\">Confirm Password</Label>\n            <Input\n              id=\"confirmPassword\"\n              type=\"password\"\n              value={confirmPassword}\n              onChange={(e) => setConfirmPassword(e.target.value)}\n              required\n              disabled={isLoading}\n            />\n          </div>\n          {error && (\n            <p className=\"text-sm text-destructive\">{error}</p>\n          )}\n          <Button type=\"submit\" className=\"w-full\" disabled={isLoading}>\n            {isLoading ? \"Creating account...\" : \"Register\"}\n          </Button>\n        </form>\n      </CardContent>\n      <CardFooter className=\"justify-center\">\n        <p className=\"text-sm text-muted-foreground\">\n          Already have an account?{\" \"}\n          <Link href={ROUTES.LOGIN} className=\"text-primary hover:underline\">\n            Login\n          </Link>\n        </p>\n      </CardFooter>\n    </Card>\n  );\n}\n","frontend/src/components/auth/index.ts":"export { LoginForm } from \"./login-form\";\nexport { RegisterForm } from \"./register-form\";\n","frontend/src/components/auth/login-form.tsx":"\"use client\";\n\nimport { useState } from \"react\";\nimport Link from \"next/link\";\nimport { useAuth } from \"@/hooks\";\nimport { Button, Input, Label, Card, CardHeader, CardTitle, CardContent, CardFooter } from \"@/components/ui\";\nimport { ApiError } from \"@/lib/api-client\";\nimport { ROUTES } from \"@/lib/constants\";\n{%- if cookiecutter.enable_oauth_google %}\nimport { GoogleIcon } from \"@/components/icons/google-icon\";\n{%- endif %}\n\nexport function LoginForm() {\n  const { login } = useAuth();\n  const [email, setEmail] = useState(\"\");\n  const [password, setPassword] = useState(\"\");\n  const [error, setError] = useState(\"\");\n  const [isLoading, setIsLoading] = useState(false);\n{%- if cookiecutter.enable_oauth_google %}\n  const [isOAuthLoading, setIsOAuthLoading] = useState(false);\n{%- endif %}\n\n  const handleSubmit = async (e: React.FormEvent) => {\n    e.preventDefault();\n    setIsLoading(true);\n    setError(\"\");\n\n    try {\n      await login({ email, password });\n    } catch (err) {\n      if (err instanceof ApiError) {\n        setError(err.message);\n      } else {\n        setError(\"Login failed. Please try again.\");\n      }\n      setIsLoading(false);\n    }\n  };\n\n{%- if cookiecutter.enable_oauth_google %}\n\n  const handleGoogleLogin = () => {\n    setIsOAuthLoading(true);\n    // Redirect to backend OAuth endpoint\n    window.location.href = `${process.env.NEXT_PUBLIC_API_URL}/api/v1/oauth/google/login`;\n  };\n{%- endif %}\n\n  return (\n    <Card className=\"w-full max-w-md mx-auto\">\n      <CardHeader>\n        <CardTitle className=\"text-2xl text-center\">Login</CardTitle>\n      </CardHeader>\n      <CardContent>\n        <form onSubmit={handleSubmit} className=\"space-y-4\">\n          <div className=\"space-y-2\">\n            <Label htmlFor=\"email\">Email</Label>\n            <Input\n              id=\"email\"\n              type=\"email\"\n              placeholder=\"you@example.com\"\n              value={email}\n              onChange={(e) => setEmail(e.target.value)}\n              required\n              disabled={isLoading}\n            />\n          </div>\n          <div className=\"space-y-2\">\n            <Label htmlFor=\"password\">Password</Label>\n            <Input\n              id=\"password\"\n              type=\"password\"\n              value={password}\n              onChange={(e) => setPassword(e.target.value)}\n              required\n              disabled={isLoading}\n            />\n          </div>\n          {error && (\n            <p className=\"text-sm text-destructive\">{error}</p>\n          )}\n          <Button type=\"submit\" className=\"w-full\" disabled={isLoading}>\n            {isLoading ? \"Logging in...\" : \"Login\"}\n          </Button>\n        </form>\n\n{%- if cookiecutter.enable_oauth_google %}\n\n        <div className=\"relative my-6\">\n          <div className=\"absolute inset-0 flex items-center\">\n            <span className=\"w-full border-t\" />\n          </div>\n          <div className=\"relative flex justify-center text-xs uppercase\">\n            <span className=\"bg-card px-2 text-muted-foreground\">Or continue with</span>\n          </div>\n        </div>\n\n        <Button\n          type=\"button\"\n          variant=\"outline\"\n          className=\"w-full\"\n          onClick={handleGoogleLogin}\n          disabled={isOAuthLoading || isLoading}\n        >\n          <GoogleIcon className=\"mr-2 h-4 w-4\" />\n          {isOAuthLoading ? \"Redirecting...\" : \"Continue with Google\"}\n        </Button>\n{%- endif %}\n      </CardContent>\n      <CardFooter className=\"justify-center\">\n        <p className=\"text-sm text-muted-foreground\">\n          Don&apos;t have an account?{\" \"}\n          <Link href={ROUTES.REGISTER} className=\"text-primary hover:underline\">\n            Register\n          </Link>\n        </p>\n      </CardFooter>\n    </Card>\n  );\n}\n","frontend/src/components/layout/header.tsx":"\"use client\";\n\nimport Link from \"next/link\";\nimport { useAuth } from \"@/hooks\";\nimport { Button } from \"@/components/ui\";\nimport { ThemeToggle } from \"@/components/theme\";\n{%- if cookiecutter.enable_i18n %}\nimport { LanguageSwitcherCompact } from \"@/components/language-switcher\";\n{%- endif %}\nimport { ROUTES } from \"@/lib/constants\";\nimport { LogOut, User, Menu } from \"lucide-react\";\nimport { useSidebarStore } from \"@/stores\";\n\nexport function Header() {\n  const { user, isAuthenticated, logout } = useAuth();\n  const { toggle } = useSidebarStore();\n\n  return (\n    <header className=\"sticky top-0 z-40 w-full border-b bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60\">\n      <div className=\"flex h-14 items-center justify-between px-3 sm:px-6\">\n        <Button\n          variant=\"ghost\"\n          size=\"sm\"\n          className=\"h-10 w-10 p-0 md:hidden\"\n          onClick={toggle}\n        >\n          <Menu className=\"h-5 w-5\" />\n          <span className=\"sr-only\">Toggle menu</span>\n        </Button>\n\n        <div className=\"hidden md:block\" />\n\n        <div className=\"flex items-center gap-2 sm:gap-3\">\n{%- if cookiecutter.enable_i18n %}\n          <LanguageSwitcherCompact />\n{%- endif %}\n          <ThemeToggle />\n          {isAuthenticated ? (\n            <>\n              <Button variant=\"ghost\" size=\"sm\" asChild className=\"h-10 px-2 sm:px-3\">\n                <Link href={ROUTES.PROFILE} className=\"flex items-center gap-2\">\n                  <User className=\"h-4 w-4\" />\n                  <span className=\"hidden max-w-32 truncate sm:inline\">{user?.email}</span>\n                </Link>\n              </Button>\n              <Button variant=\"ghost\" size=\"sm\" onClick={logout} className=\"h-10 w-10 p-0 sm:w-auto sm:px-3\">\n                <LogOut className=\"h-4 w-4\" />\n                <span className=\"sr-only sm:not-sr-only sm:ml-2\">Logout</span>\n              </Button>\n            </>\n          ) : (\n            <>\n              <Button variant=\"ghost\" size=\"sm\" asChild className=\"h-10\">\n                <Link href={ROUTES.LOGIN}>Login</Link>\n              </Button>\n              <Button size=\"sm\" asChild className=\"h-10\">\n                <Link href={ROUTES.REGISTER}>Register</Link>\n              </Button>\n            </>\n          )}\n        </div>\n      </div>\n    </header>\n  );\n}\n","frontend/src/components/layout/sidebar.tsx":"\"use client\";\n\nimport Link from \"next/link\";\nimport { usePathname } from \"next/navigation\";\nimport { cn } from \"@/lib/utils\";\nimport { ROUTES } from \"@/lib/constants\";\nimport { LayoutDashboard, MessageSquare } from \"lucide-react\";\nimport { useSidebarStore } from \"@/stores\";\nimport { Sheet, SheetContent, SheetHeader, SheetTitle, SheetClose } from \"@/components/ui\";\n\nconst navigation = [\n  { name: \"Dashboard\", href: ROUTES.DASHBOARD, icon: LayoutDashboard },\n  { name: \"Chat\", href: ROUTES.CHAT, icon: MessageSquare },\n];\n\nfunction NavLinks({ onNavigate }: { onNavigate?: () => void }) {\n  const pathname = usePathname();\n\n  return (\n    <nav className=\"flex-1 space-y-1 p-4\">\n      {navigation.map((item) => {\n        const isActive = pathname === item.href;\n        return (\n          <Link\n            key={item.name}\n            href={item.href}\n            onClick={onNavigate}\n            className={cn(\n              \"flex items-center gap-3 rounded-lg px-3 py-3 text-sm font-medium transition-colors\",\n              \"min-h-[44px]\",\n              isActive\n                ? \"bg-secondary text-secondary-foreground\"\n                : \"text-muted-foreground hover:bg-secondary/50 hover:text-secondary-foreground\"\n            )}\n          >\n            <item.icon className=\"h-5 w-5\" />\n            {item.name}\n          </Link>\n        );\n      })}\n    </nav>\n  );\n}\n\nfunction SidebarContent({ onNavigate }: { onNavigate?: () => void }) {\n  return (\n    <div className=\"flex h-full flex-col\">\n      <div className=\"flex h-14 items-center border-b px-4\">\n        <Link\n          href={ROUTES.HOME}\n          className=\"flex items-center gap-2 font-semibold\"\n          onClick={onNavigate}\n        >\n          <span>{\"{{ cookiecutter.project_name }}\"}</span>\n        </Link>\n      </div>\n      <NavLinks onNavigate={onNavigate} />\n    </div>\n  );\n}\n\nexport function Sidebar() {\n  const { isOpen, close } = useSidebarStore();\n\n  return (\n    <>\n      <aside className=\"hidden w-64 shrink-0 border-r bg-background md:block\">\n        <SidebarContent />\n      </aside>\n\n      <Sheet open={isOpen} onOpenChange={close}>\n        <SheetContent side=\"left\" className=\"w-72 p-0\">\n          <SheetHeader className=\"h-14 px-4\">\n            <SheetTitle>{\"{{ cookiecutter.project_name }}\"}</SheetTitle>\n            <SheetClose onClick={close} />\n          </SheetHeader>\n          <NavLinks onNavigate={close} />\n        </SheetContent>\n      </Sheet>\n    </>\n  );\n}\n","frontend/src/components/layout/index.ts":"export { Header } from \"./header\";\nexport { Sidebar } from \"./sidebar\";\n","frontend/src/components/theme/theme-provider.tsx":"{%- if cookiecutter.use_frontend %}\n\"use client\";\n\nimport { useEffect } from \"react\";\nimport { useThemeStore, getResolvedTheme } from \"@/stores/theme-store\";\n\ninterface ThemeProviderProps {\n  children: React.ReactNode;\n}\n\nexport function ThemeProvider({ children }: ThemeProviderProps) {\n  const { theme } = useThemeStore();\n\n  useEffect(() => {\n    const root = document.documentElement;\n    const resolvedTheme = getResolvedTheme(theme);\n\n    // Remove both classes first\n    root.classList.remove(\"light\", \"dark\");\n    // Add the current theme class\n    root.classList.add(resolvedTheme);\n\n    // Update color-scheme for native elements\n    root.style.colorScheme = resolvedTheme;\n  }, [theme]);\n\n  // Listen for system theme changes when using \"system\" theme\n  useEffect(() => {\n    if (theme !== \"system\") return;\n\n    const mediaQuery = window.matchMedia(\"(prefers-color-scheme: dark)\");\n\n    const handleChange = () => {\n      const root = document.documentElement;\n      const resolvedTheme = mediaQuery.matches ? \"dark\" : \"light\";\n\n      root.classList.remove(\"light\", \"dark\");\n      root.classList.add(resolvedTheme);\n      root.style.colorScheme = resolvedTheme;\n    };\n\n    mediaQuery.addEventListener(\"change\", handleChange);\n    return () => mediaQuery.removeEventListener(\"change\", handleChange);\n  }, [theme]);\n\n  return <>{children}</>;\n}\n{%- else %}\n/* Theme provider - frontend not configured */\nexport function ThemeProvider({ children }: { children: React.ReactNode }) {\n  return <>{children}</>;\n}\n{%- endif %}\n","frontend/src/components/theme/index.ts":"{%- if cookiecutter.use_frontend %}\nexport { ThemeProvider } from \"./theme-provider\";\nexport { ThemeToggle } from \"./theme-toggle\";\n{%- else %}\n/* Theme components - frontend not configured */\nexport {};\n{%- endif %}\n","frontend/src/components/theme/theme-toggle.tsx":"{%- if cookiecutter.use_frontend %}\n\"use client\";\n\nimport { useEffect, useState } from \"react\";\nimport { Moon, Sun, Monitor } from \"lucide-react\";\nimport { Button } from \"@/components/ui/button\";\nimport { useThemeStore, Theme, getResolvedTheme } from \"@/stores/theme-store\";\n\ninterface ThemeToggleProps {\n  variant?: \"icon\" | \"dropdown\";\n  className?: string;\n}\n\nexport function ThemeToggle({ variant = \"icon\", className }: ThemeToggleProps) {\n  const { theme, setTheme } = useThemeStore();\n  const [mounted, setMounted] = useState(false);\n\n  // Prevent hydration mismatch by only rendering after mount\n  useEffect(() => {\n    setMounted(true);\n  }, []);\n\n  const resolvedTheme = getResolvedTheme(theme);\n\n  const cycleTheme = () => {\n    const themes: Theme[] = [\"light\", \"dark\", \"system\"];\n    const currentIndex = themes.indexOf(theme);\n    const nextIndex = (currentIndex + 1) % themes.length;\n    setTheme(themes[nextIndex]);\n  };\n\n  // Render placeholder during SSR to prevent hydration mismatch\n  if (!mounted) {\n    return (\n      <Button\n        variant=\"ghost\"\n        size=\"icon\"\n        className={className}\n        aria-label=\"Toggle theme\"\n      >\n        <Sun className=\"h-5 w-5\" />\n      </Button>\n    );\n  }\n\n  if (variant === \"icon\") {\n    return (\n      <Button\n        variant=\"ghost\"\n        size=\"icon\"\n        onClick={cycleTheme}\n        className={className}\n        aria-label={`Switch theme (current: ${theme})`}\n        title={`Theme: ${theme}`}\n      >\n        {resolvedTheme === \"dark\" ? (\n          <Moon className=\"h-5 w-5\" />\n        ) : (\n          <Sun className=\"h-5 w-5\" />\n        )}\n        {theme === \"system\" && (\n          <span className=\"sr-only\">(following system)</span>\n        )}\n      </Button>\n    );\n  }\n\n  return (\n    <div className={`flex gap-1 ${className}`}>\n      <Button\n        variant={theme === \"light\" ? \"default\" : \"ghost\"}\n        size=\"icon\"\n        onClick={() => setTheme(\"light\")}\n        aria-label=\"Light mode\"\n        title=\"Light mode\"\n      >\n        <Sun className=\"h-4 w-4\" />\n      </Button>\n      <Button\n        variant={theme === \"dark\" ? \"default\" : \"ghost\"}\n        size=\"icon\"\n        onClick={() => setTheme(\"dark\")}\n        aria-label=\"Dark mode\"\n        title=\"Dark mode\"\n      >\n        <Moon className=\"h-4 w-4\" />\n      </Button>\n      <Button\n        variant={theme === \"system\" ? \"default\" : \"ghost\"}\n        size=\"icon\"\n        onClick={() => setTheme(\"system\")}\n        aria-label=\"System theme\"\n        title=\"System theme\"\n      >\n        <Monitor className=\"h-4 w-4\" />\n      </Button>\n    </div>\n  );\n}\n{%- else %}\n/* Theme toggle - frontend not configured */\nexport function ThemeToggle() {\n  return null;\n}\n{%- endif %}\n","frontend/src/components/icons/google-icon.tsx":"{%- if cookiecutter.enable_oauth_google %}\nimport { SVGProps } from \"react\";\n\nexport function GoogleIcon(props: SVGProps<SVGSVGElement>) {\n  return (\n    <svg\n      xmlns=\"http://www.w3.org/2000/svg\"\n      viewBox=\"0 0 24 24\"\n      {...props}\n    >\n      <path\n        fill=\"#4285F4\"\n        d=\"M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z\"\n      />\n      <path\n        fill=\"#34A853\"\n        d=\"M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z\"\n      />\n      <path\n        fill=\"#FBBC05\"\n        d=\"M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z\"\n      />\n      <path\n        fill=\"#EA4335\"\n        d=\"M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z\"\n      />\n    </svg>\n  );\n}\n{%- else %}\n// Google icon component - OAuth not enabled\n{%- endif %}\n","frontend/src/components/icons/index.ts":"{%- if cookiecutter.enable_oauth_google %}\nexport { GoogleIcon } from \"./google-icon\";\n{%- endif %}\n","frontend/src/components/language-switcher.tsx":"{%- if cookiecutter.enable_i18n %}\n'use client';\n\nimport { useLocale } from 'next-intl';\nimport { useRouter, usePathname } from 'next/navigation';\nimport { locales, type Locale, getLocaleLabel } from '@/i18n';\n\n/**\n * Language switcher dropdown component.\n * Allows users to switch between available locales.\n */\nexport function LanguageSwitcher() {\n  const locale = useLocale();\n  const router = useRouter();\n  const pathname = usePathname();\n\n  const handleChange = (newLocale: Locale) => {\n    // Remove the current locale from pathname and add the new one\n    const segments = pathname.split('/');\n    segments[1] = newLocale;\n    const newPath = segments.join('/');\n    router.push(newPath);\n  };\n\n  return (\n    <div className=\"relative\">\n      <select\n        value={locale}\n        onChange={(e) => handleChange(e.target.value as Locale)}\n        className=\"appearance-none bg-transparent border border-gray-300 dark:border-gray-600 rounded-md px-3 py-1.5 pr-8 text-sm cursor-pointer hover:border-gray-400 dark:hover:border-gray-500 focus:outline-none focus:ring-2 focus:ring-blue-500\"\n        aria-label=\"Select language\"\n      >\n        {locales.map((loc) => (\n          <option key={loc} value={loc}>\n            {getLocaleLabel(loc)}\n          </option>\n        ))}\n      </select>\n      <div className=\"pointer-events-none absolute inset-y-0 right-0 flex items-center px-2 text-gray-500\">\n        <svg className=\"h-4 w-4\" fill=\"none\" stroke=\"currentColor\" viewBox=\"0 0 24 24\">\n          <path strokeLinecap=\"round\" strokeLinejoin=\"round\" strokeWidth=\"2\" d=\"M19 9l-7 7-7-7\" />\n        </svg>\n      </div>\n    </div>\n  );\n}\n\n/**\n * Compact language switcher with flag icons.\n */\nexport function LanguageSwitcherCompact() {\n  const locale = useLocale();\n  const router = useRouter();\n  const pathname = usePathname();\n\n  const flags: Record<Locale, string> = {\n    en: 'üá¨üáß',\n    pl: 'üáµüá±',\n  };\n\n  const handleChange = (newLocale: Locale) => {\n    const segments = pathname.split('/');\n    segments[1] = newLocale;\n    const newPath = segments.join('/');\n    router.push(newPath);\n  };\n\n  return (\n    <div className=\"flex gap-1\">\n      {locales.map((loc) => (\n        <button\n          key={loc}\n          onClick={() => handleChange(loc)}\n          className={`px-2 py-1 rounded-md text-lg transition-opacity ${\n            locale === loc\n              ? 'opacity-100 bg-gray-100 dark:bg-gray-800'\n              : 'opacity-50 hover:opacity-75'\n          }`}\n          aria-label={getLocaleLabel(loc)}\n          aria-pressed={locale === loc}\n        >\n          {flags[loc]}\n        </button>\n      ))}\n    </div>\n  );\n}\n{%- else %}\n// i18n is disabled - no language switcher component\nexport function LanguageSwitcher() {\n  return null;\n}\n\nexport function LanguageSwitcherCompact() {\n  return null;\n}\n{%- endif %}\n","frontend/src/hooks/use-auth.ts":"\"use client\";\n\nimport { useCallback, useEffect } from \"react\";\nimport { useRouter } from \"next/navigation\";\nimport { useAuthStore } from \"@/stores\";\nimport { apiClient, ApiError } from \"@/lib/api-client\";\nimport type { User, LoginRequest, RegisterRequest } from \"@/types\";\nimport { ROUTES } from \"@/lib/constants\";\n\nexport function useAuth() {\n  const router = useRouter();\n  const { user, isAuthenticated, isLoading, setUser, setLoading, logout } =\n    useAuthStore();\n\n  // Check auth status on mount\n  useEffect(() => {\n    const checkAuth = async () => {\n      try {\n        const userData = await apiClient.get<User>(\"/auth/me\");\n        setUser(userData);\n      } catch {\n        setUser(null);\n      }\n    };\n\n    if (isLoading) {\n      checkAuth();\n    }\n  }, [isLoading, setUser]);\n\n  const login = useCallback(\n    async (credentials: LoginRequest) => {\n      setLoading(true);\n      try {\n        const response = await apiClient.post<{ user: User; message: string }>(\n          \"/auth/login\",\n          credentials\n        );\n        setUser(response.user);\n        router.push(ROUTES.DASHBOARD);\n        return response;\n      } catch (error) {\n        setLoading(false);\n        throw error;\n      }\n    },\n    [router, setUser, setLoading]\n  );\n\n  const register = useCallback(\n    async (data: RegisterRequest) => {\n      const response = await apiClient.post<{ id: string; email: string }>(\n        \"/auth/register\",\n        data\n      );\n      return response;\n    },\n    []\n  );\n\n  const handleLogout = useCallback(async () => {\n    try {\n      await apiClient.post(\"/auth/logout\");\n    } catch {\n      // Ignore logout errors\n    } finally {\n      logout();\n      router.push(ROUTES.LOGIN);\n    }\n  }, [logout, router]);\n\n  const refreshToken = useCallback(async () => {\n    try {\n      await apiClient.post(\"/auth/refresh\");\n      // Re-fetch user after token refresh\n      const userData = await apiClient.get<User>(\"/auth/me\");\n      setUser(userData);\n      return true;\n    } catch (error) {\n      if (error instanceof ApiError && error.status === 401) {\n        logout();\n        router.push(ROUTES.LOGIN);\n      }\n      return false;\n    }\n  }, [logout, router, setUser]);\n\n  return {\n    user,\n    isAuthenticated,\n    isLoading,\n    login,\n    register,\n    logout: handleLogout,\n    refreshToken,\n  };\n}\n","frontend/src/hooks/use-conversations.ts":"{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n\"use client\";\n\nimport { useCallback } from \"react\";\nimport { apiClient } from \"@/lib/api-client\";\nimport { useConversationStore, useChatStore } from \"@/stores\";\nimport type {\n  Conversation,\n  ConversationMessage,\n  ConversationListResponse,\n} from \"@/types\";\n\ninterface CreateConversationResponse {\n  id: string;\n  title?: string;\n  created_at: string;\n  updated_at: string;\n  is_archived: boolean;\n}\n\ninterface MessagesResponse {\n  items: ConversationMessage[];\n  total: number;\n}\n\nexport function useConversations() {\n  const {\n    conversations,\n    currentConversationId,\n    currentMessages,\n    isLoading,\n    error,\n    setConversations,\n    addConversation,\n    updateConversation,\n    removeConversation,\n    setCurrentConversationId,\n    setCurrentMessages,\n    setLoading,\n    setError,\n  } = useConversationStore();\n  const { clearMessages } = useChatStore();\n\n  const fetchConversations = useCallback(async () => {\n    setLoading(true);\n    setError(null);\n    try {\n      const response = await apiClient.get<ConversationListResponse>(\n        \"/conversations\"\n      );\n      setConversations(response.items);\n    } catch (err) {\n      const message =\n        err instanceof Error ? err.message : \"Failed to fetch conversations\";\n      setError(message);\n    } finally {\n      setLoading(false);\n    }\n  }, [setConversations, setLoading, setError]);\n\n  const createConversation = useCallback(\n    async (title?: string): Promise<Conversation | null> => {\n      setLoading(true);\n      setError(null);\n      try {\n        const response = await apiClient.post<CreateConversationResponse>(\n          \"/conversations\",\n          { title }\n        );\n        const newConversation: Conversation = {\n          id: response.id,\n          title: response.title,\n          created_at: response.created_at,\n          updated_at: response.updated_at,\n          is_archived: response.is_archived,\n        };\n        addConversation(newConversation);\n        return newConversation;\n      } catch (err) {\n        const message =\n          err instanceof Error ? err.message : \"Failed to create conversation\";\n        setError(message);\n        return null;\n      } finally {\n        setLoading(false);\n      }\n    },\n    [addConversation, setLoading, setError]\n  );\n\n  const selectConversation = useCallback(\n    async (id: string) => {\n      setCurrentConversationId(id);\n      clearMessages();\n      setLoading(true);\n      setError(null);\n      try {\n        const response = await apiClient.get<MessagesResponse>(\n          `/conversations/${id}/messages`\n        );\n        setCurrentMessages(response.items);\n      } catch (err) {\n        const message =\n          err instanceof Error ? err.message : \"Failed to fetch messages\";\n        setError(message);\n      } finally {\n        setLoading(false);\n      }\n    },\n    [setCurrentConversationId, clearMessages, setCurrentMessages, setLoading, setError]\n  );\n\n  const archiveConversation = useCallback(\n    async (id: string) => {\n      try {\n        await apiClient.patch(`/conversations/${id}`, { is_archived: true });\n        updateConversation(id, { is_archived: true });\n      } catch (err) {\n        const message =\n          err instanceof Error ? err.message : \"Failed to archive conversation\";\n        setError(message);\n      }\n    },\n    [updateConversation, setError]\n  );\n\n  const deleteConversation = useCallback(\n    async (id: string) => {\n      try {\n        await apiClient.delete(`/conversations/${id}`);\n        removeConversation(id);\n      } catch (err) {\n        const message =\n          err instanceof Error ? err.message : \"Failed to delete conversation\";\n        setError(message);\n      }\n    },\n    [removeConversation, setError]\n  );\n\n  const renameConversation = useCallback(\n    async (id: string, title: string) => {\n      try {\n        await apiClient.patch(`/conversations/${id}`, { title });\n        updateConversation(id, { title });\n      } catch (err) {\n        const message =\n          err instanceof Error ? err.message : \"Failed to rename conversation\";\n        setError(message);\n      }\n    },\n    [updateConversation, setError]\n  );\n\n  const startNewChat = useCallback(async () => {\n    clearMessages();\n    setCurrentMessages([]);\n    const newConversation = await createConversation();\n    if (newConversation) {\n      setCurrentConversationId(newConversation.id);\n    }\n  }, [clearMessages, setCurrentMessages, createConversation, setCurrentConversationId]);\n\n  return {\n    conversations,\n    currentConversationId,\n    currentMessages,\n    isLoading,\n    error,\n    fetchConversations,\n    createConversation,\n    selectConversation,\n    archiveConversation,\n    deleteConversation,\n    renameConversation,\n    startNewChat,\n  };\n}\n{%- else %}\n// Conversations hook - not configured (enable_conversation_persistence is false)\n{%- endif %}\n","frontend/src/hooks/use-websocket.ts":"\"use client\";\n\nimport { useCallback, useEffect, useRef, useState } from \"react\";\n\ninterface UseWebSocketOptions {\n  url: string;\n  onMessage?: (event: MessageEvent) => void;\n  onOpen?: () => void;\n  onClose?: () => void;\n  onError?: (error: Event) => void;\n  reconnect?: boolean;\n  reconnectInterval?: number;\n  maxReconnectAttempts?: number;\n}\n\nexport function useWebSocket({\n  url,\n  onMessage,\n  onOpen,\n  onClose,\n  onError,\n  reconnect = true,\n  reconnectInterval = 3000,\n  maxReconnectAttempts = 5,\n}: UseWebSocketOptions) {\n  const [isConnected, setIsConnected] = useState(false);\n  const wsRef = useRef<WebSocket | null>(null);\n  const reconnectTimeoutRef = useRef<NodeJS.Timeout | null>(null);\n  const reconnectAttemptsRef = useRef(0);\n\n  // Use refs for callbacks to avoid recreating connect function\n  const onMessageRef = useRef(onMessage);\n  const onOpenRef = useRef(onOpen);\n  const onCloseRef = useRef(onClose);\n  const onErrorRef = useRef(onError);\n\n  // Keep refs updated\n  useEffect(() => {\n    onMessageRef.current = onMessage;\n    onOpenRef.current = onOpen;\n    onCloseRef.current = onClose;\n    onErrorRef.current = onError;\n  }, [onMessage, onOpen, onClose, onError]);\n\n  const connect = useCallback(() => {\n    if (wsRef.current?.readyState === WebSocket.OPEN) return;\n\n    const ws = new WebSocket(url);\n    wsRef.current = ws;\n\n    ws.onopen = () => {\n      setIsConnected(true);\n      reconnectAttemptsRef.current = 0;\n      onOpenRef.current?.();\n    };\n\n    ws.onmessage = (event) => {\n      onMessageRef.current?.(event);\n    };\n\n    ws.onclose = () => {\n      setIsConnected(false);\n      onCloseRef.current?.();\n\n      if (reconnect && reconnectAttemptsRef.current < maxReconnectAttempts) {\n        reconnectTimeoutRef.current = setTimeout(() => {\n          reconnectAttemptsRef.current += 1;\n          connect();\n        }, reconnectInterval);\n      }\n    };\n\n    ws.onerror = (error) => {\n      onErrorRef.current?.(error);\n    };\n  }, [url, reconnect, reconnectInterval, maxReconnectAttempts]);\n\n  const disconnect = useCallback(() => {\n    if (reconnectTimeoutRef.current) {\n      clearTimeout(reconnectTimeoutRef.current);\n    }\n    wsRef.current?.close();\n    wsRef.current = null;\n  }, []);\n\n  const sendMessage = useCallback((data: string | object) => {\n    if (wsRef.current?.readyState === WebSocket.OPEN) {\n      const message = typeof data === \"string\" ? data : JSON.stringify(data);\n      wsRef.current.send(message);\n    }\n  }, []);\n\n  useEffect(() => {\n    return () => {\n      disconnect();\n    };\n  }, [disconnect]);\n\n  return {\n    isConnected,\n    connect,\n    disconnect,\n    sendMessage,\n  };\n}\n","frontend/src/hooks/use-local-chat.ts":"\"use client\";\n\nimport { useCallback, useRef, useState } from \"react\";\nimport { nanoid } from \"nanoid\";\nimport { useWebSocket } from \"./use-websocket\";\nimport { useLocalChatStore } from \"@/stores/local-chat-store\";\nimport type { ChatMessage, ToolCall, WSEvent, PendingApproval, Decision } from \"@/types\";\nimport { WS_URL } from \"@/lib/constants\";\n\nexport function useLocalChat() {\n  const {\n    currentConversationId,\n    getCurrentMessages,\n    createConversation,\n    addMessage,\n    updateMessage,\n    addToolCall,\n    updateToolCall,\n    clearCurrentMessages,\n  } = useLocalChatStore();\n\n  const messages = getCurrentMessages();\n  const [isProcessing, setIsProcessing] = useState(false);\n  const [currentMessageId, setCurrentMessageId] = useState<string | null>(null);\n  // Use ref for groupId to avoid React state timing issues with rapid WebSocket events\n  const currentGroupIdRef = useRef<string | null>(null);\n  // Human-in-the-Loop: pending tool approval state\n  const [pendingApproval, setPendingApproval] = useState<PendingApproval | null>(null);\n\n  const handleWebSocketMessage = useCallback(\n    (event: MessageEvent) => {\n      const wsEvent: WSEvent = JSON.parse(event.data);\n\n      // Helper to create a new message for CrewAI events\n      const createNewMessage = (content: string): string => {\n        // Mark previous message as not streaming before creating new one\n        if (currentMessageId) {\n          updateMessage(currentMessageId, (msg) => ({\n            ...msg,\n            isStreaming: false,\n          }));\n        }\n\n        const newMsgId = nanoid();\n        addMessage({\n          id: newMsgId,\n          role: \"assistant\",\n          content,\n          timestamp: new Date(),\n          isStreaming: true,\n          toolCalls: [],\n          groupId: currentGroupIdRef.current || undefined,\n        });\n        setCurrentMessageId(newMsgId);\n        return newMsgId;\n      };\n\n      switch (wsEvent.type) {\n        case \"model_request_start\": {\n          // PydanticAI/LangChain - create message immediately\n          createNewMessage(\"\");\n          break;\n        }\n\n        case \"crew_start\":\n        case \"crew_started\": {\n          // CrewAI - generate groupId for this execution, wait for agent events\n          currentGroupIdRef.current = nanoid();\n          break;\n        }\n\n        case \"text_delta\": {\n          if (currentMessageId) {\n            const content = (wsEvent.data as { index: number; content: string })\n              .content;\n            updateMessage(currentMessageId, (msg) => ({\n              ...msg,\n              content: msg.content + content,\n            }));\n          }\n          break;\n        }\n\n        // CrewAI agent events - each agent gets its own message container\n        case \"agent_started\": {\n          const { agent } = wsEvent.data as {\n            agent: string;\n            task: string;\n          };\n          // Create NEW message for this agent (groupId read from ref)\n          createNewMessage(`ü§ñ **${agent}** is starting...`);\n          break;\n        }\n\n        case \"agent_completed\": {\n          // Finalize current agent's message with output\n          if (currentMessageId) {\n            const { agent, output } = wsEvent.data as {\n              agent: string;\n              output: string;\n            };\n            updateMessage(currentMessageId, (msg) => ({\n              ...msg,\n              content: `‚úÖ **${agent}**\\n\\n${output}`,\n              isStreaming: false,\n            }));\n          }\n          break;\n        }\n\n        // CrewAI task events - create separate message for each task\n        case \"task_started\": {\n          const { description, agent } = wsEvent.data as {\n            task_id: string;\n            description: string;\n            agent: string;\n          };\n          // Create NEW message for this task (groupId read from ref)\n          createNewMessage(`üìã **Task** (${agent})\\n\\n${description}`);\n          break;\n        }\n\n        case \"task_completed\": {\n          // Finalize the task message\n          if (currentMessageId) {\n            const { output, agent } = wsEvent.data as {\n              task_id: string;\n              output: string;\n              agent: string;\n            };\n            updateMessage(currentMessageId, (msg) => ({\n              ...msg,\n              content: `‚úÖ **Task completed** (${agent})\\n\\n${output}`,\n              isStreaming: false,\n            }));\n          }\n          break;\n        }\n\n        // CrewAI tool events - add as tool calls to current message\n        case \"tool_started\": {\n          if (currentMessageId) {\n            const { tool_name, tool_args, agent } = wsEvent.data as {\n              tool_name: string;\n              tool_args: string;\n              agent: string;\n            };\n            const toolCall: ToolCall = {\n              id: nanoid(),\n              name: tool_name,\n              args: { input: tool_args, agent },\n              status: \"running\",\n            };\n            addToolCall(currentMessageId, toolCall);\n          }\n          break;\n        }\n\n        case \"tool_finished\": {\n          // Tool finished - update last tool call status\n          if (currentMessageId) {\n            const { tool_name, tool_result } = wsEvent.data as {\n              tool_name: string;\n              tool_result: string;\n              agent: string;\n            };\n            // Find and update the matching tool call\n            updateMessage(currentMessageId, (msg) => {\n              const toolCalls = msg.toolCalls || [];\n              const lastToolCall = toolCalls.find(\n                (tc) => tc.name === tool_name && tc.status === \"running\"\n              );\n              if (lastToolCall) {\n                return {\n                  ...msg,\n                  toolCalls: toolCalls.map((tc) =>\n                    tc.id === lastToolCall.id\n                      ? { ...tc, result: tool_result, status: \"completed\" as const }\n                      : tc\n                  ),\n                };\n              }\n              return msg;\n            });\n          }\n          break;\n        }\n\n        // LLM events - silently ignored\n        case \"llm_started\":\n        case \"llm_completed\": {\n          break;\n        }\n\n        case \"tool_call\": {\n          if (currentMessageId) {\n            const { tool_name, args, tool_call_id } = wsEvent.data as {\n              tool_name: string;\n              args: Record<string, unknown>;\n              tool_call_id: string;\n            };\n            const toolCall: ToolCall = {\n              id: tool_call_id,\n              name: tool_name,\n              args,\n              status: \"running\",\n            };\n            addToolCall(currentMessageId, toolCall);\n          }\n          break;\n        }\n\n        case \"tool_result\": {\n          if (currentMessageId) {\n            const { tool_call_id, content } = wsEvent.data as {\n              tool_call_id: string;\n              content: string;\n            };\n            updateToolCall(currentMessageId, tool_call_id, {\n              result: content,\n              status: \"completed\",\n            });\n          }\n          break;\n        }\n\n        case \"final_result\": {\n          if (currentMessageId) {\n            const { output } = wsEvent.data as { output: string };\n            // For CrewAI, replace content with final output if it exists\n            if (output) {\n              updateMessage(currentMessageId, (msg) => ({\n                ...msg,\n                content: msg.content || output,\n                isStreaming: false,\n              }));\n            } else {\n              updateMessage(currentMessageId, (msg) => ({\n                ...msg,\n                isStreaming: false,\n              }));\n            }\n          }\n          setIsProcessing(false);\n          setCurrentMessageId(null);\n          currentGroupIdRef.current = null;\n          break;\n        }\n\n        case \"error\": {\n          if (currentMessageId) {\n            const { message } = wsEvent.data as { message: string };\n            updateMessage(currentMessageId, (msg) => ({\n              ...msg,\n              content: msg.content + `\\n\\n‚ùå Error: ${message || \"Unknown error\"}`,\n              isStreaming: false,\n            }));\n          }\n          setIsProcessing(false);\n          break;\n        }\n\n        case \"tool_approval_required\": {\n          // Human-in-the-Loop: AI wants to execute tools that need approval\n          const { action_requests, review_configs } = wsEvent.data as {\n            action_requests: Array<{\n              id: string;\n              tool_name: string;\n              args: Record<string, unknown>;\n            }>;\n            review_configs: Array<{\n              tool_name: string;\n              allow_edit?: boolean;\n              timeout?: number;\n            }>;\n          };\n          setPendingApproval({\n            actionRequests: action_requests,\n            reviewConfigs: review_configs,\n          });\n          // Show pending tools in the current message\n          if (currentMessageId) {\n            const toolNames = action_requests.map((ar) => ar.tool_name).join(\", \");\n            updateMessage(currentMessageId, (msg) => ({\n              ...msg,\n              content: msg.content + `\\n\\n‚è∏Ô∏è Waiting for approval: ${toolNames}`,\n            }));\n          }\n          break;\n        }\n\n        case \"complete\": {\n          setIsProcessing(false);\n          break;\n        }\n      }\n    },\n    [currentMessageId, addMessage, updateMessage, addToolCall, updateToolCall]\n  );\n\n  const wsUrl = `${WS_URL}/api/v1/ws/agent`;\n\n  const { isConnected, connect, disconnect, sendMessage } = useWebSocket({\n    url: wsUrl,\n    onMessage: handleWebSocketMessage,\n  });\n\n  const sendChatMessage = useCallback(\n    (content: string) => {\n      let convId = currentConversationId;\n      if (!convId) {\n        convId = createConversation();\n      }\n\n      const userMessage: ChatMessage = {\n        id: nanoid(),\n        role: \"user\",\n        content,\n        timestamp: new Date(),\n      };\n      addMessage(userMessage);\n\n      setIsProcessing(true);\n      sendMessage({ message: content });\n    },\n    [addMessage, sendMessage, currentConversationId, createConversation]\n  );\n\n  const startNewChat = useCallback(() => {\n    createConversation();\n  }, [createConversation]);\n\n  // Human-in-the-Loop: send resume message with user decisions\n  const sendResumeDecisions = useCallback(\n    (decisions: Decision[]) => {\n      // Clear pending approval state\n      setPendingApproval(null);\n\n      // Update message to show decisions were made\n      if (currentMessageId) {\n        const approvedCount = decisions.filter((d) => d.type === \"approve\").length;\n        const editedCount = decisions.filter((d) => d.type === \"edit\").length;\n        const rejectedCount = decisions.filter((d) => d.type === \"reject\").length;\n\n        const summaryParts: string[] = [];\n        if (approvedCount > 0) summaryParts.push(`${approvedCount} approved`);\n        if (editedCount > 0) summaryParts.push(`${editedCount} edited`);\n        if (rejectedCount > 0) summaryParts.push(`${rejectedCount} rejected`);\n\n        updateMessage(currentMessageId, (msg) => ({\n          ...msg,\n          content: msg.content.replace(\n            /\\n\\n‚è∏Ô∏è Waiting for approval:.*$/,\n            `\\n\\n‚úÖ Decisions: ${summaryParts.join(\", \")}`\n          ),\n        }));\n      }\n\n      // Send resume message to WebSocket\n      sendMessage({\n        type: \"resume\",\n        decisions: decisions.map((d) => {\n          if (d.type === \"edit\" && d.editedAction) {\n            return {\n              type: \"edit\",\n              edited_action: d.editedAction,\n            };\n          }\n          return { type: d.type };\n        }),\n      });\n    },\n    [currentMessageId, updateMessage, sendMessage]\n  );\n\n  return {\n    messages,\n    currentConversationId,\n    isConnected,\n    isProcessing,\n    connect,\n    disconnect,\n    sendMessage: sendChatMessage,\n    clearMessages: clearCurrentMessages,\n    startNewChat,\n    // Human-in-the-Loop support\n    pendingApproval,\n    sendResumeDecisions,\n  };\n}\n","frontend/src/hooks/use-chat.ts":"\"use client\";\n\nimport { useCallback, useRef, useState } from \"react\";\nimport { nanoid } from \"nanoid\";\nimport { useWebSocket } from \"./use-websocket\";\nimport { useChatStore } from \"@/stores\";\nimport type { ChatMessage, ToolCall, WSEvent, PendingApproval, Decision } from \"@/types\";\nimport { WS_URL } from \"@/lib/constants\";\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nimport { useConversationStore } from \"@/stores\";\n{%- endif %}\n\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\ninterface UseChatOptions {\n  conversationId?: string | null;\n  onConversationCreated?: (conversationId: string) => void;\n}\n\nexport function useChat(options: UseChatOptions = {}) {\n  const { conversationId, onConversationCreated } = options;\n  const { setCurrentConversationId } = useConversationStore();\n{%- else %}\nexport function useChat() {\n{%- endif %}\n  const {\n    messages,\n    addMessage,\n    updateMessage,\n    addToolCall,\n    updateToolCall,\n    clearMessages,\n  } = useChatStore();\n\n  const [isProcessing, setIsProcessing] = useState(false);\n  const [currentMessageId, setCurrentMessageId] = useState<string | null>(null);\n  // Use ref for groupId to avoid React state timing issues with rapid WebSocket events\n  const currentGroupIdRef = useRef<string | null>(null);\n  // Human-in-the-Loop: pending tool approval state\n  const [pendingApproval, setPendingApproval] = useState<PendingApproval | null>(null);\n\n  const handleWebSocketMessage = useCallback(\n    (event: MessageEvent) => {\n      const wsEvent: WSEvent = JSON.parse(event.data);\n\n      // Helper to create a new message\n      const createNewMessage = (content: string): string => {\n        // Mark previous message as not streaming before creating new one\n        if (currentMessageId) {\n          updateMessage(currentMessageId, (msg) => ({\n            ...msg,\n            isStreaming: false,\n          }));\n        }\n\n        const newMsgId = nanoid();\n        addMessage({\n          id: newMsgId,\n          role: \"assistant\",\n          content,\n          timestamp: new Date(),\n          isStreaming: true,\n          toolCalls: [],\n          groupId: currentGroupIdRef.current || undefined,\n        });\n        setCurrentMessageId(newMsgId);\n        return newMsgId;\n      };\n\n      switch (wsEvent.type) {\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n        case \"conversation_created\": {\n          // Handle new conversation created by backend\n          const { conversation_id } = wsEvent.data as { conversation_id: string };\n          setCurrentConversationId(conversation_id);\n          onConversationCreated?.(conversation_id);\n          break;\n        }\n\n        case \"message_saved\": {\n          // Message was saved to database, update local ID if needed\n          // We don't need to do anything special here for now\n          break;\n        }\n{%- endif %}\n\n        case \"model_request_start\": {\n          // PydanticAI/LangChain - create message immediately\n          createNewMessage(\"\");\n          break;\n        }\n\n        case \"crew_start\":\n        case \"crew_started\": {\n          // CrewAI - generate groupId for this execution, wait for agent events\n          currentGroupIdRef.current = nanoid();\n          break;\n        }\n\n        case \"text_delta\": {\n          // Append text delta to current message\n          if (currentMessageId) {\n            const content = (wsEvent.data as { index: number; content: string }).content;\n            updateMessage(currentMessageId, (msg) => ({\n              ...msg,\n              content: msg.content + content,\n            }));\n          }\n          break;\n        }\n\n        // CrewAI agent events - each agent gets its own message container\n        case \"agent_started\": {\n          const { agent } = wsEvent.data as {\n            agent: string;\n            task: string;\n          };\n          // Create NEW message for this agent (groupId read from ref)\n          createNewMessage(`ü§ñ **${agent}** is starting...`);\n          break;\n        }\n\n        case \"agent_completed\": {\n          // Finalize current agent's message with output\n          if (currentMessageId) {\n            const { agent, output } = wsEvent.data as {\n              agent: string;\n              output: string;\n            };\n            updateMessage(currentMessageId, (msg) => ({\n              ...msg,\n              content: `‚úÖ **${agent}**\\n\\n${output}`,\n              isStreaming: false,\n            }));\n          }\n          break;\n        }\n\n        // CrewAI task events - create separate message for each task\n        case \"task_started\": {\n          const { description, agent } = wsEvent.data as {\n            task_id: string;\n            description: string;\n            agent: string;\n          };\n          // Create NEW message for this task (groupId read from ref)\n          createNewMessage(`üìã **Task** (${agent})\\n\\n${description}`);\n          break;\n        }\n\n        case \"task_completed\": {\n          // Finalize the task message\n          if (currentMessageId) {\n            const { output, agent } = wsEvent.data as {\n              task_id: string;\n              output: string;\n              agent: string;\n            };\n            updateMessage(currentMessageId, (msg) => ({\n              ...msg,\n              content: `‚úÖ **Task completed** (${agent})\\n\\n${output}`,\n              isStreaming: false,\n            }));\n          }\n          break;\n        }\n\n        // CrewAI tool events\n        case \"tool_started\": {\n          if (currentMessageId) {\n            const { tool_name, tool_args, agent } = wsEvent.data as {\n              tool_name: string;\n              tool_args: string;\n              agent: string;\n            };\n            const toolCall: ToolCall = {\n              id: nanoid(),\n              name: tool_name,\n              args: { input: tool_args, agent },\n              status: \"running\",\n            };\n            addToolCall(currentMessageId, toolCall);\n          }\n          break;\n        }\n\n        case \"tool_finished\": {\n          // Tool finished - update last tool call status\n          if (currentMessageId) {\n            const { tool_name, tool_result } = wsEvent.data as {\n              tool_name: string;\n              tool_result: string;\n              agent: string;\n            };\n            // Find and update the matching tool call\n            updateMessage(currentMessageId, (msg) => {\n              const toolCalls = msg.toolCalls || [];\n              const lastToolCall = toolCalls.find(\n                (tc) => tc.name === tool_name && tc.status === \"running\"\n              );\n              if (lastToolCall) {\n                return {\n                  ...msg,\n                  toolCalls: toolCalls.map((tc) =>\n                    tc.id === lastToolCall.id\n                      ? { ...tc, result: tool_result, status: \"completed\" as const }\n                      : tc\n                  ),\n                };\n              }\n              return msg;\n            });\n          }\n          break;\n        }\n\n        // LLM events (can be used for showing thinking status)\n        case \"llm_started\":\n        case \"llm_completed\": {\n          // LLM lifecycle events - optionally show status\n          break;\n        }\n\n        case \"tool_call\": {\n          // Add tool call to current message\n          if (currentMessageId) {\n            const { tool_name, args, tool_call_id } = wsEvent.data as {\n              tool_name: string;\n              args: Record<string, unknown>;\n              tool_call_id: string;\n            };\n            const toolCall: ToolCall = {\n              id: tool_call_id,\n              name: tool_name,\n              args,\n              status: \"running\",\n            };\n            addToolCall(currentMessageId, toolCall);\n          }\n          break;\n        }\n\n        case \"tool_result\": {\n          // Update tool call with result\n          if (currentMessageId) {\n            const { tool_call_id, content } = wsEvent.data as {\n              tool_call_id: string;\n              content: string;\n            };\n            updateToolCall(currentMessageId, tool_call_id, {\n              result: content,\n              status: \"completed\",\n            });\n          }\n          break;\n        }\n\n        case \"final_result\": {\n          // Finalize message\n          if (currentMessageId) {\n            const { output } = wsEvent.data as { output: string };\n            if (output) {\n              updateMessage(currentMessageId, (msg) => ({\n                ...msg,\n                content: msg.content || output,\n                isStreaming: false,\n              }));\n            } else {\n              updateMessage(currentMessageId, (msg) => ({\n                ...msg,\n                isStreaming: false,\n              }));\n            }\n          }\n          setIsProcessing(false);\n          setCurrentMessageId(null);\n          currentGroupIdRef.current = null;\n          break;\n        }\n\n        case \"error\": {\n          // Handle error\n          if (currentMessageId) {\n            const { message } = wsEvent.data as { message: string };\n            updateMessage(currentMessageId, (msg) => ({\n              ...msg,\n              content: msg.content + `\\n\\n‚ùå Error: ${message || \"Unknown error\"}`,\n              isStreaming: false,\n            }));\n          }\n          setIsProcessing(false);\n          break;\n        }\n\n        case \"tool_approval_required\": {\n          // Human-in-the-Loop: AI wants to execute tools that need approval\n          const { action_requests, review_configs } = wsEvent.data as {\n            action_requests: Array<{\n              id: string;\n              tool_name: string;\n              args: Record<string, unknown>;\n            }>;\n            review_configs: Array<{\n              tool_name: string;\n              allow_edit?: boolean;\n              timeout?: number;\n            }>;\n          };\n          setPendingApproval({\n            actionRequests: action_requests,\n            reviewConfigs: review_configs,\n          });\n          // Show pending tools in the current message\n          if (currentMessageId) {\n            const toolNames = action_requests.map((ar) => ar.tool_name).join(\", \");\n            updateMessage(currentMessageId, (msg) => ({\n              ...msg,\n              content: msg.content + `\\n\\n‚è∏Ô∏è Waiting for approval: ${toolNames}`,\n            }));\n          }\n          break;\n        }\n\n        case \"complete\": {\n          setIsProcessing(false);\n          break;\n        }\n      }\n    },\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n    [currentMessageId, addMessage, updateMessage, addToolCall, updateToolCall, setCurrentConversationId, onConversationCreated]\n{%- else %}\n    [currentMessageId, addMessage, updateMessage, addToolCall, updateToolCall]\n{%- endif %}\n  );\n\n  const wsUrl = `${WS_URL}/api/v1/ws/agent`;\n\n  const { isConnected, connect, disconnect, sendMessage } = useWebSocket({\n    url: wsUrl,\n    onMessage: handleWebSocketMessage,\n  });\n\n  const sendChatMessage = useCallback(\n    (content: string) => {\n      // Add user message\n      const userMessage: ChatMessage = {\n        id: nanoid(),\n        role: \"user\",\n        content,\n        timestamp: new Date(),\n      };\n      addMessage(userMessage);\n\n      // Send to WebSocket\n      setIsProcessing(true);\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n      sendMessage({\n        message: content,\n        conversation_id: conversationId || null,\n      });\n{%- else %}\n      sendMessage({ message: content });\n{%- endif %}\n    },\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n    [addMessage, sendMessage, conversationId]\n{%- else %}\n    [addMessage, sendMessage]\n{%- endif %}\n  );\n\n  // Human-in-the-Loop: send resume message with user decisions\n  const sendResumeDecisions = useCallback(\n    (decisions: Decision[]) => {\n      // Clear pending approval state\n      setPendingApproval(null);\n\n      // Update message to show decisions were made\n      if (currentMessageId) {\n        const approvedCount = decisions.filter((d) => d.type === \"approve\").length;\n        const editedCount = decisions.filter((d) => d.type === \"edit\").length;\n        const rejectedCount = decisions.filter((d) => d.type === \"reject\").length;\n\n        const summaryParts: string[] = [];\n        if (approvedCount > 0) summaryParts.push(`${approvedCount} approved`);\n        if (editedCount > 0) summaryParts.push(`${editedCount} edited`);\n        if (rejectedCount > 0) summaryParts.push(`${rejectedCount} rejected`);\n\n        updateMessage(currentMessageId, (msg) => ({\n          ...msg,\n          content: msg.content.replace(\n            /\\n\\n‚è∏Ô∏è Waiting for approval:.*$/,\n            `\\n\\n‚úÖ Decisions: ${summaryParts.join(\", \")}`\n          ),\n        }));\n      }\n\n      // Send resume message to WebSocket\n      sendMessage({\n        type: \"resume\",\n        decisions: decisions.map((d) => {\n          if (d.type === \"edit\" && d.editedAction) {\n            return {\n              type: \"edit\",\n              edited_action: d.editedAction,\n            };\n          }\n          return { type: d.type };\n        }),\n      });\n    },\n    [currentMessageId, updateMessage, sendMessage]\n  );\n\n  return {\n    messages,\n    isConnected,\n    isProcessing,\n    connect,\n    disconnect,\n    sendMessage: sendChatMessage,\n    clearMessages,\n    // Human-in-the-Loop support\n    pendingApproval,\n    sendResumeDecisions,\n  };\n}\n","frontend/src/hooks/index.ts":"export { useAuth } from \"./use-auth\";\nexport { useWebSocket } from \"./use-websocket\";\nexport { useChat } from \"./use-chat\";\nexport { useLocalChat } from \"./use-local-chat\";\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nexport { useConversations } from \"./use-conversations\";\n{%- endif %}\n","frontend/src/lib/api-client.ts":"/**\n * Client-side API client.\n * All requests go through Next.js API routes (/api/*), never directly to the backend.\n * This keeps the backend URL hidden from the browser.\n */\n\nexport class ApiError extends Error {\n  constructor(\n    public status: number,\n    public message: string,\n    public data?: unknown\n  ) {\n    super(message);\n    this.name = \"ApiError\";\n  }\n}\n\ninterface RequestOptions extends Omit<RequestInit, \"body\"> {\n  params?: Record<string, string>;\n  body?: unknown;\n}\n\nclass ApiClient {\n  private async request<T>(\n    endpoint: string,\n    options: RequestOptions = {}\n  ): Promise<T> {\n    const { params, body, ...fetchOptions } = options;\n\n    let url = `/api${endpoint}`;\n\n    if (params) {\n      const searchParams = new URLSearchParams(params);\n      url += `?${searchParams.toString()}`;\n    }\n\n    const response = await fetch(url, {\n      ...fetchOptions,\n      headers: {\n        \"Content-Type\": \"application/json\",\n        ...fetchOptions.headers,\n      },\n      body: body ? JSON.stringify(body) : undefined,\n    });\n\n    if (!response.ok) {\n      let errorData;\n      try {\n        errorData = await response.json();\n      } catch {\n        errorData = null;\n      }\n      throw new ApiError(\n        response.status,\n        errorData?.detail || errorData?.message || \"Request failed\",\n        errorData\n      );\n    }\n\n    // Handle empty responses\n    const text = await response.text();\n    if (!text) {\n      return null as T;\n    }\n\n    return JSON.parse(text);\n  }\n\n  get<T>(endpoint: string, options?: RequestOptions) {\n    return this.request<T>(endpoint, { ...options, method: \"GET\" });\n  }\n\n  post<T>(endpoint: string, body?: unknown, options?: RequestOptions) {\n    return this.request<T>(endpoint, { ...options, method: \"POST\", body });\n  }\n\n  put<T>(endpoint: string, body?: unknown, options?: RequestOptions) {\n    return this.request<T>(endpoint, { ...options, method: \"PUT\", body });\n  }\n\n  patch<T>(endpoint: string, body?: unknown, options?: RequestOptions) {\n    return this.request<T>(endpoint, { ...options, method: \"PATCH\", body });\n  }\n\n  delete<T>(endpoint: string, options?: RequestOptions) {\n    return this.request<T>(endpoint, { ...options, method: \"DELETE\" });\n  }\n}\n\nexport const apiClient = new ApiClient();\n","frontend/src/lib/utils.test.ts":"{%- if cookiecutter.use_frontend %}\nimport { describe, it, expect } from \"vitest\";\nimport { cn } from \"./utils\";\n\ndescribe(\"cn utility function\", () => {\n  it(\"should merge class names\", () => {\n    const result = cn(\"class1\", \"class2\");\n    expect(result).toBe(\"class1 class2\");\n  });\n\n  it(\"should handle conditional classes\", () => {\n    const result = cn(\"base\", { active: true, disabled: false });\n    expect(result).toContain(\"base\");\n    expect(result).toContain(\"active\");\n    expect(result).not.toContain(\"disabled\");\n  });\n\n  it(\"should handle undefined and null values\", () => {\n    const result = cn(\"base\", undefined, null, \"extra\");\n    expect(result).toBe(\"base extra\");\n  });\n\n  it(\"should merge tailwind classes correctly\", () => {\n    // tailwind-merge should handle conflicting utilities\n    const result = cn(\"px-2 py-1\", \"px-4\");\n    expect(result).toContain(\"px-4\");\n    expect(result).toContain(\"py-1\");\n  });\n\n  it(\"should handle empty input\", () => {\n    const result = cn();\n    expect(result).toBe(\"\");\n  });\n\n  it(\"should handle array of classes\", () => {\n    const result = cn([\"class1\", \"class2\"]);\n    expect(result).toContain(\"class1\");\n    expect(result).toContain(\"class2\");\n  });\n});\n{%- else %}\n/* Utils tests - frontend not configured */\nexport {};\n{%- endif %}\n","frontend/src/lib/utils.ts":"import { type ClassValue, clsx } from \"clsx\";\nimport { twMerge } from \"tailwind-merge\";\n\n/**\n * Merge Tailwind CSS classes with clsx.\n * This is the standard utility used by shadcn/ui components.\n */\nexport function cn(...inputs: ClassValue[]) {\n  return twMerge(clsx(inputs));\n}\n\n/**\n * Format a date to a human-readable string.\n */\nexport function formatDate(date: Date | string): string {\n  const d = typeof date === \"string\" ? new Date(date) : date;\n  return d.toLocaleDateString(\"en-US\", {\n    year: \"numeric\",\n    month: \"short\",\n    day: \"numeric\",\n  });\n}\n\n/**\n * Format a date to include time.\n */\nexport function formatDateTime(date: Date | string): string {\n  const d = typeof date === \"string\" ? new Date(date) : date;\n  return d.toLocaleString(\"en-US\", {\n    year: \"numeric\",\n    month: \"short\",\n    day: \"numeric\",\n    hour: \"2-digit\",\n    minute: \"2-digit\",\n  });\n}\n\n/**\n * Truncate a string to a maximum length.\n */\nexport function truncate(str: string, maxLength: number): string {\n  if (str.length <= maxLength) return str;\n  return str.slice(0, maxLength - 3) + \"...\";\n}\n","frontend/src/lib/constants.ts":"/**\n * Application constants.\n */\n\nexport const APP_NAME = \"{{ cookiecutter.project_name }}\";\nexport const APP_DESCRIPTION = \"{{ cookiecutter.project_description }}\";\n\n// API Routes (Next.js internal routes)\nexport const API_ROUTES = {\n  // Auth\n  LOGIN: \"/auth/login\",\n  REGISTER: \"/auth/register\",\n  LOGOUT: \"/auth/logout\",\n  REFRESH: \"/auth/refresh\",\n  ME: \"/auth/me\",\n\n  // Health\n  HEALTH: \"/health\",\n\n  // Users\n  USERS: \"/users\",\n\n  // Chat (AI Agent)\n  CHAT: \"/chat\",\n} as const;\n\n// Navigation routes\nexport const ROUTES = {\n  HOME: \"/\",\n  LOGIN: \"/login\",\n  REGISTER: \"/register\",\n  DASHBOARD: \"/dashboard\",\n  CHAT: \"/chat\",\n  PROFILE: \"/profile\",\n  SETTINGS: \"/settings\",\n} as const;\n\n// WebSocket URL (for chat - this needs to be direct to backend for WS)\nexport const WS_URL = process.env.NEXT_PUBLIC_WS_URL || \"ws://localhost:{{ cookiecutter.backend_port }}\";\n","frontend/src/lib/server-api.ts":"/**\n * Server-side API client for calling the FastAPI backend.\n * This module is used by Next.js API routes to proxy requests.\n * IMPORTANT: This file should only be imported in server-side code (API routes, Server Components).\n */\n\nconst BACKEND_URL = process.env.BACKEND_URL || \"http://localhost:8000\";\n\nexport class BackendApiError extends Error {\n  constructor(\n    public status: number,\n    public statusText: string,\n    public data?: unknown\n  ) {\n    super(`Backend API error: ${status} ${statusText}`);\n    this.name = \"BackendApiError\";\n  }\n}\n\ninterface RequestOptions extends RequestInit {\n  params?: Record<string, string>;\n}\n\n/**\n * Make a request to the FastAPI backend.\n * This should only be called from Next.js API routes or Server Components.\n */\nexport async function backendFetch<T>(\n  endpoint: string,\n  options: RequestOptions = {}\n): Promise<T> {\n  const { params, ...fetchOptions } = options;\n\n  let url = `${BACKEND_URL}${endpoint}`;\n\n  if (params) {\n    const searchParams = new URLSearchParams(params);\n    url += `?${searchParams.toString()}`;\n  }\n\n  const response = await fetch(url, {\n    ...fetchOptions,\n    headers: {\n      \"Content-Type\": \"application/json\",\n      ...fetchOptions.headers,\n    },\n  });\n\n  if (!response.ok) {\n    let errorData;\n    try {\n      errorData = await response.json();\n    } catch {\n      errorData = null;\n    }\n    throw new BackendApiError(response.status, response.statusText, errorData);\n  }\n\n  // Handle empty responses\n  const text = await response.text();\n  if (!text) {\n    return null as T;\n  }\n\n  return JSON.parse(text);\n}\n\n/**\n * Forward authorization header from the incoming request to the backend.\n */\nexport function getAuthHeaders(\n  authHeader: string | null\n): Record<string, string> {\n  if (!authHeader) {\n    return {};\n  }\n  return { Authorization: authHeader };\n}\n","Makefile":".PHONY: install format lint test run clean help db-init\n\n# === Setup ===\ninstall:\n\tuv sync --directory backend --dev\n{%- if cookiecutter.enable_precommit %}\n\t@if git rev-parse --git-dir > /dev/null 2>&1; then \\\n\t\tuv run --directory backend pre-commit install; \\\n\telse \\\n\t\techo \"‚ö†Ô∏è  Not a git repository - skipping pre-commit install\"; \\\n\t\techo \"   Run 'git init && make install' to set up pre-commit hooks\"; \\\n\tfi\n{%- endif %}\n\t@echo \"\"\n\t@echo \"‚úÖ Installation complete!\"\n\t@echo \"\"\n\t@echo \"Next steps:\"\n{%- if not cookiecutter.generate_env %}\n\t@echo \"  ‚Ä¢ cd backend && cp .env.example .env\"\n\t@echo \"  ‚Ä¢ Edit backend/.env with your settings\"\n{%- endif %}\n{%- if cookiecutter.use_postgresql %}\n\t@echo \"  ‚Ä¢ make docker-db        # Start PostgreSQL\"\n\t@echo \"  ‚Ä¢ make db-upgrade       # Apply migrations\"\n{%- endif %}\n\t@echo \"  ‚Ä¢ make run              # Start development server\"\n{%- if cookiecutter.generate_env %}\n\t@echo \"\"\n\t@echo \"Note: backend/.env is pre-configured for development\"\n{%- endif %}\n\n# === Code Quality ===\nformat:\n\tuv run --directory backend ruff format app tests cli\n\tuv run --directory backend ruff check app tests cli --fix\n\nlint:\n\tuv run --directory backend ruff check app tests cli\n\tuv run --directory backend ruff format app tests cli --check\n\tuv run --directory backend mypy app\n\n# === Testing ===\ntest:\n\tuv run --directory backend pytest tests/ -v\n\ntest-cov:\n\tuv run --directory backend pytest tests/ -v --cov=app --cov-report=html --cov-report=term-missing\n\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\n# === Database ===\n{%- if cookiecutter.use_postgresql and cookiecutter.enable_docker %}\ndb-init: docker-db\n\t@echo \"Waiting for PostgreSQL to be ready...\"\n\t@sleep 3\n\tuv run --directory backend {{ cookiecutter.project_slug }} db upgrade\n\t@echo \"\"\n\t@echo \"‚úÖ Database initialized!\"\n{%- else %}\ndb-init:\n\tuv run --directory backend {{ cookiecutter.project_slug }} db upgrade\n\t@echo \"\"\n\t@echo \"‚úÖ Database initialized!\"\n{%- endif %}\n\ndb-migrate:\n\t@read -p \"Migration message: \" msg; \\\n\tuv run --directory backend {{ cookiecutter.project_slug }} db migrate -m \"$$msg\"\n\ndb-upgrade:\n\tuv run --directory backend {{ cookiecutter.project_slug }} db upgrade\n\ndb-downgrade:\n\tuv run --directory backend {{ cookiecutter.project_slug }} db downgrade\n\ndb-current:\n\tuv run --directory backend {{ cookiecutter.project_slug }} db current\n\ndb-history:\n\tuv run --directory backend {{ cookiecutter.project_slug }} db history\n{%- endif %}\n\n# === Server ===\nrun:\n\tuv run --directory backend {{ cookiecutter.project_slug }} server run --reload\n\nrun-prod:\n\tuv run --directory backend {{ cookiecutter.project_slug }} server run --host 0.0.0.0 --port 8000\n\nroutes:\n\tuv run --directory backend {{ cookiecutter.project_slug }} server routes\n\n{%- if cookiecutter.use_jwt %}\n\n# === Users ===\ncreate-admin:\n\t@echo \"Creating admin user...\"\n\tuv run --directory backend {{ cookiecutter.project_slug }} user create-admin\n\nuser-create:\n\tuv run --directory backend {{ cookiecutter.project_slug }} user create\n\nuser-list:\n\tuv run --directory backend {{ cookiecutter.project_slug }} user list\n{%- endif %}\n\n{%- if cookiecutter.use_celery %}\n\n# === Celery ===\ncelery-worker:\n\tuv run --directory backend {{ cookiecutter.project_slug }} celery worker\n\ncelery-beat:\n\tuv run --directory backend {{ cookiecutter.project_slug }} celery beat\n\ncelery-flower:\n\tuv run --directory backend {{ cookiecutter.project_slug }} celery flower\n\t@echo \"\"\n\t@echo \"‚úÖ Flower started at http://localhost:5555\"\n{%- endif %}\n\n{%- if cookiecutter.use_taskiq %}\n\n# === Taskiq ===\ntaskiq-worker:\n\tuv run --directory backend {{ cookiecutter.project_slug }} taskiq worker\n\ntaskiq-scheduler:\n\tuv run --directory backend {{ cookiecutter.project_slug }} taskiq scheduler\n{%- endif %}\n\n{%- if cookiecutter.enable_docker %}\n\n# === Docker: Backend (Development) ===\ndocker-up:\n\tdocker-compose up -d\n\t@echo \"\"\n\t@echo \"‚úÖ Backend services started!\"\n\t@echo \"   API: http://localhost:{{ cookiecutter.backend_port }}\"\n\t@echo \"   Docs: http://localhost:{{ cookiecutter.backend_port }}/docs\"\n{%- if cookiecutter.use_celery %}\n\t@echo \"   Flower: http://localhost:5555\"\n{%- endif %}\n{%- if cookiecutter.use_postgresql %}\n\t@echo \"   PostgreSQL: localhost:5432\"\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n\t@echo \"   Redis: localhost:6379\"\n{%- endif %}\n\ndocker-down:\n\tdocker-compose down\n{%- if cookiecutter.use_frontend %}\n\tdocker-compose -f docker-compose.frontend.yml down 2>/dev/null || true\n{%- endif %}\n\ndocker-logs:\n\tdocker-compose logs -f\n\ndocker-build:\n\tdocker-compose build\n\ndocker-shell:\n\tdocker-compose exec app /bin/bash\n\n{%- if cookiecutter.use_frontend %}\n\n# === Docker: Frontend (Development) ===\ndocker-frontend:\n\tdocker-compose -f docker-compose.frontend.yml up -d\n\t@echo \"\"\n\t@echo \"‚úÖ Frontend started!\"\n\t@echo \"   URL: http://localhost:{{ cookiecutter.frontend_port }}\"\n\t@echo \"\"\n\t@echo \"Note: Backend must be running (make docker-up)\"\n\ndocker-frontend-down:\n\tdocker-compose -f docker-compose.frontend.yml down\n\ndocker-frontend-logs:\n\tdocker-compose -f docker-compose.frontend.yml logs -f\n\ndocker-frontend-build:\n\tdocker-compose -f docker-compose.frontend.yml build\n{%- endif %}\n\n# === Docker: Production (with Traefik) ===\ndocker-prod:\n\tdocker-compose -f docker-compose.prod.yml up -d\n\t@echo \"\"\n\t@echo \"‚úÖ Production services started with Traefik!\"\n\t@echo \"\"\n\t@echo \"Endpoints (replace DOMAIN with your domain):\"\n{%- if cookiecutter.use_frontend %}\n\t@echo \"   Frontend: https://$$DOMAIN\"\n{%- endif %}\n\t@echo \"   API: https://api.$$DOMAIN\"\n{%- if cookiecutter.use_celery %}\n\t@echo \"   Flower: https://flower.$$DOMAIN\"\n{%- endif %}\n\t@echo \"   Traefik: https://traefik.$$DOMAIN\"\n\ndocker-prod-down:\n\tdocker-compose -f docker-compose.prod.yml down\n\ndocker-prod-logs:\n\tdocker-compose -f docker-compose.prod.yml logs -f\n\ndocker-prod-build:\n\tdocker-compose -f docker-compose.prod.yml build\n\n{%- if cookiecutter.use_postgresql %}\n\n# === Docker: Individual Services ===\ndocker-db:\n\tdocker-compose up -d db\n\t@echo \"\"\n\t@echo \"‚úÖ PostgreSQL started on port 5432\"\n\t@echo \"   Connection: postgresql://postgres:postgres@localhost:5432/{{ cookiecutter.project_slug }}\"\n\ndocker-db-stop:\n\tdocker-compose stop db\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n\ndocker-redis:\n\tdocker-compose up -d redis\n\t@echo \"\"\n\t@echo \"‚úÖ Redis started on port 6379\"\n\ndocker-redis-stop:\n\tdocker-compose stop redis\n{%- endif %}\n{%- endif %}\n\n# === Cleanup ===\nclean:\n\tfind . -type d -name __pycache__ -exec rm -rf {} + 2>/dev/null || true\n\tfind . -type d -name .pytest_cache -exec rm -rf {} + 2>/dev/null || true\n\tfind . -type d -name .ruff_cache -exec rm -rf {} + 2>/dev/null || true\n\tfind . -type d -name .mypy_cache -exec rm -rf {} + 2>/dev/null || true\n\trm -rf htmlcov/ .coverage coverage.xml\n\n# === Help ===\nhelp:\n\t@echo \"\"\n\t@echo \"{{ cookiecutter.project_name }} - Available Commands\"\n\t@echo \"======================================\"\n\t@echo \"\"\n\t@echo \"Setup:\"\n\t@echo \"  make install       Install dependencies + pre-commit hooks\"\n\t@echo \"\"\n\t@echo \"Development:\"\n\t@echo \"  make run           Start dev server (with hot reload)\"\n\t@echo \"  make test          Run tests\"\n\t@echo \"  make lint          Check code quality\"\n\t@echo \"  make format        Auto-format code\"\n\t@echo \"\"\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\t@echo \"Database:\"\n\t@echo \"  make db-init       Initialize database (start + migrate)\"\n\t@echo \"  make db-migrate    Create new migration\"\n\t@echo \"  make db-upgrade    Apply migrations\"\n\t@echo \"  make db-downgrade  Rollback last migration\"\n\t@echo \"  make db-current    Show current migration\"\n\t@echo \"\"\n{%- endif %}\n{%- if cookiecutter.use_jwt %}\n\t@echo \"Users:\"\n\t@echo \"  make create-admin  Create admin user (for SQLAdmin access)\"\n\t@echo \"  make user-create   Create new user (interactive)\"\n\t@echo \"  make user-list     List all users\"\n\t@echo \"\"\n{%- endif %}\n{%- if cookiecutter.use_celery %}\n\t@echo \"Celery:\"\n\t@echo \"  make celery-worker  Start Celery worker\"\n\t@echo \"  make celery-beat    Start Celery beat scheduler\"\n\t@echo \"  make celery-flower  Start Flower monitoring UI\"\n\t@echo \"\"\n{%- endif %}\n{%- if cookiecutter.use_taskiq %}\n\t@echo \"Taskiq:\"\n\t@echo \"  make taskiq-worker     Start Taskiq worker\"\n\t@echo \"  make taskiq-scheduler  Start Taskiq scheduler\"\n\t@echo \"\"\n{%- endif %}\n{%- if cookiecutter.enable_docker %}\n\t@echo \"Docker (Development):\"\n\t@echo \"  make docker-up            Start backend services\"\n\t@echo \"  make docker-down          Stop all services\"\n\t@echo \"  make docker-logs          View backend logs\"\n\t@echo \"  make docker-build         Build backend images\"\n{%- if cookiecutter.use_frontend %}\n\t@echo \"  make docker-frontend      Start frontend (separate)\"\n\t@echo \"  make docker-frontend-down Stop frontend\"\n{%- endif %}\n{%- if cookiecutter.use_postgresql %}\n\t@echo \"  make docker-db            Start only PostgreSQL\"\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n\t@echo \"  make docker-redis         Start only Redis\"\n{%- endif %}\n\t@echo \"\"\n\t@echo \"Docker (Production with Traefik):\"\n\t@echo \"  make docker-prod          Start production stack\"\n\t@echo \"  make docker-prod-down     Stop production stack\"\n\t@echo \"  make docker-prod-logs     View production logs\"\n\t@echo \"\"\n{%- endif %}\n\t@echo \"Other:\"\n\t@echo \"  make routes        Show all API routes\"\n\t@echo \"  make clean         Clean cache files\"\n\t@echo \"\"\n","backend/app/clients/__init__.py":"\"\"\"External service clients.\n\nThis module contains thin wrappers around external services like Redis.\n\"\"\"\n{%- if cookiecutter.enable_redis %}\n\nfrom app.clients.redis import RedisClient\n{%- endif %}\n\n__all__ = [\n{%- if cookiecutter.enable_redis %}\n    \"RedisClient\",\n{%- endif %}\n]\n","backend/app/clients/redis.py":"{%- if cookiecutter.enable_redis %}\n\"\"\"Redis client wrapper.\n\nProvides a class-based Redis client for connection management and operations.\n\"\"\"\n\nfrom redis import asyncio as aioredis\n\nfrom app.core.config import settings\n\n\nclass RedisClient:\n    \"\"\"Redis client wrapper for connection lifecycle management.\n\n    Usage in FastAPI lifespan:\n        async with contextmanager():\n            redis = RedisClient(settings.REDIS_URL)\n            await redis.connect()\n            yield {\"redis\": redis}\n            await redis.close()\n    \"\"\"\n\n    def __init__(self, url: str | None = None):\n        self.url = url or settings.REDIS_URL\n        self.client: aioredis.Redis | None = None\n\n    async def connect(self) -> None:\n        \"\"\"Connect to Redis server.\"\"\"\n        self.client = aioredis.from_url(\n            self.url,\n            encoding=\"utf-8\",\n            decode_responses=True,\n        )\n\n    async def close(self) -> None:\n        \"\"\"Close Redis connection.\"\"\"\n        if self.client:\n            await self.client.close()\n            self.client = None\n\n    async def get(self, key: str) -> str | None:\n        \"\"\"Get a value by key.\"\"\"\n        if not self.client:\n            raise RuntimeError(\"Redis client not connected\")\n        return await self.client.get(key)\n\n    async def set(\n        self,\n        key: str,\n        value: str,\n        ttl: int | None = None,\n    ) -> None:\n        \"\"\"Set a value with optional TTL (in seconds).\"\"\"\n        if not self.client:\n            raise RuntimeError(\"Redis client not connected\")\n        await self.client.set(key, value, ex=ttl)\n\n    async def delete(self, key: str) -> int:\n        \"\"\"Delete a key. Returns number of keys deleted.\"\"\"\n        if not self.client:\n            raise RuntimeError(\"Redis client not connected\")\n        return await self.client.delete(key)\n\n    async def exists(self, key: str) -> bool:\n        \"\"\"Check if key exists.\"\"\"\n        if not self.client:\n            raise RuntimeError(\"Redis client not connected\")\n        return bool(await self.client.exists(key))\n\n    async def ping(self) -> bool:\n        \"\"\"Ping Redis server. Returns True if connected.\"\"\"\n        if not self.client:\n            return False\n        try:\n            await self.client.ping()\n            return True\n        except Exception:\n            return False\n\n    @property\n    def raw(self) -> aioredis.Redis:\n        \"\"\"Access the underlying aioredis client for advanced operations.\"\"\"\n        if not self.client:\n            raise RuntimeError(\"Redis client not connected\")\n        return self.client\n{%- else %}\n\"\"\"Redis client - not configured.\"\"\"\n{%- endif %}\n","backend/app/core/config.py":"\"\"\"Application configuration using Pydantic BaseSettings.\"\"\"\n{% if cookiecutter.use_database or cookiecutter.enable_redis -%}\n# ruff: noqa: I001 - Imports structured for Jinja2 template conditionals\n{% endif %}\nfrom pathlib import Path\nfrom typing import Literal\n\n{% if cookiecutter.use_database or cookiecutter.enable_redis -%}\nfrom pydantic import computed_field, field_validator{% if cookiecutter.use_jwt or cookiecutter.use_api_key or cookiecutter.enable_cors %}, ValidationInfo{% endif %}\n{% else -%}\nfrom pydantic import field_validator{% if cookiecutter.use_jwt or cookiecutter.use_api_key or cookiecutter.enable_cors %}, ValidationInfo{% endif %}\n{% endif -%}\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\n\n\ndef find_env_file() -> Path | None:\n    \"\"\"Find .env file in current or parent directories.\"\"\"\n    current = Path.cwd()\n    for path in [current, current.parent]:\n        env_file = path / \".env\"\n        if env_file.exists():\n            return env_file\n    return None\n\n\nclass Settings(BaseSettings):\n    \"\"\"Application settings.\"\"\"\n\n    model_config = SettingsConfigDict(\n        env_file=find_env_file(),\n        env_ignore_empty=True,\n        extra=\"ignore\",\n    )\n\n    # === Project ===\n    PROJECT_NAME: str = \"{{ cookiecutter.project_name }}\"\n    API_V1_STR: str = \"/api/v1\"\n    DEBUG: bool = False\n    ENVIRONMENT: Literal[\"development\", \"local\", \"staging\", \"production\"] = \"local\"\n\n{%- if cookiecutter.enable_logfire %}\n\n    # === Logfire ===\n    LOGFIRE_TOKEN: str | None = None\n    LOGFIRE_SERVICE_NAME: str = \"{{ cookiecutter.project_slug }}\"\n    LOGFIRE_ENVIRONMENT: str = \"development\"\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\n\n    # === Database (PostgreSQL async) ===\n    POSTGRES_HOST: str = \"localhost\"\n    POSTGRES_PORT: int = 5432\n    POSTGRES_USER: str = \"postgres\"\n    POSTGRES_PASSWORD: str = \"\"\n    POSTGRES_DB: str = \"{{ cookiecutter.project_slug }}\"\n\n    @computed_field  # type: ignore[prop-decorator]\n    @property\n    def DATABASE_URL(self) -> str:\n        \"\"\"Build async PostgreSQL connection URL.\"\"\"\n        return (\n            f\"postgresql+asyncpg://{self.POSTGRES_USER}:{self.POSTGRES_PASSWORD}\"\n            f\"@{self.POSTGRES_HOST}:{self.POSTGRES_PORT}/{self.POSTGRES_DB}\"\n        )\n\n    @computed_field  # type: ignore[prop-decorator]\n    @property\n    def DATABASE_URL_SYNC(self) -> str:\n        \"\"\"Build sync PostgreSQL connection URL (for Alembic).\"\"\"\n        return (\n            f\"postgresql://{self.POSTGRES_USER}:{self.POSTGRES_PASSWORD}\"\n            f\"@{self.POSTGRES_HOST}:{self.POSTGRES_PORT}/{self.POSTGRES_DB}\"\n        )\n\n    # Pool configuration\n    DB_POOL_SIZE: int = {{ cookiecutter.db_pool_size }}\n    DB_MAX_OVERFLOW: int = {{ cookiecutter.db_max_overflow }}\n    DB_POOL_TIMEOUT: int = {{ cookiecutter.db_pool_timeout }}\n{%- endif %}\n\n{%- if cookiecutter.use_mongodb %}\n\n    # === Database (MongoDB async) ===\n    MONGO_HOST: str = \"localhost\"\n    MONGO_PORT: int = 27017\n    MONGO_DB: str = \"{{ cookiecutter.project_slug }}\"\n    MONGO_USER: str | None = None\n    MONGO_PASSWORD: str | None = None\n\n    @computed_field  # type: ignore[prop-decorator]\n    @property\n    def MONGO_URL(self) -> str:\n        \"\"\"Build MongoDB connection URL.\"\"\"\n        if self.MONGO_USER and self.MONGO_PASSWORD:\n            return f\"mongodb://{self.MONGO_USER}:{self.MONGO_PASSWORD}@{self.MONGO_HOST}:{self.MONGO_PORT}\"\n        return f\"mongodb://{self.MONGO_HOST}:{self.MONGO_PORT}\"\n{%- endif %}\n\n{%- if cookiecutter.use_sqlite %}\n\n    # === Database (SQLite sync) ===\n    SQLITE_PATH: str = \"./{{ cookiecutter.project_slug }}.db\"\n\n    @computed_field  # type: ignore[prop-decorator]\n    @property\n    def DATABASE_URL(self) -> str:\n        \"\"\"Build SQLite connection URL.\"\"\"\n        return f\"sqlite:///{self.SQLITE_PATH}\"\n{%- endif %}\n\n{%- if cookiecutter.use_jwt or (cookiecutter.enable_admin_panel and cookiecutter.admin_require_auth) or cookiecutter.enable_oauth %}\n\n    # === Auth (SECRET_KEY for JWT/Session/Admin) ===\n    SECRET_KEY: str = \"change-me-in-production-use-openssl-rand-hex-32\"\n\n    @field_validator(\"SECRET_KEY\")\n    @classmethod\n    def validate_secret_key(cls, v: str, info: ValidationInfo) -> str:\n        \"\"\"Validate SECRET_KEY is secure in production.\"\"\"\n        if len(v) < 32:\n            raise ValueError(\"SECRET_KEY must be at least 32 characters long\")\n        # Get environment from values if available\n        env = info.data.get(\"ENVIRONMENT\", \"local\") if info.data else \"local\"\n        if v == \"change-me-in-production-use-openssl-rand-hex-32\" and env == \"production\":\n            raise ValueError(\n                \"SECRET_KEY must be changed in production! \"\n                \"Generate a secure key with: openssl rand -hex 32\"\n            )\n        return v\n{%- endif %}\n\n{%- if cookiecutter.use_jwt %}\n\n    # === JWT Settings ===\n    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30  # 30 minutes\n    REFRESH_TOKEN_EXPIRE_MINUTES: int = 60 * 24 * 7  # 7 days\n    ALGORITHM: str = \"HS256\"\n{%- endif %}\n\n{%- if cookiecutter.enable_oauth_google %}\n\n    # === OAuth2 (Google) ===\n    GOOGLE_CLIENT_ID: str = \"\"\n    GOOGLE_CLIENT_SECRET: str = \"\"\n    GOOGLE_REDIRECT_URI: str = \"http://localhost:{{ cookiecutter.backend_port }}/api/v1/oauth/google/callback\"\n{%- endif %}\n\n{%- if cookiecutter.use_api_key %}\n\n    # === Auth (API Key) ===\n    API_KEY: str = \"change-me-in-production\"\n    API_KEY_HEADER: str = \"X-API-Key\"\n\n    @field_validator(\"API_KEY\")\n    @classmethod\n    def validate_api_key(cls, v: str, info: ValidationInfo) -> str:\n        \"\"\"Validate API_KEY is set in production.\"\"\"\n        env = info.data.get(\"ENVIRONMENT\", \"local\") if info.data else \"local\"\n        if v == \"change-me-in-production\" and env == \"production\":\n            raise ValueError(\n                \"API_KEY must be changed in production! \"\n                \"Generate a secure key with: openssl rand -hex 32\"\n            )\n        return v\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n\n    # === Redis ===\n    REDIS_HOST: str = \"localhost\"\n    REDIS_PORT: int = 6379\n    REDIS_PASSWORD: str | None = None\n    REDIS_DB: int = 0\n\n    @computed_field  # type: ignore[prop-decorator]\n    @property\n    def REDIS_URL(self) -> str:\n        \"\"\"Build Redis connection URL.\"\"\"\n        if self.REDIS_PASSWORD:\n            return f\"redis://:{self.REDIS_PASSWORD}@{self.REDIS_HOST}:{self.REDIS_PORT}/{self.REDIS_DB}\"\n        return f\"redis://{self.REDIS_HOST}:{self.REDIS_PORT}/{self.REDIS_DB}\"\n{%- endif %}\n\n{%- if cookiecutter.enable_rate_limiting %}\n\n    # === Rate Limiting ===\n    RATE_LIMIT_REQUESTS: int = {{ cookiecutter.rate_limit_requests }}\n    RATE_LIMIT_PERIOD: int = {{ cookiecutter.rate_limit_period }}  # seconds\n{%- endif %}\n\n{%- if cookiecutter.use_celery %}\n\n    # === Celery ===\n    CELERY_BROKER_URL: str = \"redis://localhost:6379/0\"\n    CELERY_RESULT_BACKEND: str = \"redis://localhost:6379/0\"\n{%- endif %}\n\n{%- if cookiecutter.use_taskiq %}\n\n    # === Taskiq ===\n    TASKIQ_BROKER_URL: str = \"redis://localhost:6379/1\"\n    TASKIQ_RESULT_BACKEND: str = \"redis://localhost:6379/1\"\n{%- endif %}\n\n{%- if cookiecutter.use_arq %}\n\n    # === ARQ (Async Redis Queue) ===\n    ARQ_REDIS_HOST: str = \"localhost\"\n    ARQ_REDIS_PORT: int = 6379\n    ARQ_REDIS_PASSWORD: str | None = None\n    ARQ_REDIS_DB: int = 2\n{%- endif %}\n\n{%- if cookiecutter.enable_sentry %}\n\n    # === Sentry ===\n    SENTRY_DSN: str | None = None\n{%- endif %}\n\n{%- if cookiecutter.enable_prometheus %}\n\n    # === Prometheus ===\n    PROMETHEUS_METRICS_PATH: str = \"/metrics\"\n    PROMETHEUS_INCLUDE_IN_SCHEMA: bool = False\n{%- endif %}\n\n{%- if cookiecutter.enable_file_storage %}\n\n    # === File Storage (S3/MinIO) ===\n    S3_ENDPOINT: str | None = None\n    S3_ACCESS_KEY: str = \"\"\n    S3_SECRET_KEY: str = \"\"\n    S3_BUCKET: str = \"{{ cookiecutter.project_slug }}\"\n    S3_REGION: str = \"us-east-1\"\n{%- endif %}\n\n{%- if cookiecutter.enable_ai_agent %}\n\n    # === AI Agent ({{ cookiecutter.ai_framework }}, {{ cookiecutter.llm_provider }}) ===\n{%- if cookiecutter.use_openai %}\n    OPENAI_API_KEY: str = \"\"\n    AI_MODEL: str = \"gpt-4o-mini\"\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\n    ANTHROPIC_API_KEY: str = \"\"\n    AI_MODEL: str = \"claude-sonnet-4-5-20241022\"\n{%- endif %}\n{%- if cookiecutter.use_openrouter %}\n    OPENROUTER_API_KEY: str = \"\"\n    AI_MODEL: str = \"anthropic/claude-3.5-sonnet\"\n{%- endif %}\n    AI_TEMPERATURE: float = 0.7\n    AI_FRAMEWORK: str = \"{{ cookiecutter.ai_framework }}\"\n    LLM_PROVIDER: str = \"{{ cookiecutter.llm_provider }}\"\n{%- if cookiecutter.use_langchain %}\n\n    # === LangSmith (LangChain observability) ===\n    LANGCHAIN_TRACING_V2: bool = True\n    LANGCHAIN_API_KEY: str | None = None\n    LANGCHAIN_PROJECT: str = \"{{ cookiecutter.project_slug }}\"\n    LANGCHAIN_ENDPOINT: str = \"https://api.smith.langchain.com\"\n{%- endif %}\n{%- if cookiecutter.use_deepagents %}\n\n    # === DeepAgents Configuration ===\n    # Skills paths (comma-separated, relative to backend dir)\n    DEEPAGENTS_SKILLS_PATHS: str | None = None  # e.g. \"/skills/user/,/skills/project/\"\n    # Enable built-in tools\n    DEEPAGENTS_ENABLE_FILESYSTEM: bool = True  # ls, read_file, write_file, edit_file, glob, grep\n    DEEPAGENTS_ENABLE_EXECUTE: bool = False  # shell execution (disabled by default for security)\n    DEEPAGENTS_ENABLE_TODOS: bool = True  # write_todos tool\n    DEEPAGENTS_ENABLE_SUBAGENTS: bool = True  # task tool for spawning subagents\n    # Human-in-the-loop: tools requiring approval (comma-separated)\n    # e.g. \"write_file,edit_file,execute\" or \"all\" for all tools\n    DEEPAGENTS_INTERRUPT_TOOLS: str | None = None\n    # Allowed decisions for interrupted tools: approve,edit,reject\n    DEEPAGENTS_ALLOWED_DECISIONS: str = \"approve,edit,reject\"\n{%- endif %}\n{%- endif %}\n\n{%- if cookiecutter.enable_cors %}\n\n    # === CORS ===\n    CORS_ORIGINS: list[str] = [\"http://localhost:3000\", \"http://localhost:8080\"]\n    CORS_ALLOW_CREDENTIALS: bool = True\n    CORS_ALLOW_METHODS: list[str] = [\"*\"]\n    CORS_ALLOW_HEADERS: list[str] = [\"*\"]\n\n    @field_validator(\"CORS_ORIGINS\")\n    @classmethod\n    def validate_cors_origins(cls, v: list[str], info: ValidationInfo) -> list[str]:\n        \"\"\"Warn if CORS_ORIGINS is too permissive in production.\"\"\"\n        env = info.data.get(\"ENVIRONMENT\", \"local\") if info.data else \"local\"\n        if \"*\" in v and env == \"production\":\n            raise ValueError(\n                \"CORS_ORIGINS cannot contain '*' in production! \"\n                \"Specify explicit allowed origins.\"\n            )\n        return v\n{%- endif %}\n\n\nsettings = Settings()\n","backend/app/core/csrf.py":"{%- if cookiecutter.use_jwt %}\n\"\"\"CSRF protection middleware for FastAPI.\n\nThis module provides CSRF (Cross-Site Request Forgery) protection for\nstate-changing HTTP methods (POST, PUT, PATCH, DELETE).\n\nThe protection works by:\n1. Setting a CSRF token in a cookie on initial request\n2. Requiring the token to be sent in a header for state-changing requests\n3. Comparing the cookie token with the header token\n\nUsage:\n    Add to your main.py:\n\n    from app.core.csrf import CSRFMiddleware\n\n    app.add_middleware(CSRFMiddleware)\n\n    For endpoints that should be exempt (e.g., login):\n\n    @router.post(\"/login\", tags=[\"csrf-exempt\"])\n    async def login(...):\n        ...\n\"\"\"\n\nimport secrets\nfrom collections.abc import Callable\nfrom typing import ClassVar\n\nfrom fastapi import Request, Response\nfrom fastapi.responses import JSONResponse\nfrom starlette.middleware.base import BaseHTTPMiddleware\n\nfrom app.core.config import settings\n\n\nclass CSRFMiddleware(BaseHTTPMiddleware):\n    \"\"\"CSRF protection middleware.\n\n    Protects against Cross-Site Request Forgery attacks by requiring\n    a token to be present in both a cookie and a header for state-changing requests.\n    \"\"\"\n\n    # Methods that require CSRF protection\n    PROTECTED_METHODS: ClassVar[set[str]] = {\"POST\", \"PUT\", \"PATCH\", \"DELETE\"}\n\n    # Cookie settings\n    COOKIE_NAME: ClassVar[str] = \"csrf_token\"\n    HEADER_NAME: ClassVar[str] = \"X-CSRF-Token\"\n\n    # Paths to exclude from CSRF protection\n    EXEMPT_PATHS: ClassVar[set[str]] = {\n        \"/api/v1/auth/login\",\n        \"/api/v1/auth/register\",\n        \"/api/v1/auth/refresh\",\n        \"/api/v1/health\",\n        \"/api/v1/ready\",\n        \"/docs\",\n        \"/openapi.json\",\n        \"/redoc\",\n    }\n\n    def __init__(self, app: Callable, **kwargs):\n        super().__init__(app)\n        self.exempt_paths = set(kwargs.get(\"exempt_paths\", self.EXEMPT_PATHS))\n        self.cookie_name = kwargs.get(\"cookie_name\", self.COOKIE_NAME)\n        self.header_name = kwargs.get(\"header_name\", self.HEADER_NAME)\n\n    async def dispatch(self, request: Request, call_next: Callable) -> Response:\n        \"\"\"Handle the request and apply CSRF protection.\"\"\"\n        # Skip for exempt paths\n        if self._is_exempt(request):\n            return await call_next(request)\n\n        # Get or generate CSRF token\n        csrf_token = request.cookies.get(self.cookie_name)\n        if not csrf_token:\n            csrf_token = self._generate_token()\n\n        # Check CSRF for protected methods\n        if request.method in self.PROTECTED_METHODS:\n            header_token = request.headers.get(self.header_name)\n\n            if not header_token:\n                return JSONResponse(\n                    status_code=403,\n                    content={\n                        \"detail\": \"CSRF token missing\",\n                        \"message\": f\"Include the '{self.header_name}' header with the CSRF token\",\n                    },\n                )\n\n            if not secrets.compare_digest(csrf_token, header_token):\n                return JSONResponse(\n                    status_code=403,\n                    content={\n                        \"detail\": \"CSRF token invalid\",\n                        \"message\": \"The CSRF token does not match\",\n                    },\n                )\n\n        # Process the request\n        response = await call_next(request)\n\n        # Set CSRF token cookie if not present\n        if not request.cookies.get(self.cookie_name):\n            response.set_cookie(\n                key=self.cookie_name,\n                value=csrf_token,\n                httponly=False,  # JavaScript needs to read this\n                secure=not settings.DEBUG,\n                samesite=\"lax\",\n                max_age=3600 * 24,  # 24 hours\n            )\n\n        return response\n\n    def _is_exempt(self, request: Request) -> bool:\n        \"\"\"Check if the request path is exempt from CSRF protection.\"\"\"\n        path = request.url.path\n\n        # Check exact path matches\n        if path in self.exempt_paths:\n            return True\n\n        # Check path prefixes\n        for exempt in self.exempt_paths:\n            if path.startswith(exempt):\n                return True\n\n        # Check if endpoint has \"csrf-exempt\" tag\n        route = request.scope.get(\"route\")\n        return bool(route and hasattr(route, \"tags\") and \"csrf-exempt\" in route.tags)\n\n    @staticmethod\n    def _generate_token() -> str:\n        \"\"\"Generate a secure CSRF token.\"\"\"\n        return secrets.token_urlsafe(32)\n\n\ndef get_csrf_token(request: Request) -> str:\n    \"\"\"Get the current CSRF token from cookies or generate a new one.\n\n    Use this in templates or API responses to provide the token to clients.\n    \"\"\"\n    token = request.cookies.get(CSRFMiddleware.COOKIE_NAME)\n    if not token:\n        token = secrets.token_urlsafe(32)\n    return token\n\n{%- else %}\n\"\"\"CSRF protection - authentication not enabled.\"\"\"\n{%- endif %}\n","backend/app/core/logfire_setup.py":"{%- if cookiecutter.enable_logfire %}\n\"\"\"Logfire observability configuration.\"\"\"\n\nimport logfire\n\nfrom app.core.config import settings\n\n\ndef setup_logfire() -> None:\n    \"\"\"Configure Logfire instrumentation.\"\"\"\n    logfire.configure(\n        token=settings.LOGFIRE_TOKEN,\n        service_name=settings.LOGFIRE_SERVICE_NAME,\n        environment=settings.LOGFIRE_ENVIRONMENT,\n        send_to_logfire=\"if-token-present\",\n    )\n\n\ndef instrument_app(app):\n    \"\"\"Instrument FastAPI app with Logfire.\"\"\"\n{%- if cookiecutter.logfire_fastapi %}\n    logfire.instrument_fastapi(app)\n{%- else %}\n    pass\n{%- endif %}\n\n\n{%- if cookiecutter.use_postgresql and cookiecutter.logfire_database %}\n\n\ndef instrument_asyncpg():\n    \"\"\"Instrument asyncpg for PostgreSQL.\"\"\"\n    logfire.instrument_asyncpg()\n{%- endif %}\n\n\n{%- if cookiecutter.use_mongodb and cookiecutter.logfire_database %}\n\n\ndef instrument_pymongo():\n    \"\"\"Instrument PyMongo/Motor for MongoDB.\"\"\"\n    logfire.instrument_pymongo(capture_statement=settings.DEBUG)\n{%- endif %}\n\n\n{%- if cookiecutter.use_sqlite and cookiecutter.logfire_database %}\n\n\ndef instrument_sqlalchemy(engine):\n    \"\"\"Instrument SQLAlchemy for SQLite.\"\"\"\n    logfire.instrument_sqlalchemy(engine=engine)\n{%- endif %}\n\n\n{%- if cookiecutter.enable_redis and cookiecutter.logfire_redis %}\n\n\ndef instrument_redis():\n    \"\"\"Instrument Redis.\"\"\"\n    logfire.instrument_redis()\n{%- endif %}\n\n\n{%- if cookiecutter.use_celery and cookiecutter.logfire_celery %}\n\n\ndef instrument_celery():\n    \"\"\"Instrument Celery.\"\"\"\n    logfire.instrument_celery()\n{%- endif %}\n\n\n{%- if cookiecutter.logfire_httpx %}\n\n\ndef instrument_httpx():\n    \"\"\"Instrument HTTPX for outgoing HTTP requests.\"\"\"\n    logfire.instrument_httpx()\n{%- endif %}\n\n\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_pydantic_ai %}\n\n\ndef instrument_pydantic_ai():\n    \"\"\"Instrument PydanticAI for AI agent observability.\"\"\"\n    logfire.instrument_pydantic_ai()\n{%- endif %}\n{%- else %}\n\"\"\"Logfire is disabled for this project.\"\"\"\n\n\ndef setup_logfire() -> None:\n    \"\"\"No-op when Logfire is disabled.\"\"\"\n    pass\n\n\ndef instrument_app(app):\n    \"\"\"No-op when Logfire is disabled.\"\"\"\n    pass\n{%- endif %}\n","backend/app/core/security.py":"{%- if cookiecutter.use_jwt %}\n\"\"\"Security utilities for JWT authentication.\"\"\"\n\nfrom datetime import UTC, datetime, timedelta\nfrom typing import Any\n\nimport bcrypt\nimport jwt\n\nfrom app.core.config import settings\n\n\ndef create_access_token(\n    subject: str | Any,\n    expires_delta: timedelta | None = None,\n) -> str:\n    \"\"\"Create a JWT access token.\"\"\"\n    if expires_delta:\n        expire = datetime.now(UTC) + expires_delta\n    else:\n        expire = datetime.now(UTC) + timedelta(\n            minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES\n        )\n\n    to_encode = {\"exp\": expire, \"sub\": str(subject), \"type\": \"access\"}\n    return jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)\n\n\ndef create_refresh_token(\n    subject: str | Any,\n    expires_delta: timedelta | None = None,\n) -> str:\n    \"\"\"Create a JWT refresh token.\"\"\"\n    if expires_delta:\n        expire = datetime.now(UTC) + expires_delta\n    else:\n        expire = datetime.now(UTC) + timedelta(\n            minutes=settings.REFRESH_TOKEN_EXPIRE_MINUTES\n        )\n\n    to_encode = {\"exp\": expire, \"sub\": str(subject), \"type\": \"refresh\"}\n    return jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)\n\n\ndef verify_token(token: str) -> dict[str, Any] | None:\n    \"\"\"Verify a JWT token and return payload.\"\"\"\n    try:\n        payload = jwt.decode(\n            token,\n            settings.SECRET_KEY,\n            algorithms=[settings.ALGORITHM],\n        )\n        return payload\n    except jwt.PyJWTError:\n        return None\n\n\ndef verify_password(plain_password: str, hashed_password: str) -> bool:\n    \"\"\"Verify a password against a hash.\"\"\"\n    return bcrypt.checkpw(\n        plain_password.encode(\"utf-8\"),\n        hashed_password.encode(\"utf-8\"),\n    )\n\n\ndef get_password_hash(password: str) -> str:\n    \"\"\"Hash a password.\"\"\"\n    return bcrypt.hashpw(\n        password.encode(\"utf-8\"),\n        bcrypt.gensalt(),\n    ).decode(\"utf-8\")\n\n\n{%- elif cookiecutter.use_api_key %}\n\"\"\"Security utilities for API Key authentication.\"\"\"\n\nfrom fastapi import HTTPException, Security, status\nfrom fastapi.security import APIKeyHeader\n\nfrom app.core.config import settings\n\napi_key_header = APIKeyHeader(name=settings.API_KEY_HEADER, auto_error=False)\n\n\nasync def verify_api_key(api_key: str = Security(api_key_header)) -> str:\n    \"\"\"Verify API key from header.\"\"\"\n    if api_key is None:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"API Key header missing\",\n        )\n    if api_key != settings.API_KEY:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"Invalid API Key\",\n        )\n    return api_key\n\n\n{%- else %}\n\"\"\"Security - not configured.\"\"\"\n{%- endif %}\n","backend/app/core/cache.py":"{%- if cookiecutter.enable_caching %}\n\"\"\"Caching configuration using fastapi-cache2.\"\"\"\n\nfrom fastapi_cache import FastAPICache\nfrom fastapi_cache.backends.redis import RedisBackend\n\nfrom app.clients.redis import RedisClient\n\n\ndef setup_cache(redis: RedisClient) -> None:\n    \"\"\"Initialize FastAPI cache with Redis backend.\n\n    Uses the shared Redis client from lifespan state.\n    \"\"\"\n    FastAPICache.init(RedisBackend(redis.raw), prefix=\"{{ cookiecutter.project_slug }}:cache:\")\n{%- else %}\n\"\"\"Caching - not configured.\"\"\"\n\n\nasync def setup_cache() -> None:\n    \"\"\"No-op when caching is disabled.\"\"\"\n    pass\n{%- endif %}\n","backend/app/core/__init__.py":"\"\"\"Core application configuration and utilities.\"\"\"\n\nfrom .config import settings\n\n__all__ = [\"settings\"]\n","backend/app/core/rate_limit.py":"{%- if cookiecutter.enable_rate_limiting %}\n\"\"\"Rate limiting configuration using slowapi.\n\nDefault rate limit: {{ cookiecutter.rate_limit_requests }} requests per {{ cookiecutter.rate_limit_period }} seconds.\nOverride with RATE_LIMIT_REQUESTS and RATE_LIMIT_PERIOD environment variables.\n\"\"\"\n\nfrom slowapi import Limiter\nfrom slowapi.util import get_remote_address\n\nfrom app.core.config import settings\n\n\ndef get_default_rate_limit() -> str:\n    \"\"\"Get default rate limit string from settings.\n\n    Returns a rate limit string like \"100/minute\" or \"60/second\".\n    \"\"\"\n    requests = settings.RATE_LIMIT_REQUESTS\n    period = settings.RATE_LIMIT_PERIOD\n\n    # Convert period to a human-readable format\n    period_map = {\n        60: \"minute\",\n        3600: \"hour\",\n        86400: \"day\",\n    }\n\n    if period in period_map:\n        return f\"{requests}/{period_map[period]}\"\n    # For custom periods, use \"per X seconds\"\n    return f\"{requests}/{period} seconds\"\n\n\n# Rate limiter instance with configurable default\nlimiter = Limiter(\n    key_func=get_remote_address,\n    default_limits=[get_default_rate_limit()],\n)\n\n# Common rate limit decorators for convenience\n# Usage: @rate_limit_low, @rate_limit_medium, @rate_limit_high\ndef rate_limit_low(limit: str = \"10/minute\"):\n    \"\"\"Low rate limit for expensive operations.\"\"\"\n    return limiter.limit(limit)\n\n\ndef rate_limit_medium(limit: str = \"30/minute\"):\n    \"\"\"Medium rate limit for standard operations.\"\"\"\n    return limiter.limit(limit)\n\n\ndef rate_limit_high(limit: str = \"100/minute\"):\n    \"\"\"High rate limit for lightweight operations.\"\"\"\n    return limiter.limit(limit)\n{%- else %}\n\"\"\"Rate limiting - not configured.\"\"\"\n{%- endif %}\n","backend/app/core/exceptions.py":"\"\"\"Application exceptions.\n\nDomain exceptions with HTTP status codes for the hybrid approach.\nThese exceptions are caught by exception handlers and converted to proper HTTP responses.\n\"\"\"\n\nfrom typing import Any\n\n\nclass AppException(Exception):\n    \"\"\"Base exception for all application errors.\n\n    Attributes:\n        message: Human-readable error message.\n        code: Machine-readable error code for clients.\n        status_code: HTTP status code to return.\n        details: Additional error details (e.g., field names, IDs).\n    \"\"\"\n\n    message: str = \"An error occurred\"\n    code: str = \"APP_ERROR\"\n    status_code: int = 500\n\n    def __init__(\n        self,\n        message: str | None = None,\n        code: str | None = None,\n        details: dict[str, Any] | None = None,\n    ):\n        self.message = message or self.__class__.message\n        self.code = code or self.__class__.code\n        self.details = details or {}\n        super().__init__(self.message)\n\n    def __repr__(self) -> str:\n        return f\"{self.__class__.__name__}(message={self.message!r}, code={self.code!r})\"\n\n\n# === 4xx Client Errors ===\n\n\nclass NotFoundError(AppException):\n    \"\"\"Resource not found (404).\"\"\"\n\n    message = \"Resource not found\"\n    code = \"NOT_FOUND\"\n    status_code = 404\n\n\nclass AlreadyExistsError(AppException):\n    \"\"\"Resource already exists (409).\"\"\"\n\n    message = \"Resource already exists\"\n    code = \"ALREADY_EXISTS\"\n    status_code = 409\n\n\nclass ValidationError(AppException):\n    \"\"\"Validation error (422).\"\"\"\n\n    message = \"Validation error\"\n    code = \"VALIDATION_ERROR\"\n    status_code = 422\n\n\nclass AuthenticationError(AppException):\n    \"\"\"Authentication failed (401).\"\"\"\n\n    message = \"Authentication failed\"\n    code = \"AUTHENTICATION_ERROR\"\n    status_code = 401\n\n\nclass AuthorizationError(AppException):\n    \"\"\"Authorization failed - insufficient permissions (403).\"\"\"\n\n    message = \"Insufficient permissions\"\n    code = \"AUTHORIZATION_ERROR\"\n    status_code = 403\n\n\nclass RateLimitError(AppException):\n    \"\"\"Rate limit exceeded (429).\"\"\"\n\n    message = \"Rate limit exceeded\"\n    code = \"RATE_LIMIT_EXCEEDED\"\n    status_code = 429\n\n\nclass BadRequestError(AppException):\n    \"\"\"Bad request (400).\"\"\"\n\n    message = \"Bad request\"\n    code = \"BAD_REQUEST\"\n    status_code = 400\n\n\n# === 5xx Server Errors ===\n\n\nclass ExternalServiceError(AppException):\n    \"\"\"External service unavailable (503).\"\"\"\n\n    message = \"External service unavailable\"\n    code = \"EXTERNAL_SERVICE_ERROR\"\n    status_code = 503\n\n\nclass DatabaseError(AppException):\n    \"\"\"Database error (500).\"\"\"\n\n    message = \"Database error\"\n    code = \"DATABASE_ERROR\"\n    status_code = 500\n\n\nclass InternalError(AppException):\n    \"\"\"Internal server error (500).\"\"\"\n\n    message = \"Internal server error\"\n    code = \"INTERNAL_ERROR\"\n    status_code = 500\n","backend/app/core/sanitize.py":"\"\"\"Input sanitization utilities.\n\nThis module provides security-focused input sanitization functions:\n- HTML sanitization to prevent XSS attacks\n- Path traversal prevention for file operations\n- Common input cleaning utilities\n\nNote: SQL injection is prevented by using SQLAlchemy ORM with parameterized queries.\n\"\"\"\n\nimport html\nimport os\nimport re\nimport unicodedata\nfrom pathlib import Path\nfrom typing import TypeVar\n\n# Default allowed HTML tags for rich text content\nDEFAULT_ALLOWED_TAGS = frozenset({\n    \"a\", \"abbr\", \"acronym\", \"b\", \"blockquote\", \"br\", \"code\",\n    \"em\", \"i\", \"li\", \"ol\", \"p\", \"pre\", \"strong\", \"ul\",\n})\n\n# Default allowed HTML attributes\nDEFAULT_ALLOWED_ATTRIBUTES = {\n    \"a\": frozenset({\"href\", \"title\", \"rel\"}),\n    \"abbr\": frozenset({\"title\"}),\n    \"acronym\": frozenset({\"title\"}),\n}\n\n\ndef sanitize_html(\n    content: str,\n    allowed_tags: frozenset[str] | None = None,\n    strip: bool = True,\n) -> str:\n    \"\"\"Sanitize HTML content to prevent XSS attacks.\n\n    This is a simple implementation that escapes all HTML.\n    For rich text support, consider using the `bleach` library.\n\n    Args:\n        content: The HTML content to sanitize.\n        allowed_tags: Not used in simple mode (for bleach compatibility).\n        strip: Not used in simple mode (for bleach compatibility).\n\n    Returns:\n        Escaped HTML-safe string.\n\n    Example:\n        >>> sanitize_html(\"<script>alert('xss')</script>\")\n        \"&lt;script&gt;alert('xss')&lt;/script&gt;\"\n    \"\"\"\n    if not content:\n        return \"\"\n\n    return html.escape(content)\n\n\ndef sanitize_filename(filename: str, allow_unicode: bool = False) -> str:\n    \"\"\"Sanitize a filename to prevent path traversal and unsafe characters.\n\n    Args:\n        filename: The filename to sanitize.\n        allow_unicode: Whether to allow unicode characters.\n\n    Returns:\n        A safe filename string.\n\n    Example:\n        >>> sanitize_filename(\"../../../etc/passwd\")\n        \"etc_passwd\"\n        >>> sanitize_filename(\"hello world.txt\")\n        \"hello_world.txt\"\n    \"\"\"\n    if not filename:\n        return \"\"\n\n    # Normalize unicode\n    if allow_unicode:\n        filename = unicodedata.normalize(\"NFKC\", filename)\n    else:\n        filename = (\n            unicodedata.normalize(\"NFKD\", filename)\n            .encode(\"ascii\", \"ignore\")\n            .decode(\"ascii\")\n        )\n\n    # Get just the filename (remove any path components)\n    filename = os.path.basename(filename)\n\n    # Remove null bytes\n    filename = filename.replace(\"\\x00\", \"\")\n\n    # Replace path separators and special characters\n    filename = re.sub(r\"[/\\\\:*?\\\"<>|]\", \"_\", filename)\n\n    # Replace multiple underscores/spaces with single underscore\n    filename = re.sub(r\"[\\s_]+\", \"_\", filename)\n\n    # Remove leading/trailing underscores and dots\n    filename = filename.strip(\"._\")\n\n    # Ensure we have a valid filename\n    if not filename:\n        return \"unnamed\"\n\n    return filename\n\n\ndef validate_safe_path(\n    base_dir: Path | str,\n    user_path: str,\n) -> Path:\n    \"\"\"Validate that a user-provided path is within the allowed base directory.\n\n    Prevents path traversal attacks by ensuring the resolved path\n    is within the expected directory.\n\n    Args:\n        base_dir: The base directory that all paths must be within.\n        user_path: The user-provided path to validate.\n\n    Returns:\n        The resolved, safe path.\n\n    Raises:\n        ValueError: If the path would escape the base directory.\n\n    Example:\n        >>> validate_safe_path(\"/uploads\", \"../../../etc/passwd\")\n        Raises ValueError\n        >>> validate_safe_path(\"/uploads\", \"images/photo.jpg\")\n        Path(\"/uploads/images/photo.jpg\")\n    \"\"\"\n    base_path = Path(base_dir).resolve()\n    user_path_sanitized = sanitize_filename(user_path.lstrip(\"/\\\\\"))\n\n    # Resolve the full path\n    full_path = (base_path / user_path_sanitized).resolve()\n\n    # Check if the resolved path is within the base directory\n    try:\n        full_path.relative_to(base_path)\n    except ValueError as err:\n        raise ValueError(\n            f\"Path traversal detected: {user_path!r} would escape {base_dir!r}\"\n        ) from err\n\n    return full_path\n\n\ndef sanitize_string(\n    value: str,\n    max_length: int | None = None,\n    allow_newlines: bool = True,\n    strip_whitespace: bool = True,\n) -> str:\n    \"\"\"Sanitize a string input with various options.\n\n    Args:\n        value: The string to sanitize.\n        max_length: Maximum allowed length (truncates if exceeded).\n        allow_newlines: Whether to preserve newlines.\n        strip_whitespace: Whether to strip leading/trailing whitespace.\n\n    Returns:\n        Sanitized string.\n    \"\"\"\n    if not value:\n        return \"\"\n\n    # Strip null bytes and other control characters (except newlines if allowed)\n    if allow_newlines:\n        value = re.sub(r\"[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f]\", \"\", value)\n    else:\n        value = re.sub(r\"[\\x00-\\x1f\\x7f]\", \"\", value)\n\n    # Strip whitespace if requested\n    if strip_whitespace:\n        value = value.strip()\n\n    # Truncate if needed\n    if max_length is not None and len(value) > max_length:\n        value = value[:max_length]\n\n    return value\n\n\ndef sanitize_email(email: str) -> str:\n    \"\"\"Basic email sanitization.\n\n    Note: For proper email validation, use Pydantic's EmailStr type.\n    This function only performs basic cleaning.\n\n    Args:\n        email: The email address to sanitize.\n\n    Returns:\n        Lowercased, stripped email.\n    \"\"\"\n    if not email:\n        return \"\"\n\n    return email.strip().lower()\n\n\nT = TypeVar(\"T\", int, float)\n\n\ndef sanitize_numeric(\n    value: str | int | float,\n    value_type: type[T],\n    min_value: T | None = None,\n    max_value: T | None = None,\n    default: T | None = None,\n) -> T | None:\n    \"\"\"Sanitize and validate a numeric value.\n\n    Args:\n        value: The value to sanitize (can be string or numeric).\n        value_type: The expected type (int or float).\n        min_value: Minimum allowed value.\n        max_value: Maximum allowed value.\n        default: Default value if conversion fails.\n\n    Returns:\n        The sanitized numeric value, or default if invalid.\n\n    Example:\n        >>> sanitize_numeric(\"100\", int, min_value=0, max_value=1000)\n        100\n        >>> sanitize_numeric(\"abc\", int, default=0)\n        0\n    \"\"\"\n    try:\n        result = value_type(value)\n\n        if min_value is not None and result < min_value:\n            result = min_value\n        if max_value is not None and result > max_value:\n            result = max_value\n\n        return result\n    except (ValueError, TypeError):\n        return default\n\n\ndef escape_sql_like(pattern: str, escape_char: str = \"\\\\\") -> str:\n    \"\"\"Escape special characters in a LIKE pattern.\n\n    Use this when building LIKE queries with user input.\n\n    Args:\n        pattern: The pattern to escape.\n        escape_char: The escape character to use.\n\n    Returns:\n        Escaped pattern safe for use in LIKE queries.\n\n    Example:\n        >>> escape_sql_like(\"100%\")\n        \"100\\\\%\"\n        >>> escape_sql_like(\"under_score\")\n        \"under\\\\_score\"\n    \"\"\"\n    # Escape the escape character first, then special chars\n    pattern = pattern.replace(escape_char, escape_char + escape_char)\n    pattern = pattern.replace(\"%\", escape_char + \"%\")\n    pattern = pattern.replace(\"_\", escape_char + \"_\")\n    return pattern\n","backend/app/core/middleware.py":"\"\"\"Application middleware.\"\"\"\n\nfrom typing import ClassVar\nfrom uuid import uuid4\n\nfrom starlette.middleware.base import BaseHTTPMiddleware\nfrom starlette.requests import Request\nfrom starlette.responses import Response\n\n\nclass RequestIDMiddleware(BaseHTTPMiddleware):\n    \"\"\"Middleware that adds a unique request ID to each request.\n\n    The request ID is taken from the X-Request-ID header if present,\n    otherwise a new UUID is generated. The ID is added to the response\n    headers and is available in request.state.request_id.\n    \"\"\"\n\n    async def dispatch(self, request: Request, call_next) -> Response:\n        \"\"\"Add request ID to request state and response headers.\"\"\"\n        request_id = request.headers.get(\"X-Request-ID\", str(uuid4()))\n        request.state.request_id = request_id\n\n        response = await call_next(request)\n        response.headers[\"X-Request-ID\"] = request_id\n        return response\n\n\nclass SecurityHeadersMiddleware(BaseHTTPMiddleware):\n    \"\"\"Middleware that adds security headers to all responses.\n\n    This includes:\n    - Content-Security-Policy (CSP)\n    - X-Content-Type-Options\n    - X-Frame-Options\n    - X-XSS-Protection\n    - Referrer-Policy\n    - Permissions-Policy\n\n    Usage:\n        app.add_middleware(SecurityHeadersMiddleware)\n\n        # Or with custom CSP:\n        app.add_middleware(\n            SecurityHeadersMiddleware,\n            csp_directives={\n                \"default-src\": \"'self'\",\n                \"script-src\": \"'self' 'unsafe-inline'\",\n            }\n        )\n    \"\"\"\n\n    DEFAULT_CSP_DIRECTIVES: ClassVar[dict[str, str]] = {\n        \"default-src\": \"'self'\",\n        \"script-src\": \"'self'\",\n        \"style-src\": \"'self' 'unsafe-inline'\",  # Allow inline styles for some UI libs\n        \"img-src\": \"'self' data: https:\",\n        \"font-src\": \"'self' data:\",\n        \"connect-src\": \"'self'\",\n        \"frame-ancestors\": \"'none'\",\n        \"base-uri\": \"'self'\",\n        \"form-action\": \"'self'\",\n    }\n\n    def __init__(\n        self,\n        app,\n        csp_directives: dict | None = None,\n        exclude_paths: set | None = None,\n    ):\n        super().__init__(app)\n        self.csp_directives = csp_directives or self.DEFAULT_CSP_DIRECTIVES\n        self.exclude_paths = exclude_paths or {\"/docs\", \"/redoc\", \"/openapi.json\"}\n\n    async def dispatch(self, request: Request, call_next) -> Response:\n        \"\"\"Add security headers to the response.\"\"\"\n        response = await call_next(request)\n\n        # Skip for docs/openapi endpoints which need different CSP\n        if request.url.path in self.exclude_paths:\n            return response\n\n        # Build CSP header\n        csp_value = \"; \".join(\n            f\"{directive} {value}\" for directive, value in self.csp_directives.items()\n        )\n\n        # Add security headers\n        response.headers[\"Content-Security-Policy\"] = csp_value\n        response.headers[\"X-Content-Type-Options\"] = \"nosniff\"\n        response.headers[\"X-Frame-Options\"] = \"DENY\"\n        response.headers[\"X-XSS-Protection\"] = \"1; mode=block\"\n        response.headers[\"Referrer-Policy\"] = \"strict-origin-when-cross-origin\"\n        response.headers[\"Permissions-Policy\"] = (\n            \"accelerometer=(), camera=(), geolocation=(), gyroscope=(), \"\n            \"magnetometer=(), microphone=(), payment=(), usb=()\"\n        )\n\n        return response\n","backend/app/core/oauth.py":"{%- if cookiecutter.enable_oauth %}\n\"\"\"OAuth2 client configuration.\"\"\"\n\nfrom authlib.integrations.starlette_client import OAuth\n\nfrom app.core.config import settings\n\noauth = OAuth()\n\n{%- if cookiecutter.enable_oauth_google %}\n\n# Configure Google OAuth2\noauth.register(\n    name=\"google\",\n    client_id=settings.GOOGLE_CLIENT_ID,\n    client_secret=settings.GOOGLE_CLIENT_SECRET,\n    server_metadata_url=\"https://accounts.google.com/.well-known/openid-configuration\",\n    client_kwargs={\"scope\": \"openid email profile\"},\n)\n{%- endif %}\n{%- else %}\n\"\"\"OAuth module - not configured.\"\"\"\n{%- endif %}\n","backend/app/__init__.py":"\"\"\"{{ cookiecutter.project_description }}\"\"\"\n\n__version__ = \"0.1.0\"\n","backend/app/agents/tools/datetime_tool.py":"{%- if cookiecutter.enable_ai_agent %}\n\"\"\"Date and time utilities for agents.\"\"\"\n\nfrom datetime import datetime\n\n\ndef get_current_datetime() -> str:\n    \"\"\"Get the current date and time.\n\n    Returns:\n        A string with the current date and time.\n    \"\"\"\n    now = datetime.now()\n    return f\"Current date: {now.strftime('%Y-%m-%d')}, Current time: {now.strftime('%H:%M:%S')}\"\n{%- else %}\n\"\"\"Datetime tools - not configured.\"\"\"\n{%- endif %}\n","backend/app/agents/tools/__init__.py":"{%- if cookiecutter.enable_ai_agent %}\n\"\"\"Agent tools module.\n\nThis module contains utility functions that can be used as agent tools.\nTools are registered in the agent definition using @agent.tool decorator.\n\"\"\"\n\nfrom app.agents.tools.datetime_tool import get_current_datetime\n\n__all__ = [\"get_current_datetime\"]\n{%- else %}\n\"\"\"Agent tools - not configured.\"\"\"\n{%- endif %}\n","backend/app/agents/deepagents_assistant.py":"{%- if cookiecutter.enable_ai_agent and cookiecutter.use_deepagents %}\n\"\"\"DeepAgents implementation with middleware stacking and human-in-the-loop.\n\nDeepAgents is a framework for building agentic coding assistants.\nIt uses LangGraph under the hood and comes with built-in tools for:\n- File operations: ls, read_file, write_file, edit_file, glob, grep\n- Task management: write_todos, task (subagent spawning)\n- Shell execution: execute (when sandbox backend is enabled)\n\nHuman-in-the-loop (HITL) support:\n- Configure tools requiring approval via DEEPAGENTS_INTERRUPT_TOOLS\n- Allowed decisions: approve, edit, reject\n- Interrupts are returned via stream/run and can be resumed with decisions\n\nConfiguration via settings:\n- DEEPAGENTS_SKILLS_PATHS: Comma-separated skill paths\n- DEEPAGENTS_ENABLE_FILESYSTEM: Enable file tools (default: True)\n- DEEPAGENTS_ENABLE_EXECUTE: Enable shell execution (default: False)\n- DEEPAGENTS_ENABLE_TODOS: Enable todo list tool (default: True)\n- DEEPAGENTS_ENABLE_SUBAGENTS: Enable subagent spawning (default: True)\n- DEEPAGENTS_INTERRUPT_TOOLS: Tools requiring human approval\n- DEEPAGENTS_ALLOWED_DECISIONS: Allowed decisions (approve,edit,reject)\n\"\"\"\n\nimport logging\nfrom typing import Annotated, Any, TypedDict\n\nfrom deepagents import create_deep_agent\nfrom deepagents.backends import StateBackend\nfrom langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.graph.message import add_messages\nfrom langgraph.types import Command, interrupt\n{%- if cookiecutter.use_openai %}\nfrom langchain_openai import ChatOpenAI\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\nfrom langchain_anthropic import ChatAnthropic\n{%- endif %}\n\nfrom app.agents.prompts import DEFAULT_SYSTEM_PROMPT\nfrom app.core.config import settings\n\nlogger = logging.getLogger(__name__)\n\n\nclass AgentContext(TypedDict, total=False):\n    \"\"\"Runtime context for the agent.\n\n    Passed via config parameter to the graph.\n    \"\"\"\n\n    user_id: str | None\n    user_name: str | None\n    metadata: dict[str, Any]\n\n\nclass AgentState(TypedDict):\n    \"\"\"State for the DeepAgents agent.\n\n    This is what flows through the agent graph.\n    The messages field uses add_messages reducer to properly\n    append new messages to the conversation history.\n    \"\"\"\n\n    messages: Annotated[list[BaseMessage], add_messages]\n\n\nclass InterruptData(TypedDict):\n    \"\"\"Data structure for human-in-the-loop interrupts.\"\"\"\n\n    action_requests: list[dict[str, Any]]  # List of tool calls pending approval\n    review_configs: list[dict[str, Any]]  # Config for each tool (allowed_decisions)\n\n\nclass Decision(TypedDict, total=False):\n    \"\"\"Human decision for a tool call.\"\"\"\n\n    type: str  # \"approve\", \"edit\", or \"reject\"\n    edited_action: dict[str, Any] | None  # For \"edit\" type: modified tool call\n\n\ndef _parse_skills_paths() -> list[str] | None:\n    \"\"\"Parse skills paths from settings.\n\n    Returns:\n        List of skill paths or None if not configured.\n    \"\"\"\n    if not settings.DEEPAGENTS_SKILLS_PATHS:\n        return None\n\n    paths = [p.strip() for p in settings.DEEPAGENTS_SKILLS_PATHS.split(\",\") if p.strip()]\n    return paths if paths else None\n\n\ndef _parse_interrupt_config() -> dict[str, bool | dict[str, list[str]]] | None:\n    \"\"\"Parse interrupt_on configuration from settings.\n\n    Returns:\n        Dict mapping tool names to interrupt configs, or None if not configured.\n    \"\"\"\n    if not settings.DEEPAGENTS_INTERRUPT_TOOLS:\n        return None\n\n    tools = [t.strip() for t in settings.DEEPAGENTS_INTERRUPT_TOOLS.split(\",\") if t.strip()]\n    if not tools:\n        return None\n\n    # Parse allowed decisions\n    allowed = [d.strip() for d in settings.DEEPAGENTS_ALLOWED_DECISIONS.split(\",\") if d.strip()]\n    if not allowed:\n        allowed = [\"approve\", \"edit\", \"reject\"]\n\n    # Build interrupt_on config\n    interrupt_on: dict[str, bool | dict[str, list[str]]] = {}\n\n    # Built-in DeepAgents tools\n    builtin_tools = [\n        \"ls\", \"read_file\", \"write_file\", \"edit_file\", \"glob\", \"grep\",\n        \"execute\", \"write_todos\", \"task\"\n    ]\n\n    if \"all\" in tools:\n        # Interrupt all tools\n        for tool_name in builtin_tools:\n            interrupt_on[tool_name] = {\"allowed_decisions\": allowed}\n    else:\n        for tool_name in tools:\n            interrupt_on[tool_name] = {\"allowed_decisions\": allowed}\n\n    return interrupt_on if interrupt_on else None\n\n\nclass DeepAgentsAssistant:\n    \"\"\"Wrapper for DeepAgents with run() and stream() methods.\n\n    DeepAgents creates a LangGraph-based agent with built-in tools for\n    filesystem operations, task management, and code execution.\n\n    Uses StateBackend (in-memory) for file state management.\n    Skills can be configured via DEEPAGENTS_SKILLS_PATHS setting.\n    Human-in-the-loop via DEEPAGENTS_INTERRUPT_TOOLS setting.\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name: str | None = None,\n        temperature: float | None = None,\n        system_prompt: str | None = None,\n        skills: list[str] | None = None,\n        interrupt_on: dict[str, bool | dict[str, list[str]]] | None = None,\n    ):\n        \"\"\"Initialize DeepAgentsAssistant.\n\n        Args:\n            model_name: LLM model name (default from settings.AI_MODEL)\n            temperature: LLM temperature (default from settings.AI_TEMPERATURE)\n            system_prompt: System prompt (default from DEFAULT_SYSTEM_PROMPT)\n            skills: List of skill paths (default from settings.DEEPAGENTS_SKILLS_PATHS)\n            interrupt_on: Dict of tool names to interrupt configs (default from settings)\n        \"\"\"\n        self.model_name = model_name or settings.AI_MODEL\n        self.temperature = temperature or settings.AI_TEMPERATURE\n        self.system_prompt = system_prompt or DEFAULT_SYSTEM_PROMPT\n        self.skills = skills if skills is not None else _parse_skills_paths()\n        self.interrupt_on = interrupt_on if interrupt_on is not None else _parse_interrupt_config()\n        self._graph = None\n        self._checkpointer = MemorySaver()\n\n    def _create_model(self):\n        \"\"\"Create the LLM model for DeepAgents.\"\"\"\n{%- if cookiecutter.use_openai %}\n        return ChatOpenAI(\n            model=self.model_name,\n            temperature=self.temperature,\n            api_key=settings.OPENAI_API_KEY,\n            streaming=True,\n        )\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\n        return ChatAnthropic(\n            model=self.model_name,\n            temperature=self.temperature,\n            api_key=settings.ANTHROPIC_API_KEY,\n            streaming=True,\n        )\n{%- endif %}\n\n    @property\n    def graph(self):\n        \"\"\"Get or create the compiled graph instance.\n\n        The agent is created with:\n        - StateBackend: In-memory file state management\n        - TodoListMiddleware: For task tracking (if enabled)\n        - FilesystemMiddleware: For file operations (if enabled)\n        - SubAgentMiddleware: For spawning subagents (if enabled)\n        - Skills: Loaded from configured paths (if any)\n        - interrupt_on: Human-in-the-loop config (if any)\n        \"\"\"\n        if self._graph is None:\n            model = self._create_model()\n\n            # Create agent with StateBackend (in-memory)\n            self._graph = create_deep_agent(\n                model=model,\n                system_prompt=self.system_prompt,\n                checkpointer=self._checkpointer,\n                backend=lambda rt: StateBackend(rt),\n                skills=self.skills,\n                interrupt_on=self.interrupt_on,\n            )\n\n            logger.info(\n                f\"DeepAgents initialized with model={self.model_name}, \"\n                f\"skills={self.skills}, \"\n                f\"interrupt_on={list(self.interrupt_on.keys()) if self.interrupt_on else None}, \"\n                f\"filesystem={settings.DEEPAGENTS_ENABLE_FILESYSTEM}, \"\n                f\"execute={settings.DEEPAGENTS_ENABLE_EXECUTE}\"\n            )\n\n        return self._graph\n\n    @staticmethod\n    def _convert_history(\n        history: list[dict[str, str]] | None,\n    ) -> list[HumanMessage | AIMessage | SystemMessage]:\n        \"\"\"Convert conversation history to LangChain message format.\"\"\"\n        messages: list[HumanMessage | AIMessage | SystemMessage] = []\n\n        for msg in history or []:\n            if msg[\"role\"] == \"user\":\n                messages.append(HumanMessage(content=msg[\"content\"]))\n            elif msg[\"role\"] == \"assistant\":\n                messages.append(AIMessage(content=msg[\"content\"]))\n            elif msg[\"role\"] == \"system\":\n                messages.append(SystemMessage(content=msg[\"content\"]))\n\n        return messages\n\n    @staticmethod\n    def extract_interrupt(result: dict[str, Any]) -> InterruptData | None:\n        \"\"\"Extract interrupt data from agent result if present.\n\n        Args:\n            result: The result from agent.invoke() or final state from stream.\n\n        Returns:\n            InterruptData if interrupted, None otherwise.\n        \"\"\"\n        if not result.get(\"__interrupt__\"):\n            return None\n\n        interrupt_value = result[\"__interrupt__\"][0].value\n        return InterruptData(\n            action_requests=interrupt_value.get(\"action_requests\", []),\n            review_configs=interrupt_value.get(\"review_configs\", []),\n        )\n\n    async def run(\n        self,\n        user_input: str,\n        history: list[dict[str, str]] | None = None,\n        context: AgentContext | None = None,\n        thread_id: str = \"default\",\n        files: dict[str, str] | None = None,\n    ) -> tuple[str, list[Any], AgentContext, InterruptData | None]:\n        \"\"\"Run agent and return the output along with tool call events.\n\n        Args:\n            user_input: User's message.\n            history: Conversation history as list of {\"role\": \"...\", \"content\": \"...\"}.\n            context: Optional runtime context with user info.\n            thread_id: Thread ID for conversation continuity.\n            files: Optional dict of {path: content} to provide to StateBackend.\n\n        Returns:\n            Tuple of (output_text, tool_events, context, interrupt_data).\n            interrupt_data is None if not interrupted, otherwise contains pending approvals.\n        \"\"\"\n        messages = self._convert_history(history)\n        messages.append(HumanMessage(content=user_input))\n\n        agent_context: AgentContext = context if context is not None else {}\n\n        logger.info(f\"Running DeepAgents with user input: {user_input[:100]}...\")\n\n        config = {\n            \"configurable\": {\n                \"thread_id\": thread_id,\n                **agent_context,\n            }\n        }\n\n        # Prepare input with optional files for StateBackend\n        input_data: dict[str, Any] = {\"messages\": messages}\n        if files:\n            input_data[\"files\"] = files\n\n        result = await self.graph.ainvoke(input_data, config=config)\n\n        # Check for interrupt\n        interrupt_data = self.extract_interrupt(result)\n        if interrupt_data:\n            logger.info(f\"Agent interrupted with {len(interrupt_data['action_requests'])} pending approvals\")\n            return \"\", [], agent_context, interrupt_data\n\n        # Extract the final response and tool events\n        output = \"\"\n        tool_events: list[Any] = []\n\n        for message in result.get(\"messages\", []):\n            if isinstance(message, AIMessage):\n                if message.content:\n                    output = message.content if isinstance(message.content, str) else str(message.content)\n                if hasattr(message, \"tool_calls\") and message.tool_calls:\n                    tool_events.extend(message.tool_calls)\n\n        logger.info(f\"DeepAgents run complete. Output length: {len(output)} chars\")\n\n        return output, tool_events, agent_context, None\n\n    async def resume(\n        self,\n        decisions: list[Decision],\n        thread_id: str = \"default\",\n        context: AgentContext | None = None,\n    ) -> tuple[str, list[Any], AgentContext, InterruptData | None]:\n        \"\"\"Resume agent execution after human-in-the-loop interrupt.\n\n        Args:\n            decisions: List of decisions for each pending tool call.\n            thread_id: Thread ID (must match the interrupted session).\n            context: Optional runtime context.\n\n        Returns:\n            Tuple of (output_text, tool_events, context, interrupt_data).\n        \"\"\"\n        agent_context: AgentContext = context if context is not None else {}\n\n        config = {\n            \"configurable\": {\n                \"thread_id\": thread_id,\n                **agent_context,\n            }\n        }\n\n        logger.info(f\"Resuming DeepAgents with {len(decisions)} decisions\")\n\n        # Resume with Command\n        result = await self.graph.ainvoke(\n            Command(resume={\"decisions\": decisions}),\n            config=config\n        )\n\n        # Check for another interrupt\n        interrupt_data = self.extract_interrupt(result)\n        if interrupt_data:\n            logger.info(f\"Agent interrupted again with {len(interrupt_data['action_requests'])} pending approvals\")\n            return \"\", [], agent_context, interrupt_data\n\n        # Extract the final response and tool events\n        output = \"\"\n        tool_events: list[Any] = []\n\n        for message in result.get(\"messages\", []):\n            if isinstance(message, AIMessage):\n                if message.content:\n                    output = message.content if isinstance(message.content, str) else str(message.content)\n                if hasattr(message, \"tool_calls\") and message.tool_calls:\n                    tool_events.extend(message.tool_calls)\n\n        logger.info(f\"DeepAgents resume complete. Output length: {len(output)} chars\")\n\n        return output, tool_events, agent_context, None\n\n    async def stream(\n        self,\n        user_input: str,\n        history: list[dict[str, str]] | None = None,\n        context: AgentContext | None = None,\n        thread_id: str = \"default\",\n        files: dict[str, str] | None = None,\n    ):\n        \"\"\"Stream agent execution with message and state update streaming.\n\n        Args:\n            user_input: User's message.\n            history: Conversation history.\n            context: Optional runtime context.\n            thread_id: Thread ID for conversation continuity.\n            files: Optional dict of {path: content} to provide to StateBackend.\n\n        Yields:\n            Tuples of (stream_mode, data) for streaming responses.\n            - stream_mode=\"messages\": (chunk, metadata) for LLM tokens\n            - stream_mode=\"updates\": state updates after each node\n            - stream_mode=\"interrupt\": InterruptData when human approval needed\n        \"\"\"\n        messages = self._convert_history(history)\n        messages.append(HumanMessage(content=user_input))\n\n        agent_context: AgentContext = context if context is not None else {}\n\n        config = {\n            \"configurable\": {\n                \"thread_id\": thread_id,\n                **agent_context,\n            }\n        }\n\n        # Prepare input with optional files for StateBackend\n        input_data: dict[str, Any] = {\"messages\": messages}\n        if files:\n            input_data[\"files\"] = files\n\n        logger.info(f\"Starting DeepAgents stream for user input: {user_input[:100]}...\")\n\n        final_state: dict[str, Any] = {}\n\n        async for stream_mode, data in self.graph.astream(\n            input_data,\n            config=config,\n            stream_mode=[\"messages\", \"updates\"],\n        ):\n            final_state = data if stream_mode == \"updates\" else final_state\n            yield stream_mode, data\n\n        # Check for interrupt after stream completes\n        # Get the final state to check for interrupts\n        state = await self.graph.aget_state(config)\n        if state.next:  # If there's a next step, we're likely interrupted\n            # Fetch the actual interrupt data\n            result = await self.graph.ainvoke(input_data, config=config)\n            interrupt_data = self.extract_interrupt(result)\n            if interrupt_data:\n                yield \"interrupt\", interrupt_data\n\n    async def stream_resume(\n        self,\n        decisions: list[Decision],\n        thread_id: str = \"default\",\n        context: AgentContext | None = None,\n    ):\n        \"\"\"Stream agent execution after resuming from interrupt.\n\n        Args:\n            decisions: List of decisions for each pending tool call.\n            thread_id: Thread ID (must match the interrupted session).\n            context: Optional runtime context.\n\n        Yields:\n            Tuples of (stream_mode, data) for streaming responses.\n        \"\"\"\n        agent_context: AgentContext = context if context is not None else {}\n\n        config = {\n            \"configurable\": {\n                \"thread_id\": thread_id,\n                **agent_context,\n            }\n        }\n\n        logger.info(f\"Streaming resume with {len(decisions)} decisions\")\n\n        async for stream_mode, data in self.graph.astream(\n            Command(resume={\"decisions\": decisions}),\n            config=config,\n            stream_mode=[\"messages\", \"updates\"],\n        ):\n            yield stream_mode, data\n\n        # Check for another interrupt\n        state = await self.graph.aget_state(config)\n        if state.next:\n            result = await self.graph.ainvoke(\n                Command(resume={\"decisions\": decisions}),\n                config=config\n            )\n            interrupt_data = self.extract_interrupt(result)\n            if interrupt_data:\n                yield \"interrupt\", interrupt_data\n\n\ndef get_agent(\n    skills: list[str] | None = None,\n    interrupt_on: dict[str, bool | dict[str, list[str]]] | None = None,\n) -> DeepAgentsAssistant:\n    \"\"\"Factory function to create a DeepAgentsAssistant.\n\n    Args:\n        skills: Optional list of skill paths to override settings.\n        interrupt_on: Optional interrupt config to override settings.\n\n    Returns:\n        Configured DeepAgentsAssistant instance.\n    \"\"\"\n    return DeepAgentsAssistant(skills=skills, interrupt_on=interrupt_on)\n\n\nasync def run_agent(\n    user_input: str,\n    history: list[dict[str, str]],\n    context: AgentContext | None = None,\n    thread_id: str = \"default\",\n    files: dict[str, str] | None = None,\n) -> tuple[str, list[Any], AgentContext, InterruptData | None]:\n    \"\"\"Run agent and return the output along with tool call events.\n\n    This is a convenience function for backwards compatibility.\n\n    Args:\n        user_input: User's message.\n        history: Conversation history.\n        context: Optional runtime context.\n        thread_id: Thread ID for conversation continuity.\n        files: Optional dict of {path: content} to provide to StateBackend.\n\n    Returns:\n        Tuple of (output_text, tool_events, context, interrupt_data).\n    \"\"\"\n    agent = get_agent()\n    return await agent.run(user_input, history, context, thread_id, files)\n{%- else %}\n\"\"\"DeepAgents Assistant agent - not configured.\"\"\"\n{%- endif %}\n","backend/app/agents/assistant.py":"{%- if cookiecutter.enable_ai_agent and cookiecutter.use_pydantic_ai %}\n\"\"\"Assistant agent with PydanticAI.\n\nThe main conversational agent that can be extended with custom tools.\n\"\"\"\n\nimport logging\nfrom dataclasses import dataclass, field\nfrom typing import Any\n\nfrom pydantic_ai import Agent, RunContext\nfrom pydantic_ai.messages import (\n    ModelRequest,\n    ModelResponse,\n    SystemPromptPart,\n    TextPart,\n    UserPromptPart,\n)\n{%- if cookiecutter.use_openai %}\nfrom pydantic_ai.models.openai import OpenAIChatModel\nfrom pydantic_ai.providers.openai import OpenAIProvider\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\nfrom pydantic_ai.models.anthropic import AnthropicModel\n{%- endif %}\n{%- if cookiecutter.use_openrouter %}\nfrom pydantic_ai.models.openrouter import OpenRouterModel\nfrom pydantic_ai.providers.openrouter import OpenRouterProvider\n{%- endif %}\nfrom pydantic_ai.settings import ModelSettings\n\nfrom app.agents.prompts import DEFAULT_SYSTEM_PROMPT\nfrom app.agents.tools import get_current_datetime\nfrom app.core.config import settings\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass Deps:\n    \"\"\"Dependencies for the assistant agent.\n\n    These are passed to tools via RunContext.\n    \"\"\"\n\n    user_id: str | None = None\n    user_name: str | None = None\n    metadata: dict[str, Any] = field(default_factory=dict)\n\n\nclass AssistantAgent:\n    \"\"\"Assistant agent wrapper for conversational AI.\n\n    Encapsulates agent creation and execution with tool support.\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name: str | None = None,\n        temperature: float | None = None,\n        system_prompt: str | None = None,\n    ):\n        self.model_name = model_name or settings.AI_MODEL\n        self.temperature = temperature or settings.AI_TEMPERATURE\n        self.system_prompt = system_prompt or DEFAULT_SYSTEM_PROMPT\n        self._agent: Agent[Deps, str] | None = None\n\n    def _create_agent(self) -> Agent[Deps, str]:\n        \"\"\"Create and configure the PydanticAI agent.\"\"\"\n{%- if cookiecutter.use_openai %}\n        model = OpenAIChatModel(\n            self.model_name,\n            provider=OpenAIProvider(api_key=settings.OPENAI_API_KEY),\n        )\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\n        model = AnthropicModel(\n            self.model_name,\n            api_key=settings.ANTHROPIC_API_KEY,\n        )\n{%- endif %}\n{%- if cookiecutter.use_openrouter %}\n        model = OpenRouterModel(\n            self.model_name,\n            provider=OpenRouterProvider(api_key=settings.OPENROUTER_API_KEY),\n        )\n{%- endif %}\n\n        agent = Agent[Deps, str](\n            model=model,\n            model_settings=ModelSettings(temperature=self.temperature),\n            system_prompt=self.system_prompt,\n        )\n\n        self._register_tools(agent)\n\n        return agent\n\n    def _register_tools(self, agent: Agent[Deps, str]) -> None:\n        \"\"\"Register all tools on the agent.\"\"\"\n\n        @agent.tool\n        async def current_datetime(ctx: RunContext[Deps]) -> str:\n            \"\"\"Get the current date and time.\n\n            Use this tool when you need to know the current date or time.\n            \"\"\"\n            return get_current_datetime()\n\n    @property\n    def agent(self) -> Agent[Deps, str]:\n        \"\"\"Get or create the agent instance.\"\"\"\n        if self._agent is None:\n            self._agent = self._create_agent()\n        return self._agent\n\n    async def run(\n        self,\n        user_input: str,\n        history: list[dict[str, str]] | None = None,\n        deps: Deps | None = None,\n    ) -> tuple[str, list[Any], Deps]:\n        \"\"\"Run agent and return the output along with tool call events.\n\n        Args:\n            user_input: User's message.\n            history: Conversation history as list of {\"role\": \"...\", \"content\": \"...\"}.\n            deps: Optional dependencies. If not provided, a new Deps will be created.\n\n        Returns:\n            Tuple of (output_text, tool_events, deps).\n        \"\"\"\n        model_history: list[ModelRequest | ModelResponse] = []\n\n        for msg in history or []:\n            if msg[\"role\"] == \"user\":\n                model_history.append(ModelRequest(parts=[UserPromptPart(content=msg[\"content\"])]))\n            elif msg[\"role\"] == \"assistant\":\n                model_history.append(ModelResponse(parts=[TextPart(content=msg[\"content\"])]))\n            elif msg[\"role\"] == \"system\":\n                model_history.append(ModelRequest(parts=[SystemPromptPart(content=msg[\"content\"])]))\n\n        agent_deps = deps if deps is not None else Deps()\n\n        logger.info(f\"Running agent with user input: {user_input[:100]}...\")\n        result = await self.agent.run(user_input, deps=agent_deps, message_history=model_history)\n\n        tool_events: list[Any] = []\n        for message in result.all_messages():\n            if hasattr(message, \"parts\"):\n                for part in message.parts:\n                    if hasattr(part, \"tool_name\"):\n                        tool_events.append(part)\n\n        logger.info(f\"Agent run complete. Output length: {len(result.output)} chars\")\n\n        return result.output, tool_events, agent_deps\n\n    async def iter(\n        self,\n        user_input: str,\n        history: list[dict[str, str]] | None = None,\n        deps: Deps | None = None,\n    ):\n        \"\"\"Stream agent execution with full event access.\n\n        Args:\n            user_input: User's message.\n            history: Conversation history.\n            deps: Optional dependencies.\n\n        Yields:\n            Agent events for streaming responses.\n        \"\"\"\n        model_history: list[ModelRequest | ModelResponse] = []\n\n        for msg in history or []:\n            if msg[\"role\"] == \"user\":\n                model_history.append(ModelRequest(parts=[UserPromptPart(content=msg[\"content\"])]))\n            elif msg[\"role\"] == \"assistant\":\n                model_history.append(ModelResponse(parts=[TextPart(content=msg[\"content\"])]))\n            elif msg[\"role\"] == \"system\":\n                model_history.append(ModelRequest(parts=[SystemPromptPart(content=msg[\"content\"])]))\n\n        agent_deps = deps if deps is not None else Deps()\n\n        async with self.agent.iter(\n            user_input,\n            deps=agent_deps,\n            message_history=model_history,\n        ) as run:\n            async for event in run:\n                yield event\n\n\ndef get_agent() -> AssistantAgent:\n    \"\"\"Factory function to create an AssistantAgent.\n\n    Returns:\n        Configured AssistantAgent instance.\n    \"\"\"\n    return AssistantAgent()\n\n\nasync def run_agent(\n    user_input: str,\n    history: list[dict[str, str]],\n    deps: Deps | None = None,\n) -> tuple[str, list[Any], Deps]:\n    \"\"\"Run agent and return the output along with tool call events.\n\n    This is a convenience function for backwards compatibility.\n\n    Args:\n        user_input: User's message.\n        history: Conversation history.\n        deps: Optional dependencies.\n\n    Returns:\n        Tuple of (output_text, tool_events, deps).\n    \"\"\"\n    agent = get_agent()\n    return await agent.run(user_input, history, deps)\n{%- else %}\n\"\"\"PydanticAI Assistant agent - not configured.\"\"\"\n{%- endif %}\n","backend/app/agents/langgraph_assistant.py":"{%- if cookiecutter.enable_ai_agent and cookiecutter.use_langgraph %}\n\"\"\"LangGraph ReAct Agent implementation.\n\nA simple ReAct (Reasoning + Acting) agent built with LangGraph.\nUses a graph-based architecture with conditional edges for tool execution.\n\"\"\"\n\nimport logging\nfrom typing import Annotated, Any, Literal, TypedDict\n\nfrom langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage, ToolMessage\nfrom langchain_core.tools import tool\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.graph import END, START, StateGraph\nfrom langgraph.graph.message import add_messages\n{%- if cookiecutter.use_openai %}\nfrom langchain_openai import ChatOpenAI\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\nfrom langchain_anthropic import ChatAnthropic\n{%- endif %}\n\nfrom app.agents.prompts import DEFAULT_SYSTEM_PROMPT\nfrom app.agents.tools import get_current_datetime\nfrom app.core.config import settings\n\nlogger = logging.getLogger(__name__)\n\n\nclass AgentContext(TypedDict, total=False):\n    \"\"\"Runtime context for the agent.\n\n    Passed via config parameter to the graph.\n    \"\"\"\n\n    user_id: str | None\n    user_name: str | None\n    metadata: dict[str, Any]\n\n\nclass AgentState(TypedDict):\n    \"\"\"State for the LangGraph agent.\n\n    This is what flows through the agent graph.\n    The messages field uses add_messages reducer to properly\n    append new messages to the conversation history.\n    \"\"\"\n\n    messages: Annotated[list[BaseMessage], add_messages]\n\n\n@tool\ndef current_datetime() -> str:\n    \"\"\"Get the current date and time.\n\n    Use this tool when you need to know the current date or time.\n    \"\"\"\n    return get_current_datetime()\n\n\n# List of all available tools\nALL_TOOLS = [current_datetime]\n\n# Create a dictionary for quick tool lookup by name\nTOOLS_BY_NAME = {t.name: t for t in ALL_TOOLS}\n\n\nclass LangGraphAssistant:\n    \"\"\"ReAct agent wrapper using LangGraph.\n\n    Implements a graph-based agent with:\n    - An agent node that processes messages and decides actions\n    - A tools node that executes tool calls\n    - Conditional edges that loop back for tool execution or end\n\n    The ReAct pattern:\n    1. Agent receives input and reasons about it\n    2. If tool calls are needed, execute them\n    3. Tool results are added to messages\n    4. Agent reasons again with new information\n    5. Repeat until agent provides final response\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name: str | None = None,\n        temperature: float | None = None,\n        system_prompt: str | None = None,\n    ):\n        self.model_name = model_name or settings.AI_MODEL\n        self.temperature = temperature or settings.AI_TEMPERATURE\n        self.system_prompt = system_prompt or DEFAULT_SYSTEM_PROMPT\n        self._graph = None\n        self._checkpointer = MemorySaver()\n\n    def _create_model(self):\n        \"\"\"Create the LLM model with tools bound.\"\"\"\n{%- if cookiecutter.use_openai %}\n        model = ChatOpenAI(\n            model=self.model_name,\n            temperature=self.temperature,\n            api_key=settings.OPENAI_API_KEY,\n            streaming=True,\n        )\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\n        model = ChatAnthropic(\n            model=self.model_name,\n            temperature=self.temperature,\n            api_key=settings.ANTHROPIC_API_KEY,\n            streaming=True,\n        )\n{%- endif %}\n\n        return model.bind_tools(ALL_TOOLS)\n\n    def _agent_node(self, state: AgentState) -> dict[str, list[BaseMessage]]:\n        \"\"\"Agent node that processes messages and decides whether to call tools.\n\n        This is the main reasoning node in the ReAct pattern.\n        \"\"\"\n        model = self._create_model()\n\n        # Prepend system message to the conversation\n        messages = [SystemMessage(content=self.system_prompt), *state[\"messages\"]]\n\n        response = model.invoke(messages)\n\n        logger.info(\n            f\"Agent processed message - Tool calls: {len(response.tool_calls) if hasattr(response, 'tool_calls') else 0}\"\n        )\n\n        return {\"messages\": [response]}\n\n    def _tools_node(self, state: AgentState) -> dict[str, list[ToolMessage]]:\n        \"\"\"Tools node that executes tool calls from the agent.\n\n        Processes each tool call and returns results as ToolMessages.\n        \"\"\"\n        messages = state[\"messages\"]\n        last_message = messages[-1]\n\n        tool_results = []\n\n        if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n            for tool_call in last_message.tool_calls:\n                tool_name = tool_call[\"name\"]\n                tool_args = tool_call[\"args\"]\n                tool_id = tool_call[\"id\"]\n\n                logger.info(f\"Executing tool: {tool_name} with args: {tool_args}\")\n\n                try:\n                    tool_fn = TOOLS_BY_NAME.get(tool_name)\n                    if tool_fn:\n                        result = tool_fn.invoke(tool_args)\n                        tool_results.append(\n                            ToolMessage(\n                                content=str(result),\n                                tool_call_id=tool_id,\n                                name=tool_name,\n                            )\n                        )\n                        logger.info(f\"Tool {tool_name} completed successfully\")\n                    else:\n                        error_msg = f\"Unknown tool: {tool_name}\"\n                        logger.error(error_msg)\n                        tool_results.append(\n                            ToolMessage(\n                                content=error_msg,\n                                tool_call_id=tool_id,\n                                name=tool_name,\n                            )\n                        )\n                except Exception as e:\n                    error_msg = f\"Error executing {tool_name}: {str(e)}\"\n                    logger.error(error_msg, exc_info=True)\n                    tool_results.append(\n                        ToolMessage(\n                            content=error_msg,\n                            tool_call_id=tool_id,\n                            name=tool_name,\n                        )\n                    )\n\n        return {\"messages\": tool_results}\n\n    def _should_continue(self, state: AgentState) -> Literal[\"tools\", \"__end__\"]:\n        \"\"\"Conditional edge that decides whether to continue to tools or end.\n\n        Returns:\n            - \"tools\" if the agent made tool calls (needs to execute tools)\n            - \"__end__\" if the agent provided a final response (no tool calls)\n        \"\"\"\n        messages = state[\"messages\"]\n        last_message = messages[-1]\n\n        if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n            logger.info(f\"Continuing to tools - {len(last_message.tool_calls)} tool(s) to execute\")\n            return \"tools\"\n\n        logger.info(\"No tool calls - ending conversation\")\n        return \"__end__\"\n\n    def _build_graph(self) -> StateGraph:\n        \"\"\"Build and compile the LangGraph state graph.\"\"\"\n        workflow = StateGraph(AgentState)\n\n        # Add nodes\n        workflow.add_node(\"agent\", self._agent_node)\n        workflow.add_node(\"tools\", self._tools_node)\n\n        # Add edges\n        workflow.add_edge(START, \"agent\")\n        workflow.add_conditional_edges(\n            \"agent\",\n            self._should_continue,\n            {\"tools\": \"tools\", \"__end__\": END},\n        )\n        workflow.add_edge(\"tools\", \"agent\")\n\n        return workflow.compile(checkpointer=self._checkpointer)\n\n    @property\n    def graph(self):\n        \"\"\"Get or create the compiled graph instance.\"\"\"\n        if self._graph is None:\n            self._graph = self._build_graph()\n        return self._graph\n\n    @staticmethod\n    def _convert_history(\n        history: list[dict[str, str]] | None,\n    ) -> list[HumanMessage | AIMessage | SystemMessage]:\n        \"\"\"Convert conversation history to LangChain message format.\"\"\"\n        messages: list[HumanMessage | AIMessage | SystemMessage] = []\n\n        for msg in history or []:\n            if msg[\"role\"] == \"user\":\n                messages.append(HumanMessage(content=msg[\"content\"]))\n            elif msg[\"role\"] == \"assistant\":\n                messages.append(AIMessage(content=msg[\"content\"]))\n            elif msg[\"role\"] == \"system\":\n                messages.append(SystemMessage(content=msg[\"content\"]))\n\n        return messages\n\n    async def run(\n        self,\n        user_input: str,\n        history: list[dict[str, str]] | None = None,\n        context: AgentContext | None = None,\n        thread_id: str = \"default\",\n    ) -> tuple[str, list[Any], AgentContext]:\n        \"\"\"Run agent and return the output along with tool call events.\n\n        Args:\n            user_input: User's message.\n            history: Conversation history as list of {\"role\": \"...\", \"content\": \"...\"}.\n            context: Optional runtime context with user info.\n            thread_id: Thread ID for conversation continuity.\n\n        Returns:\n            Tuple of (output_text, tool_events, context).\n        \"\"\"\n        messages = self._convert_history(history)\n        messages.append(HumanMessage(content=user_input))\n\n        agent_context: AgentContext = context if context is not None else {}\n\n        logger.info(f\"Running agent with user input: {user_input[:100]}...\")\n\n        config = {\n            \"configurable\": {\n                \"thread_id\": thread_id,\n                **agent_context,\n            }\n        }\n\n        result = await self.graph.ainvoke({\"messages\": messages}, config=config)\n\n        # Extract the final response and tool events\n        output = \"\"\n        tool_events: list[Any] = []\n\n        for message in result.get(\"messages\", []):\n            if isinstance(message, AIMessage):\n                if message.content:\n                    output = message.content if isinstance(message.content, str) else str(message.content)\n                if hasattr(message, \"tool_calls\") and message.tool_calls:\n                    tool_events.extend(message.tool_calls)\n\n        logger.info(f\"Agent run complete. Output length: {len(output)} chars\")\n\n        return output, tool_events, agent_context\n\n    async def stream(\n        self,\n        user_input: str,\n        history: list[dict[str, str]] | None = None,\n        context: AgentContext | None = None,\n        thread_id: str = \"default\",\n    ):\n        \"\"\"Stream agent execution with message and state update streaming.\n\n        Args:\n            user_input: User's message.\n            history: Conversation history.\n            context: Optional runtime context.\n            thread_id: Thread ID for conversation continuity.\n\n        Yields:\n            Tuples of (stream_mode, data) for streaming responses.\n            - stream_mode=\"messages\": (chunk, metadata) for LLM tokens\n            - stream_mode=\"updates\": state updates after each node\n        \"\"\"\n        messages = self._convert_history(history)\n        messages.append(HumanMessage(content=user_input))\n\n        agent_context: AgentContext = context if context is not None else {}\n\n        config = {\n            \"configurable\": {\n                \"thread_id\": thread_id,\n                **agent_context,\n            }\n        }\n\n        logger.info(f\"Starting stream for user input: {user_input[:100]}...\")\n\n        async for stream_mode, data in self.graph.astream(\n            {\"messages\": messages},\n            config=config,\n            stream_mode=[\"messages\", \"updates\"],\n        ):\n            yield stream_mode, data\n\n\ndef get_agent() -> LangGraphAssistant:\n    \"\"\"Factory function to create a LangGraphAssistant.\n\n    Returns:\n        Configured LangGraphAssistant instance.\n    \"\"\"\n    return LangGraphAssistant()\n\n\nasync def run_agent(\n    user_input: str,\n    history: list[dict[str, str]],\n    context: AgentContext | None = None,\n    thread_id: str = \"default\",\n) -> tuple[str, list[Any], AgentContext]:\n    \"\"\"Run agent and return the output along with tool call events.\n\n    This is a convenience function for backwards compatibility.\n\n    Args:\n        user_input: User's message.\n        history: Conversation history.\n        context: Optional runtime context.\n        thread_id: Thread ID for conversation continuity.\n\n    Returns:\n        Tuple of (output_text, tool_events, context).\n    \"\"\"\n    agent = get_agent()\n    return await agent.run(user_input, history, context, thread_id)\n{%- else %}\n\"\"\"LangGraph Assistant agent - not configured.\"\"\"\n{%- endif %}\n","backend/app/agents/__init__.py":"{%- if cookiecutter.enable_ai_agent and cookiecutter.use_pydantic_ai %}\n\"\"\"AI Agents module using PydanticAI.\n\nThis module contains agents that handle AI-powered interactions.\nTools are defined in the tools/ subdirectory.\n\"\"\"\n\nfrom app.agents.assistant import AssistantAgent, Deps\n\n__all__ = [\"AssistantAgent\", \"Deps\"]\n{%- elif cookiecutter.enable_ai_agent and cookiecutter.use_langchain %}\n\"\"\"AI Agents module using LangChain.\n\nThis module contains agents that handle AI-powered interactions.\nTools are defined in the tools/ subdirectory.\n\"\"\"\n\nfrom app.agents.langchain_assistant import AgentContext, AgentState, LangChainAssistant\n\n__all__ = [\"LangChainAssistant\", \"AgentContext\", \"AgentState\"]\n{%- elif cookiecutter.enable_ai_agent and cookiecutter.use_langgraph %}\n\"\"\"AI Agents module using LangGraph.\n\nThis module contains a ReAct agent built with LangGraph.\nTools are defined in the tools/ subdirectory.\n\"\"\"\n\nfrom app.agents.langgraph_assistant import AgentContext, AgentState, LangGraphAssistant\n\n__all__ = [\"LangGraphAssistant\", \"AgentContext\", \"AgentState\"]\n{%- elif cookiecutter.enable_ai_agent and cookiecutter.use_crewai %}\n\"\"\"AI Agents module using CrewAI.\n\nThis module contains a multi-agent crew built with CrewAI.\nAgents work together in a team to accomplish complex tasks.\n\"\"\"\n\nfrom app.agents.crewai_assistant import CrewAIAssistant, CrewConfig, CrewContext\n\n__all__ = [\"CrewAIAssistant\", \"CrewConfig\", \"CrewContext\"]\n{%- elif cookiecutter.enable_ai_agent and cookiecutter.use_deepagents %}\n\"\"\"AI Agents module using DeepAgents.\n\nThis module contains an agentic coding assistant built with DeepAgents.\nDeepAgents provides built-in tools for filesystem operations, task management,\nand code execution.\n\"\"\"\n\nfrom app.agents.deepagents_assistant import AgentContext, AgentState, DeepAgentsAssistant\n\n__all__ = [\"DeepAgentsAssistant\", \"AgentContext\", \"AgentState\"]\n{%- else %}\n\"\"\"AI Agents - not configured.\"\"\"\n{%- endif %}\n","backend/app/agents/prompts.py":"{%- if cookiecutter.enable_ai_agent %}\n\"\"\"System prompts for AI agents.\n\nCentralized location for all agent prompts to make them easy to find and modify.\n\"\"\"\n\nDEFAULT_SYSTEM_PROMPT = \"\"\"You are a helpful assistant.\"\"\"\n{%- else %}\n\"\"\"AI Agent prompts - not configured.\"\"\"\n{%- endif %}\n","backend/app/agents/crewai_assistant.py":"{%- if cookiecutter.enable_ai_agent and cookiecutter.use_crewai %}\n\"\"\"CrewAI Multi-Agent implementation.\n\nA multi-agent orchestration framework using CrewAI.\nEnables teams of AI agents to work together on complex tasks.\nUses CrewAI's event system for real-time streaming to WebSocket.\n\"\"\"\n\nimport asyncio\nimport logging\nimport os\nfrom queue import Empty, Queue\nfrom threading import Thread\nfrom typing import Any, TypedDict\n\n# Disable CrewAI interactive prompts for server use\nos.environ.setdefault(\"CREWAI_DISABLE_TRACES_PROMPT\", \"true\")\n\nfrom crewai import Agent, Crew, Process, Task\nfrom crewai.events import (\n    crewai_event_bus,\n    CrewKickoffStartedEvent,\n    CrewKickoffCompletedEvent,\n    CrewKickoffFailedEvent,\n    AgentExecutionStartedEvent,\n    AgentExecutionCompletedEvent,\n    TaskStartedEvent,\n    TaskCompletedEvent,\n    ToolUsageStartedEvent,\n    ToolUsageFinishedEvent,\n    LLMCallStartedEvent,\n    LLMCallCompletedEvent,\n)\nfrom pydantic import BaseModel, Field\n{%- if cookiecutter.use_openai %}\nfrom langchain_openai import ChatOpenAI\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\nfrom langchain_anthropic import ChatAnthropic\n{%- endif %}\n\nfrom app.agents.prompts import DEFAULT_SYSTEM_PROMPT\nfrom app.core.config import settings\n\nlogger = logging.getLogger(__name__)\n\n\nclass AgentConfig(BaseModel):\n    \"\"\"Configuration for a single agent.\"\"\"\n\n    role: str = Field(..., description=\"Agent's role/title\")\n    goal: str = Field(..., description=\"Agent's primary goal\")\n    backstory: str = Field(..., description=\"Agent's background context\")\n    tools: list[str] = Field(default_factory=list)\n    allow_delegation: bool = True\n    verbose: bool = True\n\n\nclass TaskConfig(BaseModel):\n    \"\"\"Configuration for a single task.\"\"\"\n\n    description: str = Field(..., description=\"Task description\")\n    expected_output: str = Field(..., description=\"Expected output format\")\n    agent_role: str = Field(..., description=\"Role of agent to execute this\")\n    context_from: list[str] = Field(default_factory=list)\n\n\nclass CrewConfig(BaseModel):\n    \"\"\"Configuration for the entire crew.\"\"\"\n\n    name: str = \"default_crew\"\n    process: str = \"sequential\"  # sequential, hierarchical\n    memory: bool = True\n    max_rpm: int = 10\n    agents: list[AgentConfig] = Field(default_factory=list)\n    tasks: list[TaskConfig] = Field(default_factory=list)\n\n\nclass CrewContext(TypedDict, total=False):\n    \"\"\"Runtime context for crew execution.\"\"\"\n\n    user_id: str | None\n    user_name: str | None\n    metadata: dict[str, Any]\n\n\nclass CrewEventQueueListener:\n    \"\"\"Event listener that sends CrewAI events to a queue for WebSocket streaming.\n\n    Registers handlers with the global crewai_event_bus to capture all events\n    and forward them to a queue for async WebSocket streaming.\n    \"\"\"\n\n    def __init__(self, event_queue: Queue):\n        self._event_queue = event_queue\n        self._handlers: list[Any] = []\n        self._register_handlers()\n\n    def _register_handlers(self):\n        \"\"\"Register all event handlers with the CrewAI event bus.\"\"\"\n\n        def on_crew_started(source, event: CrewKickoffStartedEvent):\n            self._event_queue.put({\n                \"type\": \"crew_started\",\n                \"crew_name\": getattr(event, \"crew_name\", \"crew\"),\n                \"crew_id\": str(getattr(event, \"crew_id\", \"\")),\n            })\n\n        def on_crew_completed(source, event: CrewKickoffCompletedEvent):\n            output = getattr(event, \"output\", None)\n            self._event_queue.put({\n                \"type\": \"crew_complete\",\n                \"result\": str(output.raw if hasattr(output, \"raw\") else output) if output else \"\",\n            })\n\n        def on_crew_failed(source, event: CrewKickoffFailedEvent):\n            self._event_queue.put({\n                \"type\": \"error\",\n                \"error\": str(getattr(event, \"error\", \"Unknown error\")),\n            })\n\n        def on_agent_started(source, event: AgentExecutionStartedEvent):\n            agent = getattr(event, \"agent\", None)\n            self._event_queue.put({\n                \"type\": \"agent_started\",\n                \"agent\": getattr(agent, \"role\", \"Unknown\") if agent else \"Unknown\",\n                \"task\": str(getattr(event, \"task\", \"\")),\n            })\n\n        def on_agent_completed(source, event: AgentExecutionCompletedEvent):\n            agent = getattr(event, \"agent\", None)\n            output = getattr(event, \"output\", None)\n            self._event_queue.put({\n                \"type\": \"agent_completed\",\n                \"agent\": getattr(agent, \"role\", \"Unknown\") if agent else \"Unknown\",\n                \"output\": str(output) if output else \"\",\n            })\n\n        def on_task_started(source, event: TaskStartedEvent):\n            task = getattr(event, \"task\", None)\n            self._event_queue.put({\n                \"type\": \"task_started\",\n                \"task_id\": str(getattr(task, \"id\", \"\")) if task else \"\",\n                \"description\": str(getattr(task, \"description\", \"\")) if task else \"\",\n                \"agent\": getattr(getattr(task, \"agent\", None), \"role\", \"Unknown\") if task else \"Unknown\",\n            })\n\n        def on_task_completed(source, event: TaskCompletedEvent):\n            task = getattr(event, \"task\", None)\n            output = getattr(event, \"output\", None)\n            self._event_queue.put({\n                \"type\": \"task_completed\",\n                \"task_id\": str(getattr(task, \"id\", \"\")) if task else \"\",\n                \"output\": str(output.raw if hasattr(output, \"raw\") else output) if output else \"\",\n                \"agent\": getattr(getattr(task, \"agent\", None), \"role\", \"Unknown\") if task else \"Unknown\",\n            })\n\n        def on_tool_started(source, event: ToolUsageStartedEvent):\n            self._event_queue.put({\n                \"type\": \"tool_started\",\n                \"tool_name\": str(getattr(event, \"tool_name\", \"Unknown\")),\n                \"tool_args\": str(getattr(event, \"tool_args\", {})),\n                \"agent\": str(getattr(event, \"agent\", \"Unknown\")),\n            })\n\n        def on_tool_finished(source, event: ToolUsageFinishedEvent):\n            self._event_queue.put({\n                \"type\": \"tool_finished\",\n                \"tool_name\": str(getattr(event, \"tool_name\", \"Unknown\")),\n                \"tool_result\": str(getattr(event, \"tool_result\", \"\")),\n                \"agent\": str(getattr(event, \"agent\", \"Unknown\")),\n            })\n\n        def on_llm_started(source, event: LLMCallStartedEvent):\n            self._event_queue.put({\n                \"type\": \"llm_started\",\n                \"agent\": str(getattr(event, \"agent\", \"Unknown\")),\n            })\n\n        def on_llm_completed(source, event: LLMCallCompletedEvent):\n            response = getattr(event, \"response\", None)\n            self._event_queue.put({\n                \"type\": \"llm_completed\",\n                \"agent\": str(getattr(event, \"agent\", \"Unknown\")),\n                \"response\": str(response) if response else \"\",\n            })\n\n        # Register handlers with the event bus\n        crewai_event_bus.on(CrewKickoffStartedEvent)(on_crew_started)\n        crewai_event_bus.on(CrewKickoffCompletedEvent)(on_crew_completed)\n        crewai_event_bus.on(CrewKickoffFailedEvent)(on_crew_failed)\n        crewai_event_bus.on(AgentExecutionStartedEvent)(on_agent_started)\n        crewai_event_bus.on(AgentExecutionCompletedEvent)(on_agent_completed)\n        crewai_event_bus.on(TaskStartedEvent)(on_task_started)\n        crewai_event_bus.on(TaskCompletedEvent)(on_task_completed)\n        crewai_event_bus.on(ToolUsageStartedEvent)(on_tool_started)\n        crewai_event_bus.on(ToolUsageFinishedEvent)(on_tool_finished)\n        crewai_event_bus.on(LLMCallStartedEvent)(on_llm_started)\n        crewai_event_bus.on(LLMCallCompletedEvent)(on_llm_completed)\n\n        # Store references to prevent garbage collection\n        self._handlers = [\n            on_crew_started, on_crew_completed, on_crew_failed,\n            on_agent_started, on_agent_completed,\n            on_task_started, on_task_completed,\n            on_tool_started, on_tool_finished,\n            on_llm_started, on_llm_completed,\n        ]\n\n\nclass CrewAIAssistant:\n    \"\"\"Multi-agent crew orchestration using CrewAI.\n\n    Supports:\n    - Multiple specialized agents with different roles\n    - Sequential or hierarchical task execution\n    - Agent delegation and collaboration\n    - Real-time event streaming via WebSocket\n\n    CrewAI Pattern:\n    1. Define agents with roles, goals, and backstories\n    2. Define tasks assigned to specific agents\n    3. Crew executes tasks in order (sequential/hierarchical)\n    4. Events are streamed in real-time to connected clients\n    5. Final output aggregated from all task results\n    \"\"\"\n\n    def __init__(\n        self,\n        config: CrewConfig | None = None,\n        model_name: str | None = None,\n        temperature: float | None = None,\n        system_prompt: str | None = None,\n    ):\n        self.config = config or self._default_config()\n        self.model_name = model_name or settings.AI_MODEL\n        self.temperature = temperature or settings.AI_TEMPERATURE\n        self.system_prompt = system_prompt or DEFAULT_SYSTEM_PROMPT\n        self._crew: Crew | None = None\n        self._agents: dict[str, Agent] = {}\n\n    def _default_config(self) -> CrewConfig:\n        \"\"\"Default crew configuration for general assistance.\"\"\"\n        return CrewConfig(\n            name=\"assistant_crew\",\n            process=\"sequential\",\n            memory=False,  # Disable memory for simpler setup\n            agents=[\n                AgentConfig(\n                    role=\"Research Analyst\",\n                    goal=\"Gather and analyze information accurately to help the user\",\n                    backstory=\"You are an expert research analyst skilled at finding and synthesizing information. You always provide accurate, well-researched answers.\",\n                    tools=[],\n                    allow_delegation=False,  # Simpler without delegation\n                ),\n                AgentConfig(\n                    role=\"Content Writer\",\n                    goal=\"Create clear, well-structured responses for the user\",\n                    backstory=\"You are a skilled writer who produces high-quality, readable content. You take research findings and transform them into helpful responses.\",\n                    tools=[],\n                    allow_delegation=False,\n                ),\n            ],\n            tasks=[\n                TaskConfig(\n                    description=\"Research and analyze the user's query: {user_input}. Gather all relevant information needed to provide a comprehensive answer.\",\n                    expected_output=\"Comprehensive research findings with key facts and insights\",\n                    agent_role=\"Research Analyst\",\n                ),\n                TaskConfig(\n                    description=\"Based on the research findings, write a clear, helpful response to the user's original query.\",\n                    expected_output=\"A well-written, user-friendly response that addresses the query\",\n                    agent_role=\"Content Writer\",\n                    context_from=[\"Research Analyst\"],\n                ),\n            ],\n        )\n\n    def _get_llm(self):\n        \"\"\"Get LLM instance based on settings.\"\"\"\n{%- if cookiecutter.use_openai %}\n        return ChatOpenAI(\n            model=self.model_name,\n            temperature=self.temperature,\n            api_key=settings.OPENAI_API_KEY,\n        )\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\n        return ChatAnthropic(\n            model=self.model_name,\n            temperature=self.temperature,\n            api_key=settings.ANTHROPIC_API_KEY,\n        )\n{%- endif %}\n\n    def _build_agents(self) -> dict[str, Agent]:\n        \"\"\"Build Agent instances from config.\"\"\"\n        agents = {}\n        llm = self._get_llm()\n\n        for agent_config in self.config.agents:\n            agent = Agent(\n                role=agent_config.role,\n                goal=agent_config.goal,\n                backstory=agent_config.backstory,\n                tools=[],\n                allow_delegation=agent_config.allow_delegation,\n                verbose=agent_config.verbose,\n                llm=llm,\n            )\n            agents[agent_config.role] = agent\n\n        return agents\n\n    def _build_tasks(self, agents: dict[str, Agent]) -> list[Task]:\n        \"\"\"Build Task instances from config.\"\"\"\n        tasks = []\n        task_by_agent: dict[str, Task] = {}\n\n        for task_config in self.config.tasks:\n            agent = agents.get(task_config.agent_role)\n            if not agent:\n                raise ValueError(f\"Agent '{task_config.agent_role}' not found\")\n\n            context = [\n                task_by_agent[role]\n                for role in task_config.context_from\n                if role in task_by_agent\n            ]\n\n            task = Task(\n                description=task_config.description,\n                expected_output=task_config.expected_output,\n                agent=agent,\n                context=context if context else None,\n            )\n            tasks.append(task)\n            task_by_agent[task_config.agent_role] = task\n\n        return tasks\n\n    def _build_crew(self) -> Crew:\n        \"\"\"Build and return the Crew instance.\"\"\"\n        self._agents = self._build_agents()\n        tasks = self._build_tasks(self._agents)\n\n        process = (\n            Process.hierarchical\n            if self.config.process == \"hierarchical\"\n            else Process.sequential\n        )\n\n        return Crew(\n            agents=list(self._agents.values()),\n            tasks=tasks,\n            process=process,\n            memory=self.config.memory,\n            verbose=False,  # Disable console output for server use\n        )\n\n    @property\n    def crew(self) -> Crew:\n        \"\"\"Get or create the Crew instance.\"\"\"\n        if self._crew is None:\n            self._crew = self._build_crew()\n        return self._crew\n\n    async def run(\n        self,\n        user_input: str,\n        history: list[dict[str, str]] | None = None,\n        context: CrewContext | None = None,\n        thread_id: str = \"default\",\n    ) -> tuple[str, list[dict[str, Any]], CrewContext]:\n        \"\"\"Run the crew and return results.\n\n        Args:\n            user_input: User's message/request.\n            history: Conversation history (for context).\n            context: Runtime context.\n            thread_id: Thread ID for conversation continuity.\n\n        Returns:\n            Tuple of (output_text, task_results, context).\n        \"\"\"\n        crew_context: CrewContext = context if context is not None else {}\n\n        inputs = {\n            \"user_input\": user_input,\n            \"history\": self._format_history(history),\n            **crew_context.get(\"metadata\", {}),\n        }\n\n        logger.info(f\"Starting CrewAI execution: {user_input[:100]}...\")\n\n        # Reset crew for fresh execution\n        self._crew = None\n\n        loop = asyncio.get_event_loop()\n        result = await loop.run_in_executor(\n            None,\n            lambda: self.crew.kickoff(inputs=inputs)\n        )\n\n        task_results = []\n        for task in self.crew.tasks:\n            if task.output:\n                task_results.append({\n                    \"agent\": task.agent.role if task.agent else \"Unknown\",\n                    \"description\": task.description[:100],\n                    \"output\": str(task.output.raw if hasattr(task.output, \"raw\") else task.output),\n                })\n\n        output = str(result.raw if hasattr(result, \"raw\") else result) if result else \"\"\n        logger.info(f\"CrewAI execution complete. Output length: {len(output)}\")\n\n        return output, task_results, crew_context\n\n    async def stream(\n        self,\n        user_input: str,\n        history: list[dict[str, str]] | None = None,\n        context: CrewContext | None = None,\n        thread_id: str = \"default\",\n    ):\n        \"\"\"Stream crew execution with real-time event updates.\n\n        Uses CrewAI's event system to capture and stream:\n        - crew_started: Crew execution begins\n        - agent_started/completed: Agent lifecycle events\n        - task_started/completed: Task lifecycle events\n        - tool_started/finished: Tool usage events\n        - llm_started/completed: LLM call events\n        - crew_complete: Final result\n        - error: Error occurred\n\n        Args:\n            user_input: User's message.\n            history: Conversation history.\n            context: Optional runtime context.\n            thread_id: Thread ID for conversation continuity.\n\n        Yields:\n            Dict events with type and data.\n        \"\"\"\n        event_queue: Queue = Queue()\n\n        inputs = {\n            \"user_input\": user_input,\n            \"history\": self._format_history(history),\n        }\n\n        # Reset crew for fresh execution\n        self._crew = None\n\n        # Create event listener BEFORE starting thread (keeps reference alive)\n        listener = CrewEventQueueListener(event_queue)\n\n        def run_with_events():\n            \"\"\"Run crew with event listener.\"\"\"\n            nonlocal listener  # Keep reference to prevent GC\n            try:\n                # Build and run crew\n                crew = self.crew\n                result = crew.kickoff(inputs=inputs)\n\n                # Ensure final result is sent (event bus may have already sent it)\n                if result:\n                    event_queue.put({\n                        \"type\": \"crew_complete\",\n                        \"result\": str(result.raw if hasattr(result, \"raw\") else result),\n                    })\n\n            except Exception as e:\n                logger.error(f\"CrewAI execution error: {e}\", exc_info=True)\n                event_queue.put({\n                    \"type\": \"error\",\n                    \"error\": str(e),\n                })\n            finally:\n                event_queue.put(None)  # Signal completion\n\n        # Start crew in background thread\n        thread = Thread(target=run_with_events, daemon=True)\n        thread.start()\n\n        # Yield events as they arrive\n        while True:\n            await asyncio.sleep(0.05)\n\n            while True:\n                try:\n                    event = event_queue.get_nowait()\n                    if event is None:\n                        thread.join(timeout=2.0)\n                        _ = listener  # Keep reference until done\n                        return\n                    yield event\n                except Empty:\n                    break\n\n            # Check if thread is still alive\n            if not thread.is_alive():\n                # Drain remaining events\n                while True:\n                    try:\n                        event = event_queue.get_nowait()\n                        if event is None:\n                            _ = listener  # Keep reference until done\n                            return\n                        yield event\n                    except Empty:\n                        break\n                _ = listener  # Keep reference until done\n                return\n\n    def _format_history(self, history: list[dict[str, str]] | None) -> str:\n        \"\"\"Format conversation history as context string.\"\"\"\n        if not history:\n            return \"\"\n\n        formatted = []\n        for msg in history[-5:]:\n            role = msg.get(\"role\", \"unknown\")\n            content = msg.get(\"content\", \"\")\n            formatted.append(f\"{role.upper()}: {content}\")\n\n        return \"\\n\".join(formatted)\n\n\ndef get_crew() -> CrewAIAssistant:\n    \"\"\"Factory function to create a CrewAIAssistant.\n\n    Returns:\n        Configured CrewAIAssistant instance.\n    \"\"\"\n    return CrewAIAssistant()\n\n\nasync def run_crew(\n    user_input: str,\n    history: list[dict[str, str]],\n    context: CrewContext | None = None,\n    thread_id: str = \"default\",\n) -> tuple[str, list[dict[str, Any]], CrewContext]:\n    \"\"\"Run crew and return the output along with task results.\n\n    This is a convenience function for backwards compatibility.\n\n    Args:\n        user_input: User's message.\n        history: Conversation history.\n        context: Optional runtime context.\n        thread_id: Thread ID for conversation continuity.\n\n    Returns:\n        Tuple of (output_text, task_results, context).\n    \"\"\"\n    crew = get_crew()\n    return await crew.run(user_input, history, context, thread_id)\n{%- else %}\n\"\"\"CrewAI Assistant agent - not configured.\"\"\"\n{%- endif %}\n","backend/app/agents/langchain_assistant.py":"{%- if cookiecutter.enable_ai_agent and cookiecutter.use_langchain %}\n\"\"\"Assistant agent with LangChain.\n\nThe main conversational agent that can be extended with custom tools.\n\"\"\"\n\nimport logging\nfrom typing import Any, TypedDict\n\nfrom langchain.agents import create_agent\nfrom langchain.messages import AIMessage, HumanMessage, SystemMessage\nfrom langchain.tools import tool\n{%- if cookiecutter.use_openai %}\nfrom langchain_openai import ChatOpenAI\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\nfrom langchain_anthropic import ChatAnthropic\n{%- endif %}\n\nfrom app.agents.prompts import DEFAULT_SYSTEM_PROMPT\nfrom app.agents.tools import get_current_datetime\nfrom app.core.config import settings\n\nlogger = logging.getLogger(__name__)\n\n\nclass AgentContext(TypedDict, total=False):\n    \"\"\"Runtime context for the agent.\n\n    Passed via context parameter to agent.invoke()/stream().\n    \"\"\"\n\n    user_id: str | None\n    user_name: str | None\n    metadata: dict[str, Any]\n\n\nclass AgentState(TypedDict):\n    \"\"\"State for the LangChain agent.\n\n    This is what flows through the agent graph.\n    \"\"\"\n\n    messages: list[Any]\n\n\n@tool\ndef current_datetime() -> str:\n    \"\"\"Get the current date and time.\n\n    Use this tool when you need to know the current date or time.\n    \"\"\"\n    return get_current_datetime()\n\n\nclass LangChainAssistant:\n    \"\"\"Assistant agent wrapper for conversational AI using LangChain.\n\n    Encapsulates agent creation and execution with tool support.\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name: str | None = None,\n        temperature: float | None = None,\n        system_prompt: str | None = None,\n    ):\n        self.model_name = model_name or settings.AI_MODEL\n        self.temperature = temperature or settings.AI_TEMPERATURE\n        self.system_prompt = system_prompt or DEFAULT_SYSTEM_PROMPT\n        self._agent = None\n        self._tools = [current_datetime]\n\n    def _create_agent(self):\n        \"\"\"Create and configure the LangChain agent.\"\"\"\n{%- if cookiecutter.use_openai %}\n        model = ChatOpenAI(\n            model=self.model_name,\n            temperature=self.temperature,\n            api_key=settings.OPENAI_API_KEY,\n        )\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\n        model = ChatAnthropic(\n            model=self.model_name,\n            temperature=self.temperature,\n            api_key=settings.ANTHROPIC_API_KEY,\n        )\n{%- endif %}\n\n        agent = create_agent(\n            model=model,\n            tools=self._tools,\n            system_prompt=self.system_prompt,\n        )\n\n        return agent\n\n    @property\n    def agent(self):\n        \"\"\"Get or create the agent instance.\"\"\"\n        if self._agent is None:\n            self._agent = self._create_agent()\n        return self._agent\n\n    @staticmethod\n    def _convert_history(\n        history\n        : list[dict[str, str]] | None\n    ) -> list[HumanMessage | AIMessage | SystemMessage]:\n        \"\"\"Convert conversation history to LangChain message format.\"\"\"\n        messages: list[HumanMessage | AIMessage | SystemMessage] = []\n\n        for msg in history or []:\n            if msg[\"role\"] == \"user\":\n                messages.append(HumanMessage(content=msg[\"content\"]))\n            elif msg[\"role\"] == \"assistant\":\n                messages.append(AIMessage(content=msg[\"content\"]))\n            elif msg[\"role\"] == \"system\":\n                messages.append(SystemMessage(content=msg[\"content\"]))\n\n        return messages\n\n    async def run(\n        self,\n        user_input: str,\n        history: list[dict[str, str]] | None = None,\n        context: AgentContext | None = None,\n    ) -> tuple[str, list[Any], AgentContext]:\n        \"\"\"Run agent and return the output along with tool call events.\n\n        Args:\n            user_input: User's message.\n            history: Conversation history as list of {\"role\": \"...\", \"content\": \"...\"}.\n            context: Optional runtime context with user info.\n\n        Returns:\n            Tuple of (output_text, tool_events, context).\n        \"\"\"\n        messages = self._convert_history(history)\n        messages.append(HumanMessage(content=user_input))\n\n        agent_context: AgentContext = context if context is not None else {}\n\n        logger.info(f\"Running agent with user input: {user_input[:100]}...\")\n\n        result = self.agent.invoke(\n            {\"messages\": messages},\n            config={\"configurable\": agent_context} if agent_context else None,\n        )\n\n        # Extract the final response\n        output = \"\"\n        tool_events: list[Any] = []\n\n        for message in result.get(\"messages\", []):\n            if hasattr(message, \"content\") and isinstance(message, AIMessage):\n                output = message.content\n            if hasattr(message, \"tool_calls\") and message.tool_calls:\n                tool_events.extend(message.tool_calls)\n\n        logger.info(f\"Agent run complete. Output length: {len(output)} chars\")\n\n        return output, tool_events, agent_context\n\n    async def stream(\n        self,\n        user_input: str,\n        history: list[dict[str, str]] | None = None,\n        context: AgentContext | None = None,\n    ):\n        \"\"\"Stream agent execution with token-level streaming.\n\n        Args:\n            user_input: User's message.\n            history: Conversation history.\n            context: Optional runtime context.\n\n        Yields:\n            Tuples of (stream_mode, data) for streaming responses.\n            - stream_mode=\"messages\": (token, metadata) for LLM tokens\n            - stream_mode=\"updates\": state updates after each step\n        \"\"\"\n        messages = self._convert_history(history)\n        messages.append(HumanMessage(content=user_input))\n\n        agent_context: AgentContext = context if context is not None else {}\n\n        async for event in self.agent.astream(\n            {\"messages\": messages},\n            stream_mode=[\"messages\", \"updates\"],\n            config={\"configurable\": agent_context} if agent_context else None,\n        ):\n            yield event\n\n\ndef get_agent() -> LangChainAssistant:\n    \"\"\"Factory function to create a LangChainAssistant.\n\n    Returns:\n        Configured LangChainAssistant instance.\n    \"\"\"\n    return LangChainAssistant()\n\n\nasync def run_agent(\n    user_input: str,\n    history: list[dict[str, str]],\n    context: AgentContext | None = None,\n) -> tuple[str, list[Any], AgentContext]:\n    \"\"\"Run agent and return the output along with tool call events.\n\n    This is a convenience function for backwards compatibility.\n\n    Args:\n        user_input: User's message.\n        history: Conversation history.\n        context: Optional runtime context.\n\n    Returns:\n        Tuple of (output_text, tool_events, context).\n    \"\"\"\n    agent = get_agent()\n    return await agent.run(user_input, history, context)\n{%- else %}\n\"\"\"LangChain Assistant agent - not configured.\"\"\"\n{%- endif %}\n","backend/app/pipelines/__init__.py":"\"\"\"Background processing pipelines.\n\nThis module contains ETL pipelines, data processing workflows,\nand batch operations that run as background tasks.\n\"\"\"\n\nfrom app.pipelines.base import BasePipeline, PipelineResult\n\n__all__ = [\"BasePipeline\", \"PipelineResult\"]\n","backend/app/pipelines/base.py":"\"\"\"Base pipeline classes.\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass, field\n\n\n@dataclass\nclass PipelineResult:\n    \"\"\"Result of a pipeline execution.\n\n    Attributes:\n        processed: Number of items successfully processed.\n        failed: Number of items that failed processing.\n        errors: List of error messages for failed items.\n        metadata: Additional metadata about the pipeline run.\n    \"\"\"\n\n    processed: int\n    failed: int = 0\n    errors: list[str] = field(default_factory=list)\n    metadata: dict = field(default_factory=dict)\n\n    @property\n    def success_rate(self) -> float:\n        \"\"\"Calculate success rate as a percentage.\"\"\"\n        total = self.processed + self.failed\n        if total == 0:\n            return 100.0\n        return (self.processed / total) * 100\n\n    @property\n    def has_errors(self) -> bool:\n        \"\"\"Check if any errors occurred.\"\"\"\n        return self.failed > 0 or len(self.errors) > 0\n\n\nclass BasePipeline(ABC):\n    \"\"\"Base class for all pipelines.\n\n    Pipelines are used for background processing tasks like:\n    - ETL operations\n    - Batch data processing\n    - Embedding generation\n    - Data synchronization\n\n    Subclasses must implement the `run` method.\n    \"\"\"\n\n    @abstractmethod\n    async def run(self) -> PipelineResult:\n        \"\"\"Execute the pipeline.\n\n        Returns:\n            PipelineResult with processing statistics.\n        \"\"\"\n        pass\n\n    async def validate(self) -> bool:\n        \"\"\"Validate pipeline configuration before running.\n\n        Override this method to add custom validation logic.\n\n        Returns:\n            True if validation passes, False otherwise.\n        \"\"\"\n        return True\n\n    async def cleanup(self) -> None:  # noqa: B027\n        \"\"\"Cleanup resources after pipeline execution.\n\n        Override this method to add custom cleanup logic.\n        Default implementation does nothing.\n        \"\"\"\n","backend/app/repositories/user.py":"{%- if cookiecutter.use_jwt and cookiecutter.use_postgresql %}\n\"\"\"User repository (PostgreSQL async).\n\nContains only database operations. Business logic (password hashing,\nvalidation) is handled by UserService in app/services/user.py.\n\"\"\"\n\nfrom uuid import UUID\n\nfrom sqlalchemy import select\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.db.models.user import User\n\n\nasync def get_by_id(db: AsyncSession, user_id: UUID) -> User | None:\n    \"\"\"Get user by ID.\"\"\"\n    return await db.get(User, user_id)\n\n\nasync def get_by_email(db: AsyncSession, email: str) -> User | None:\n    \"\"\"Get user by email.\"\"\"\n    result = await db.execute(select(User).where(User.email == email))\n    return result.scalar_one_or_none()\n\n\n{%- if cookiecutter.enable_oauth %}\n\n\nasync def get_by_oauth(db: AsyncSession, provider: str, oauth_id: str) -> User | None:\n    \"\"\"Get user by OAuth provider and ID.\"\"\"\n    result = await db.execute(\n        select(User).where(User.oauth_provider == provider, User.oauth_id == oauth_id)\n    )\n    return result.scalar_one_or_none()\n{%- endif %}\n\n\nasync def get_multi(\n    db: AsyncSession,\n    *,\n    skip: int = 0,\n    limit: int = 100,\n) -> list[User]:\n    \"\"\"Get multiple users with pagination.\"\"\"\n    result = await db.execute(select(User).offset(skip).limit(limit))\n    return list(result.scalars().all())\n\n\nasync def create(\n    db: AsyncSession,\n    *,\n    email: str,\n    hashed_password: str | None,\n    full_name: str | None = None,\n    is_active: bool = True,\n    is_superuser: bool = False,\n    role: str = \"user\",\n{%- if cookiecutter.enable_oauth %}\n    oauth_provider: str | None = None,\n    oauth_id: str | None = None,\n{%- endif %}\n) -> User:\n    \"\"\"Create a new user.\n\n    Note: Password should already be hashed by the service layer.\n    \"\"\"\n    user = User(\n        email=email,\n        hashed_password=hashed_password,\n        full_name=full_name,\n        is_active=is_active,\n        is_superuser=is_superuser,\n        role=role,\n{%- if cookiecutter.enable_oauth %}\n        oauth_provider=oauth_provider,\n        oauth_id=oauth_id,\n{%- endif %}\n    )\n    db.add(user)\n    await db.flush()\n    await db.refresh(user)\n    return user\n\n\nasync def update(\n    db: AsyncSession,\n    *,\n    db_user: User,\n    update_data: dict,\n) -> User:\n    \"\"\"Update a user.\n\n    Note: If password needs updating, it should already be hashed.\n    \"\"\"\n    for field, value in update_data.items():\n        setattr(db_user, field, value)\n\n    db.add(db_user)\n    await db.flush()\n    await db.refresh(db_user)\n    return db_user\n\n\nasync def delete(db: AsyncSession, user_id: UUID) -> User | None:\n    \"\"\"Delete a user.\"\"\"\n    user = await get_by_id(db, user_id)\n    if user:\n        await db.delete(user)\n        await db.flush()\n    return user\n\n\n{%- elif cookiecutter.use_jwt and cookiecutter.use_sqlite %}\n\"\"\"User repository (SQLite sync).\n\nContains only database operations. Business logic (password hashing,\nvalidation) is handled by UserService in app/services/user.py.\n\"\"\"\n\nfrom sqlalchemy import select\nfrom sqlalchemy.orm import Session\n\nfrom app.db.models.user import User\n\n\ndef get_by_id(db: Session, user_id: str) -> User | None:\n    \"\"\"Get user by ID.\"\"\"\n    return db.get(User, user_id)\n\n\ndef get_by_email(db: Session, email: str) -> User | None:\n    \"\"\"Get user by email.\"\"\"\n    result = db.execute(select(User).where(User.email == email))\n    return result.scalar_one_or_none()\n\n\n{%- if cookiecutter.enable_oauth %}\n\n\ndef get_by_oauth(db: Session, provider: str, oauth_id: str) -> User | None:\n    \"\"\"Get user by OAuth provider and ID.\"\"\"\n    result = db.execute(\n        select(User).where(User.oauth_provider == provider, User.oauth_id == oauth_id)\n    )\n    return result.scalar_one_or_none()\n{%- endif %}\n\n\ndef get_multi(\n    db: Session,\n    *,\n    skip: int = 0,\n    limit: int = 100,\n) -> list[User]:\n    \"\"\"Get multiple users with pagination.\"\"\"\n    result = db.execute(select(User).offset(skip).limit(limit))\n    return list(result.scalars().all())\n\n\ndef create(\n    db: Session,\n    *,\n    email: str,\n    hashed_password: str | None,\n    full_name: str | None = None,\n    is_active: bool = True,\n    is_superuser: bool = False,\n    role: str = \"user\",\n{%- if cookiecutter.enable_oauth %}\n    oauth_provider: str | None = None,\n    oauth_id: str | None = None,\n{%- endif %}\n) -> User:\n    \"\"\"Create a new user.\n\n    Note: Password should already be hashed by the service layer.\n    \"\"\"\n    user = User(\n        email=email,\n        hashed_password=hashed_password,\n        full_name=full_name,\n        is_active=is_active,\n        is_superuser=is_superuser,\n        role=role,\n{%- if cookiecutter.enable_oauth %}\n        oauth_provider=oauth_provider,\n        oauth_id=oauth_id,\n{%- endif %}\n    )\n    db.add(user)\n    db.flush()\n    db.refresh(user)\n    return user\n\n\ndef update(\n    db: Session,\n    *,\n    db_user: User,\n    update_data: dict,\n) -> User:\n    \"\"\"Update a user.\n\n    Note: If password needs updating, it should already be hashed.\n    \"\"\"\n    for field, value in update_data.items():\n        setattr(db_user, field, value)\n\n    db.add(db_user)\n    db.flush()\n    db.refresh(db_user)\n    return db_user\n\n\ndef delete(db: Session, user_id: str) -> User | None:\n    \"\"\"Delete a user.\"\"\"\n    user = get_by_id(db, user_id)\n    if user:\n        db.delete(user)\n        db.flush()\n    return user\n\n\n{%- elif cookiecutter.use_jwt and cookiecutter.use_mongodb %}\n\"\"\"User repository (MongoDB).\n\nContains only database operations. Business logic (password hashing,\nvalidation) is handled by UserService in app/services/user.py.\n\"\"\"\n\nfrom app.db.models.user import User\n\n\nasync def get_by_id(user_id: str) -> User | None:\n    \"\"\"Get user by ID.\"\"\"\n    return await User.get(user_id)\n\n\nasync def get_by_email(email: str) -> User | None:\n    \"\"\"Get user by email.\"\"\"\n    return await User.find_one(User.email == email)\n\n\n{%- if cookiecutter.enable_oauth %}\n\n\nasync def get_by_oauth(provider: str, oauth_id: str) -> User | None:\n    \"\"\"Get user by OAuth provider and ID.\"\"\"\n    return await User.find_one(User.oauth_provider == provider, User.oauth_id == oauth_id)\n{%- endif %}\n\n\nasync def get_multi(\n    *,\n    skip: int = 0,\n    limit: int = 100,\n) -> list[User]:\n    \"\"\"Get multiple users with pagination.\"\"\"\n    return await User.find_all().skip(skip).limit(limit).to_list()\n\n\nasync def create(\n    *,\n    email: str,\n    hashed_password: str | None,\n    full_name: str | None = None,\n    is_active: bool = True,\n    is_superuser: bool = False,\n    role: str = \"user\",\n{%- if cookiecutter.enable_oauth %}\n    oauth_provider: str | None = None,\n    oauth_id: str | None = None,\n{%- endif %}\n) -> User:\n    \"\"\"Create a new user.\n\n    Note: Password should already be hashed by the service layer.\n    \"\"\"\n    user = User(\n        email=email,\n        hashed_password=hashed_password,\n        full_name=full_name,\n        is_active=is_active,\n        is_superuser=is_superuser,\n        role=role,\n{%- if cookiecutter.enable_oauth %}\n        oauth_provider=oauth_provider,\n        oauth_id=oauth_id,\n{%- endif %}\n    )\n    await user.insert()\n    return user\n\n\nasync def update(\n    *,\n    db_user: User,\n    update_data: dict,\n) -> User:\n    \"\"\"Update a user.\n\n    Note: If password needs updating, it should already be hashed.\n    \"\"\"\n    for field, value in update_data.items():\n        setattr(db_user, field, value)\n\n    await db_user.save()\n    return db_user\n\n\nasync def delete(user_id: str) -> User | None:\n    \"\"\"Delete a user.\"\"\"\n    user = await get_by_id(user_id)\n    if user:\n        await user.delete()\n    return user\n\n\n{%- else %}\n\"\"\"User repository - not configured.\"\"\"\n{%- endif %}\n","backend/app/repositories/webhook.py":"{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\n{%- if cookiecutter.use_postgresql %}\n\"\"\"Webhook repository (PostgreSQL async).\"\"\"\n\nfrom uuid import UUID\n\nfrom sqlalchemy import func, select\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.db.models.webhook import Webhook, WebhookDelivery\nfrom app.schemas.webhook import WebhookUpdate\n\n\nasync def get_by_id(db: AsyncSession, webhook_id: UUID) -> Webhook | None:\n    \"\"\"Get webhook by ID.\"\"\"\n    return await db.get(Webhook, webhook_id)\n\n\nasync def get_list(\n    db: AsyncSession,\n    *,\n    user_id: UUID | None = None,\n    skip: int = 0,\n    limit: int = 50,\n) -> tuple[list[Webhook], int]:\n    \"\"\"Get list of webhooks with pagination.\"\"\"\n    query = select(Webhook)\n    if user_id:\n        query = query.where(Webhook.user_id == user_id)\n    query = query.order_by(Webhook.created_at.desc())\n\n    # Get total count\n    count_query = select(func.count()).select_from(query.subquery())\n    total = await db.scalar(count_query) or 0\n\n    # Get paginated results\n    query = query.offset(skip).limit(limit)\n    result = await db.execute(query)\n    return list(result.scalars().all()), total\n\n\nasync def get_by_event(db: AsyncSession, event_type: str) -> list[Webhook]:\n    \"\"\"Get all active webhooks subscribed to an event type.\"\"\"\n    result = await db.execute(\n        select(Webhook).where(\n            Webhook.is_active.is_(True),\n            Webhook.events.contains([event_type]),\n        )\n    )\n    return list(result.scalars().all())\n\n\nasync def create(\n    db: AsyncSession,\n    *,\n    name: str,\n    url: str,\n    secret: str,\n    events: list[str],\n    description: str | None = None,\n    user_id: UUID | None = None,\n) -> Webhook:\n    \"\"\"Create a new webhook.\"\"\"\n    webhook = Webhook(\n        name=name,\n        url=url,\n        secret=secret,\n        events=events,\n        description=description,\n{%- if cookiecutter.use_jwt %}\n        user_id=user_id,\n{%- endif %}\n    )\n    db.add(webhook)\n    await db.flush()\n    await db.refresh(webhook)\n    return webhook\n\n\nasync def update(\n    db: AsyncSession,\n    webhook: Webhook,\n    data: WebhookUpdate,\n) -> Webhook:\n    \"\"\"Update a webhook.\"\"\"\n    update_data = data.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(webhook, field, value)\n    db.add(webhook)\n    await db.flush()\n    await db.refresh(webhook)\n    return webhook\n\n\nasync def update_secret(db: AsyncSession, webhook: Webhook, new_secret: str) -> Webhook:\n    \"\"\"Update webhook secret.\"\"\"\n    webhook.secret = new_secret\n    db.add(webhook)\n    await db.flush()\n    await db.refresh(webhook)\n    return webhook\n\n\nasync def delete(db: AsyncSession, webhook: Webhook) -> None:\n    \"\"\"Delete a webhook.\"\"\"\n    await db.delete(webhook)\n    await db.flush()\n\n\nasync def get_deliveries(\n    db: AsyncSession,\n    webhook_id: UUID,\n    *,\n    skip: int = 0,\n    limit: int = 50,\n) -> tuple[list[WebhookDelivery], int]:\n    \"\"\"Get delivery history for a webhook.\"\"\"\n    query = (\n        select(WebhookDelivery)\n        .where(WebhookDelivery.webhook_id == webhook_id)\n        .order_by(WebhookDelivery.created_at.desc())\n    )\n\n    count_query = select(func.count()).select_from(query.subquery())\n    total = await db.scalar(count_query) or 0\n\n    query = query.offset(skip).limit(limit)\n    result = await db.execute(query)\n    return list(result.scalars().all()), total\n\n\n{%- elif cookiecutter.use_sqlite %}\n\"\"\"Webhook repository (SQLite sync).\"\"\"\n\nfrom sqlalchemy import func, select\nfrom sqlalchemy.orm import Session as DBSession\n\nfrom app.db.models.webhook import Webhook, WebhookDelivery\nfrom app.schemas.webhook import WebhookUpdate\n\n\ndef get_by_id(db: DBSession, webhook_id: str) -> Webhook | None:\n    \"\"\"Get webhook by ID.\"\"\"\n    return db.get(Webhook, webhook_id)\n\n\ndef get_list(\n    db: DBSession,\n    *,\n    user_id: str | None = None,\n    skip: int = 0,\n    limit: int = 50,\n) -> tuple[list[Webhook], int]:\n    \"\"\"Get list of webhooks with pagination.\"\"\"\n    query = select(Webhook)\n    if user_id:\n        query = query.where(Webhook.user_id == user_id)\n    query = query.order_by(Webhook.created_at.desc())\n\n    count_query = select(func.count()).select_from(query.subquery())\n    total = db.scalar(count_query) or 0\n\n    query = query.offset(skip).limit(limit)\n    result = db.execute(query)\n    return list(result.scalars().all()), total\n\n\ndef get_by_event(db: DBSession, event_type: str) -> list[Webhook]:\n    \"\"\"Get all active webhooks subscribed to an event type.\"\"\"\n    # For SQLite, we need to check if event is in the JSON array\n    result = db.execute(select(Webhook).where(Webhook.is_active.is_(True)))\n    webhooks = result.scalars().all()\n    return [w for w in webhooks if event_type in w.events]\n\n\ndef create(\n    db: DBSession,\n    *,\n    name: str,\n    url: str,\n    secret: str,\n    events: list[str],\n    description: str | None = None,\n    user_id: str | None = None,\n) -> Webhook:\n    \"\"\"Create a new webhook.\"\"\"\n    webhook = Webhook(\n        name=name,\n        url=url,\n        secret=secret,\n        description=description,\n{%- if cookiecutter.use_jwt %}\n        user_id=user_id,\n{%- endif %}\n    )\n    webhook.events = events  # Use the property setter\n    db.add(webhook)\n    db.flush()\n    db.refresh(webhook)\n    return webhook\n\n\ndef update(\n    db: DBSession,\n    webhook: Webhook,\n    data: WebhookUpdate,\n) -> Webhook:\n    \"\"\"Update a webhook.\"\"\"\n    update_data = data.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        if field == \"events\":\n            webhook.events = value  # Use property setter\n        else:\n            setattr(webhook, field, value)\n    db.add(webhook)\n    db.flush()\n    db.refresh(webhook)\n    return webhook\n\n\ndef update_secret(db: DBSession, webhook: Webhook, new_secret: str) -> Webhook:\n    \"\"\"Update webhook secret.\"\"\"\n    webhook.secret = new_secret\n    db.add(webhook)\n    db.flush()\n    db.refresh(webhook)\n    return webhook\n\n\ndef delete(db: DBSession, webhook: Webhook) -> None:\n    \"\"\"Delete a webhook.\"\"\"\n    db.delete(webhook)\n    db.flush()\n\n\ndef get_deliveries(\n    db: DBSession,\n    webhook_id: str,\n    *,\n    skip: int = 0,\n    limit: int = 50,\n) -> tuple[list[WebhookDelivery], int]:\n    \"\"\"Get delivery history for a webhook.\"\"\"\n    query = (\n        select(WebhookDelivery)\n        .where(WebhookDelivery.webhook_id == webhook_id)\n        .order_by(WebhookDelivery.created_at.desc())\n    )\n\n    count_query = select(func.count()).select_from(query.subquery())\n    total = db.scalar(count_query) or 0\n\n    query = query.offset(skip).limit(limit)\n    result = db.execute(query)\n    return list(result.scalars().all()), total\n\n\n{%- elif cookiecutter.use_mongodb %}\n\"\"\"Webhook repository (MongoDB).\"\"\"\n\nfrom app.db.models.webhook import Webhook, WebhookDelivery\nfrom app.schemas.webhook import WebhookUpdate\n\n\nasync def get_by_id(webhook_id: str) -> Webhook | None:\n    \"\"\"Get webhook by ID.\"\"\"\n    return await Webhook.get(webhook_id)\n\n\nasync def get_list(\n    *,\n    user_id: str | None = None,\n    skip: int = 0,\n    limit: int = 50,\n) -> tuple[list[Webhook], int]:\n    \"\"\"Get list of webhooks with pagination.\"\"\"\n    query = Webhook.find()\n    if user_id:\n        query = query.find(Webhook.user_id == user_id)\n\n    total = await query.count()\n    webhooks = await query.sort(-Webhook.created_at).skip(skip).limit(limit).to_list()\n    return webhooks, total\n\n\nasync def get_by_event(event_type: str) -> list[Webhook]:\n    \"\"\"Get all active webhooks subscribed to an event type.\"\"\"\n    return await Webhook.find(\n        Webhook.is_active == True,\n        Webhook.events == event_type,  # MongoDB $elemMatch\n    ).to_list()\n\n\nasync def create(\n    *,\n    name: str,\n    url: str,\n    secret: str,\n    events: list[str],\n    description: str | None = None,\n    user_id: str | None = None,\n) -> Webhook:\n    \"\"\"Create a new webhook.\"\"\"\n    webhook = Webhook(\n        name=name,\n        url=url,\n        secret=secret,\n        events=events,\n        description=description,\n{%- if cookiecutter.use_jwt %}\n        user_id=user_id,\n{%- endif %}\n    )\n    await webhook.insert()\n    return webhook\n\n\nasync def update(\n    webhook: Webhook,\n    data: WebhookUpdate,\n) -> Webhook:\n    \"\"\"Update a webhook.\"\"\"\n    update_data = data.model_dump(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(webhook, field, value)\n    await webhook.save()\n    return webhook\n\n\nasync def update_secret(webhook: Webhook, new_secret: str) -> Webhook:\n    \"\"\"Update webhook secret.\"\"\"\n    webhook.secret = new_secret\n    await webhook.save()\n    return webhook\n\n\nasync def delete(webhook: Webhook) -> None:\n    \"\"\"Delete a webhook.\"\"\"\n    await webhook.delete()\n\n\nasync def get_deliveries(\n    webhook_id: str,\n    *,\n    skip: int = 0,\n    limit: int = 50,\n) -> tuple[list[WebhookDelivery], int]:\n    \"\"\"Get delivery history for a webhook.\"\"\"\n    query = WebhookDelivery.find(WebhookDelivery.webhook_id == webhook_id)\n    total = await query.count()\n    deliveries = await query.sort(-WebhookDelivery.created_at).skip(skip).limit(limit).to_list()\n    return deliveries, total\n\n\n{%- endif %}\n{%- else %}\n\"\"\"Webhook repository - not configured.\"\"\"\n{%- endif %}\n","backend/app/repositories/conversation.py":"{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_postgresql %}\n\"\"\"Conversation repository (PostgreSQL async).\n\nContains database operations for Conversation, Message, and ToolCall entities.\n\"\"\"\n\nfrom datetime import datetime\nfrom uuid import UUID\n\nfrom sqlalchemy import func, select, update as sql_update\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom sqlalchemy.orm import selectinload\n\nfrom app.db.models.conversation import Conversation, Message, ToolCall\n\n\n# =============================================================================\n# Conversation Operations\n# =============================================================================\n\n\nasync def get_conversation_by_id(\n    db: AsyncSession,\n    conversation_id: UUID,\n    *,\n    include_messages: bool = False,\n) -> Conversation | None:\n    \"\"\"Get conversation by ID, optionally with messages.\"\"\"\n    if include_messages:\n        query = (\n            select(Conversation)\n            .options(selectinload(Conversation.messages).selectinload(Message.tool_calls))\n            .where(Conversation.id == conversation_id)\n        )\n        result = await db.execute(query)\n        return result.scalar_one_or_none()\n    return await db.get(Conversation, conversation_id)\n\n\nasync def get_conversations_by_user(\n    db: AsyncSession,\n{%- if cookiecutter.use_jwt %}\n    user_id: UUID | None = None,\n{%- endif %}\n    *,\n    skip: int = 0,\n    limit: int = 50,\n    include_archived: bool = False,\n) -> list[Conversation]:\n    \"\"\"Get conversations for a user with pagination.\"\"\"\n    query = select(Conversation)\n{%- if cookiecutter.use_jwt %}\n    if user_id:\n        query = query.where(Conversation.user_id == user_id)\n{%- endif %}\n    if not include_archived:\n        query = query.where(Conversation.is_archived == False)  # noqa: E712\n    query = query.order_by(Conversation.updated_at.desc()).offset(skip).limit(limit)\n    result = await db.execute(query)\n    return list(result.scalars().all())\n\n\nasync def count_conversations(\n    db: AsyncSession,\n{%- if cookiecutter.use_jwt %}\n    user_id: UUID | None = None,\n{%- endif %}\n    *,\n    include_archived: bool = False,\n) -> int:\n    \"\"\"Count conversations for a user.\"\"\"\n    query = select(func.count(Conversation.id))\n{%- if cookiecutter.use_jwt %}\n    if user_id:\n        query = query.where(Conversation.user_id == user_id)\n{%- endif %}\n    if not include_archived:\n        query = query.where(Conversation.is_archived == False)  # noqa: E712\n    result = await db.execute(query)\n    return result.scalar() or 0\n\n\nasync def create_conversation(\n    db: AsyncSession,\n    *,\n{%- if cookiecutter.use_jwt %}\n    user_id: UUID | None = None,\n{%- endif %}\n    title: str | None = None,\n) -> Conversation:\n    \"\"\"Create a new conversation.\"\"\"\n    conversation = Conversation(\n{%- if cookiecutter.use_jwt %}\n        user_id=user_id,\n{%- endif %}\n        title=title,\n    )\n    db.add(conversation)\n    await db.flush()\n    await db.refresh(conversation)\n    return conversation\n\n\nasync def update_conversation(\n    db: AsyncSession,\n    *,\n    db_conversation: Conversation,\n    update_data: dict,\n) -> Conversation:\n    \"\"\"Update a conversation.\"\"\"\n    for field, value in update_data.items():\n        setattr(db_conversation, field, value)\n\n    db.add(db_conversation)\n    await db.flush()\n    await db.refresh(db_conversation)\n    return db_conversation\n\n\nasync def archive_conversation(\n    db: AsyncSession,\n    conversation_id: UUID,\n) -> Conversation | None:\n    \"\"\"Archive a conversation.\"\"\"\n    conversation = await get_conversation_by_id(db, conversation_id)\n    if conversation:\n        conversation.is_archived = True\n        db.add(conversation)\n        await db.flush()\n        await db.refresh(conversation)\n    return conversation\n\n\nasync def delete_conversation(db: AsyncSession, conversation_id: UUID) -> bool:\n    \"\"\"Delete a conversation and all related messages/tool_calls (cascades).\"\"\"\n    conversation = await get_conversation_by_id(db, conversation_id)\n    if conversation:\n        await db.delete(conversation)\n        await db.flush()\n        return True\n    return False\n\n\n# =============================================================================\n# Message Operations\n# =============================================================================\n\n\nasync def get_message_by_id(db: AsyncSession, message_id: UUID) -> Message | None:\n    \"\"\"Get message by ID.\"\"\"\n    return await db.get(Message, message_id)\n\n\nasync def get_messages_by_conversation(\n    db: AsyncSession,\n    conversation_id: UUID,\n    *,\n    skip: int = 0,\n    limit: int = 100,\n    include_tool_calls: bool = False,\n) -> list[Message]:\n    \"\"\"Get messages for a conversation with pagination.\"\"\"\n    query = select(Message).where(Message.conversation_id == conversation_id)\n    if include_tool_calls:\n        query = query.options(selectinload(Message.tool_calls))\n    query = query.order_by(Message.created_at.asc()).offset(skip).limit(limit)\n    result = await db.execute(query)\n    return list(result.scalars().all())\n\n\nasync def count_messages(db: AsyncSession, conversation_id: UUID) -> int:\n    \"\"\"Count messages in a conversation.\"\"\"\n    query = select(func.count(Message.id)).where(Message.conversation_id == conversation_id)\n    result = await db.execute(query)\n    return result.scalar() or 0\n\n\nasync def create_message(\n    db: AsyncSession,\n    *,\n    conversation_id: UUID,\n    role: str,\n    content: str,\n    model_name: str | None = None,\n    tokens_used: int | None = None,\n) -> Message:\n    \"\"\"Create a new message.\"\"\"\n    message = Message(\n        conversation_id=conversation_id,\n        role=role,\n        content=content,\n        model_name=model_name,\n        tokens_used=tokens_used,\n    )\n    db.add(message)\n    await db.flush()\n    await db.refresh(message)\n\n    # Update conversation's updated_at timestamp\n    await db.execute(\n        sql_update(Conversation)\n        .where(Conversation.id == conversation_id)\n        .values(updated_at=message.created_at)\n    )\n\n    return message\n\n\nasync def delete_message(db: AsyncSession, message_id: UUID) -> bool:\n    \"\"\"Delete a message.\"\"\"\n    message = await get_message_by_id(db, message_id)\n    if message:\n        await db.delete(message)\n        await db.flush()\n        return True\n    return False\n\n\n# =============================================================================\n# ToolCall Operations\n# =============================================================================\n\n\nasync def get_tool_call_by_id(db: AsyncSession, tool_call_id: UUID) -> ToolCall | None:\n    \"\"\"Get tool call by ID.\"\"\"\n    return await db.get(ToolCall, tool_call_id)\n\n\nasync def get_tool_calls_by_message(\n    db: AsyncSession,\n    message_id: UUID,\n) -> list[ToolCall]:\n    \"\"\"Get tool calls for a message.\"\"\"\n    query = (\n        select(ToolCall)\n        .where(ToolCall.message_id == message_id)\n        .order_by(ToolCall.started_at.asc())\n    )\n    result = await db.execute(query)\n    return list(result.scalars().all())\n\n\nasync def create_tool_call(\n    db: AsyncSession,\n    *,\n    message_id: UUID,\n    tool_call_id: str,\n    tool_name: str,\n    args: dict,\n    started_at: datetime,\n) -> ToolCall:\n    \"\"\"Create a new tool call record.\"\"\"\n    tool_call = ToolCall(\n        message_id=message_id,\n        tool_call_id=tool_call_id,\n        tool_name=tool_name,\n        args=args,\n        started_at=started_at,\n        status=\"running\",\n    )\n    db.add(tool_call)\n    await db.flush()\n    await db.refresh(tool_call)\n    return tool_call\n\n\nasync def complete_tool_call(\n    db: AsyncSession,\n    *,\n    db_tool_call: ToolCall,\n    result: str,\n    completed_at: datetime,\n    success: bool = True,\n) -> ToolCall:\n    \"\"\"Mark a tool call as completed.\"\"\"\n    db_tool_call.result = result\n    db_tool_call.completed_at = completed_at\n    db_tool_call.status = \"completed\" if success else \"failed\"\n\n    # Calculate duration\n    if db_tool_call.started_at:\n        delta = completed_at - db_tool_call.started_at\n        db_tool_call.duration_ms = int(delta.total_seconds() * 1000)\n\n    db.add(db_tool_call)\n    await db.flush()\n    await db.refresh(db_tool_call)\n    return db_tool_call\n\n\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_sqlite %}\n\"\"\"Conversation repository (SQLite sync).\n\nContains database operations for Conversation, Message, and ToolCall entities.\n\"\"\"\n\nfrom datetime import datetime\n\nfrom sqlalchemy import func, select, update as sql_update\nfrom sqlalchemy.orm import Session, selectinload\n\nfrom app.db.models.conversation import Conversation, Message, ToolCall\n\n\n# =============================================================================\n# Conversation Operations\n# =============================================================================\n\n\ndef get_conversation_by_id(\n    db: Session,\n    conversation_id: str,\n    *,\n    include_messages: bool = False,\n) -> Conversation | None:\n    \"\"\"Get conversation by ID, optionally with messages.\"\"\"\n    if include_messages:\n        query = (\n            select(Conversation)\n            .options(selectinload(Conversation.messages).selectinload(Message.tool_calls))\n            .where(Conversation.id == conversation_id)\n        )\n        result = db.execute(query)\n        return result.scalar_one_or_none()\n    return db.get(Conversation, conversation_id)\n\n\ndef get_conversations_by_user(\n    db: Session,\n{%- if cookiecutter.use_jwt %}\n    user_id: str | None = None,\n{%- endif %}\n    *,\n    skip: int = 0,\n    limit: int = 50,\n    include_archived: bool = False,\n) -> list[Conversation]:\n    \"\"\"Get conversations for a user with pagination.\"\"\"\n    query = select(Conversation)\n{%- if cookiecutter.use_jwt %}\n    if user_id:\n        query = query.where(Conversation.user_id == user_id)\n{%- endif %}\n    if not include_archived:\n        query = query.where(Conversation.is_archived == False)  # noqa: E712\n    query = query.order_by(Conversation.updated_at.desc()).offset(skip).limit(limit)\n    result = db.execute(query)\n    return list(result.scalars().all())\n\n\ndef count_conversations(\n    db: Session,\n{%- if cookiecutter.use_jwt %}\n    user_id: str | None = None,\n{%- endif %}\n    *,\n    include_archived: bool = False,\n) -> int:\n    \"\"\"Count conversations for a user.\"\"\"\n    query = select(func.count(Conversation.id))\n{%- if cookiecutter.use_jwt %}\n    if user_id:\n        query = query.where(Conversation.user_id == user_id)\n{%- endif %}\n    if not include_archived:\n        query = query.where(Conversation.is_archived == False)  # noqa: E712\n    result = db.execute(query)\n    return result.scalar() or 0\n\n\ndef create_conversation(\n    db: Session,\n    *,\n{%- if cookiecutter.use_jwt %}\n    user_id: str | None = None,\n{%- endif %}\n    title: str | None = None,\n) -> Conversation:\n    \"\"\"Create a new conversation.\"\"\"\n    conversation = Conversation(\n{%- if cookiecutter.use_jwt %}\n        user_id=user_id,\n{%- endif %}\n        title=title,\n    )\n    db.add(conversation)\n    db.flush()\n    db.refresh(conversation)\n    return conversation\n\n\ndef update_conversation(\n    db: Session,\n    *,\n    db_conversation: Conversation,\n    update_data: dict,\n) -> Conversation:\n    \"\"\"Update a conversation.\"\"\"\n    for field, value in update_data.items():\n        setattr(db_conversation, field, value)\n\n    db.add(db_conversation)\n    db.flush()\n    db.refresh(db_conversation)\n    return db_conversation\n\n\ndef archive_conversation(\n    db: Session,\n    conversation_id: str,\n) -> Conversation | None:\n    \"\"\"Archive a conversation.\"\"\"\n    conversation = get_conversation_by_id(db, conversation_id)\n    if conversation:\n        conversation.is_archived = True\n        db.add(conversation)\n        db.flush()\n        db.refresh(conversation)\n    return conversation\n\n\ndef delete_conversation(db: Session, conversation_id: str) -> bool:\n    \"\"\"Delete a conversation and all related messages/tool_calls (cascades).\"\"\"\n    conversation = get_conversation_by_id(db, conversation_id)\n    if conversation:\n        db.delete(conversation)\n        db.flush()\n        return True\n    return False\n\n\n# =============================================================================\n# Message Operations\n# =============================================================================\n\n\ndef get_message_by_id(db: Session, message_id: str) -> Message | None:\n    \"\"\"Get message by ID.\"\"\"\n    return db.get(Message, message_id)\n\n\ndef get_messages_by_conversation(\n    db: Session,\n    conversation_id: str,\n    *,\n    skip: int = 0,\n    limit: int = 100,\n    include_tool_calls: bool = False,\n) -> list[Message]:\n    \"\"\"Get messages for a conversation with pagination.\"\"\"\n    query = select(Message).where(Message.conversation_id == conversation_id)\n    if include_tool_calls:\n        query = query.options(selectinload(Message.tool_calls))\n    query = query.order_by(Message.created_at.asc()).offset(skip).limit(limit)\n    result = db.execute(query)\n    return list(result.scalars().all())\n\n\ndef count_messages(db: Session, conversation_id: str) -> int:\n    \"\"\"Count messages in a conversation.\"\"\"\n    query = select(func.count(Message.id)).where(Message.conversation_id == conversation_id)\n    result = db.execute(query)\n    return result.scalar() or 0\n\n\ndef create_message(\n    db: Session,\n    *,\n    conversation_id: str,\n    role: str,\n    content: str,\n    model_name: str | None = None,\n    tokens_used: int | None = None,\n) -> Message:\n    \"\"\"Create a new message.\"\"\"\n    message = Message(\n        conversation_id=conversation_id,\n        role=role,\n        content=content,\n        model_name=model_name,\n        tokens_used=tokens_used,\n    )\n    db.add(message)\n    db.flush()\n    db.refresh(message)\n\n    # Update conversation's updated_at timestamp\n    db.execute(\n        sql_update(Conversation)\n        .where(Conversation.id == conversation_id)\n        .values(updated_at=message.created_at)\n    )\n\n    return message\n\n\ndef delete_message(db: Session, message_id: str) -> bool:\n    \"\"\"Delete a message.\"\"\"\n    message = get_message_by_id(db, message_id)\n    if message:\n        db.delete(message)\n        db.flush()\n        return True\n    return False\n\n\n# =============================================================================\n# ToolCall Operations\n# =============================================================================\n\n\ndef get_tool_call_by_id(db: Session, tool_call_id: str) -> ToolCall | None:\n    \"\"\"Get tool call by ID.\"\"\"\n    return db.get(ToolCall, tool_call_id)\n\n\ndef get_tool_calls_by_message(\n    db: Session,\n    message_id: str,\n) -> list[ToolCall]:\n    \"\"\"Get tool calls for a message.\"\"\"\n    query = (\n        select(ToolCall)\n        .where(ToolCall.message_id == message_id)\n        .order_by(ToolCall.started_at.asc())\n    )\n    result = db.execute(query)\n    return list(result.scalars().all())\n\n\ndef create_tool_call(\n    db: Session,\n    *,\n    message_id: str,\n    tool_call_id: str,\n    tool_name: str,\n    args: dict,\n    started_at: datetime,\n) -> ToolCall:\n    \"\"\"Create a new tool call record.\"\"\"\n    import json\n\n    tool_call = ToolCall(\n        message_id=message_id,\n        tool_call_id=tool_call_id,\n        tool_name=tool_name,\n        args=json.dumps(args),  # SQLite stores as JSON string\n        started_at=started_at,\n        status=\"running\",\n    )\n    db.add(tool_call)\n    db.flush()\n    db.refresh(tool_call)\n    return tool_call\n\n\ndef complete_tool_call(\n    db: Session,\n    *,\n    db_tool_call: ToolCall,\n    result: str,\n    completed_at: datetime,\n    success: bool = True,\n) -> ToolCall:\n    \"\"\"Mark a tool call as completed.\"\"\"\n    db_tool_call.result = result\n    db_tool_call.completed_at = completed_at\n    db_tool_call.status = \"completed\" if success else \"failed\"\n\n    # Calculate duration\n    if db_tool_call.started_at:\n        delta = completed_at - db_tool_call.started_at\n        db_tool_call.duration_ms = int(delta.total_seconds() * 1000)\n\n    db.add(db_tool_call)\n    db.flush()\n    db.refresh(db_tool_call)\n    return db_tool_call\n\n\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n\"\"\"Conversation repository (MongoDB).\n\nContains database operations for Conversation, Message, and ToolCall entities.\n\"\"\"\n\nfrom datetime import UTC, datetime\n\nfrom app.db.models.conversation import Conversation, Message, ToolCall\n\n\n# =============================================================================\n# Conversation Operations\n# =============================================================================\n\n\nasync def get_conversation_by_id(\n    conversation_id: str,\n    *,\n    include_messages: bool = False,\n) -> Conversation | None:\n    \"\"\"Get conversation by ID.\"\"\"\n    conversation = await Conversation.get(conversation_id)\n    # Note: MongoDB doesn't auto-load related documents; handle in service layer\n    return conversation\n\n\nasync def get_conversations_by_user(\n{%- if cookiecutter.use_jwt %}\n    user_id: str | None = None,\n{%- endif %}\n    *,\n    skip: int = 0,\n    limit: int = 50,\n    include_archived: bool = False,\n) -> list[Conversation]:\n    \"\"\"Get conversations for a user with pagination.\"\"\"\n    query_filter = {}\n{%- if cookiecutter.use_jwt %}\n    if user_id:\n        query_filter[\"user_id\"] = user_id\n{%- endif %}\n    if not include_archived:\n        query_filter[\"is_archived\"] = False\n\n    return await Conversation.find(query_filter).sort(\"-created_at\").skip(skip).limit(limit).to_list()\n\n\nasync def count_conversations(\n{%- if cookiecutter.use_jwt %}\n    user_id: str | None = None,\n{%- endif %}\n    *,\n    include_archived: bool = False,\n) -> int:\n    \"\"\"Count conversations for a user.\"\"\"\n    query_filter = {}\n{%- if cookiecutter.use_jwt %}\n    if user_id:\n        query_filter[\"user_id\"] = user_id\n{%- endif %}\n    if not include_archived:\n        query_filter[\"is_archived\"] = False\n\n    return await Conversation.find(query_filter).count()\n\n\nasync def create_conversation(\n    *,\n{%- if cookiecutter.use_jwt %}\n    user_id: str | None = None,\n{%- endif %}\n    title: str | None = None,\n) -> Conversation:\n    \"\"\"Create a new conversation.\"\"\"\n    conversation = Conversation(\n{%- if cookiecutter.use_jwt %}\n        user_id=user_id,\n{%- endif %}\n        title=title,\n    )\n    await conversation.insert()\n    return conversation\n\n\nasync def update_conversation(\n    *,\n    db_conversation: Conversation,\n    update_data: dict,\n) -> Conversation:\n    \"\"\"Update a conversation.\"\"\"\n    for field, value in update_data.items():\n        setattr(db_conversation, field, value)\n    db_conversation.updated_at = datetime.now(UTC)\n    await db_conversation.save()\n    return db_conversation\n\n\nasync def archive_conversation(\n    conversation_id: str,\n) -> Conversation | None:\n    \"\"\"Archive a conversation.\"\"\"\n    conversation = await get_conversation_by_id(conversation_id)\n    if conversation:\n        conversation.is_archived = True\n        conversation.updated_at = datetime.now(UTC)\n        await conversation.save()\n    return conversation\n\n\nasync def delete_conversation(conversation_id: str) -> bool:\n    \"\"\"Delete a conversation and all related messages/tool_calls.\"\"\"\n    conversation = await get_conversation_by_id(conversation_id)\n    if conversation:\n        # Delete related messages and tool calls\n        messages = await get_messages_by_conversation(str(conversation.id))\n        for message in messages:\n            await ToolCall.find(ToolCall.message_id == str(message.id)).delete()\n        await Message.find(Message.conversation_id == str(conversation.id)).delete()\n        await conversation.delete()\n        return True\n    return False\n\n\n# =============================================================================\n# Message Operations\n# =============================================================================\n\n\nasync def get_message_by_id(message_id: str) -> Message | None:\n    \"\"\"Get message by ID.\"\"\"\n    return await Message.get(message_id)\n\n\nasync def get_messages_by_conversation(\n    conversation_id: str,\n    *,\n    skip: int = 0,\n    limit: int = 100,\n) -> list[Message]:\n    \"\"\"Get messages for a conversation with pagination.\"\"\"\n    return await (\n        Message.find(Message.conversation_id == conversation_id)\n        .sort(\"created_at\")\n        .skip(skip)\n        .limit(limit)\n        .to_list()\n    )\n\n\nasync def count_messages(conversation_id: str) -> int:\n    \"\"\"Count messages in a conversation.\"\"\"\n    return await Message.find(Message.conversation_id == conversation_id).count()\n\n\nasync def create_message(\n    *,\n    conversation_id: str,\n    role: str,\n    content: str,\n    model_name: str | None = None,\n    tokens_used: int | None = None,\n) -> Message:\n    \"\"\"Create a new message.\"\"\"\n    message = Message(\n        conversation_id=conversation_id,\n        role=role,\n        content=content,\n        model_name=model_name,\n        tokens_used=tokens_used,\n    )\n    await message.insert()\n\n    # Update conversation's updated_at timestamp\n    conversation = await get_conversation_by_id(conversation_id)\n    if conversation:\n        conversation.updated_at = datetime.now(UTC)\n        await conversation.save()\n\n    return message\n\n\nasync def delete_message(message_id: str) -> bool:\n    \"\"\"Delete a message and its tool calls.\"\"\"\n    message = await get_message_by_id(message_id)\n    if message:\n        await ToolCall.find(ToolCall.message_id == str(message.id)).delete()\n        await message.delete()\n        return True\n    return False\n\n\n# =============================================================================\n# ToolCall Operations\n# =============================================================================\n\n\nasync def get_tool_call_by_id(tool_call_id: str) -> ToolCall | None:\n    \"\"\"Get tool call by ID.\"\"\"\n    return await ToolCall.get(tool_call_id)\n\n\nasync def get_tool_calls_by_message(\n    message_id: str,\n) -> list[ToolCall]:\n    \"\"\"Get tool calls for a message.\"\"\"\n    return await (\n        ToolCall.find(ToolCall.message_id == message_id)\n        .sort(\"started_at\")\n        .to_list()\n    )\n\n\nasync def create_tool_call(\n    *,\n    message_id: str,\n    tool_call_id: str,\n    tool_name: str,\n    args: dict,\n    started_at: datetime,\n) -> ToolCall:\n    \"\"\"Create a new tool call record.\"\"\"\n    tool_call = ToolCall(\n        message_id=message_id,\n        tool_call_id=tool_call_id,\n        tool_name=tool_name,\n        args=args,\n        started_at=started_at,\n        status=\"running\",\n    )\n    await tool_call.insert()\n    return tool_call\n\n\nasync def complete_tool_call(\n    *,\n    db_tool_call: ToolCall,\n    result: str,\n    completed_at: datetime,\n    success: bool = True,\n) -> ToolCall:\n    \"\"\"Mark a tool call as completed.\"\"\"\n    db_tool_call.result = result\n    db_tool_call.completed_at = completed_at\n    db_tool_call.status = \"completed\" if success else \"failed\"\n\n    # Calculate duration\n    if db_tool_call.started_at:\n        delta = completed_at - db_tool_call.started_at\n        db_tool_call.duration_ms = int(delta.total_seconds() * 1000)\n\n    await db_tool_call.save()\n    return db_tool_call\n\n\n{%- else %}\n\"\"\"Conversation repository - not configured.\"\"\"\n{%- endif %}\n","backend/app/repositories/session.py":"{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\n{%- if cookiecutter.use_postgresql %}\n\"\"\"Session repository (PostgreSQL async).\"\"\"\n\nfrom datetime import UTC, datetime\nfrom uuid import UUID\n\nfrom sqlalchemy import select, update\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.db.models.session import Session\n\n\nasync def get_by_id(db: AsyncSession, session_id: UUID) -> Session | None:\n    \"\"\"Get session by ID.\"\"\"\n    return await db.get(Session, session_id)\n\n\nasync def get_by_refresh_token_hash(db: AsyncSession, token_hash: str) -> Session | None:\n    \"\"\"Get session by refresh token hash.\"\"\"\n    result = await db.execute(\n        select(Session).where(\n            Session.refresh_token_hash == token_hash,\n            Session.is_active.is_(True),\n        )\n    )\n    return result.scalar_one_or_none()\n\n\nasync def get_user_sessions(\n    db: AsyncSession,\n    user_id: UUID,\n    *,\n    active_only: bool = True,\n) -> list[Session]:\n    \"\"\"Get all sessions for a user.\"\"\"\n    query = select(Session).where(Session.user_id == user_id)\n    if active_only:\n        query = query.where(Session.is_active.is_(True))\n    query = query.order_by(Session.last_used_at.desc())\n    result = await db.execute(query)\n    return list(result.scalars().all())\n\n\nasync def create(\n    db: AsyncSession,\n    *,\n    user_id: UUID,\n    refresh_token_hash: str,\n    expires_at: datetime,\n    device_name: str | None = None,\n    device_type: str | None = None,\n    ip_address: str | None = None,\n    user_agent: str | None = None,\n) -> Session:\n    \"\"\"Create a new session.\"\"\"\n    session = Session(\n        user_id=user_id,\n        refresh_token_hash=refresh_token_hash,\n        expires_at=expires_at,\n        device_name=device_name,\n        device_type=device_type,\n        ip_address=ip_address,\n        user_agent=user_agent,\n    )\n    db.add(session)\n    await db.flush()\n    await db.refresh(session)\n    return session\n\n\nasync def update_last_used(db: AsyncSession, session_id: UUID) -> None:\n    \"\"\"Update session last used timestamp.\"\"\"\n    await db.execute(\n        update(Session)\n        .where(Session.id == session_id)\n        .values(last_used_at=datetime.now(UTC))\n    )\n    await db.flush()\n\n\nasync def deactivate(db: AsyncSession, session_id: UUID) -> Session | None:\n    \"\"\"Deactivate a session (logout).\"\"\"\n    session = await get_by_id(db, session_id)\n    if session:\n        session.is_active = False\n        db.add(session)\n        await db.flush()\n    return session\n\n\nasync def deactivate_all_user_sessions(db: AsyncSession, user_id: UUID) -> int:\n    \"\"\"Deactivate all sessions for a user. Returns count of deactivated sessions.\"\"\"\n    result = await db.execute(\n        update(Session)\n        .where(Session.user_id == user_id, Session.is_active.is_(True))\n        .values(is_active=False)\n    )\n    await db.flush()\n    return result.rowcount\n\n\nasync def deactivate_by_refresh_token_hash(db: AsyncSession, token_hash: str) -> Session | None:\n    \"\"\"Deactivate session by refresh token hash.\"\"\"\n    session = await get_by_refresh_token_hash(db, token_hash)\n    if session:\n        session.is_active = False\n        db.add(session)\n        await db.flush()\n    return session\n\n\n{%- elif cookiecutter.use_sqlite %}\n\"\"\"Session repository (SQLite sync).\"\"\"\n\nfrom datetime import UTC, datetime\n\nfrom sqlalchemy import select, update\nfrom sqlalchemy.orm import Session as DBSession\n\nfrom app.db.models.session import Session\n\n\ndef get_by_id(db: DBSession, session_id: str) -> Session | None:\n    \"\"\"Get session by ID.\"\"\"\n    return db.get(Session, session_id)\n\n\ndef get_by_refresh_token_hash(db: DBSession, token_hash: str) -> Session | None:\n    \"\"\"Get session by refresh token hash.\"\"\"\n    result = db.execute(\n        select(Session).where(\n            Session.refresh_token_hash == token_hash,\n            Session.is_active.is_(True),\n        )\n    )\n    return result.scalar_one_or_none()\n\n\ndef get_user_sessions(\n    db: DBSession,\n    user_id: str,\n    *,\n    active_only: bool = True,\n) -> list[Session]:\n    \"\"\"Get all sessions for a user.\"\"\"\n    query = select(Session).where(Session.user_id == user_id)\n    if active_only:\n        query = query.where(Session.is_active.is_(True))\n    query = query.order_by(Session.last_used_at.desc())\n    result = db.execute(query)\n    return list(result.scalars().all())\n\n\ndef create(\n    db: DBSession,\n    *,\n    user_id: str,\n    refresh_token_hash: str,\n    expires_at: datetime,\n    device_name: str | None = None,\n    device_type: str | None = None,\n    ip_address: str | None = None,\n    user_agent: str | None = None,\n) -> Session:\n    \"\"\"Create a new session.\"\"\"\n    session = Session(\n        user_id=user_id,\n        refresh_token_hash=refresh_token_hash,\n        expires_at=expires_at,\n        device_name=device_name,\n        device_type=device_type,\n        ip_address=ip_address,\n        user_agent=user_agent,\n    )\n    db.add(session)\n    db.flush()\n    db.refresh(session)\n    return session\n\n\ndef update_last_used(db: DBSession, session_id: str) -> None:\n    \"\"\"Update session last used timestamp.\"\"\"\n    db.execute(\n        update(Session)\n        .where(Session.id == session_id)\n        .values(last_used_at=datetime.now(UTC))\n    )\n    db.flush()\n\n\ndef deactivate(db: DBSession, session_id: str) -> Session | None:\n    \"\"\"Deactivate a session (logout).\"\"\"\n    session = get_by_id(db, session_id)\n    if session:\n        session.is_active = False\n        db.add(session)\n        db.flush()\n    return session\n\n\ndef deactivate_all_user_sessions(db: DBSession, user_id: str) -> int:\n    \"\"\"Deactivate all sessions for a user. Returns count of deactivated sessions.\"\"\"\n    result = db.execute(\n        update(Session)\n        .where(Session.user_id == user_id, Session.is_active.is_(True))\n        .values(is_active=False)\n    )\n    db.flush()\n    return result.rowcount\n\n\ndef deactivate_by_refresh_token_hash(db: DBSession, token_hash: str) -> Session | None:\n    \"\"\"Deactivate session by refresh token hash.\"\"\"\n    session = get_by_refresh_token_hash(db, token_hash)\n    if session:\n        session.is_active = False\n        db.add(session)\n        db.flush()\n    return session\n\n\n{%- elif cookiecutter.use_mongodb %}\n\"\"\"Session repository (MongoDB).\"\"\"\n\nfrom datetime import UTC, datetime\n\nfrom app.db.models.session import Session\n\n\nasync def get_by_id(session_id: str) -> Session | None:\n    \"\"\"Get session by ID.\"\"\"\n    return await Session.get(session_id)\n\n\nasync def get_by_refresh_token_hash(token_hash: str) -> Session | None:\n    \"\"\"Get session by refresh token hash.\"\"\"\n    return await Session.find_one(\n        Session.refresh_token_hash == token_hash,\n        Session.is_active == True,\n    )\n\n\nasync def get_user_sessions(\n    user_id: str,\n    *,\n    active_only: bool = True,\n) -> list[Session]:\n    \"\"\"Get all sessions for a user.\"\"\"\n    query = Session.find(Session.user_id == user_id)\n    if active_only:\n        query = query.find(Session.is_active == True)\n    return await query.sort(-Session.last_used_at).to_list()\n\n\nasync def create(\n    *,\n    user_id: str,\n    refresh_token_hash: str,\n    expires_at: datetime,\n    device_name: str | None = None,\n    device_type: str | None = None,\n    ip_address: str | None = None,\n    user_agent: str | None = None,\n) -> Session:\n    \"\"\"Create a new session.\"\"\"\n    session = Session(\n        user_id=user_id,\n        refresh_token_hash=refresh_token_hash,\n        expires_at=expires_at,\n        device_name=device_name,\n        device_type=device_type,\n        ip_address=ip_address,\n        user_agent=user_agent,\n    )\n    await session.insert()\n    return session\n\n\nasync def update_last_used(session_id: str) -> None:\n    \"\"\"Update session last used timestamp.\"\"\"\n    session = await get_by_id(session_id)\n    if session:\n        session.last_used_at = datetime.now(UTC)\n        await session.save()\n\n\nasync def deactivate(session_id: str) -> Session | None:\n    \"\"\"Deactivate a session (logout).\"\"\"\n    session = await get_by_id(session_id)\n    if session:\n        session.is_active = False\n        await session.save()\n    return session\n\n\nasync def deactivate_all_user_sessions(user_id: str) -> int:\n    \"\"\"Deactivate all sessions for a user. Returns count of deactivated sessions.\"\"\"\n    result = await Session.find(\n        Session.user_id == user_id,\n        Session.is_active == True,\n    ).update({\"$set\": {\"is_active\": False}})\n    return result.modified_count if result else 0\n\n\nasync def deactivate_by_refresh_token_hash(token_hash: str) -> Session | None:\n    \"\"\"Deactivate session by refresh token hash.\"\"\"\n    session = await get_by_refresh_token_hash(token_hash)\n    if session:\n        session.is_active = False\n        await session.save()\n    return session\n\n\n{%- endif %}\n{%- else %}\n\"\"\"Session repository - not configured.\"\"\"\n{%- endif %}\n","backend/app/repositories/__init__.py":"\"\"\"Repository layer for database operations.\"\"\"\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite or cookiecutter.use_jwt or cookiecutter.include_example_crud or cookiecutter.enable_conversation_persistence or cookiecutter.enable_webhooks %}\n# ruff: noqa: I001, RUF022 - Imports structured for Jinja2 template conditionals\n{%- endif %}\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\nfrom app.repositories.base import BaseRepository\n{%- endif %}\n{%- if cookiecutter.use_jwt %}\n\nfrom app.repositories import user as user_repo\n{%- endif %}\n{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\n\nfrom app.repositories import session as session_repo\n{%- endif %}\n{%- if cookiecutter.include_example_crud and cookiecutter.use_database %}\n\nfrom app.repositories import item as item_repo\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n\nfrom app.repositories import conversation as conversation_repo\n{%- endif %}\n{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\n\nfrom app.repositories import webhook as webhook_repo\n{%- endif %}\n\n__all__ = [\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n    \"BaseRepository\",\n{%- endif %}\n{%- if cookiecutter.use_jwt %}\n    \"user_repo\",\n{%- endif %}\n{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\n    \"session_repo\",\n{%- endif %}\n{%- if cookiecutter.include_example_crud and cookiecutter.use_database %}\n    \"item_repo\",\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n    \"conversation_repo\",\n{%- endif %}\n{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\n    \"webhook_repo\",\n{%- endif %}\n]\n","backend/app/repositories/base.py":"{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\"\"\"Base repository with generic CRUD operations.\"\"\"\n\nfrom typing import Any, Generic, TypeVar\n\nfrom pydantic import BaseModel\nfrom sqlalchemy import select\n{%- if cookiecutter.use_postgresql %}\nfrom sqlalchemy.ext.asyncio import AsyncSession\n{%- else %}\nfrom sqlalchemy.orm import Session\n{%- endif %}\n\n{%- if cookiecutter.use_sqlmodel %}\nfrom sqlmodel import SQLModel\n\nModelType = TypeVar(\"ModelType\", bound=SQLModel)\n{%- else %}\nfrom app.db.base import Base\n\nModelType = TypeVar(\"ModelType\", bound=Base)\n{%- endif %}\nCreateSchemaType = TypeVar(\"CreateSchemaType\", bound=BaseModel)\nUpdateSchemaType = TypeVar(\"UpdateSchemaType\", bound=BaseModel)\n\n\nclass BaseRepository(Generic[ModelType, CreateSchemaType, UpdateSchemaType]):\n    \"\"\"Base class for repository operations.\n\n    Provides generic CRUD operations for SQLAlchemy models.\n    Subclasses should specify the model type via the model attribute.\n    \"\"\"\n\n    def __init__(self, model: type[ModelType]):\n        self.model = model\n\n{%- if cookiecutter.use_postgresql %}\n\n    async def get(self, db: AsyncSession, id: Any) -> ModelType | None:\n        \"\"\"Get a single record by ID.\"\"\"\n        return await db.get(self.model, id)\n\n    async def get_multi(\n        self,\n        db: AsyncSession,\n        *,\n        skip: int = 0,\n        limit: int = 100,\n    ) -> list[ModelType]:\n        \"\"\"Get multiple records with pagination.\"\"\"\n        result = await db.execute(\n            select(self.model).offset(skip).limit(limit)\n        )\n        return list(result.scalars().all())\n\n    async def create(\n        self,\n        db: AsyncSession,\n        *,\n        obj_in: CreateSchemaType,\n    ) -> ModelType:\n        \"\"\"Create a new record.\"\"\"\n        obj_in_data = obj_in.model_dump()\n        db_obj = self.model(**obj_in_data)\n        db.add(db_obj)\n        await db.flush()\n        await db.refresh(db_obj)\n        return db_obj\n\n    async def update(\n        self,\n        db: AsyncSession,\n        *,\n        db_obj: ModelType,\n        obj_in: UpdateSchemaType | dict[str, Any],\n    ) -> ModelType:\n        \"\"\"Update a record.\"\"\"\n        update_data = obj_in if isinstance(obj_in, dict) else obj_in.model_dump(exclude_unset=True)\n\n        for field, value in update_data.items():\n            setattr(db_obj, field, value)\n\n        db.add(db_obj)\n        await db.flush()\n        await db.refresh(db_obj)\n        return db_obj\n\n    async def delete(self, db: AsyncSession, *, id: Any) -> ModelType | None:\n        \"\"\"Delete a record.\"\"\"\n        obj = await self.get(db, id)\n        if obj:\n            await db.delete(obj)\n            await db.flush()\n        return obj\n\n{%- else %}\n\n    def get(self, db: Session, id: Any) -> ModelType | None:\n        \"\"\"Get a single record by ID.\"\"\"\n        return db.get(self.model, id)\n\n    def get_multi(\n        self,\n        db: Session,\n        *,\n        skip: int = 0,\n        limit: int = 100,\n    ) -> list[ModelType]:\n        \"\"\"Get multiple records with pagination.\"\"\"\n        result = db.execute(\n            select(self.model).offset(skip).limit(limit)\n        )\n        return list(result.scalars().all())\n\n    def create(\n        self,\n        db: Session,\n        *,\n        obj_in: CreateSchemaType,\n    ) -> ModelType:\n        \"\"\"Create a new record.\"\"\"\n        obj_in_data = obj_in.model_dump()\n        db_obj = self.model(**obj_in_data)\n        db.add(db_obj)\n        db.flush()\n        db.refresh(db_obj)\n        return db_obj\n\n    def update(\n        self,\n        db: Session,\n        *,\n        db_obj: ModelType,\n        obj_in: UpdateSchemaType | dict[str, Any],\n    ) -> ModelType:\n        \"\"\"Update a record.\"\"\"\n        if isinstance(obj_in, dict):\n            update_data = obj_in\n        else:\n            update_data = obj_in.model_dump(exclude_unset=True)\n\n        for field, value in update_data.items():\n            setattr(db_obj, field, value)\n\n        db.add(db_obj)\n        db.flush()\n        db.refresh(db_obj)\n        return db_obj\n\n    def delete(self, db: Session, *, id: Any) -> ModelType | None:\n        \"\"\"Delete a record.\"\"\"\n        obj = self.get(db, id)\n        if obj:\n            db.delete(obj)\n            db.flush()\n        return obj\n{%- endif %}\n{%- else %}\n\"\"\"Base repository - not using SQLAlchemy.\"\"\"\n{%- endif %}\n","backend/app/repositories/item.py":"{%- if cookiecutter.include_example_crud and cookiecutter.use_postgresql %}\n\"\"\"Item repository (PostgreSQL async).\n\nContains database operations for Item entity. Business logic\nshould be handled by ItemService in app/services/item.py.\n\"\"\"\n\nfrom uuid import UUID\n\nfrom sqlalchemy import select\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.db.models.item import Item\n\n\nasync def get_by_id(db: AsyncSession, item_id: UUID) -> Item | None:\n    \"\"\"Get item by ID.\"\"\"\n    return await db.get(Item, item_id)\n\n\nasync def get_multi(\n    db: AsyncSession,\n    *,\n    skip: int = 0,\n    limit: int = 100,\n    active_only: bool = False,\n) -> list[Item]:\n    \"\"\"Get multiple items with pagination.\"\"\"\n    query = select(Item)\n    if active_only:\n        query = query.where(Item.is_active == True)  # noqa: E712\n    query = query.offset(skip).limit(limit)\n    result = await db.execute(query)\n    return list(result.scalars().all())\n\n\nasync def create(\n    db: AsyncSession,\n    *,\n    title: str,\n    description: str | None = None,\n) -> Item:\n    \"\"\"Create a new item.\"\"\"\n    item = Item(\n        title=title,\n        description=description,\n    )\n    db.add(item)\n    await db.flush()\n    await db.refresh(item)\n    return item\n\n\nasync def update(\n    db: AsyncSession,\n    *,\n    db_item: Item,\n    update_data: dict,\n) -> Item:\n    \"\"\"Update an item.\"\"\"\n    for field, value in update_data.items():\n        setattr(db_item, field, value)\n\n    db.add(db_item)\n    await db.flush()\n    await db.refresh(db_item)\n    return db_item\n\n\nasync def delete(db: AsyncSession, item_id: UUID) -> Item | None:\n    \"\"\"Delete an item.\"\"\"\n    item = await get_by_id(db, item_id)\n    if item:\n        await db.delete(item)\n        await db.flush()\n    return item\n\n\n{%- elif cookiecutter.include_example_crud and cookiecutter.use_sqlite %}\n\"\"\"Item repository (SQLite sync).\n\nContains database operations for Item entity. Business logic\nshould be handled by ItemService in app/services/item.py.\n\"\"\"\n\nfrom sqlalchemy import select\nfrom sqlalchemy.orm import Session\n\nfrom app.db.models.item import Item\n\n\ndef get_by_id(db: Session, item_id: str) -> Item | None:\n    \"\"\"Get item by ID.\"\"\"\n    return db.get(Item, item_id)\n\n\ndef get_multi(\n    db: Session,\n    *,\n    skip: int = 0,\n    limit: int = 100,\n    active_only: bool = False,\n) -> list[Item]:\n    \"\"\"Get multiple items with pagination.\"\"\"\n    query = select(Item)\n    if active_only:\n        query = query.where(Item.is_active == True)  # noqa: E712\n    query = query.offset(skip).limit(limit)\n    result = db.execute(query)\n    return list(result.scalars().all())\n\n\ndef create(\n    db: Session,\n    *,\n    title: str,\n    description: str | None = None,\n) -> Item:\n    \"\"\"Create a new item.\"\"\"\n    item = Item(\n        title=title,\n        description=description,\n    )\n    db.add(item)\n    db.flush()\n    db.refresh(item)\n    return item\n\n\ndef update(\n    db: Session,\n    *,\n    db_item: Item,\n    update_data: dict,\n) -> Item:\n    \"\"\"Update an item.\"\"\"\n    for field, value in update_data.items():\n        setattr(db_item, field, value)\n\n    db.add(db_item)\n    db.flush()\n    db.refresh(db_item)\n    return db_item\n\n\ndef delete(db: Session, item_id: str) -> Item | None:\n    \"\"\"Delete an item.\"\"\"\n    item = get_by_id(db, item_id)\n    if item:\n        db.delete(item)\n        db.flush()\n    return item\n\n\n{%- elif cookiecutter.include_example_crud and cookiecutter.use_mongodb %}\n\"\"\"Item repository (MongoDB).\n\nContains database operations for Item entity. Business logic\nshould be handled by ItemService in app/services/item.py.\n\"\"\"\n\nfrom datetime import UTC, datetime\n\nfrom app.db.models.item import Item\n\n\nasync def get_by_id(item_id: str) -> Item | None:\n    \"\"\"Get item by ID.\"\"\"\n    return await Item.get(item_id)\n\n\nasync def get_multi(\n    *,\n    skip: int = 0,\n    limit: int = 100,\n    active_only: bool = False,\n) -> list[Item]:\n    \"\"\"Get multiple items with pagination.\"\"\"\n    query = Item.find_all()\n    if active_only:\n        query = Item.find(Item.is_active == True)  # noqa: E712\n    return await query.skip(skip).limit(limit).to_list()\n\n\nasync def create(\n    *,\n    title: str,\n    description: str | None = None,\n) -> Item:\n    \"\"\"Create a new item.\"\"\"\n    item = Item(\n        title=title,\n        description=description,\n    )\n    await item.insert()\n    return item\n\n\nasync def update(\n    *,\n    db_item: Item,\n    update_data: dict,\n) -> Item:\n    \"\"\"Update an item.\"\"\"\n    for field, value in update_data.items():\n        setattr(db_item, field, value)\n    db_item.updated_at = datetime.now(UTC)\n    await db_item.save()\n    return db_item\n\n\nasync def delete(item_id: str) -> Item | None:\n    \"\"\"Delete an item.\"\"\"\n    item = await get_by_id(item_id)\n    if item:\n        await item.delete()\n    return item\n\n\n{%- else %}\n\"\"\"Item repository - not configured.\"\"\"\n{%- endif %}\n","backend/app/schemas/user.py":"{%- if cookiecutter.use_jwt %}\n\"\"\"User schemas.\"\"\"\n\nfrom enum import StrEnum\nfrom uuid import UUID\n\nfrom pydantic import EmailStr, Field\n\nfrom app.schemas.base import BaseSchema, TimestampSchema\n\n\nclass UserRole(StrEnum):\n    \"\"\"User role enumeration for API schemas.\"\"\"\n\n    ADMIN = \"admin\"\n    USER = \"user\"\n\n\nclass UserBase(BaseSchema):\n    \"\"\"Base user schema.\"\"\"\n\n    email: EmailStr = Field(max_length=255)\n    full_name: str | None = Field(default=None, max_length=255)\n    is_active: bool = True\n\n\nclass UserCreate(BaseSchema):\n    \"\"\"Schema for creating a user.\"\"\"\n\n    email: EmailStr = Field(max_length=255)\n    password: str = Field(min_length=8, max_length=128)\n    full_name: str | None = Field(default=None, max_length=255)\n    role: UserRole = UserRole.USER\n\n\nclass UserUpdate(BaseSchema):\n    \"\"\"Schema for updating a user.\"\"\"\n\n    email: EmailStr | None = Field(default=None, max_length=255)\n    password: str | None = Field(default=None, min_length=8, max_length=128)\n    full_name: str | None = Field(default=None, max_length=255)\n    is_active: bool | None = None\n    role: UserRole | None = None\n\n\nclass UserRead(UserBase, TimestampSchema):\n    \"\"\"Schema for reading a user.\"\"\"\n\n{%- if cookiecutter.use_postgresql %}\n    id: UUID\n{%- elif cookiecutter.use_sqlite or cookiecutter.use_mongodb %}\n    id: str\n{%- endif %}\n    is_superuser: bool = False\n    role: UserRole = UserRole.USER\n\n\nclass UserInDB(UserRead):\n    \"\"\"User schema with hashed password (internal use).\"\"\"\n\n    hashed_password: str\n{%- else %}\n\"\"\"User schemas - not configured.\"\"\"\n{%- endif %}\n","backend/app/schemas/token.py":"{%- if cookiecutter.use_jwt %}\n\"\"\"Token schemas.\"\"\"\n\nfrom typing import Literal\n\nfrom pydantic import BaseModel\n\n\nclass Token(BaseModel):\n    \"\"\"OAuth2 token response with refresh token.\"\"\"\n\n    access_token: str\n    refresh_token: str\n    token_type: str = \"bearer\"\n\n\nclass TokenPayload(BaseModel):\n    \"\"\"JWT token payload.\"\"\"\n\n    sub: str | None = None\n    exp: int | None = None\n    type: Literal[\"access\", \"refresh\"] | None = None\n\n\nclass RefreshTokenRequest(BaseModel):\n    \"\"\"Request body for token refresh.\"\"\"\n\n    refresh_token: str\n{%- else %}\n\"\"\"Token schemas - not configured.\"\"\"\n{%- endif %}\n","backend/app/schemas/webhook.py":"{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\n\"\"\"Webhook schemas.\"\"\"\n\nfrom datetime import datetime\n{%- if cookiecutter.use_postgresql %}\nfrom uuid import UUID\n{%- endif %}\n\nfrom pydantic import BaseModel, Field, HttpUrl\n\n\nclass WebhookCreate(BaseModel):\n    \"\"\"Schema for creating a webhook.\"\"\"\n\n    name: str = Field(..., min_length=1, max_length=255)\n    url: HttpUrl\n    events: list[str] = Field(..., min_length=1)\n    description: str | None = None\n\n\nclass WebhookUpdate(BaseModel):\n    \"\"\"Schema for updating a webhook.\"\"\"\n\n    name: str | None = Field(None, min_length=1, max_length=255)\n    url: HttpUrl | None = None\n    events: list[str] | None = Field(None, min_length=1)\n    is_active: bool | None = None\n    description: str | None = None\n\n\nclass WebhookRead(BaseModel):\n    \"\"\"Schema for reading a webhook.\"\"\"\n\n{%- if cookiecutter.use_postgresql %}\n    id: UUID\n{%- else %}\n    id: str\n{%- endif %}\n    name: str\n    url: str\n    events: list[str]\n    is_active: bool\n    description: str | None\n    created_at: datetime\n    updated_at: datetime\n\n\nclass WebhookDeliveryRead(BaseModel):\n    \"\"\"Schema for reading a webhook delivery.\"\"\"\n\n{%- if cookiecutter.use_postgresql %}\n    id: UUID\n    webhook_id: UUID\n{%- else %}\n    id: str\n    webhook_id: str\n{%- endif %}\n    event_type: str\n    response_status: int | None\n    error_message: str | None\n    attempt_count: int\n    success: bool\n    created_at: datetime\n    delivered_at: datetime | None\n\n\nclass WebhookListResponse(BaseModel):\n    \"\"\"Response for list of webhooks.\"\"\"\n\n    items: list[WebhookRead]\n    total: int\n\n\nclass WebhookDeliveryListResponse(BaseModel):\n    \"\"\"Response for list of webhook deliveries.\"\"\"\n\n    items: list[WebhookDeliveryRead]\n    total: int\n\n\nclass WebhookTestResponse(BaseModel):\n    \"\"\"Response for webhook test.\"\"\"\n\n    success: bool\n    status_code: int | None\n    message: str\n{%- else %}\n\"\"\"Webhook schemas - not configured.\"\"\"\n{%- endif %}\n","backend/app/schemas/conversation.py":"{%- if cookiecutter.enable_conversation_persistence %}\n\"\"\"Conversation schemas for AI chat persistence.\n\nThis module contains Pydantic schemas for Conversation, Message, and ToolCall entities.\n\"\"\"\n\nfrom datetime import datetime\nfrom typing import Literal\n\n{%- if cookiecutter.use_postgresql %}\nfrom uuid import UUID\n{%- endif %}\n\nfrom pydantic import Field\n\nfrom app.schemas.base import BaseSchema, TimestampSchema\n\n\n# =============================================================================\n# Tool Call Schemas\n# =============================================================================\n\n\nclass ToolCallBase(BaseSchema):\n    \"\"\"Base tool call schema.\"\"\"\n\n    tool_call_id: str = Field(..., description=\"External tool call ID from AI framework\")\n    tool_name: str = Field(..., max_length=100, description=\"Name of the tool called\")\n    args: dict = Field(default_factory=dict, description=\"Tool arguments\")\n\n\nclass ToolCallCreate(ToolCallBase):\n    \"\"\"Schema for creating a tool call record.\"\"\"\n\n    started_at: datetime | None = Field(default=None, description=\"When the tool call started\")\n\n\nclass ToolCallComplete(BaseSchema):\n    \"\"\"Schema for completing a tool call.\"\"\"\n\n    result: str = Field(..., description=\"Tool execution result\")\n    completed_at: datetime | None = Field(default=None, description=\"When the tool call completed\")\n    success: bool = Field(default=True, description=\"Whether the tool call succeeded\")\n\n\nclass ToolCallRead(ToolCallBase):\n    \"\"\"Schema for reading a tool call (API response).\"\"\"\n\n{%- if cookiecutter.use_postgresql %}\n    id: UUID\n    message_id: UUID\n{%- else %}\n    id: str\n    message_id: str\n{%- endif %}\n    result: str | None = None\n    status: Literal[\"pending\", \"running\", \"completed\", \"failed\"] = \"pending\"\n    started_at: datetime\n    completed_at: datetime | None = None\n    duration_ms: int | None = None\n\n\n# =============================================================================\n# Message Schemas\n# =============================================================================\n\n\nclass MessageBase(BaseSchema):\n    \"\"\"Base message schema.\"\"\"\n\n    role: Literal[\"user\", \"assistant\", \"system\"] = Field(..., description=\"Message role\")\n    content: str = Field(..., description=\"Message content\")\n\n\nclass MessageCreate(MessageBase):\n    \"\"\"Schema for creating a message.\"\"\"\n\n    model_name: str | None = Field(default=None, max_length=100, description=\"AI model used\")\n    tokens_used: int | None = Field(default=None, ge=0, description=\"Token count\")\n\n\nclass MessageRead(MessageBase, TimestampSchema):\n    \"\"\"Schema for reading a message (API response).\"\"\"\n\n{%- if cookiecutter.use_postgresql %}\n    id: UUID\n    conversation_id: UUID\n{%- else %}\n    id: str\n    conversation_id: str\n{%- endif %}\n    model_name: str | None = None\n    tokens_used: int | None = None\n    tool_calls: list[ToolCallRead] = Field(default_factory=list)\n\n\nclass MessageReadSimple(MessageBase, TimestampSchema):\n    \"\"\"Simplified message schema without tool calls.\"\"\"\n\n{%- if cookiecutter.use_postgresql %}\n    id: UUID\n    conversation_id: UUID\n{%- else %}\n    id: str\n    conversation_id: str\n{%- endif %}\n    model_name: str | None = None\n    tokens_used: int | None = None\n\n\n# =============================================================================\n# Conversation Schemas\n# =============================================================================\n\n\nclass ConversationBase(BaseSchema):\n    \"\"\"Base conversation schema.\"\"\"\n\n    title: str | None = Field(default=None, max_length=255, description=\"Conversation title\")\n\n\nclass ConversationCreate(ConversationBase):\n    \"\"\"Schema for creating a conversation.\"\"\"\n\n{%- if cookiecutter.use_jwt %}\n{%- if cookiecutter.use_postgresql %}\n    user_id: UUID | None = Field(default=None, description=\"Owner user ID\")\n{%- else %}\n    user_id: str | None = Field(default=None, description=\"Owner user ID\")\n{%- endif %}\n{%- endif %}\n    pass\n\n\nclass ConversationUpdate(BaseSchema):\n    \"\"\"Schema for updating a conversation.\"\"\"\n\n    title: str | None = Field(default=None, max_length=255)\n    is_archived: bool | None = None\n\n\nclass ConversationRead(ConversationBase, TimestampSchema):\n    \"\"\"Schema for reading a conversation (API response).\"\"\"\n\n{%- if cookiecutter.use_postgresql %}\n    id: UUID\n{%- if cookiecutter.use_jwt %}\n    user_id: UUID | None = None\n{%- endif %}\n{%- else %}\n    id: str\n{%- if cookiecutter.use_jwt %}\n    user_id: str | None = None\n{%- endif %}\n{%- endif %}\n    is_archived: bool = False\n\n\nclass ConversationReadWithMessages(ConversationRead):\n    \"\"\"Conversation with all messages.\"\"\"\n\n    messages: list[MessageRead] = Field(default_factory=list)\n\n\nclass ConversationList(BaseSchema):\n    \"\"\"Schema for listing conversations.\"\"\"\n\n    items: list[ConversationRead]\n    total: int\n\n\n# =============================================================================\n# Aggregated Schemas for API Responses\n# =============================================================================\n\n\nclass MessageList(BaseSchema):\n    \"\"\"Schema for listing messages.\"\"\"\n\n    items: list[MessageReadSimple]\n    total: int\n\n\nclass ConversationWithLatestMessage(ConversationRead):\n    \"\"\"Conversation with its latest message for list views.\"\"\"\n\n    latest_message: MessageReadSimple | None = None\n    message_count: int = 0\n\n{%- else %}\n\"\"\"Conversation schemas - not configured.\"\"\"\n{%- endif %}\n","backend/app/schemas/session.py":"{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\n\"\"\"Session schemas.\"\"\"\n\nfrom datetime import datetime\n{%- if cookiecutter.use_postgresql %}\nfrom uuid import UUID\n{%- endif %}\n\nfrom pydantic import BaseModel\n\n\nclass SessionRead(BaseModel):\n    \"\"\"Session response schema.\"\"\"\n\n{%- if cookiecutter.use_postgresql %}\n    id: UUID\n{%- else %}\n    id: str\n{%- endif %}\n    device_name: str | None = None\n    device_type: str | None = None\n    ip_address: str | None = None\n    is_current: bool = False\n    created_at: datetime\n    last_used_at: datetime\n\n\nclass SessionListResponse(BaseModel):\n    \"\"\"Response for list of sessions.\"\"\"\n\n    sessions: list[SessionRead]\n    total: int\n\n\nclass LogoutAllResponse(BaseModel):\n    \"\"\"Response for logout all sessions.\"\"\"\n\n    message: str\n    sessions_logged_out: int\n{%- else %}\n\"\"\"Session schemas - not configured.\"\"\"\n{%- endif %}\n","backend/app/schemas/__init__.py":"\"\"\"Pydantic schemas.\"\"\"\n{%- set schemas = [] %}\n{%- if cookiecutter.use_jwt or cookiecutter.include_example_crud or cookiecutter.enable_conversation_persistence or cookiecutter.enable_webhooks %}\n# ruff: noqa: I001, RUF022 - Imports structured for Jinja2 template conditionals\n{%- endif %}\n{%- if cookiecutter.use_jwt %}\n{%- set _ = schemas.extend([\"UserCreate\", \"UserRead\", \"UserUpdate\", \"Token\", \"TokenPayload\"]) %}\n\nfrom app.schemas.token import Token, TokenPayload\nfrom app.schemas.user import UserCreate, UserRead, UserUpdate\n{%- endif %}\n{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\n{%- set _ = schemas.extend([\"SessionRead\", \"SessionListResponse\", \"LogoutAllResponse\"]) %}\n\nfrom app.schemas.session import SessionRead, SessionListResponse, LogoutAllResponse\n{%- endif %}\n{%- if cookiecutter.include_example_crud and cookiecutter.use_database %}\n{%- set _ = schemas.extend([\"ItemCreate\", \"ItemRead\", \"ItemUpdate\"]) %}\n\nfrom app.schemas.item import ItemCreate, ItemRead, ItemUpdate\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n{%- set _ = schemas.extend([\"ConversationCreate\", \"ConversationRead\", \"ConversationUpdate\", \"MessageCreate\", \"MessageRead\", \"ToolCallRead\"]) %}\n\nfrom app.schemas.conversation import (\n    ConversationCreate,\n    ConversationRead,\n    ConversationUpdate,\n    MessageCreate,\n    MessageRead,\n    ToolCallRead,\n)\n{%- endif %}\n{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\n{%- set _ = schemas.extend([\"WebhookCreate\", \"WebhookRead\", \"WebhookUpdate\", \"WebhookDeliveryRead\", \"WebhookListResponse\", \"WebhookDeliveryListResponse\", \"WebhookTestResponse\"]) %}\n\nfrom app.schemas.webhook import (\n    WebhookCreate,\n    WebhookRead,\n    WebhookUpdate,\n    WebhookDeliveryRead,\n    WebhookListResponse,\n    WebhookDeliveryListResponse,\n    WebhookTestResponse,\n)\n{%- endif %}\n{%- if schemas %}\n\n__all__ = {{ schemas }}\n{%- endif %}\n","backend/app/schemas/base.py":"\"\"\"Base Pydantic schemas.\"\"\"\n\nfrom datetime import datetime\nfrom typing import Any\nfrom zoneinfo import ZoneInfo\n\nfrom pydantic import BaseModel, ConfigDict\n\n\ndef serialize_datetime(dt: datetime) -> str:\n    \"\"\"Serialize datetime to ISO format with timezone.\n\n    Ensures all datetimes have explicit timezone (defaults to UTC).\n    \"\"\"\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=ZoneInfo(\"UTC\"))\n    return dt.isoformat()\n\n\nclass BaseSchema(BaseModel):\n    \"\"\"Base schema with common configuration.\"\"\"\n\n    model_config = ConfigDict(\n        from_attributes=True,\n        populate_by_name=True,\n        str_strip_whitespace=True,\n        json_encoders={datetime: serialize_datetime},\n    )\n\n    def serializable_dict(self, **kwargs: Any) -> dict[str, Any]:\n        \"\"\"Return a dict with only JSON-serializable fields.\"\"\"\n        from fastapi.encoders import jsonable_encoder\n\n        return jsonable_encoder(self.model_dump(**kwargs))\n\n\nclass TimestampSchema(BaseModel):\n    \"\"\"Schema with timestamp fields.\"\"\"\n\n    created_at: datetime\n    updated_at: datetime | None = None\n\n\nclass BaseResponse(BaseModel):\n    \"\"\"Standard API response.\"\"\"\n\n    success: bool = True\n    message: str | None = None\n\n\nclass ErrorResponse(BaseModel):\n    \"\"\"Standard error response.\"\"\"\n\n    success: bool = False\n    error: str\n    detail: str | None = None\n    code: str | None = None\n","backend/app/schemas/item.py":"{%- if cookiecutter.include_example_crud %}\n\"\"\"Item schemas - example CRUD entity.\n\nThis module demonstrates standard Pydantic schemas for a CRUD entity.\nYou can use it as a template for creating your own schemas.\n\"\"\"\n\n{%- if cookiecutter.use_postgresql %}\nfrom uuid import UUID\n{%- endif %}\n\nfrom pydantic import Field\n\nfrom app.schemas.base import BaseSchema, TimestampSchema\n\n\nclass ItemBase(BaseSchema):\n    \"\"\"Base item schema with common fields.\"\"\"\n\n    title: str = Field(max_length=255, description=\"Item title\")\n    description: str | None = Field(default=None, description=\"Item description\")\n\n\nclass ItemCreate(ItemBase):\n    \"\"\"Schema for creating an item.\"\"\"\n\n    pass\n\n\nclass ItemUpdate(BaseSchema):\n    \"\"\"Schema for updating an item.\n\n    All fields are optional to allow partial updates.\n    \"\"\"\n\n    title: str | None = Field(default=None, max_length=255)\n    description: str | None = Field(default=None)\n    is_active: bool | None = None\n\n\nclass ItemRead(ItemBase, TimestampSchema):\n    \"\"\"Schema for reading an item (API response).\"\"\"\n\n{%- if cookiecutter.use_postgresql %}\n    id: UUID\n{%- else %}\n    id: str\n{%- endif %}\n    is_active: bool = True\n{%- else %}\n\"\"\"Item schemas - not configured.\"\"\"\n{%- endif %}\n","backend/app/admin.py":"{%- if cookiecutter.enable_admin_panel and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) and cookiecutter.use_sqlalchemy %}\n\"\"\"SQLAdmin configuration with automatic model discovery.\"\"\"\n\nfrom typing import Any, ClassVar\n\nfrom sqlalchemy import String, inspect\nfrom sqlalchemy.engine import Engine\nfrom sqlalchemy.orm import DeclarativeBase\nfrom sqladmin import Admin, ModelView\n{%- if cookiecutter.admin_require_auth %}\nfrom sqladmin.authentication import AuthenticationBackend\nfrom starlette.requests import Request\n{%- endif %}\n\nfrom app.core.config import settings\n{%- if cookiecutter.admin_require_auth %}\nfrom app.core.security import verify_password\n{%- endif %}\nfrom app.db.base import Base\nfrom app.db.models.user import User\n{%- if cookiecutter.enable_session_management %}\nfrom app.db.models.session import Session\n{%- endif %}\n{%- if cookiecutter.include_example_crud %}\nfrom app.db.models.item import Item\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence %}\nfrom app.db.models.conversation import Conversation, Message, ToolCall\n{%- endif %}\n{%- if cookiecutter.enable_webhooks %}\nfrom app.db.models.webhook import Webhook, WebhookDelivery\n{%- endif %}\n\n\n# Columns that should be excluded from forms (sensitive data)\nSENSITIVE_COLUMN_PATTERNS: list[str] = [\n    \"password\",\n    \"hashed_password\",\n    \"secret\",\n    \"token\",\n    \"api_key\",\n    \"refresh_token\",\n]\n\n# Columns that should be searchable by default (string columns)\nSEARCHABLE_COLUMN_TYPES: tuple[type, ...] = (String,)\n\n# Columns that are auto-generated and should be excluded from create/edit forms\nAUTO_GENERATED_COLUMNS: list[str] = [\n    \"created_at\",\n    \"updated_at\",\n]\n\n# Model icons mapping (model name -> Font Awesome icon)\nMODEL_ICONS: dict[str, str] = {\n    \"User\": \"fa-solid fa-user\",\n    \"Session\": \"fa-solid fa-key\",\n    \"Item\": \"fa-solid fa-box\",\n    \"Conversation\": \"fa-solid fa-comments\",\n    \"Message\": \"fa-solid fa-message\",\n    \"ToolCall\": \"fa-solid fa-wrench\",\n    \"Webhook\": \"fa-solid fa-link\",\n    \"WebhookDelivery\": \"fa-solid fa-paper-plane\",\n}\n\n\ndef discover_models(base: type[DeclarativeBase]) -> list[type]:\n    \"\"\"Discover all SQLAlchemy models registered with the given Base.\n\n    Args:\n        base: The SQLAlchemy DeclarativeBase class.\n\n    Returns:\n        List of model classes that inherit from the Base.\n    \"\"\"\n    return [mapper.class_ for mapper in base.registry.mappers]\n\n\ndef get_model_columns(model: type) -> list[str]:\n    \"\"\"Get all column names from a SQLAlchemy model.\n\n    Args:\n        model: The SQLAlchemy model class.\n\n    Returns:\n        List of column names.\n    \"\"\"\n    mapper = inspect(model)\n    return [column.key for column in mapper.columns]\n\n\ndef get_searchable_columns(model: type) -> list[str]:\n    \"\"\"Get columns suitable for searching (String type columns).\n\n    Args:\n        model: The SQLAlchemy model class.\n\n    Returns:\n        List of searchable column names.\n    \"\"\"\n    mapper = inspect(model)\n    searchable = []\n    for column in mapper.columns:\n        # Include String columns that are not sensitive\n        is_searchable_type = isinstance(column.type, SEARCHABLE_COLUMN_TYPES)\n        is_sensitive = any(pattern in column.key.lower() for pattern in SENSITIVE_COLUMN_PATTERNS)\n        if is_searchable_type and not is_sensitive:\n            searchable.append(column.key)\n    return searchable\n\n\ndef get_sortable_columns(model: type) -> list[str]:\n    \"\"\"Get columns suitable for sorting.\n\n    Args:\n        model: The SQLAlchemy model class.\n\n    Returns:\n        List of sortable column names.\n    \"\"\"\n    mapper = inspect(model)\n    return [column.key for column in mapper.columns]\n\n\ndef get_form_excluded_columns(model: type) -> list[str]:\n    \"\"\"Get columns that should be excluded from create/edit forms.\n\n    Excludes sensitive columns and auto-generated columns.\n\n    Args:\n        model: The SQLAlchemy model class.\n\n    Returns:\n        List of column names to exclude from forms.\n    \"\"\"\n    excluded = []\n    for column_name in get_model_columns(model):\n        # Exclude sensitive columns\n        if any(pattern in column_name.lower() for pattern in SENSITIVE_COLUMN_PATTERNS):\n            excluded.append(column_name)\n        # Exclude auto-generated columns\n        elif column_name in AUTO_GENERATED_COLUMNS:\n            excluded.append(column_name)\n    return excluded\n\n\ndef pluralize(name: str) -> str:\n    \"\"\"Simple pluralization for model names.\n\n    Args:\n        name: Singular name.\n\n    Returns:\n        Pluralized name.\n    \"\"\"\n    if name.endswith(\"y\"):\n        return name[:-1] + \"ies\"\n    elif name.endswith(\"s\") or name.endswith(\"x\") or name.endswith(\"ch\") or name.endswith(\"sh\"):\n        return name + \"es\"\n    return name + \"s\"\n\n\ndef create_model_admin(\n    model: type,\n    *,\n    name: str | None = None,\n    name_plural: str | None = None,\n    icon: str | None = None,\n    column_list: list[Any] | None = None,\n    column_searchable_list: list[Any] | None = None,\n    column_sortable_list: list[Any] | None = None,\n    form_excluded_columns: list[Any] | None = None,\n    can_create: bool = True,\n    can_edit: bool = True,\n    can_delete: bool = True,\n    can_view_details: bool = True,\n) -> type[ModelView]:\n    \"\"\"Dynamically create a ModelView class for a SQLAlchemy model.\n\n    Args:\n        model: The SQLAlchemy model class.\n        name: Display name (defaults to model class name).\n        name_plural: Plural display name (defaults to auto-pluralized name).\n        icon: Font Awesome icon class.\n        column_list: Columns to display in list view.\n        column_searchable_list: Columns to enable search on.\n        column_sortable_list: Columns to enable sorting on.\n        form_excluded_columns: Columns to exclude from forms.\n        can_create: Allow creating new records.\n        can_edit: Allow editing records.\n        can_delete: Allow deleting records.\n        can_view_details: Allow viewing record details.\n\n    Returns:\n        A dynamically created ModelView subclass.\n    \"\"\"\n    import types\n\n    model_name = model.__name__\n\n    # Use provided values or generate defaults\n    _name = name or model_name\n    _name_plural = name_plural or pluralize(_name)\n    _icon = icon or MODEL_ICONS.get(model_name, \"fa-solid fa-database\")\n\n    # Get column attributes from the model\n    _column_list = column_list\n    if _column_list is None:\n        columns = get_model_columns(model)\n        _column_list = [getattr(model, col) for col in columns if hasattr(model, col)]\n\n    _column_searchable_list = column_searchable_list\n    if _column_searchable_list is None:\n        searchable = get_searchable_columns(model)\n        _column_searchable_list = [getattr(model, col) for col in searchable if hasattr(model, col)]\n\n    _column_sortable_list = column_sortable_list\n    if _column_sortable_list is None:\n        sortable = get_sortable_columns(model)\n        _column_sortable_list = [getattr(model, col) for col in sortable if hasattr(model, col)]\n\n    _form_excluded_columns = form_excluded_columns\n    if _form_excluded_columns is None:\n        excluded = get_form_excluded_columns(model)\n        _form_excluded_columns = [getattr(model, col) for col in excluded if hasattr(model, col)]\n\n    # Create class attributes in the exec_body callback\n    def exec_body(ns: dict[str, Any]) -> None:\n        ns[\"name\"] = _name\n        ns[\"name_plural\"] = _name_plural\n        ns[\"icon\"] = _icon\n        ns[\"column_list\"] = _column_list\n        ns[\"column_searchable_list\"] = _column_searchable_list\n        ns[\"column_sortable_list\"] = _column_sortable_list\n        ns[\"form_excluded_columns\"] = _form_excluded_columns\n        ns[\"can_create\"] = can_create\n        ns[\"can_edit\"] = can_edit\n        ns[\"can_delete\"] = can_delete\n        ns[\"can_view_details\"] = can_view_details\n        # Add ClassVar type hints for sqladmin compatibility\n        ns[\"__annotations__\"] = {\n            \"column_list\": ClassVar,\n            \"column_searchable_list\": ClassVar,\n            \"column_sortable_list\": ClassVar,\n            \"form_excluded_columns\": ClassVar,\n            \"can_create\": ClassVar,\n            \"can_edit\": ClassVar,\n            \"can_delete\": ClassVar,\n            \"can_view_details\": ClassVar,\n        }\n\n    # Create the class using types.new_class to properly pass model kwarg to metaclass\n    class_name = f\"{model_name}Admin\"\n    admin_class = types.new_class(\n        class_name,\n        (ModelView,),\n        {\"model\": model},  # Pass model to metaclass\n        exec_body,\n    )\n\n    return admin_class  # type: ignore[return-value]\n\n\ndef register_models_auto(\n    admin: Admin,\n    base: type[DeclarativeBase],\n    *,\n    exclude_models: list[type] | None = None,\n    custom_configs: dict[type, dict[str, Any]] | None = None,\n) -> list[type[ModelView]]:\n    \"\"\"Auto-discover and register all models with the admin panel.\n\n    Args:\n        admin: The SQLAdmin instance.\n        base: The SQLAlchemy DeclarativeBase class.\n        exclude_models: Models to exclude from auto-registration.\n        custom_configs: Custom configuration overrides per model.\n\n    Returns:\n        List of registered ModelView classes.\n    \"\"\"\n    exclude_models = exclude_models or []\n    custom_configs = custom_configs or {}\n\n    registered_views: list[type[ModelView]] = []\n    models = discover_models(base)\n\n    for model in models:\n        if model in exclude_models:\n            continue\n\n        # Get custom config for this model if provided\n        config = custom_configs.get(model, {})\n\n        # Create and register the admin view\n        admin_class = create_model_admin(model, **config)\n        admin.add_view(admin_class)\n        registered_views.append(admin_class)\n\n    return registered_views\n\n\n# SQLAdmin requires a synchronous engine\n_sync_engine: Engine | None = None\n\n\ndef get_sync_engine() -> Engine:\n    \"\"\"Get or create the synchronous engine for SQLAdmin.\"\"\"\n    global _sync_engine\n    if _sync_engine is None:\n        from sqlalchemy import create_engine\n\n        _sync_engine = create_engine(settings.DATABASE_URL_SYNC, echo=settings.DEBUG)\n    return _sync_engine\n\n\n{%- if cookiecutter.admin_require_auth %}\n\n\nclass AdminAuth(AuthenticationBackend):\n    \"\"\"Admin panel authentication backend.\n\n    Requires superuser credentials to access the admin panel.\n    \"\"\"\n\n    async def login(self, request: Request) -> bool:\n        \"\"\"Validate admin login credentials.\"\"\"\n        form = await request.form()\n        email = form.get(\"username\")\n        password = form.get(\"password\")\n\n        if not email or not password:\n            return False\n\n        # Get user from database\n        from sqlalchemy.orm import Session as DBSession\n\n        with DBSession(get_sync_engine()) as session:\n            user = session.query(User).filter(User.email == email).first()\n\n            if (\n                user\n                and verify_password(str(password), user.hashed_password)\n                and user.is_superuser\n            ):\n                # Store user info in session\n                request.session[\"admin_user_id\"] = str(user.id)\n                request.session[\"admin_email\"] = user.email\n                return True\n\n        return False\n\n    async def logout(self, request: Request) -> bool:\n        \"\"\"Clear admin session.\"\"\"\n        request.session.clear()\n        return True\n\n    async def authenticate(self, request: Request) -> bool:\n        \"\"\"Check if user is authenticated.\"\"\"\n        admin_user_id = request.session.get(\"admin_user_id\")\n        if not admin_user_id:\n            return False\n\n        # Verify user still exists and is superuser\n        from sqlalchemy.orm import Session as DBSession\n\n        with DBSession(get_sync_engine()) as session:\n            user = session.query(User).filter(User.id == admin_user_id).first()\n            if user and user.is_superuser and user.is_active:\n                return True\n\n        # User no longer valid, clear session\n        request.session.clear()\n        return False\n{%- endif %}\n\n\nCUSTOM_MODEL_CONFIGS: dict[type, dict[str, Any]] = {\n    User: {\n        \"icon\": \"fa-solid fa-user\",\n        \"form_excluded_columns\": [User.hashed_password, User.created_at, User.updated_at],\n    },\n{%- if cookiecutter.enable_session_management %}\n    Session: {\n        \"icon\": \"fa-solid fa-key\",\n        \"form_excluded_columns\": [Session.refresh_token_hash],\n        \"can_create\": False,  # Sessions are created via login\n    },\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence %}\n    ToolCall: {\n        \"icon\": \"fa-solid fa-wrench\",\n        \"can_create\": False,  # Tool calls are created by the agent\n    },\n{%- endif %}\n{%- if cookiecutter.enable_webhooks %}\n    Webhook: {\n        \"icon\": \"fa-solid fa-link\",\n        \"form_excluded_columns\": [Webhook.secret],\n    },\n    WebhookDelivery: {\n        \"icon\": \"fa-solid fa-paper-plane\",\n        \"can_create\": False,  # Deliveries are created by webhook dispatch\n        \"can_edit\": False,\n    },\n{%- endif %}\n}\n\n\ndef setup_admin(app) -> Admin:\n    \"\"\"Setup SQLAdmin for the FastAPI app with automatic model discovery.\n\n    Automatically discovers all SQLAlchemy models from the Base registry\n    and creates admin views for them with sensible defaults.\n\n    Custom configurations can be provided in CUSTOM_MODEL_CONFIGS to override\n    default behavior for specific models.\n    \"\"\"\n    sync_engine = get_sync_engine()\n\n    {%- if cookiecutter.admin_require_auth %}\n    authentication_backend = AdminAuth(secret_key=settings.SECRET_KEY)\n    admin = Admin(\n        app,\n        sync_engine,\n        title=\"{{ cookiecutter.project_name }} Admin\",\n        authentication_backend=authentication_backend,\n    )\n    {%- else %}\n    admin = Admin(\n        app,\n        sync_engine,\n        title=\"{{ cookiecutter.project_name }} Admin\",\n    )\n    {%- endif %}\n\n    # Auto-register all models from Base with custom configs\n    register_models_auto(\n        admin,\n        Base,\n        custom_configs=CUSTOM_MODEL_CONFIGS,\n    )\n\n    return admin\n{%- else %}\n\"\"\"Admin panel - not configured.\"\"\"\n{%- endif %}\n","backend/app/db/session.py":"{%- if cookiecutter.use_postgresql %}\n\"\"\"Async PostgreSQL database session.\"\"\"\n\nfrom collections.abc import AsyncGenerator\nfrom contextlib import asynccontextmanager\n\nfrom sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker, create_async_engine\n\nfrom app.core.config import settings\n\nengine = create_async_engine(\n    settings.DATABASE_URL,\n    echo=settings.DEBUG,\n    pool_size=settings.DB_POOL_SIZE,\n    max_overflow=settings.DB_MAX_OVERFLOW,\n    pool_timeout=settings.DB_POOL_TIMEOUT,\n)\n\nasync_session_maker = async_sessionmaker(\n    engine,\n    class_=AsyncSession,\n    expire_on_commit=False,\n)\n\n\nasync def get_db_session() -> AsyncGenerator[AsyncSession, None]:\n    \"\"\"Get async database session for FastAPI dependency injection.\n\n    Use this with FastAPI Depends().\n    \"\"\"\n    async with async_session_maker() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n\n\n@asynccontextmanager\nasync def get_db_context() -> AsyncGenerator[AsyncSession, None]:\n    \"\"\"Get async database session as context manager.\n\n    Use this with 'async with' for manual session management (e.g., WebSockets).\n    \"\"\"\n    async with async_session_maker() as session:\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n\n\nasync def close_db() -> None:\n    \"\"\"Close database connections.\"\"\"\n    await engine.dispose()\n\n\n{%- elif cookiecutter.use_mongodb %}\n\"\"\"Async MongoDB database session.\"\"\"\n\nfrom motor.motor_asyncio import AsyncIOMotorClient, AsyncIOMotorDatabase\n\nfrom app.core.config import settings\n\nclient: AsyncIOMotorClient | None = None\n\n\nasync def get_db_session() -> AsyncIOMotorDatabase:\n    \"\"\"Get MongoDB database instance.\"\"\"\n    global client\n    if client is None:\n        client = AsyncIOMotorClient(settings.MONGO_URL)\n    return client[settings.MONGO_DB]\n\n\nasync def close_db() -> None:\n    \"\"\"Close MongoDB connection.\"\"\"\n    global client\n    if client is not None:\n        client.close()\n        client = None\n\n\n{%- elif cookiecutter.use_sqlite %}\n\"\"\"Sync SQLite database session.\"\"\"\n\nfrom collections.abc import Generator\n\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import Session, sessionmaker\n\nfrom app.core.config import settings\n\nengine = create_engine(\n    settings.DATABASE_URL,\n    connect_args={\"check_same_thread\": False},\n    echo=settings.DEBUG,\n)\n\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\n\ndef get_db_session() -> Generator[Session, None, None]:\n    \"\"\"Get sync database session.\"\"\"\n    db = SessionLocal()\n    try:\n        yield db\n        db.commit()\n    except Exception:\n        db.rollback()\n        raise\n    finally:\n        db.close()\n\n\ndef close_db() -> None:\n    \"\"\"Close database connection.\"\"\"\n    engine.dispose()\n\n\n{%- else %}\n\"\"\"No database configured.\"\"\"\n\n\nasync def get_db_session():\n    \"\"\"No-op when database is disabled.\"\"\"\n    yield None\n{%- endif %}\n","backend/app/db/__init__.py":"\"\"\"Database module.\"\"\"\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n{%- if cookiecutter.use_sqlalchemy %}\n\nfrom app.db.base import Base\n\n__all__ = [\"Base\"]\n{%- else %}\n# SQLModel uses SQLModel class directly as base, no separate Base class needed\nfrom app.db.base import TimestampMixin\n\n__all__ = [\"TimestampMixin\"]\n{%- endif %}\n{%- endif %}\n","backend/app/db/models/user.py":"{%- if cookiecutter.use_jwt and cookiecutter.use_postgresql and cookiecutter.use_sqlmodel %}\n\"\"\"User database model using SQLModel.\"\"\"\n\nimport uuid\nfrom enum import StrEnum\n{%- if cookiecutter.enable_session_management %}\nfrom typing import TYPE_CHECKING\n{%- endif %}\n\nfrom sqlalchemy import Column, String\nfrom sqlalchemy.dialects.postgresql import UUID as PG_UUID\nfrom sqlmodel import Field, Relationship, SQLModel\n\nfrom app.db.base import TimestampMixin\n\n{%- if cookiecutter.enable_session_management %}\nif TYPE_CHECKING:\n    from app.db.models.session import Session\n{%- endif %}\n\n\nclass UserRole(StrEnum):\n    \"\"\"User role enumeration.\n\n    Roles hierarchy (higher includes lower permissions):\n    - ADMIN: Full system access, can manage users and settings\n    - USER: Standard user access\n    \"\"\"\n\n    ADMIN = \"admin\"\n    USER = \"user\"\n\n\nclass User(TimestampMixin, SQLModel, table=True):\n    \"\"\"User model.\"\"\"\n\n    __tablename__ = \"users\"\n\n    id: uuid.UUID = Field(\n        default_factory=uuid.uuid4,\n        sa_column=Column(PG_UUID(as_uuid=True), primary_key=True),\n    )\n    email: str = Field(\n        sa_column=Column(String(255), unique=True, index=True, nullable=False),\n    )\n    hashed_password: str | None = Field(default=None, max_length=255)\n    full_name: str | None = Field(default=None, max_length=255)\n    is_active: bool = Field(default=True)\n    is_superuser: bool = Field(default=False)\n    role: str = Field(default=UserRole.USER.value, max_length=50)\n{%- if cookiecutter.enable_oauth %}\n    oauth_provider: str | None = Field(default=None, max_length=50)\n    oauth_id: str | None = Field(default=None, max_length=255)\n{%- endif %}\n\n{%- if cookiecutter.enable_session_management %}\n\n    # Relationship to sessions\n    sessions: list[\"Session\"] = Relationship(back_populates=\"user\")\n{%- endif %}\n\n    @property\n    def user_role(self) -> UserRole:\n        \"\"\"Get role as enum.\"\"\"\n        return UserRole(self.role)\n\n    def has_role(self, required_role: UserRole) -> bool:\n        \"\"\"Check if user has the required role or higher.\n\n        Admin role has access to everything.\n        \"\"\"\n        if self.role == UserRole.ADMIN.value:\n            return True\n        return self.role == required_role.value\n\n    def __repr__(self) -> str:\n        return f\"<User(id={self.id}, email={self.email}, role={self.role})>\"\n\n\n{%- elif cookiecutter.use_jwt and cookiecutter.use_postgresql %}\n\"\"\"User database model.\"\"\"\n\nimport uuid\nfrom enum import StrEnum\n{%- if cookiecutter.enable_session_management %}\nfrom typing import TYPE_CHECKING\n{%- endif %}\n\nfrom sqlalchemy import Boolean, String\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom sqlalchemy.orm import Mapped, mapped_column{% if cookiecutter.enable_session_management %}, relationship{% endif %}\n\nfrom app.db.base import Base, TimestampMixin\n\n{%- if cookiecutter.enable_session_management %}\nif TYPE_CHECKING:\n    from app.db.models.session import Session\n{%- endif %}\n\n\nclass UserRole(StrEnum):\n    \"\"\"User role enumeration.\n\n    Roles hierarchy (higher includes lower permissions):\n    - ADMIN: Full system access, can manage users and settings\n    - USER: Standard user access\n    \"\"\"\n\n    ADMIN = \"admin\"\n    USER = \"user\"\n\n\nclass User(Base, TimestampMixin):\n    \"\"\"User model.\"\"\"\n\n    __tablename__ = \"users\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n    email: Mapped[str] = mapped_column(String(255), unique=True, index=True, nullable=False)\n    hashed_password: Mapped[str | None] = mapped_column(String(255), nullable=True)\n    full_name: Mapped[str | None] = mapped_column(String(255), nullable=True)\n    is_active: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)\n    is_superuser: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)\n    role: Mapped[str] = mapped_column(String(50), default=UserRole.USER.value, nullable=False)\n{%- if cookiecutter.enable_oauth %}\n    oauth_provider: Mapped[str | None] = mapped_column(String(50), nullable=True, index=True)\n    oauth_id: Mapped[str | None] = mapped_column(String(255), nullable=True, index=True)\n{%- endif %}\n\n{%- if cookiecutter.enable_session_management %}\n\n    # Relationship to sessions\n    sessions: Mapped[list[\"Session\"]] = relationship(\n        \"Session\", back_populates=\"user\", cascade=\"all, delete-orphan\"\n    )\n{%- endif %}\n\n    @property\n    def user_role(self) -> UserRole:\n        \"\"\"Get role as enum.\"\"\"\n        return UserRole(self.role)\n\n    def has_role(self, required_role: UserRole) -> bool:\n        \"\"\"Check if user has the required role or higher.\n\n        Admin role has access to everything.\n        \"\"\"\n        if self.role == UserRole.ADMIN.value:\n            return True\n        return self.role == required_role.value\n\n    def __repr__(self) -> str:\n        return f\"<User(id={self.id}, email={self.email}, role={self.role})>\"\n\n\n{%- elif cookiecutter.use_jwt and cookiecutter.use_sqlite and cookiecutter.use_sqlmodel %}\n\"\"\"User database model using SQLModel.\"\"\"\n\nimport uuid\nfrom enum import StrEnum\n{%- if cookiecutter.enable_session_management %}\nfrom typing import TYPE_CHECKING\n{%- endif %}\n\nfrom sqlalchemy import Column, String\nfrom sqlmodel import Field, Relationship, SQLModel\n\nfrom app.db.base import TimestampMixin\n\n{%- if cookiecutter.enable_session_management %}\nif TYPE_CHECKING:\n    from app.db.models.session import Session\n{%- endif %}\n\n\nclass UserRole(StrEnum):\n    \"\"\"User role enumeration.\n\n    Roles hierarchy (higher includes lower permissions):\n    - ADMIN: Full system access, can manage users and settings\n    - USER: Standard user access\n    \"\"\"\n\n    ADMIN = \"admin\"\n    USER = \"user\"\n\n\nclass User(TimestampMixin, SQLModel, table=True):\n    \"\"\"User model.\"\"\"\n\n    __tablename__ = \"users\"\n\n    id: str = Field(\n        default_factory=lambda: str(uuid.uuid4()),\n        sa_column=Column(String(36), primary_key=True),\n    )\n    email: str = Field(\n        sa_column=Column(String(255), unique=True, index=True, nullable=False),\n    )\n    hashed_password: str | None = Field(default=None, max_length=255)\n    full_name: str | None = Field(default=None, max_length=255)\n    is_active: bool = Field(default=True)\n    is_superuser: bool = Field(default=False)\n    role: str = Field(default=UserRole.USER.value, max_length=50)\n{%- if cookiecutter.enable_oauth %}\n    oauth_provider: str | None = Field(default=None, max_length=50)\n    oauth_id: str | None = Field(default=None, max_length=255)\n{%- endif %}\n\n{%- if cookiecutter.enable_session_management %}\n\n    # Relationship to sessions\n    sessions: list[\"Session\"] = Relationship(back_populates=\"user\")\n{%- endif %}\n\n    @property\n    def user_role(self) -> UserRole:\n        \"\"\"Get role as enum.\"\"\"\n        return UserRole(self.role)\n\n    def has_role(self, required_role: UserRole) -> bool:\n        \"\"\"Check if user has the required role or higher.\n\n        Admin role has access to everything.\n        \"\"\"\n        if self.role == UserRole.ADMIN.value:\n            return True\n        return self.role == required_role.value\n\n    def __repr__(self) -> str:\n        return f\"<User(id={self.id}, email={self.email}, role={self.role})>\"\n\n\n{%- elif cookiecutter.use_jwt and cookiecutter.use_sqlite %}\n\"\"\"User database model.\"\"\"\n\nimport uuid\nfrom enum import StrEnum\n{%- if cookiecutter.enable_session_management %}\nfrom typing import TYPE_CHECKING\n{%- endif %}\n\nfrom sqlalchemy import Boolean, String\nfrom sqlalchemy.orm import Mapped, mapped_column{% if cookiecutter.enable_session_management %}, relationship{% endif %}\n\nfrom app.db.base import Base, TimestampMixin\n\n{%- if cookiecutter.enable_session_management %}\nif TYPE_CHECKING:\n    from app.db.models.session import Session\n{%- endif %}\n\n\nclass UserRole(StrEnum):\n    \"\"\"User role enumeration.\n\n    Roles hierarchy (higher includes lower permissions):\n    - ADMIN: Full system access, can manage users and settings\n    - USER: Standard user access\n    \"\"\"\n\n    ADMIN = \"admin\"\n    USER = \"user\"\n\n\nclass User(Base, TimestampMixin):\n    \"\"\"User model.\"\"\"\n\n    __tablename__ = \"users\"\n\n    id: Mapped[str] = mapped_column(\n        String(36), primary_key=True, default=lambda: str(uuid.uuid4())\n    )\n    email: Mapped[str] = mapped_column(String(255), unique=True, index=True, nullable=False)\n    hashed_password: Mapped[str | None] = mapped_column(String(255), nullable=True)\n    full_name: Mapped[str | None] = mapped_column(String(255), nullable=True)\n    is_active: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)\n    is_superuser: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)\n    role: Mapped[str] = mapped_column(String(50), default=UserRole.USER.value, nullable=False)\n{%- if cookiecutter.enable_oauth %}\n    oauth_provider: Mapped[str | None] = mapped_column(String(50), nullable=True, index=True)\n    oauth_id: Mapped[str | None] = mapped_column(String(255), nullable=True, index=True)\n{%- endif %}\n\n{%- if cookiecutter.enable_session_management %}\n\n    # Relationship to sessions\n    sessions: Mapped[list[\"Session\"]] = relationship(\n        \"Session\", back_populates=\"user\", cascade=\"all, delete-orphan\"\n    )\n{%- endif %}\n\n    @property\n    def user_role(self) -> UserRole:\n        \"\"\"Get role as enum.\"\"\"\n        return UserRole(self.role)\n\n    def has_role(self, required_role: UserRole) -> bool:\n        \"\"\"Check if user has the required role or higher.\n\n        Admin role has access to everything.\n        \"\"\"\n        if self.role == UserRole.ADMIN.value:\n            return True\n        return self.role == required_role.value\n\n    def __repr__(self) -> str:\n        return f\"<User(id={self.id}, email={self.email}, role={self.role})>\"\n\n\n{%- elif cookiecutter.use_jwt and cookiecutter.use_mongodb %}\n\"\"\"User document model for MongoDB.\"\"\"\n\nfrom datetime import UTC, datetime\nfrom enum import StrEnum\nfrom typing import Optional\n\nfrom beanie import Document\nfrom pydantic import EmailStr, Field\n\n\nclass UserRole(StrEnum):\n    \"\"\"User role enumeration.\n\n    Roles hierarchy (higher includes lower permissions):\n    - ADMIN: Full system access, can manage users and settings\n    - USER: Standard user access\n    \"\"\"\n\n    ADMIN = \"admin\"\n    USER = \"user\"\n\n\nclass User(Document):\n    \"\"\"User document model.\"\"\"\n\n    email: EmailStr\n    hashed_password: Optional[str] = None\n    full_name: Optional[str] = None\n    is_active: bool = True\n    is_superuser: bool = False\n    role: str = UserRole.USER.value\n{%- if cookiecutter.enable_oauth %}\n    oauth_provider: Optional[str] = None\n    oauth_id: Optional[str] = None\n{%- endif %}\n    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))\n    updated_at: Optional[datetime] = None\n\n    @property\n    def user_role(self) -> UserRole:\n        \"\"\"Get role as enum.\"\"\"\n        return UserRole(self.role)\n\n    def has_role(self, required_role: UserRole) -> bool:\n        \"\"\"Check if user has the required role or higher.\n\n        Admin role has access to everything.\n        \"\"\"\n        if self.role == UserRole.ADMIN.value:\n            return True\n        return self.role == required_role.value\n\n    class Settings:\n        name = \"users\"\n        indexes = [\n            \"email\",\n        ]\n\n\n{%- else %}\n\"\"\"User model - not configured.\"\"\"\n{%- endif %}\n","backend/app/db/models/webhook.py":"{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\n{%- if cookiecutter.use_postgresql and cookiecutter.use_sqlmodel %}\n\"\"\"Webhook database models using SQLModel (PostgreSQL async).\"\"\"\n\nimport uuid\nfrom datetime import datetime\nfrom enum import Enum\n\nfrom sqlalchemy import Column, DateTime, ForeignKey, Integer, String, Text\nfrom sqlalchemy.dialects.postgresql import ARRAY, UUID as PG_UUID\nfrom sqlmodel import Field, Relationship, SQLModel\n\nfrom app.db.base import TimestampMixin\n\n\nclass WebhookEventType(str, Enum):\n    \"\"\"Webhook event types.\"\"\"\n\n    # User events\n    USER_CREATED = \"user.created\"\n    USER_UPDATED = \"user.updated\"\n    USER_DELETED = \"user.deleted\"\n\n    # Custom events (extend as needed)\n    ITEM_CREATED = \"item.created\"\n    ITEM_UPDATED = \"item.updated\"\n    ITEM_DELETED = \"item.deleted\"\n\n\nclass Webhook(TimestampMixin, SQLModel, table=True):\n    \"\"\"Webhook subscription model.\"\"\"\n\n    __tablename__ = \"webhooks\"\n\n    id: uuid.UUID = Field(\n        default_factory=uuid.uuid4,\n        sa_column=Column(PG_UUID(as_uuid=True), primary_key=True),\n    )\n    name: str = Field(max_length=255)\n    url: str = Field(max_length=2048)\n    secret: str = Field(max_length=255)\n    events: list[str] = Field(sa_column=Column(ARRAY(String), nullable=False))\n    is_active: bool = Field(default=True)\n    description: str | None = Field(default=None, sa_column=Column(Text, nullable=True))\n\n{%- if cookiecutter.use_jwt %}\n    user_id: uuid.UUID | None = Field(\n        default=None,\n        sa_column=Column(PG_UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True),\n    )\n{%- endif %}\n\n    # Relationship to delivery logs\n    deliveries: list[\"WebhookDelivery\"] = Relationship(\n        back_populates=\"webhook\",\n        sa_relationship_kwargs={\"cascade\": \"all, delete-orphan\"},\n    )\n\n\nclass WebhookDelivery(SQLModel, table=True):\n    \"\"\"Webhook delivery log model.\"\"\"\n\n    __tablename__ = \"webhook_deliveries\"\n\n    id: uuid.UUID = Field(\n        default_factory=uuid.uuid4,\n        sa_column=Column(PG_UUID(as_uuid=True), primary_key=True),\n    )\n    webhook_id: uuid.UUID = Field(\n        sa_column=Column(PG_UUID(as_uuid=True), ForeignKey(\"webhooks.id\"), nullable=False),\n    )\n    event_type: str = Field(max_length=100)\n    payload: str = Field(sa_column=Column(Text, nullable=False))\n    response_status: int | None = Field(default=None)\n    response_body: str | None = Field(default=None, sa_column=Column(Text, nullable=True))\n    error_message: str | None = Field(default=None, sa_column=Column(Text, nullable=True))\n    attempt_count: int = Field(default=1)\n    success: bool = Field(default=False)\n    created_at: datetime = Field(sa_column=Column(DateTime, nullable=False))\n    delivered_at: datetime | None = Field(\n        default=None,\n        sa_column=Column(DateTime, nullable=True),\n    )\n\n    # Relationship\n    webhook: \"Webhook\" = Relationship(back_populates=\"deliveries\")\n\n\n{%- elif cookiecutter.use_postgresql %}\n\"\"\"Webhook database models (PostgreSQL async).\"\"\"\n\nimport uuid\nfrom datetime import datetime\nfrom enum import Enum\n\nfrom sqlalchemy import Boolean, DateTime, ForeignKey, Integer, String, Text\nfrom sqlalchemy.dialects.postgresql import ARRAY, UUID\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom app.db.base import Base, TimestampMixin\n\n\nclass WebhookEventType(str, Enum):\n    \"\"\"Webhook event types.\"\"\"\n\n    # User events\n    USER_CREATED = \"user.created\"\n    USER_UPDATED = \"user.updated\"\n    USER_DELETED = \"user.deleted\"\n\n    # Custom events (extend as needed)\n    ITEM_CREATED = \"item.created\"\n    ITEM_UPDATED = \"item.updated\"\n    ITEM_DELETED = \"item.deleted\"\n\n\nclass Webhook(Base, TimestampMixin):\n    \"\"\"Webhook subscription model.\"\"\"\n\n    __tablename__ = \"webhooks\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n    name: Mapped[str] = mapped_column(String(255), nullable=False)\n    url: Mapped[str] = mapped_column(String(2048), nullable=False)\n    secret: Mapped[str] = mapped_column(String(255), nullable=False)\n    events: Mapped[list[str]] = mapped_column(ARRAY(String), nullable=False)\n    is_active: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)\n    description: Mapped[str | None] = mapped_column(Text, nullable=True)\n\n    # Optional: Associate webhook with a user\n{%- if cookiecutter.use_jwt %}\n    user_id: Mapped[uuid.UUID | None] = mapped_column(\n        UUID(as_uuid=True), ForeignKey(\"users.id\"), nullable=True\n    )\n{%- endif %}\n\n    # Relationship to delivery logs\n    deliveries: Mapped[list[\"WebhookDelivery\"]] = relationship(\n        \"WebhookDelivery\", back_populates=\"webhook\", cascade=\"all, delete-orphan\"\n    )\n\n\nclass WebhookDelivery(Base):\n    \"\"\"Webhook delivery log model.\"\"\"\n\n    __tablename__ = \"webhook_deliveries\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n    webhook_id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True), ForeignKey(\"webhooks.id\"), nullable=False\n    )\n    event_type: Mapped[str] = mapped_column(String(100), nullable=False)\n    payload: Mapped[str] = mapped_column(Text, nullable=False)\n    response_status: Mapped[int | None] = mapped_column(Integer, nullable=True)\n    response_body: Mapped[str | None] = mapped_column(Text, nullable=True)\n    error_message: Mapped[str | None] = mapped_column(Text, nullable=True)\n    attempt_count: Mapped[int] = mapped_column(Integer, default=1, nullable=False)\n    success: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime, default=datetime.utcnow, nullable=False\n    )\n    delivered_at: Mapped[datetime | None] = mapped_column(DateTime, nullable=True)\n\n    # Relationship\n    webhook: Mapped[\"Webhook\"] = relationship(\"Webhook\", back_populates=\"deliveries\")\n\n\n{%- elif cookiecutter.use_sqlite and cookiecutter.use_sqlmodel %}\n\"\"\"Webhook database models using SQLModel (SQLite sync).\"\"\"\n\nimport json\nimport uuid\nfrom datetime import datetime\nfrom enum import Enum\n\nfrom sqlalchemy import Column, DateTime, ForeignKey, Integer, String, Text\nfrom sqlmodel import Field, Relationship, SQLModel\n\nfrom app.db.base import TimestampMixin\n\n\nclass WebhookEventType(str, Enum):\n    \"\"\"Webhook event types.\"\"\"\n\n    # User events\n    USER_CREATED = \"user.created\"\n    USER_UPDATED = \"user.updated\"\n    USER_DELETED = \"user.deleted\"\n\n    # Custom events (extend as needed)\n    ITEM_CREATED = \"item.created\"\n    ITEM_UPDATED = \"item.updated\"\n    ITEM_DELETED = \"item.deleted\"\n\n\nclass Webhook(TimestampMixin, SQLModel, table=True):\n    \"\"\"Webhook subscription model.\"\"\"\n\n    __tablename__ = \"webhooks\"\n\n    id: str = Field(\n        default_factory=lambda: str(uuid.uuid4()),\n        sa_column=Column(String(36), primary_key=True),\n    )\n    name: str = Field(max_length=255)\n    url: str = Field(max_length=2048)\n    secret: str = Field(max_length=255)\n    # Store events as JSON string for SQLite\n    events_json: str = Field(sa_column=Column(Text, nullable=False))\n    is_active: bool = Field(default=True)\n    description: str | None = Field(default=None, sa_column=Column(Text, nullable=True))\n\n{%- if cookiecutter.use_jwt %}\n    user_id: str | None = Field(\n        default=None,\n        sa_column=Column(String(36), ForeignKey(\"users.id\"), nullable=True),\n    )\n{%- endif %}\n\n    deliveries: list[\"WebhookDelivery\"] = Relationship(\n        back_populates=\"webhook\",\n        sa_relationship_kwargs={\"cascade\": \"all, delete-orphan\"},\n    )\n\n    @property\n    def events(self) -> list[str]:\n        \"\"\"Parse events from JSON string.\"\"\"\n        return json.loads(self.events_json) if self.events_json else []\n\n    @events.setter\n    def events(self, value: list[str]) -> None:\n        \"\"\"Store events as JSON string.\"\"\"\n        self.events_json = json.dumps(value)\n\n\nclass WebhookDelivery(SQLModel, table=True):\n    \"\"\"Webhook delivery log model.\"\"\"\n\n    __tablename__ = \"webhook_deliveries\"\n\n    id: str = Field(\n        default_factory=lambda: str(uuid.uuid4()),\n        sa_column=Column(String(36), primary_key=True),\n    )\n    webhook_id: str = Field(\n        sa_column=Column(String(36), ForeignKey(\"webhooks.id\"), nullable=False),\n    )\n    event_type: str = Field(max_length=100)\n    payload: str = Field(sa_column=Column(Text, nullable=False))\n    response_status: int | None = Field(default=None)\n    response_body: str | None = Field(default=None, sa_column=Column(Text, nullable=True))\n    error_message: str | None = Field(default=None, sa_column=Column(Text, nullable=True))\n    attempt_count: int = Field(default=1)\n    success: bool = Field(default=False)\n    created_at: datetime = Field(sa_column=Column(DateTime, nullable=False))\n    delivered_at: datetime | None = Field(\n        default=None,\n        sa_column=Column(DateTime, nullable=True),\n    )\n\n    webhook: \"Webhook\" = Relationship(back_populates=\"deliveries\")\n\n\n{%- elif cookiecutter.use_sqlite %}\n\"\"\"Webhook database models (SQLite sync).\"\"\"\n\nimport json\nimport uuid\nfrom datetime import datetime\nfrom enum import Enum\n\nfrom sqlalchemy import Boolean, DateTime, ForeignKey, Integer, String, Text\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom app.db.base import Base, TimestampMixin\n\n\nclass WebhookEventType(str, Enum):\n    \"\"\"Webhook event types.\"\"\"\n\n    # User events\n    USER_CREATED = \"user.created\"\n    USER_UPDATED = \"user.updated\"\n    USER_DELETED = \"user.deleted\"\n\n    # Custom events (extend as needed)\n    ITEM_CREATED = \"item.created\"\n    ITEM_UPDATED = \"item.updated\"\n    ITEM_DELETED = \"item.deleted\"\n\n\nclass Webhook(Base, TimestampMixin):\n    \"\"\"Webhook subscription model.\"\"\"\n\n    __tablename__ = \"webhooks\"\n\n    id: Mapped[str] = mapped_column(\n        String(36), primary_key=True, default=lambda: str(uuid.uuid4())\n    )\n    name: Mapped[str] = mapped_column(String(255), nullable=False)\n    url: Mapped[str] = mapped_column(String(2048), nullable=False)\n    secret: Mapped[str] = mapped_column(String(255), nullable=False)\n    # Store events as comma-separated string for SQLite\n    events_json: Mapped[str] = mapped_column(Text, nullable=False)\n    is_active: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)\n    description: Mapped[str | None] = mapped_column(Text, nullable=True)\n\n{%- if cookiecutter.use_jwt %}\n    user_id: Mapped[str | None] = mapped_column(\n        String(36), ForeignKey(\"users.id\"), nullable=True\n    )\n{%- endif %}\n\n    deliveries: Mapped[list[\"WebhookDelivery\"]] = relationship(\n        \"WebhookDelivery\", back_populates=\"webhook\", cascade=\"all, delete-orphan\"\n    )\n\n    @property\n    def events(self) -> list[str]:\n        \"\"\"Parse events from JSON string.\"\"\"\n        return json.loads(self.events_json) if self.events_json else []\n\n    @events.setter\n    def events(self, value: list[str]) -> None:\n        \"\"\"Store events as JSON string.\"\"\"\n        self.events_json = json.dumps(value)\n\n\nclass WebhookDelivery(Base):\n    \"\"\"Webhook delivery log model.\"\"\"\n\n    __tablename__ = \"webhook_deliveries\"\n\n    id: Mapped[str] = mapped_column(\n        String(36), primary_key=True, default=lambda: str(uuid.uuid4())\n    )\n    webhook_id: Mapped[str] = mapped_column(\n        String(36), ForeignKey(\"webhooks.id\"), nullable=False\n    )\n    event_type: Mapped[str] = mapped_column(String(100), nullable=False)\n    payload: Mapped[str] = mapped_column(Text, nullable=False)\n    response_status: Mapped[int | None] = mapped_column(Integer, nullable=True)\n    response_body: Mapped[str | None] = mapped_column(Text, nullable=True)\n    error_message: Mapped[str | None] = mapped_column(Text, nullable=True)\n    attempt_count: Mapped[int] = mapped_column(Integer, default=1, nullable=False)\n    success: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime, default=datetime.utcnow, nullable=False\n    )\n    delivered_at: Mapped[datetime | None] = mapped_column(DateTime, nullable=True)\n\n    webhook: Mapped[\"Webhook\"] = relationship(\"Webhook\", back_populates=\"deliveries\")\n\n\n{%- elif cookiecutter.use_mongodb %}\n\"\"\"Webhook document models (MongoDB).\"\"\"\n\nfrom datetime import UTC, datetime\nfrom enum import Enum\nfrom typing import Optional\n\nfrom beanie import Document\nfrom pydantic import Field\n\n\nclass WebhookEventType(str, Enum):\n    \"\"\"Webhook event types.\"\"\"\n\n    # User events\n    USER_CREATED = \"user.created\"\n    USER_UPDATED = \"user.updated\"\n    USER_DELETED = \"user.deleted\"\n\n    # Custom events\n    ITEM_CREATED = \"item.created\"\n    ITEM_UPDATED = \"item.updated\"\n    ITEM_DELETED = \"item.deleted\"\n\n\nclass WebhookDelivery(Document):\n    \"\"\"Webhook delivery log document.\"\"\"\n\n    webhook_id: str\n    event_type: str\n    payload: str\n    response_status: Optional[int] = None\n    response_body: Optional[str] = None\n    error_message: Optional[str] = None\n    attempt_count: int = 1\n    success: bool = False\n    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))\n    delivered_at: Optional[datetime] = None\n\n    class Settings:\n        name = \"webhook_deliveries\"\n        indexes = [\"webhook_id\", \"event_type\", \"created_at\"]\n\n\nclass Webhook(Document):\n    \"\"\"Webhook subscription document.\"\"\"\n\n    name: str\n    url: str\n    secret: str\n    events: list[str]\n    is_active: bool = True\n    description: Optional[str] = None\n{%- if cookiecutter.use_jwt %}\n    user_id: Optional[str] = None\n{%- endif %}\n    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))\n    updated_at: Optional[datetime] = None\n\n    class Settings:\n        name = \"webhooks\"\n        indexes = [\"events\", \"is_active\"]\n\n\n{%- endif %}\n{%- else %}\n\"\"\"Webhook models - not configured.\"\"\"\n{%- endif %}\n","backend/app/db/models/conversation.py":"{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_postgresql and cookiecutter.use_sqlmodel %}\n\"\"\"Conversation and message models for AI chat persistence using SQLModel.\"\"\"\n\nimport uuid\nfrom datetime import datetime\nfrom typing import TYPE_CHECKING\n\nfrom sqlalchemy import Column, DateTime, ForeignKey, Integer, String, Text\nfrom sqlalchemy.dialects.postgresql import JSONB, UUID as PG_UUID\nfrom sqlmodel import Field, Relationship, SQLModel\n\nfrom app.db.base import TimestampMixin\n\n\nclass Conversation(TimestampMixin, SQLModel, table=True):\n    \"\"\"Conversation model - groups messages in a chat session.\n\n    Attributes:\n        id: Unique conversation identifier\n        user_id: Optional user who owns this conversation (if auth enabled)\n        title: Auto-generated or user-defined title\n        is_archived: Whether the conversation is archived\n        messages: List of messages in this conversation\n    \"\"\"\n\n    __tablename__ = \"conversations\"\n\n    id: uuid.UUID = Field(\n        default_factory=uuid.uuid4,\n        sa_column=Column(PG_UUID(as_uuid=True), primary_key=True),\n    )\n{%- if cookiecutter.use_jwt %}\n    user_id: uuid.UUID | None = Field(\n        default=None,\n        sa_column=Column(\n            PG_UUID(as_uuid=True),\n            ForeignKey(\"users.id\", ondelete=\"CASCADE\"),\n            nullable=True,\n            index=True,\n        ),\n    )\n{%- endif %}\n    title: str | None = Field(default=None, max_length=255)\n    is_archived: bool = Field(default=False)\n\n    # Relationships\n    messages: list[\"Message\"] = Relationship(\n        back_populates=\"conversation\",\n        sa_relationship_kwargs={\"cascade\": \"all, delete-orphan\", \"order_by\": \"Message.created_at\"},\n    )\n\n    def __repr__(self) -> str:\n        return f\"<Conversation(id={self.id}, title={self.title})>\"\n\n\nclass Message(TimestampMixin, SQLModel, table=True):\n    \"\"\"Message model - individual message in a conversation.\n\n    Attributes:\n        id: Unique message identifier\n        conversation_id: The conversation this message belongs to\n        role: Message role (user, assistant, system)\n        content: Message text content\n        model_name: AI model used (for assistant messages)\n        tokens_used: Token count for this message\n        tool_calls: List of tool calls made in this message\n    \"\"\"\n\n    __tablename__ = \"messages\"\n\n    id: uuid.UUID = Field(\n        default_factory=uuid.uuid4,\n        sa_column=Column(PG_UUID(as_uuid=True), primary_key=True),\n    )\n    conversation_id: uuid.UUID = Field(\n        sa_column=Column(\n            PG_UUID(as_uuid=True),\n            ForeignKey(\"conversations.id\", ondelete=\"CASCADE\"),\n            nullable=False,\n            index=True,\n        ),\n    )\n    role: str = Field(max_length=20)  # user, assistant, system\n    content: str = Field(sa_column=Column(Text, nullable=False))\n    model_name: str | None = Field(default=None, max_length=100)\n    tokens_used: int | None = Field(default=None)\n\n    # Relationships\n    conversation: \"Conversation\" = Relationship(back_populates=\"messages\")\n    tool_calls: list[\"ToolCall\"] = Relationship(\n        back_populates=\"message\",\n        sa_relationship_kwargs={\"cascade\": \"all, delete-orphan\", \"order_by\": \"ToolCall.started_at\"},\n    )\n\n    def __repr__(self) -> str:\n        return f\"<Message(id={self.id}, role={self.role})>\"\n\n\nclass ToolCall(SQLModel, table=True):\n    \"\"\"ToolCall model - record of a tool invocation.\n\n    Attributes:\n        id: Unique tool call identifier\n        message_id: The assistant message that triggered this call\n        tool_call_id: External ID from PydanticAI\n        tool_name: Name of the tool that was called\n        args: JSON arguments passed to the tool\n        result: Result returned by the tool\n        status: Current status (pending, running, completed, failed)\n        started_at: When the tool call started\n        completed_at: When the tool call completed\n        duration_ms: Execution time in milliseconds\n    \"\"\"\n\n    __tablename__ = \"tool_calls\"\n\n    id: uuid.UUID = Field(\n        default_factory=uuid.uuid4,\n        sa_column=Column(PG_UUID(as_uuid=True), primary_key=True),\n    )\n    message_id: uuid.UUID = Field(\n        sa_column=Column(\n            PG_UUID(as_uuid=True),\n            ForeignKey(\"messages.id\", ondelete=\"CASCADE\"),\n            nullable=False,\n            index=True,\n        ),\n    )\n    tool_call_id: str = Field(max_length=100)\n    tool_name: str = Field(max_length=100)\n    args: dict = Field(default_factory=dict, sa_column=Column(JSONB, nullable=False, default=dict))\n    result: str | None = Field(default=None, sa_column=Column(Text, nullable=True))\n    status: str = Field(default=\"pending\", max_length=20)  # pending, running, completed, failed\n    started_at: datetime = Field(sa_column=Column(DateTime(timezone=True), nullable=False))\n    completed_at: datetime | None = Field(\n        default=None,\n        sa_column=Column(DateTime(timezone=True), nullable=True),\n    )\n    duration_ms: int | None = Field(default=None)\n\n    # Relationships\n    message: \"Message\" = Relationship(back_populates=\"tool_calls\")\n\n    def __repr__(self) -> str:\n        return f\"<ToolCall(id={self.id}, tool_name={self.tool_name}, status={self.status})>\"\n\n\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_postgresql %}\n\"\"\"Conversation and message models for AI chat persistence.\"\"\"\n\nimport uuid\nfrom datetime import datetime\nfrom typing import Literal\n\nfrom sqlalchemy import Boolean, DateTime, ForeignKey, Integer, String, Text\nfrom sqlalchemy.dialects.postgresql import JSONB, UUID\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom app.db.base import Base, TimestampMixin\n\n\nclass Conversation(Base, TimestampMixin):\n    \"\"\"Conversation model - groups messages in a chat session.\n\n    Attributes:\n        id: Unique conversation identifier\n        user_id: Optional user who owns this conversation (if auth enabled)\n        title: Auto-generated or user-defined title\n        is_archived: Whether the conversation is archived\n        messages: List of messages in this conversation\n    \"\"\"\n\n    __tablename__ = \"conversations\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n{%- if cookiecutter.use_jwt %}\n    user_id: Mapped[uuid.UUID | None] = mapped_column(\n        UUID(as_uuid=True),\n        ForeignKey(\"users.id\", ondelete=\"CASCADE\"),\n        nullable=True,\n        index=True,\n    )\n{%- endif %}\n    title: Mapped[str | None] = mapped_column(String(255), nullable=True)\n    is_archived: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)\n\n    # Relationships\n    messages: Mapped[list[\"Message\"]] = relationship(\n        \"Message\",\n        back_populates=\"conversation\",\n        cascade=\"all, delete-orphan\",\n        order_by=\"Message.created_at\",\n    )\n\n    def __repr__(self) -> str:\n        return f\"<Conversation(id={self.id}, title={self.title})>\"\n\n\nclass Message(Base, TimestampMixin):\n    \"\"\"Message model - individual message in a conversation.\n\n    Attributes:\n        id: Unique message identifier\n        conversation_id: The conversation this message belongs to\n        role: Message role (user, assistant, system)\n        content: Message text content\n        model_name: AI model used (for assistant messages)\n        tokens_used: Token count for this message\n        tool_calls: List of tool calls made in this message\n    \"\"\"\n\n    __tablename__ = \"messages\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n    conversation_id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True),\n        ForeignKey(\"conversations.id\", ondelete=\"CASCADE\"),\n        nullable=False,\n        index=True,\n    )\n    role: Mapped[str] = mapped_column(\n        String(20), nullable=False\n    )  # user, assistant, system\n    content: Mapped[str] = mapped_column(Text, nullable=False)\n    model_name: Mapped[str | None] = mapped_column(String(100), nullable=True)\n    tokens_used: Mapped[int | None] = mapped_column(Integer, nullable=True)\n\n    # Relationships\n    conversation: Mapped[\"Conversation\"] = relationship(\n        \"Conversation\", back_populates=\"messages\"\n    )\n    tool_calls: Mapped[list[\"ToolCall\"]] = relationship(\n        \"ToolCall\",\n        back_populates=\"message\",\n        cascade=\"all, delete-orphan\",\n        order_by=\"ToolCall.started_at\",\n    )\n\n    def __repr__(self) -> str:\n        return f\"<Message(id={self.id}, role={self.role})>\"\n\n\nclass ToolCall(Base):\n    \"\"\"ToolCall model - record of a tool invocation.\n\n    Attributes:\n        id: Unique tool call identifier\n        message_id: The assistant message that triggered this call\n        tool_call_id: External ID from PydanticAI\n        tool_name: Name of the tool that was called\n        args: JSON arguments passed to the tool\n        result: Result returned by the tool\n        status: Current status (pending, running, completed, failed)\n        started_at: When the tool call started\n        completed_at: When the tool call completed\n        duration_ms: Execution time in milliseconds\n    \"\"\"\n\n    __tablename__ = \"tool_calls\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n    message_id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True),\n        ForeignKey(\"messages.id\", ondelete=\"CASCADE\"),\n        nullable=False,\n        index=True,\n    )\n    tool_call_id: Mapped[str] = mapped_column(String(100), nullable=False)\n    tool_name: Mapped[str] = mapped_column(String(100), nullable=False)\n    args: Mapped[dict] = mapped_column(JSONB, nullable=False, default=dict)\n    result: Mapped[str | None] = mapped_column(Text, nullable=True)\n    status: Mapped[str] = mapped_column(\n        String(20), nullable=False, default=\"pending\"\n    )  # pending, running, completed, failed\n    started_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), nullable=False\n    )\n    completed_at: Mapped[datetime | None] = mapped_column(\n        DateTime(timezone=True), nullable=True\n    )\n    duration_ms: Mapped[int | None] = mapped_column(Integer, nullable=True)\n\n    # Relationships\n    message: Mapped[\"Message\"] = relationship(\"Message\", back_populates=\"tool_calls\")\n\n    def __repr__(self) -> str:\n        return f\"<ToolCall(id={self.id}, tool_name={self.tool_name}, status={self.status})>\"\n\n\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_sqlite and cookiecutter.use_sqlmodel %}\n\"\"\"Conversation and message models for AI chat persistence using SQLModel.\"\"\"\n\nimport uuid\nfrom datetime import datetime\n\nfrom sqlalchemy import Column, DateTime, ForeignKey, Integer, String, Text\nfrom sqlmodel import Field, Relationship, SQLModel\n\nfrom app.db.base import TimestampMixin\n\n\nclass Conversation(TimestampMixin, SQLModel, table=True):\n    \"\"\"Conversation model - groups messages in a chat session.\"\"\"\n\n    __tablename__ = \"conversations\"\n\n    id: str = Field(\n        default_factory=lambda: str(uuid.uuid4()),\n        sa_column=Column(String(36), primary_key=True),\n    )\n{%- if cookiecutter.use_jwt %}\n    user_id: str | None = Field(\n        default=None,\n        sa_column=Column(\n            String(36),\n            ForeignKey(\"users.id\", ondelete=\"CASCADE\"),\n            nullable=True,\n            index=True,\n        ),\n    )\n{%- endif %}\n    title: str | None = Field(default=None, max_length=255)\n    is_archived: bool = Field(default=False)\n\n    # Relationships\n    messages: list[\"Message\"] = Relationship(\n        back_populates=\"conversation\",\n        sa_relationship_kwargs={\"cascade\": \"all, delete-orphan\", \"order_by\": \"Message.created_at\"},\n    )\n\n    def __repr__(self) -> str:\n        return f\"<Conversation(id={self.id}, title={self.title})>\"\n\n\nclass Message(TimestampMixin, SQLModel, table=True):\n    \"\"\"Message model - individual message in a conversation.\"\"\"\n\n    __tablename__ = \"messages\"\n\n    id: str = Field(\n        default_factory=lambda: str(uuid.uuid4()),\n        sa_column=Column(String(36), primary_key=True),\n    )\n    conversation_id: str = Field(\n        sa_column=Column(\n            String(36),\n            ForeignKey(\"conversations.id\", ondelete=\"CASCADE\"),\n            nullable=False,\n            index=True,\n        ),\n    )\n    role: str = Field(max_length=20)\n    content: str = Field(sa_column=Column(Text, nullable=False))\n    model_name: str | None = Field(default=None, max_length=100)\n    tokens_used: int | None = Field(default=None)\n\n    # Relationships\n    conversation: \"Conversation\" = Relationship(back_populates=\"messages\")\n    tool_calls: list[\"ToolCall\"] = Relationship(\n        back_populates=\"message\",\n        sa_relationship_kwargs={\"cascade\": \"all, delete-orphan\", \"order_by\": \"ToolCall.started_at\"},\n    )\n\n    def __repr__(self) -> str:\n        return f\"<Message(id={self.id}, role={self.role})>\"\n\n\nclass ToolCall(SQLModel, table=True):\n    \"\"\"ToolCall model - record of a tool invocation.\"\"\"\n\n    __tablename__ = \"tool_calls\"\n\n    id: str = Field(\n        default_factory=lambda: str(uuid.uuid4()),\n        sa_column=Column(String(36), primary_key=True),\n    )\n    message_id: str = Field(\n        sa_column=Column(\n            String(36),\n            ForeignKey(\"messages.id\", ondelete=\"CASCADE\"),\n            nullable=False,\n            index=True,\n        ),\n    )\n    tool_call_id: str = Field(max_length=100)\n    tool_name: str = Field(max_length=100)\n    args: str = Field(default=\"{}\", sa_column=Column(Text, nullable=False, default=\"{}\"))  # JSON as string\n    result: str | None = Field(default=None, sa_column=Column(Text, nullable=True))\n    status: str = Field(default=\"pending\", max_length=20)\n    started_at: datetime = Field(sa_column=Column(DateTime, nullable=False))\n    completed_at: datetime | None = Field(\n        default=None,\n        sa_column=Column(DateTime, nullable=True),\n    )\n    duration_ms: int | None = Field(default=None)\n\n    # Relationships\n    message: \"Message\" = Relationship(back_populates=\"tool_calls\")\n\n    def __repr__(self) -> str:\n        return f\"<ToolCall(id={self.id}, tool_name={self.tool_name})>\"\n\n\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_sqlite %}\n\"\"\"Conversation and message models for AI chat persistence.\"\"\"\n\nimport uuid\nfrom datetime import datetime\n\nfrom sqlalchemy import Boolean, DateTime, ForeignKey, Integer, String, Text\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom app.db.base import Base, TimestampMixin\n\n\nclass Conversation(Base, TimestampMixin):\n    \"\"\"Conversation model - groups messages in a chat session.\"\"\"\n\n    __tablename__ = \"conversations\"\n\n    id: Mapped[str] = mapped_column(\n        String(36), primary_key=True, default=lambda: str(uuid.uuid4())\n    )\n{%- if cookiecutter.use_jwt %}\n    user_id: Mapped[str | None] = mapped_column(\n        String(36),\n        ForeignKey(\"users.id\", ondelete=\"CASCADE\"),\n        nullable=True,\n        index=True,\n    )\n{%- endif %}\n    title: Mapped[str | None] = mapped_column(String(255), nullable=True)\n    is_archived: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)\n\n    # Relationships\n    messages: Mapped[list[\"Message\"]] = relationship(\n        \"Message\",\n        back_populates=\"conversation\",\n        cascade=\"all, delete-orphan\",\n        order_by=\"Message.created_at\",\n    )\n\n    def __repr__(self) -> str:\n        return f\"<Conversation(id={self.id}, title={self.title})>\"\n\n\nclass Message(Base, TimestampMixin):\n    \"\"\"Message model - individual message in a conversation.\"\"\"\n\n    __tablename__ = \"messages\"\n\n    id: Mapped[str] = mapped_column(\n        String(36), primary_key=True, default=lambda: str(uuid.uuid4())\n    )\n    conversation_id: Mapped[str] = mapped_column(\n        String(36),\n        ForeignKey(\"conversations.id\", ondelete=\"CASCADE\"),\n        nullable=False,\n        index=True,\n    )\n    role: Mapped[str] = mapped_column(String(20), nullable=False)\n    content: Mapped[str] = mapped_column(Text, nullable=False)\n    model_name: Mapped[str | None] = mapped_column(String(100), nullable=True)\n    tokens_used: Mapped[int | None] = mapped_column(Integer, nullable=True)\n\n    # Relationships\n    conversation: Mapped[\"Conversation\"] = relationship(\n        \"Conversation\", back_populates=\"messages\"\n    )\n    tool_calls: Mapped[list[\"ToolCall\"]] = relationship(\n        \"ToolCall\",\n        back_populates=\"message\",\n        cascade=\"all, delete-orphan\",\n        order_by=\"ToolCall.started_at\",\n    )\n\n    def __repr__(self) -> str:\n        return f\"<Message(id={self.id}, role={self.role})>\"\n\n\nclass ToolCall(Base):\n    \"\"\"ToolCall model - record of a tool invocation.\"\"\"\n\n    __tablename__ = \"tool_calls\"\n\n    id: Mapped[str] = mapped_column(\n        String(36), primary_key=True, default=lambda: str(uuid.uuid4())\n    )\n    message_id: Mapped[str] = mapped_column(\n        String(36),\n        ForeignKey(\"messages.id\", ondelete=\"CASCADE\"),\n        nullable=False,\n        index=True,\n    )\n    tool_call_id: Mapped[str] = mapped_column(String(100), nullable=False)\n    tool_name: Mapped[str] = mapped_column(String(100), nullable=False)\n    args: Mapped[str] = mapped_column(Text, nullable=False, default=\"{}\")  # JSON as string\n    result: Mapped[str | None] = mapped_column(Text, nullable=True)\n    status: Mapped[str] = mapped_column(String(20), nullable=False, default=\"pending\")\n    started_at: Mapped[datetime] = mapped_column(DateTime, nullable=False)\n    completed_at: Mapped[datetime | None] = mapped_column(DateTime, nullable=True)\n    duration_ms: Mapped[int | None] = mapped_column(Integer, nullable=True)\n\n    # Relationships\n    message: Mapped[\"Message\"] = relationship(\"Message\", back_populates=\"tool_calls\")\n\n    def __repr__(self) -> str:\n        return f\"<ToolCall(id={self.id}, tool_name={self.tool_name})>\"\n\n\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n\"\"\"Conversation and message models for AI chat persistence (MongoDB).\"\"\"\n\nfrom datetime import UTC, datetime\nfrom typing import Literal, Optional\n\nfrom beanie import Document, Link\nfrom pydantic import Field\n\n\nclass ToolCall(Document):\n    \"\"\"ToolCall document model - record of a tool invocation.\"\"\"\n\n    message_id: str\n    tool_call_id: str\n    tool_name: str\n    args: dict = Field(default_factory=dict)\n    result: Optional[str] = None\n    status: Literal[\"pending\", \"running\", \"completed\", \"failed\"] = \"pending\"\n    started_at: datetime = Field(default_factory=lambda: datetime.now(UTC))\n    completed_at: Optional[datetime] = None\n    duration_ms: Optional[int] = None\n\n    class Settings:\n        name = \"tool_calls\"\n        indexes = [\"message_id\"]\n\n\nclass Message(Document):\n    \"\"\"Message document model - individual message in a conversation.\"\"\"\n\n    conversation_id: str\n    role: Literal[\"user\", \"assistant\", \"system\"]\n    content: str\n    model_name: Optional[str] = None\n    tokens_used: Optional[int] = None\n    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))\n\n    class Settings:\n        name = \"messages\"\n        indexes = [\"conversation_id\"]\n\n\nclass Conversation(Document):\n    \"\"\"Conversation document model - groups messages in a chat session.\"\"\"\n\n{%- if cookiecutter.use_jwt %}\n    user_id: Optional[str] = None\n{%- endif %}\n    title: Optional[str] = None\n    is_archived: bool = False\n    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))\n    updated_at: Optional[datetime] = None\n\n    class Settings:\n        name = \"conversations\"\n{%- if cookiecutter.use_jwt %}\n        indexes = [\"user_id\"]\n{%- endif %}\n\n\n{%- else %}\n\"\"\"Conversation models - not configured.\"\"\"\n{%- endif %}\n","backend/app/db/models/session.py":"{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\n{%- if cookiecutter.use_postgresql and cookiecutter.use_sqlmodel %}\n\"\"\"Session database model for tracking user sessions using SQLModel.\"\"\"\n\nimport uuid\nfrom datetime import datetime\n\nfrom sqlalchemy import Column, DateTime, ForeignKey, String, Text\nfrom sqlalchemy.dialects.postgresql import UUID as PG_UUID\nfrom sqlmodel import Field, Relationship, SQLModel\n\n\nclass Session(SQLModel, table=True):\n    \"\"\"User session model for tracking active login sessions.\"\"\"\n\n    __tablename__ = \"sessions\"\n\n    id: uuid.UUID = Field(\n        default_factory=uuid.uuid4,\n        sa_column=Column(PG_UUID(as_uuid=True), primary_key=True),\n    )\n    user_id: uuid.UUID = Field(\n        sa_column=Column(\n            PG_UUID(as_uuid=True),\n            ForeignKey(\"users.id\", ondelete=\"CASCADE\"),\n            nullable=False,\n        ),\n    )\n    refresh_token_hash: str = Field(\n        sa_column=Column(String(255), nullable=False, index=True),\n    )\n    device_name: str | None = Field(default=None, max_length=255)\n    device_type: str | None = Field(default=None, max_length=50)\n    ip_address: str | None = Field(default=None, max_length=45)\n    user_agent: str | None = Field(default=None, sa_column=Column(Text, nullable=True))\n    is_active: bool = Field(default=True)\n    created_at: datetime = Field(\n        default_factory=datetime.utcnow,\n        sa_column=Column(DateTime(timezone=True), nullable=False),\n    )\n    last_used_at: datetime = Field(\n        default_factory=datetime.utcnow,\n        sa_column=Column(DateTime(timezone=True), nullable=False),\n    )\n    expires_at: datetime = Field(\n        sa_column=Column(DateTime(timezone=True), nullable=False),\n    )\n\n    # Relationship\n    user: \"User\" = Relationship(back_populates=\"sessions\")\n\n    def __repr__(self) -> str:\n        return f\"<Session(id={self.id}, user_id={self.user_id}, device={self.device_name})>\"\n\n\n# Forward reference for type hints\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from app.db.models.user import User\n\n\n{%- elif cookiecutter.use_postgresql %}\n\"\"\"Session database model for tracking user sessions.\"\"\"\n\nimport uuid\nfrom datetime import datetime\n\nfrom sqlalchemy import Boolean, DateTime, ForeignKey, String, Text\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom app.db.base import Base\n\n\nclass Session(Base):\n    \"\"\"User session model for tracking active login sessions.\"\"\"\n\n    __tablename__ = \"sessions\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n    user_id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True), ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False\n    )\n    refresh_token_hash: Mapped[str] = mapped_column(String(255), nullable=False, index=True)\n    device_name: Mapped[str | None] = mapped_column(String(255), nullable=True)\n    device_type: Mapped[str | None] = mapped_column(String(50), nullable=True)\n    ip_address: Mapped[str | None] = mapped_column(String(45), nullable=True)\n    user_agent: Mapped[str | None] = mapped_column(Text, nullable=True)\n    is_active: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), default=datetime.utcnow, nullable=False\n    )\n    last_used_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), default=datetime.utcnow, nullable=False\n    )\n    expires_at: Mapped[datetime] = mapped_column(DateTime(timezone=True), nullable=False)\n\n    # Relationship\n    user = relationship(\"User\", back_populates=\"sessions\")\n\n    def __repr__(self) -> str:\n        return f\"<Session(id={self.id}, user_id={self.user_id}, device={self.device_name})>\"\n\n\n{%- elif cookiecutter.use_sqlite and cookiecutter.use_sqlmodel %}\n\"\"\"Session database model for tracking user sessions using SQLModel.\"\"\"\n\nimport uuid\nfrom datetime import datetime\n\nfrom sqlalchemy import Column, DateTime, ForeignKey, String, Text\nfrom sqlmodel import Field, Relationship, SQLModel\n\n\nclass Session(SQLModel, table=True):\n    \"\"\"User session model for tracking active login sessions.\"\"\"\n\n    __tablename__ = \"sessions\"\n\n    id: str = Field(\n        default_factory=lambda: str(uuid.uuid4()),\n        sa_column=Column(String(36), primary_key=True),\n    )\n    user_id: str = Field(\n        sa_column=Column(\n            String(36),\n            ForeignKey(\"users.id\", ondelete=\"CASCADE\"),\n            nullable=False,\n        ),\n    )\n    refresh_token_hash: str = Field(\n        sa_column=Column(String(255), nullable=False, index=True),\n    )\n    device_name: str | None = Field(default=None, max_length=255)\n    device_type: str | None = Field(default=None, max_length=50)\n    ip_address: str | None = Field(default=None, max_length=45)\n    user_agent: str | None = Field(default=None, sa_column=Column(Text, nullable=True))\n    is_active: bool = Field(default=True)\n    created_at: datetime = Field(\n        default_factory=datetime.utcnow,\n        sa_column=Column(DateTime, nullable=False),\n    )\n    last_used_at: datetime = Field(\n        default_factory=datetime.utcnow,\n        sa_column=Column(DateTime, nullable=False),\n    )\n    expires_at: datetime = Field(sa_column=Column(DateTime, nullable=False))\n\n    # Relationship\n    user: \"User\" = Relationship(back_populates=\"sessions\")\n\n    def __repr__(self) -> str:\n        return f\"<Session(id={self.id}, user_id={self.user_id}, device={self.device_name})>\"\n\n\n# Forward reference for type hints\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from app.db.models.user import User\n\n\n{%- elif cookiecutter.use_sqlite %}\n\"\"\"Session database model for tracking user sessions.\"\"\"\n\nimport uuid\nfrom datetime import datetime\n\nfrom sqlalchemy import Boolean, DateTime, ForeignKey, String, Text\nfrom sqlalchemy.orm import Mapped, mapped_column, relationship\n\nfrom app.db.base import Base\n\n\nclass Session(Base):\n    \"\"\"User session model for tracking active login sessions.\"\"\"\n\n    __tablename__ = \"sessions\"\n\n    id: Mapped[str] = mapped_column(\n        String(36), primary_key=True, default=lambda: str(uuid.uuid4())\n    )\n    user_id: Mapped[str] = mapped_column(\n        String(36), ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False\n    )\n    refresh_token_hash: Mapped[str] = mapped_column(String(255), nullable=False, index=True)\n    device_name: Mapped[str | None] = mapped_column(String(255), nullable=True)\n    device_type: Mapped[str | None] = mapped_column(String(50), nullable=True)\n    ip_address: Mapped[str | None] = mapped_column(String(45), nullable=True)\n    user_agent: Mapped[str | None] = mapped_column(Text, nullable=True)\n    is_active: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime, default=datetime.utcnow, nullable=False\n    )\n    last_used_at: Mapped[datetime] = mapped_column(\n        DateTime, default=datetime.utcnow, nullable=False\n    )\n    expires_at: Mapped[datetime] = mapped_column(DateTime, nullable=False)\n\n    # Relationship\n    user = relationship(\"User\", back_populates=\"sessions\")\n\n    def __repr__(self) -> str:\n        return f\"<Session(id={self.id}, user_id={self.user_id}, device={self.device_name})>\"\n\n\n{%- elif cookiecutter.use_mongodb %}\n\"\"\"Session document model for tracking user sessions.\"\"\"\n\nfrom datetime import UTC, datetime\nfrom typing import Optional\n\nfrom beanie import Document, Link\nfrom pydantic import Field\n\n\nclass Session(Document):\n    \"\"\"User session document for tracking active login sessions.\"\"\"\n\n    user_id: str\n    refresh_token_hash: str\n    device_name: Optional[str] = None\n    device_type: Optional[str] = None\n    ip_address: Optional[str] = None\n    user_agent: Optional[str] = None\n    is_active: bool = True\n    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))\n    last_used_at: datetime = Field(default_factory=lambda: datetime.now(UTC))\n    expires_at: datetime\n\n    class Settings:\n        name = \"sessions\"\n        indexes = [\n            \"user_id\",\n            \"refresh_token_hash\",\n        ]\n\n\n{%- endif %}\n{%- else %}\n\"\"\"Session model - not configured.\"\"\"\n{%- endif %}\n","backend/app/db/models/__init__.py":"\"\"\"Database models.\"\"\"\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n# ruff: noqa: I001, RUF022 - Imports structured for Jinja2 template conditionals\n{%- endif %}\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n{%- set models = [] %}\n{%- if cookiecutter.use_jwt %}\n{%- set _ = models.append(\"User\") %}\nfrom app.db.models.user import User\n{%- endif %}\n{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\n{%- set _ = models.append(\"Session\") %}\nfrom app.db.models.session import Session\n{%- endif %}\n{%- if cookiecutter.include_example_crud %}\n{%- set _ = models.append(\"Item\") %}\nfrom app.db.models.item import Item\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence %}\n{%- set _ = models.extend([\"Conversation\", \"Message\", \"ToolCall\"]) %}\nfrom app.db.models.conversation import Conversation, Message, ToolCall\n{%- endif %}\n{%- if cookiecutter.enable_webhooks %}\n{%- set _ = models.extend([\"Webhook\", \"WebhookDelivery\"]) %}\nfrom app.db.models.webhook import Webhook, WebhookDelivery\n{%- endif %}\n{%- if models %}\n\n__all__ = {{ models }}\n{%- endif %}\n{%- endif %}\n","backend/app/db/models/item.py":"{%- if cookiecutter.include_example_crud and cookiecutter.use_postgresql and cookiecutter.use_sqlmodel %}\n\"\"\"Item database model using SQLModel - example CRUD entity.\"\"\"\n\nimport uuid\n\nfrom sqlalchemy import Column, String, Text\nfrom sqlalchemy.dialects.postgresql import UUID as PG_UUID\nfrom sqlmodel import Field, SQLModel\n\nfrom app.db.base import TimestampMixin\n\n\nclass Item(TimestampMixin, SQLModel, table=True):\n    \"\"\"Item model - example entity for demonstrating CRUD operations.\n\n    This is a simple example model. You can use it as a template\n    for creating your own models or remove it if not needed.\n    \"\"\"\n\n    __tablename__ = \"items\"\n\n    id: uuid.UUID = Field(\n        default_factory=uuid.uuid4,\n        sa_column=Column(PG_UUID(as_uuid=True), primary_key=True),\n    )\n    title: str = Field(\n        sa_column=Column(String(255), nullable=False, index=True),\n    )\n    description: str | None = Field(\n        default=None,\n        sa_column=Column(Text, nullable=True),\n    )\n    is_active: bool = Field(default=True)\n\n    def __repr__(self) -> str:\n        return f\"<Item(id={self.id}, title={self.title})>\"\n\n\n{%- elif cookiecutter.include_example_crud and cookiecutter.use_postgresql %}\n\"\"\"Item database model - example CRUD entity.\"\"\"\n\nimport uuid\n\nfrom sqlalchemy import String, Text\nfrom sqlalchemy.dialects.postgresql import UUID\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nfrom app.db.base import Base, TimestampMixin\n\n\nclass Item(Base, TimestampMixin):\n    \"\"\"Item model - example entity for demonstrating CRUD operations.\n\n    This is a simple example model. You can use it as a template\n    for creating your own models or remove it if not needed.\n    \"\"\"\n\n    __tablename__ = \"items\"\n\n    id: Mapped[uuid.UUID] = mapped_column(\n        UUID(as_uuid=True), primary_key=True, default=uuid.uuid4\n    )\n    title: Mapped[str] = mapped_column(String(255), nullable=False, index=True)\n    description: Mapped[str | None] = mapped_column(Text, nullable=True)\n    is_active: Mapped[bool] = mapped_column(default=True, nullable=False)\n\n    def __repr__(self) -> str:\n        return f\"<Item(id={self.id}, title={self.title})>\"\n\n\n{%- elif cookiecutter.include_example_crud and cookiecutter.use_sqlite and cookiecutter.use_sqlmodel %}\n\"\"\"Item database model using SQLModel - example CRUD entity.\"\"\"\n\nimport uuid\n\nfrom sqlalchemy import Column, String, Text\nfrom sqlmodel import Field, SQLModel\n\nfrom app.db.base import TimestampMixin\n\n\nclass Item(TimestampMixin, SQLModel, table=True):\n    \"\"\"Item model - example entity for demonstrating CRUD operations.\n\n    This is a simple example model. You can use it as a template\n    for creating your own models or remove it if not needed.\n    \"\"\"\n\n    __tablename__ = \"items\"\n\n    id: str = Field(\n        default_factory=lambda: str(uuid.uuid4()),\n        sa_column=Column(String(36), primary_key=True),\n    )\n    title: str = Field(\n        sa_column=Column(String(255), nullable=False, index=True),\n    )\n    description: str | None = Field(\n        default=None,\n        sa_column=Column(Text, nullable=True),\n    )\n    is_active: bool = Field(default=True)\n\n    def __repr__(self) -> str:\n        return f\"<Item(id={self.id}, title={self.title})>\"\n\n\n{%- elif cookiecutter.include_example_crud and cookiecutter.use_sqlite %}\n\"\"\"Item database model - example CRUD entity.\"\"\"\n\nimport uuid\n\nfrom sqlalchemy import Boolean, String, Text\nfrom sqlalchemy.orm import Mapped, mapped_column\n\nfrom app.db.base import Base, TimestampMixin\n\n\nclass Item(Base, TimestampMixin):\n    \"\"\"Item model - example entity for demonstrating CRUD operations.\n\n    This is a simple example model. You can use it as a template\n    for creating your own models or remove it if not needed.\n    \"\"\"\n\n    __tablename__ = \"items\"\n\n    id: Mapped[str] = mapped_column(\n        String(36), primary_key=True, default=lambda: str(uuid.uuid4())\n    )\n    title: Mapped[str] = mapped_column(String(255), nullable=False, index=True)\n    description: Mapped[str | None] = mapped_column(Text, nullable=True)\n    is_active: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)\n\n    def __repr__(self) -> str:\n        return f\"<Item(id={self.id}, title={self.title})>\"\n\n\n{%- elif cookiecutter.include_example_crud and cookiecutter.use_mongodb %}\n\"\"\"Item document model for MongoDB - example CRUD entity.\"\"\"\n\nfrom datetime import UTC, datetime\nfrom typing import Optional\n\nfrom beanie import Document\nfrom pydantic import Field\n\n\nclass Item(Document):\n    \"\"\"Item document model - example entity for demonstrating CRUD operations.\n\n    This is a simple example model. You can use it as a template\n    for creating your own models or remove it if not needed.\n    \"\"\"\n\n    title: str = Field(max_length=255)\n    description: Optional[str] = None\n    is_active: bool = True\n    created_at: datetime = Field(default_factory=lambda: datetime.now(UTC))\n    updated_at: Optional[datetime] = None\n\n    class Settings:\n        name = \"items\"\n        indexes = [\n            \"title\",\n        ]\n\n\n{%- else %}\n\"\"\"Item model - not configured.\"\"\"\n{%- endif %}\n","backend/app/db/base.py":"{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n{%- if cookiecutter.use_sqlmodel %}\n\"\"\"SQLModel base model.\"\"\"\n\nfrom datetime import datetime\n\nfrom sqlalchemy import Column, DateTime, MetaData, func\nfrom sqlmodel import Field, SQLModel\n\n# Naming convention for database constraints and indexes\n# This ensures consistent naming across all migrations\nNAMING_CONVENTION = {\n    \"ix\": \"%(column_0_label)s_idx\",\n    \"uq\": \"%(table_name)s_%(column_0_name)s_key\",\n    \"ck\": \"%(table_name)s_%(constraint_name)s_check\",\n    \"fk\": \"%(table_name)s_%(column_0_name)s_fkey\",\n    \"pk\": \"%(table_name)s_pkey\",\n}\n\n# Apply naming convention to SQLModel metadata\nSQLModel.metadata.naming_convention = NAMING_CONVENTION\n\n\nclass TimestampMixin(SQLModel):\n    \"\"\"Mixin for created_at and updated_at timestamps.\"\"\"\n\n    created_at: datetime = Field(\n        sa_column=Column(\n            DateTime(timezone=True),\n            server_default=func.now(),\n            nullable=False,\n        ),\n    )\n    updated_at: datetime | None = Field(\n        default=None,\n        sa_column=Column(\n            DateTime(timezone=True),\n            onupdate=func.now(),\n            nullable=True,\n        ),\n    )\n{%- else %}\n\"\"\"SQLAlchemy base model.\"\"\"\n\nfrom datetime import datetime\n\nfrom sqlalchemy import DateTime, MetaData, func\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\n\n# Naming convention for database constraints and indexes\n# This ensures consistent naming across all migrations\nNAMING_CONVENTION = {\n    \"ix\": \"%(column_0_label)s_idx\",\n    \"uq\": \"%(table_name)s_%(column_0_name)s_key\",\n    \"ck\": \"%(table_name)s_%(constraint_name)s_check\",\n    \"fk\": \"%(table_name)s_%(column_0_name)s_fkey\",\n    \"pk\": \"%(table_name)s_pkey\",\n}\n\n\nclass Base(DeclarativeBase):\n    \"\"\"Base class for all SQLAlchemy models.\"\"\"\n\n    metadata = MetaData(naming_convention=NAMING_CONVENTION)\n\n\nclass TimestampMixin:\n    \"\"\"Mixin for created_at and updated_at timestamps.\"\"\"\n\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True),\n        server_default=func.now(),\n        nullable=False,\n    )\n    updated_at: Mapped[datetime | None] = mapped_column(\n        DateTime(timezone=True),\n        onupdate=func.now(),\n        nullable=True,\n    )\n{%- endif %}\n{%- else %}\n\"\"\"Database base - not using SQLAlchemy.\"\"\"\n{%- endif %}\n","backend/app/api/deps.py":"\"\"\"API dependencies.\n\nDependency injection factories for services, repositories, and authentication.\n\"\"\"\n{%- if cookiecutter.use_database or cookiecutter.use_jwt or cookiecutter.use_api_key or cookiecutter.enable_redis %}\n# ruff: noqa: I001, E402 - Imports structured for Jinja2 template conditionals\n{%- endif %}\n{%- if cookiecutter.use_database or cookiecutter.use_jwt or cookiecutter.use_api_key or cookiecutter.enable_redis %}\n\nfrom typing import Annotated\n\nfrom fastapi import Depends\n{%- endif %}\n{%- if cookiecutter.use_jwt %}\nfrom fastapi.security import OAuth2PasswordBearer\n{%- endif %}\n{%- if cookiecutter.use_jwt or cookiecutter.use_api_key %}\n\nfrom app.core.config import settings\n{%- endif %}\n{%- if cookiecutter.use_database %}\nfrom app.db.session import get_db_session\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nDBSession = Annotated[AsyncSession, Depends(get_db_session)]\n{%- endif %}\n\n{%- if cookiecutter.use_sqlite %}\nfrom sqlalchemy.orm import Session\n\nDBSession = Annotated[Session, Depends(get_db_session)]\n{%- endif %}\n\n{%- if cookiecutter.use_mongodb %}\nfrom motor.motor_asyncio import AsyncIOMotorDatabase\n\nDBSession = Annotated[AsyncIOMotorDatabase, Depends(get_db_session)]\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\nfrom fastapi import Request\n\nfrom app.clients.redis import RedisClient\n\n\nasync def get_redis(request: Request) -> RedisClient:\n    \"\"\"Get Redis client from lifespan state.\"\"\"\n    return request.state.redis\n\n\nRedis = Annotated[RedisClient, Depends(get_redis)]\n{%- endif %}\n\n{%- if cookiecutter.use_jwt %}\n\n\n# === Service Dependencies ===\n\nfrom app.services.user import UserService\n{%- if cookiecutter.enable_session_management %}\nfrom app.services.session import SessionService\n{%- endif %}\n{%- endif %}\n{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\nfrom app.services.webhook import WebhookService\n{%- endif %}\n{%- if cookiecutter.include_example_crud and cookiecutter.use_database %}\nfrom app.services.item import ItemService\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nfrom app.services.conversation import ConversationService\n{%- endif %}\n{%- if cookiecutter.use_jwt %}\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\n\ndef get_user_service(db: DBSession) -> UserService:\n    \"\"\"Create UserService instance with database session.\"\"\"\n    return UserService(db)\n\n{%- if cookiecutter.enable_session_management %}\n\n\ndef get_session_service(db: DBSession) -> SessionService:\n    \"\"\"Create SessionService instance with database session.\"\"\"\n    return SessionService(db)\n{%- endif %}\n{%- elif cookiecutter.use_mongodb %}\n\n\ndef get_user_service() -> UserService:\n    \"\"\"Create UserService instance.\"\"\"\n    return UserService()\n\n{%- if cookiecutter.enable_session_management %}\n\n\ndef get_session_service() -> SessionService:\n    \"\"\"Create SessionService instance.\"\"\"\n    return SessionService()\n{%- endif %}\n{%- endif %}\n\n\nUserSvc = Annotated[UserService, Depends(get_user_service)]\n{%- if cookiecutter.enable_session_management %}\nSessionSvc = Annotated[SessionService, Depends(get_session_service)]\n{%- endif %}\n{%- endif %}\n\n{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\n\ndef get_webhook_service(db: DBSession) -> WebhookService:\n    \"\"\"Create WebhookService instance with database session.\"\"\"\n    return WebhookService(db)\n{%- elif cookiecutter.use_mongodb %}\n\n\ndef get_webhook_service() -> WebhookService:\n    \"\"\"Create WebhookService instance.\"\"\"\n    return WebhookService()\n{%- endif %}\n\n\nWebhookSvc = Annotated[WebhookService, Depends(get_webhook_service)]\n{%- endif %}\n\n{%- if cookiecutter.include_example_crud and cookiecutter.use_database %}\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\n\ndef get_item_service(db: DBSession) -> ItemService:\n    \"\"\"Create ItemService instance with database session.\"\"\"\n    return ItemService(db)\n{%- elif cookiecutter.use_mongodb %}\n\n\ndef get_item_service() -> ItemService:\n    \"\"\"Create ItemService instance.\"\"\"\n    return ItemService()\n{%- endif %}\n\n\nItemSvc = Annotated[ItemService, Depends(get_item_service)]\n{%- endif %}\n\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\n\ndef get_conversation_service(db: DBSession) -> ConversationService:\n    \"\"\"Create ConversationService instance with database session.\"\"\"\n    return ConversationService(db)\n{%- elif cookiecutter.use_mongodb %}\n\n\ndef get_conversation_service() -> ConversationService:\n    \"\"\"Create ConversationService instance.\"\"\"\n    return ConversationService()\n{%- endif %}\n\n\nConversationSvc = Annotated[ConversationService, Depends(get_conversation_service)]\n{%- endif %}\n\n{%- if cookiecutter.use_jwt %}\n\n# === Authentication Dependencies ===\n\nfrom app.core.exceptions import AuthenticationError, AuthorizationError\nfrom app.db.models.user import User, UserRole\n\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=f\"{settings.API_V1_STR}/auth/login\")\n\n{%- if cookiecutter.use_postgresql %}\n\n\nasync def get_current_user(\n    token: Annotated[str, Depends(oauth2_scheme)],\n    user_service: UserSvc,\n) -> User:\n    \"\"\"Get current authenticated user from JWT token.\n\n    Returns the full User object including role information.\n\n    Raises:\n        AuthenticationError: If token is invalid or user not found.\n    \"\"\"\n    from uuid import UUID\n\n    from app.core.security import verify_token\n\n    payload = verify_token(token)\n    if payload is None:\n        raise AuthenticationError(message=\"Invalid or expired token\")\n\n    # Ensure this is an access token, not a refresh token\n    if payload.get(\"type\") != \"access\":\n        raise AuthenticationError(message=\"Invalid token type\")\n\n    user_id = payload.get(\"sub\")\n    if user_id is None:\n        raise AuthenticationError(message=\"Invalid token payload\")\n\n    user = await user_service.get_by_id(UUID(user_id))\n    if not user.is_active:\n        raise AuthenticationError(message=\"User account is disabled\")\n\n    return user\n\n\nclass RoleChecker:\n    \"\"\"Dependency class for role-based access control.\n\n    Usage:\n        # Require admin role\n        @router.get(\"/admin-only\")\n        async def admin_endpoint(\n            user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))]\n        ):\n            ...\n\n        # Require any authenticated user\n        @router.get(\"/users\")\n        async def users_endpoint(\n            user: Annotated[User, Depends(get_current_user)]\n        ):\n            ...\n    \"\"\"\n\n    def __init__(self, required_role: UserRole) -> None:\n        self.required_role = required_role\n\n    async def __call__(\n        self,\n        user: Annotated[User, Depends(get_current_user)],\n    ) -> User:\n        \"\"\"Check if user has the required role.\n\n        Raises:\n            AuthorizationError: If user doesn't have the required role.\n        \"\"\"\n        if not user.has_role(self.required_role):\n            raise AuthorizationError(\n                message=f\"Role '{self.required_role.value}' required for this action\"\n            )\n        return user\n\n\nasync def get_current_active_superuser(\n    current_user: Annotated[User, Depends(get_current_user)],\n) -> User:\n    \"\"\"Get current user and verify they are a superuser.\n\n    Raises:\n        AuthorizationError: If user is not a superuser.\n    \"\"\"\n    if not current_user.is_superuser:\n        raise AuthorizationError(message=\"Superuser privileges required\")\n    return current_user\n{%- elif cookiecutter.use_sqlite %}\n\n\ndef get_current_user(\n    token: Annotated[str, Depends(oauth2_scheme)],\n    user_service: UserSvc,\n) -> User:\n    \"\"\"Get current authenticated user from JWT token.\n\n    Returns the full User object including role information.\n\n    Raises:\n        AuthenticationError: If token is invalid or user not found.\n    \"\"\"\n    from app.core.security import verify_token\n\n    payload = verify_token(token)\n    if payload is None:\n        raise AuthenticationError(message=\"Invalid or expired token\")\n\n    # Ensure this is an access token, not a refresh token\n    if payload.get(\"type\") != \"access\":\n        raise AuthenticationError(message=\"Invalid token type\")\n\n    user_id = payload.get(\"sub\")\n    if user_id is None:\n        raise AuthenticationError(message=\"Invalid token payload\")\n\n    user = user_service.get_by_id(user_id)\n    if not user.is_active:\n        raise AuthenticationError(message=\"User account is disabled\")\n\n    return user\n\n\nclass RoleChecker:\n    \"\"\"Dependency class for role-based access control.\n\n    Usage:\n        # Require admin role\n        @router.get(\"/admin-only\")\n        def admin_endpoint(\n            user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))]\n        ):\n            ...\n\n        # Require any authenticated user\n        @router.get(\"/users\")\n        def users_endpoint(\n            user: Annotated[User, Depends(get_current_user)]\n        ):\n            ...\n    \"\"\"\n\n    def __init__(self, required_role: UserRole) -> None:\n        self.required_role = required_role\n\n    def __call__(\n        self,\n        user: Annotated[User, Depends(get_current_user)],\n    ) -> User:\n        \"\"\"Check if user has the required role.\n\n        Raises:\n            AuthorizationError: If user doesn't have the required role.\n        \"\"\"\n        if not user.has_role(self.required_role):\n            raise AuthorizationError(\n                message=f\"Role '{self.required_role.value}' required for this action\"\n            )\n        return user\n\n\ndef get_current_active_superuser(\n    current_user: Annotated[User, Depends(get_current_user)],\n) -> User:\n    \"\"\"Get current user and verify they are a superuser.\n\n    Raises:\n        AuthorizationError: If user is not a superuser.\n    \"\"\"\n    if not current_user.is_superuser:\n        raise AuthorizationError(message=\"Superuser privileges required\")\n    return current_user\n{%- elif cookiecutter.use_mongodb %}\n\n\nasync def get_current_user(\n    token: Annotated[str, Depends(oauth2_scheme)],\n    user_service: UserSvc,\n) -> User:\n    \"\"\"Get current authenticated user from JWT token.\n\n    Returns the full User object including role information.\n\n    Raises:\n        AuthenticationError: If token is invalid or user not found.\n    \"\"\"\n    from app.core.security import verify_token\n\n    payload = verify_token(token)\n    if payload is None:\n        raise AuthenticationError(message=\"Invalid or expired token\")\n\n    # Ensure this is an access token, not a refresh token\n    if payload.get(\"type\") != \"access\":\n        raise AuthenticationError(message=\"Invalid token type\")\n\n    user_id = payload.get(\"sub\")\n    if user_id is None:\n        raise AuthenticationError(message=\"Invalid token payload\")\n\n    user = await user_service.get_by_id(user_id)\n    if not user.is_active:\n        raise AuthenticationError(message=\"User account is disabled\")\n\n    return user\n\n\nclass RoleChecker:\n    \"\"\"Dependency class for role-based access control.\n\n    Usage:\n        # Require admin role\n        @router.get(\"/admin-only\")\n        async def admin_endpoint(\n            user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))]\n        ):\n            ...\n\n        # Require any authenticated user\n        @router.get(\"/users\")\n        async def users_endpoint(\n            user: Annotated[User, Depends(get_current_user)]\n        ):\n            ...\n    \"\"\"\n\n    def __init__(self, required_role: UserRole) -> None:\n        self.required_role = required_role\n\n    async def __call__(\n        self,\n        user: Annotated[User, Depends(get_current_user)],\n    ) -> User:\n        \"\"\"Check if user has the required role.\n\n        Raises:\n            AuthorizationError: If user doesn't have the required role.\n        \"\"\"\n        if not user.has_role(self.required_role):\n            raise AuthorizationError(\n                message=f\"Role '{self.required_role.value}' required for this action\"\n            )\n        return user\n\n\nasync def get_current_active_superuser(\n    current_user: Annotated[User, Depends(get_current_user)],\n) -> User:\n    \"\"\"Get current user and verify they are a superuser.\n\n    Raises:\n        AuthorizationError: If user is not a superuser.\n    \"\"\"\n    if not current_user.is_superuser:\n        raise AuthorizationError(message=\"Superuser privileges required\")\n    return current_user\n{%- endif %}\n\n\n# Type aliases for dependency injection\nCurrentUser = Annotated[User, Depends(get_current_user)]\nCurrentSuperuser = Annotated[User, Depends(get_current_active_superuser)]\nCurrentAdmin = Annotated[User, Depends(RoleChecker(UserRole.ADMIN))]\n\n\n# WebSocket authentication dependency\nfrom fastapi import WebSocket, Query, Cookie\n\n\nasync def get_current_user_ws(\n    websocket: WebSocket,\n    token: str | None = Query(None, alias=\"token\"),\n    access_token: str | None = Cookie(None),\n) -> User:\n    \"\"\"Get current user from WebSocket JWT token.\n\n    Token can be passed either as:\n    - Query parameter: ws://...?token=<jwt>\n    - Cookie: access_token cookie (set by HTTP login)\n\n    Raises:\n        AuthenticationError: If token is invalid or user not found.\n    \"\"\"\n    from uuid import UUID\n\n    from app.core.security import verify_token\n\n    # Try query parameter first, then cookie\n    auth_token = token or access_token\n\n    if not auth_token:\n        await websocket.close(code=4001, reason=\"Missing authentication token\")\n        raise AuthenticationError(message=\"Missing authentication token\")\n\n    payload = verify_token(auth_token)\n    if payload is None:\n        await websocket.close(code=4001, reason=\"Invalid or expired token\")\n        raise AuthenticationError(message=\"Invalid or expired token\")\n\n    if payload.get(\"type\") != \"access\":\n        await websocket.close(code=4001, reason=\"Invalid token type\")\n        raise AuthenticationError(message=\"Invalid token type\")\n\n    user_id = payload.get(\"sub\")\n    if user_id is None:\n        await websocket.close(code=4001, reason=\"Invalid token payload\")\n        raise AuthenticationError(message=\"Invalid token payload\")\n{%- if cookiecutter.use_postgresql %}\n\n    from app.db.session import get_db_context\n\n    async with get_db_context() as db:\n        user_service = UserService(db)\n        user = await user_service.get_by_id(UUID(user_id))\n{%- elif cookiecutter.use_mongodb %}\n\n    db = await get_db_session()\n    user_service = UserService(db)\n    user = await user_service.get_by_id(UUID(user_id))\n{%- elif cookiecutter.use_sqlite %}\n\n    with get_db_session() as db:\n        user_service = UserService(db)\n        user = user_service.get_by_id(user_id)\n{%- endif %}\n\n    if not user.is_active:\n        await websocket.close(code=4001, reason=\"User account is disabled\")\n        raise AuthenticationError(message=\"User account is disabled\")\n\n    return user\n{%- endif %}\n\n{%- if cookiecutter.use_api_key %}\n\nimport secrets\n\nfrom fastapi.security import APIKeyHeader\n\nfrom app.core.exceptions import AuthenticationError, AuthorizationError\n\napi_key_header = APIKeyHeader(name=settings.API_KEY_HEADER, auto_error=False)\n\n\nasync def verify_api_key(\n    api_key: Annotated[str | None, Depends(api_key_header)],\n) -> str:\n    \"\"\"Verify API key from header.\n\n    Uses constant-time comparison to prevent timing attacks.\n\n    Raises:\n        AuthenticationError: If API key is missing.\n        AuthorizationError: If API key is invalid.\n    \"\"\"\n    if api_key is None:\n        raise AuthenticationError(message=\"API Key header missing\")\n    if not secrets.compare_digest(api_key, settings.API_KEY):\n        raise AuthorizationError(message=\"Invalid API Key\")\n    return api_key\n\n\nValidAPIKey = Annotated[str, Depends(verify_api_key)]\n{%- endif %}\n","backend/app/api/exception_handlers.py":"\"\"\"Exception handlers for FastAPI application.\n\nThese handlers convert domain exceptions to proper HTTP responses.\n\"\"\"\n\nimport logging\nfrom typing import Union\n\nfrom fastapi import FastAPI, Request, WebSocket\nfrom fastapi.responses import JSONResponse\n\nfrom app.core.exceptions import AppException\n\nlogger = logging.getLogger(__name__)\n\n\nasync def app_exception_handler(\n    request: Union[Request, WebSocket], exc: AppException\n) -> JSONResponse:\n    \"\"\"Handle application exceptions.\n\n    Logs 5xx errors as errors and 4xx as warnings.\n    Returns a standardized JSON error response.\n\n    Note: For WebSocket connections, this handler may not be able to return\n    a response if the connection was already closed.\n    \"\"\"\n    # WebSocket objects don't have a method attribute\n    method = getattr(request, \"method\", \"WEBSOCKET\")\n\n    log_extra = {\n        \"error_code\": exc.code,\n        \"status_code\": exc.status_code,\n        \"details\": exc.details,\n        \"path\": request.url.path,\n        \"method\": method,\n    }\n\n    if exc.status_code >= 500:\n        logger.error(f\"{exc.code}: {exc.message}\", extra=log_extra)\n    else:\n        logger.warning(f\"{exc.code}: {exc.message}\", extra=log_extra)\n\n    headers: dict[str, str] = {}\n    if exc.status_code == 401:\n        headers[\"WWW-Authenticate\"] = \"Bearer\"\n\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\n            \"error\": {\n                \"code\": exc.code,\n                \"message\": exc.message,\n                \"details\": exc.details or None,\n            }\n        },\n        headers=headers,\n    )\n\n\nasync def unhandled_exception_handler(\n    request: Union[Request, WebSocket], exc: Exception\n) -> JSONResponse:\n    \"\"\"Handle unexpected exceptions.\n\n    Logs the full exception but returns a generic error to the client\n    to avoid leaking sensitive information.\n    \"\"\"\n    method = getattr(request, \"method\", \"WEBSOCKET\")\n\n    logger.exception(\n        \"Unhandled exception\",\n        extra={\n            \"path\": request.url.path,\n            \"method\": method,\n        },\n    )\n\n    return JSONResponse(\n        status_code=500,\n        content={\n            \"error\": {\n                \"code\": \"INTERNAL_ERROR\",\n                \"message\": \"An unexpected error occurred\",\n                \"details\": None,\n            }\n        },\n    )\n\n\ndef register_exception_handlers(app: FastAPI) -> None:\n    \"\"\"Register all exception handlers on the FastAPI app.\n\n    Call this after creating the FastAPI application instance.\n    \"\"\"\n    app.add_exception_handler(AppException, app_exception_handler)\n    # Uncomment to catch all unhandled exceptions:\n    # app.add_exception_handler(Exception, unhandled_exception_handler)\n","backend/app/api/__init__.py":"\"\"\"API module.\"\"\"\n","backend/app/api/versioning.py":"\"\"\"API versioning utilities and deprecation handling.\n\nThis module provides tools for managing API version deprecation:\n- Deprecation middleware for entire API versions\n- Deprecation decorator for individual endpoints\n- RFC 8594 compliant deprecation headers\n\"\"\"\n\nfrom collections.abc import Callable\nfrom datetime import datetime\nfrom functools import wraps\n\nimport logfire\nfrom fastapi import Request, Response\nfrom starlette.middleware.base import BaseHTTPMiddleware, RequestResponseEndpoint\n\n\nclass VersionDeprecationMiddleware(BaseHTTPMiddleware):\n    \"\"\"Middleware to add deprecation headers for deprecated API versions.\n\n    Adds RFC 8594 compliant headers:\n    - Deprecation: Indicates the version is deprecated\n    - Sunset: Indicates when the version will be removed\n    - Link: Points to migration documentation\n\n    Usage in main.py:\n        app.add_middleware(\n            VersionDeprecationMiddleware,\n            deprecated_versions={\"v1\": {\"sunset\": \"2025-06-01\", \"link\": \"/docs/migration/v2\"}},\n        )\n    \"\"\"\n\n    def __init__(\n        self,\n        app,\n        deprecated_versions: dict[str, dict] | None = None,\n    ):\n        \"\"\"Initialize the middleware.\n\n        Args:\n            app: The ASGI application.\n            deprecated_versions: Dict mapping version prefixes to deprecation info.\n                Each entry should have:\n                - sunset: ISO date string when version will be removed (optional)\n                - link: URL to migration documentation (optional)\n                - message: Custom deprecation message (optional)\n\n        Example:\n            {\n                \"v1\": {\n                    \"sunset\": \"2025-06-01\",\n                    \"link\": \"https://api.example.com/docs/migration/v2\",\n                    \"message\": \"Please migrate to API v2\",\n                }\n            }\n        \"\"\"\n        super().__init__(app)\n        self.deprecated_versions = deprecated_versions or {}\n\n    async def dispatch(\n        self, request: Request, call_next: RequestResponseEndpoint\n    ) -> Response:\n        \"\"\"Process the request and add deprecation headers if needed.\"\"\"\n        response = await call_next(request)\n\n        # Check if request path matches a deprecated version\n        path = request.url.path\n        for version, info in self.deprecated_versions.items():\n            if f\"/api/{version}/\" in path or path.endswith(f\"/api/{version}\"):\n                self._add_deprecation_headers(response, version, info)\n                self._log_deprecated_usage(request, version)\n                break\n\n        return response\n\n    def _add_deprecation_headers(\n        self, response: Response, version: str, info: dict\n    ) -> None:\n        \"\"\"Add RFC 8594 deprecation headers to the response.\"\"\"\n        # Deprecation header - indicates the API is deprecated\n        response.headers[\"Deprecation\"] = \"true\"\n\n        # Sunset header - when the API will be removed\n        if sunset := info.get(\"sunset\"):\n            # Convert to HTTP date format\n            sunset_date = datetime.fromisoformat(sunset)\n            response.headers[\"Sunset\"] = sunset_date.strftime(\"%a, %d %b %Y %H:%M:%S GMT\")\n\n        # Link header - documentation for migration\n        if link := info.get(\"link\"):\n            response.headers[\"Link\"] = f'<{link}>; rel=\"deprecation\"'\n\n        # Custom warning header\n        message = info.get(\"message\", f\"API {version} is deprecated\")\n        response.headers[\"X-API-Deprecation-Warning\"] = message\n\n    def _log_deprecated_usage(self, request: Request, version: str) -> None:\n        \"\"\"Log usage of deprecated API version for monitoring.\"\"\"\n        logfire.warn(\n            \"Deprecated API version accessed\",\n            version=version,\n            path=request.url.path,\n            method=request.method,\n            client_ip=request.client.host if request.client else None,\n            user_agent=request.headers.get(\"User-Agent\"),\n        )\n\n\ndef deprecated(\n    sunset: str | None = None,\n    message: str | None = None,\n    link: str | None = None,\n):\n    \"\"\"Decorator to mark an endpoint as deprecated.\n\n    Adds deprecation headers to responses from the decorated endpoint.\n    Use this for deprecating individual endpoints within an active API version.\n\n    Args:\n        sunset: ISO date string when endpoint will be removed.\n        message: Custom deprecation message.\n        link: URL to migration documentation.\n\n    Usage:\n        @router.get(\"/old-endpoint\")\n        @deprecated(\n            sunset=\"2025-06-01\",\n            message=\"Use /new-endpoint instead\",\n            link=\"/docs/migration\",\n        )\n        async def old_endpoint():\n            ...\n    \"\"\"\n\n    def decorator(func: Callable) -> Callable:\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            # Get the response from the endpoint\n            result = await func(*args, **kwargs)\n\n            # Find Response object in args (FastAPI injects it)\n            response = None\n            for arg in args:\n                if isinstance(arg, Response):\n                    response = arg\n                    break\n            for value in kwargs.values():\n                if isinstance(value, Response):\n                    response = value\n                    break\n\n            # If we have a Response object, add headers\n            if response:\n                response.headers[\"Deprecation\"] = \"true\"\n                if sunset:\n                    sunset_date = datetime.fromisoformat(sunset)\n                    response.headers[\"Sunset\"] = sunset_date.strftime(\n                        \"%a, %d %b %Y %H:%M:%S GMT\"\n                    )\n                if link:\n                    response.headers[\"Link\"] = f'<{link}>; rel=\"deprecation\"'\n                if message:\n                    response.headers[\"X-API-Deprecation-Warning\"] = message\n\n            return result\n\n        # Add deprecation info to OpenAPI schema\n        wrapper.__doc__ = (\n            f\"{func.__doc__ or ''}\\n\\n\"\n            f\"**DEPRECATED**\"\n            f\"{f': {message}' if message else ''}\"\n            f\"{f' (Sunset: {sunset})' if sunset else ''}\"\n        )\n\n        return wrapper\n\n    return decorator\n\n\n# Example usage documentation\n\"\"\"\n## Adding a New API Version\n\n1. Create a new version folder:\n   ```\n   app/api/routes/v2/\n   ‚îú‚îÄ‚îÄ __init__.py\n   ‚îú‚îÄ‚îÄ health.py\n   ‚îú‚îÄ‚îÄ auth.py\n   ‚îî‚îÄ‚îÄ ...\n   ```\n\n2. Create the v2 router in `v2/__init__.py`:\n   ```python\n   from fastapi import APIRouter\n   v2_router = APIRouter()\n   # Include routes...\n   ```\n\n3. Add the v2 router in `app/api/router.py`:\n   ```python\n   from app.api.routes.v2 import v2_router\n\n   api_router.include_router(v1_router, prefix=\"/v1\")\n   api_router.include_router(v2_router, prefix=\"/v2\")\n   ```\n\n4. Mark v1 as deprecated in `main.py`:\n   ```python\n   app.add_middleware(\n       VersionDeprecationMiddleware,\n       deprecated_versions={\n           \"v1\": {\n               \"sunset\": \"2025-12-31\",\n               \"link\": \"/docs/migration/v2\",\n               \"message\": \"Please migrate to API v2\",\n           }\n       },\n   )\n   ```\n\"\"\"\n","backend/app/api/router.py":"\"\"\"API router aggregation.\"\"\"\n\nfrom fastapi import APIRouter\n\nfrom app.api.routes.v1 import v1_router\n\napi_router = APIRouter()\n\n# API v1 routes (prefix is set in main.py via settings.API_V1_STR)\napi_router.include_router(v1_router)\n","backend/app/api/routes/v1/auth.py":"{%- if cookiecutter.use_jwt %}\n\"\"\"Authentication routes.\"\"\"\n\nfrom typing import Annotated\n{%- if cookiecutter.use_postgresql and not cookiecutter.enable_session_management %}\nfrom uuid import UUID\n{%- endif %}\n\nfrom fastapi import APIRouter, Depends{% if cookiecutter.enable_session_management %}, Request{% endif %}, status\nfrom fastapi.security import OAuth2PasswordRequestForm\n\nfrom app.api.deps import CurrentUser{% if cookiecutter.enable_session_management %}, SessionSvc{% endif %}, UserSvc\nfrom app.core.exceptions import AuthenticationError\nfrom app.core.security import create_access_token, create_refresh_token, verify_token\nfrom app.schemas.token import RefreshTokenRequest, Token\nfrom app.schemas.user import UserCreate, UserRead\n\nrouter = APIRouter()\n\n\n{%- if cookiecutter.use_postgresql %}\n\n\n@router.post(\"/login\", response_model=Token)\nasync def login(\n{%- if cookiecutter.enable_session_management %}\n    request: Request,\n{%- endif %}\n    form_data: Annotated[OAuth2PasswordRequestForm, Depends()],\n    user_service: UserSvc,\n{%- if cookiecutter.enable_session_management %}\n    session_service: SessionSvc,\n{%- endif %}\n):\n    \"\"\"OAuth2 compatible token login.\n\n    Returns access token and refresh token.\n    Raises domain exceptions handled by exception handlers.\n    \"\"\"\n    user = await user_service.authenticate(form_data.username, form_data.password)\n    access_token = create_access_token(subject=str(user.id))\n    refresh_token = create_refresh_token(subject=str(user.id))\n{%- if cookiecutter.enable_session_management %}\n\n    # Create session to track this login\n    await session_service.create_session(\n        user_id=user.id,\n        refresh_token=refresh_token,\n        ip_address=request.client.host if request.client else None,\n        user_agent=request.headers.get(\"User-Agent\"),\n    )\n{%- endif %}\n    return Token(access_token=access_token, refresh_token=refresh_token)\n\n\n@router.post(\"/register\", response_model=UserRead, status_code=status.HTTP_201_CREATED)\nasync def register(\n    user_in: UserCreate,\n    user_service: UserSvc,\n):\n    \"\"\"Register a new user.\n\n    Raises AlreadyExistsError if email is already registered.\n    \"\"\"\n    user = await user_service.register(user_in)\n    return user\n\n\n@router.post(\"/refresh\", response_model=Token)\nasync def refresh_token(\n{%- if cookiecutter.enable_session_management %}\n    request: Request,\n{%- endif %}\n    body: RefreshTokenRequest,\n    user_service: UserSvc,\n{%- if cookiecutter.enable_session_management %}\n    session_service: SessionSvc,\n{%- endif %}\n):\n    \"\"\"Get new access token using refresh token.\n\n    Raises AuthenticationError if refresh token is invalid or expired.\n    \"\"\"\n{%- if cookiecutter.enable_session_management %}\n\n    # Validate refresh token against stored session\n    session = await session_service.validate_refresh_token(body.refresh_token)\n    if not session:\n        raise AuthenticationError(message=\"Invalid or expired refresh token\")\n\n    user = await user_service.get_by_id(session.user_id)\n{%- else %}\n\n    payload = verify_token(body.refresh_token)\n    if payload is None:\n        raise AuthenticationError(message=\"Invalid or expired refresh token\")\n\n    if payload.get(\"type\") != \"refresh\":\n        raise AuthenticationError(message=\"Invalid token type\")\n\n    user_id = payload.get(\"sub\")\n    if user_id is None:\n        raise AuthenticationError(message=\"Invalid token payload\")\n\n    # Verify user still exists and is active\n    user = await user_service.get_by_id(UUID(user_id))\n{%- endif %}\n    if not user.is_active:\n        raise AuthenticationError(message=\"User account is disabled\")\n\n    access_token = create_access_token(subject=str(user.id))\n    new_refresh_token = create_refresh_token(subject=str(user.id))\n{%- if cookiecutter.enable_session_management %}\n\n    # Invalidate old session and create new one\n    await session_service.logout_by_refresh_token(body.refresh_token)\n    await session_service.create_session(\n        user_id=user.id,\n        refresh_token=new_refresh_token,\n        ip_address=request.client.host if request.client else None,\n        user_agent=request.headers.get(\"User-Agent\"),\n    )\n{%- endif %}\n    return Token(access_token=access_token, refresh_token=new_refresh_token)\n\n{%- if cookiecutter.enable_session_management %}\n\n\n@router.post(\"/logout\", status_code=status.HTTP_204_NO_CONTENT)\nasync def logout(\n    body: RefreshTokenRequest,\n    session_service: SessionSvc,\n):\n    \"\"\"Logout and invalidate the current session.\n\n    Invalidates the refresh token, preventing further token refresh.\n    \"\"\"\n    await session_service.logout_by_refresh_token(body.refresh_token)\n{%- endif %}\n\n\n@router.get(\"/me\", response_model=UserRead)\nasync def get_current_user_info(current_user: CurrentUser):\n    \"\"\"Get current authenticated user information.\"\"\"\n    return current_user\n{%- elif cookiecutter.use_mongodb %}\n\n\n@router.post(\"/login\", response_model=Token)\nasync def login(\n{%- if cookiecutter.enable_session_management %}\n    request: Request,\n{%- endif %}\n    form_data: Annotated[OAuth2PasswordRequestForm, Depends()],\n    user_service: UserSvc,\n{%- if cookiecutter.enable_session_management %}\n    session_service: SessionSvc,\n{%- endif %}\n):\n    \"\"\"OAuth2 compatible token login.\n\n    Returns access token and refresh token.\n    Raises domain exceptions handled by exception handlers.\n    \"\"\"\n    user = await user_service.authenticate(form_data.username, form_data.password)\n    access_token = create_access_token(subject=str(user.id))\n    refresh_token = create_refresh_token(subject=str(user.id))\n{%- if cookiecutter.enable_session_management %}\n\n    # Create session to track this login\n    await session_service.create_session(\n        user_id=str(user.id),\n        refresh_token=refresh_token,\n        ip_address=request.client.host if request.client else None,\n        user_agent=request.headers.get(\"User-Agent\"),\n    )\n{%- endif %}\n    return Token(access_token=access_token, refresh_token=refresh_token)\n\n\n@router.post(\"/register\", response_model=UserRead, status_code=status.HTTP_201_CREATED)\nasync def register(\n    user_in: UserCreate,\n    user_service: UserSvc,\n):\n    \"\"\"Register a new user.\n\n    Raises AlreadyExistsError if email is already registered.\n    \"\"\"\n    user = await user_service.register(user_in)\n    return user\n\n\n@router.post(\"/refresh\", response_model=Token)\nasync def refresh_token(\n{%- if cookiecutter.enable_session_management %}\n    request: Request,\n{%- endif %}\n    body: RefreshTokenRequest,\n    user_service: UserSvc,\n{%- if cookiecutter.enable_session_management %}\n    session_service: SessionSvc,\n{%- endif %}\n):\n    \"\"\"Get new access token using refresh token.\n\n    Raises AuthenticationError if refresh token is invalid or expired.\n    \"\"\"\n{%- if cookiecutter.enable_session_management %}\n    # Validate refresh token against stored session\n    session = await session_service.validate_refresh_token(body.refresh_token)\n    if not session:\n        raise AuthenticationError(message=\"Invalid or expired refresh token\")\n\n    user = await user_service.get_by_id(session.user_id)\n{%- else %}\n    payload = verify_token(body.refresh_token)\n    if payload is None:\n        raise AuthenticationError(message=\"Invalid or expired refresh token\")\n\n    if payload.get(\"type\") != \"refresh\":\n        raise AuthenticationError(message=\"Invalid token type\")\n\n    user_id = payload.get(\"sub\")\n    if user_id is None:\n        raise AuthenticationError(message=\"Invalid token payload\")\n\n    # Verify user still exists and is active\n    user = await user_service.get_by_id(user_id)\n{%- endif %}\n    if not user.is_active:\n        raise AuthenticationError(message=\"User account is disabled\")\n\n    access_token = create_access_token(subject=str(user.id))\n    new_refresh_token = create_refresh_token(subject=str(user.id))\n{%- if cookiecutter.enable_session_management %}\n\n    # Invalidate old session and create new one\n    await session_service.logout_by_refresh_token(body.refresh_token)\n    await session_service.create_session(\n        user_id=str(user.id),\n        refresh_token=new_refresh_token,\n        ip_address=request.client.host if request.client else None,\n        user_agent=request.headers.get(\"User-Agent\"),\n    )\n{%- endif %}\n    return Token(access_token=access_token, refresh_token=new_refresh_token)\n\n{%- if cookiecutter.enable_session_management %}\n\n\n@router.post(\"/logout\", status_code=status.HTTP_204_NO_CONTENT)\nasync def logout(\n    body: RefreshTokenRequest,\n    session_service: SessionSvc,\n):\n    \"\"\"Logout and invalidate the current session.\n\n    Invalidates the refresh token, preventing further token refresh.\n    \"\"\"\n    await session_service.logout_by_refresh_token(body.refresh_token)\n{%- endif %}\n\n\n@router.get(\"/me\", response_model=UserRead)\nasync def get_current_user_info(current_user: CurrentUser):\n    \"\"\"Get current authenticated user information.\"\"\"\n    return current_user\n{%- elif cookiecutter.use_sqlite %}\n\n\n@router.post(\"/login\", response_model=Token)\ndef login(\n{%- if cookiecutter.enable_session_management %}\n    request: Request,\n{%- endif %}\n    form_data: Annotated[OAuth2PasswordRequestForm, Depends()],\n    user_service: UserSvc,\n{%- if cookiecutter.enable_session_management %}\n    session_service: SessionSvc,\n{%- endif %}\n):\n    \"\"\"OAuth2 compatible token login.\n\n    Returns access token and refresh token.\n    Raises domain exceptions handled by exception handlers.\n    \"\"\"\n    user = user_service.authenticate(form_data.username, form_data.password)\n    access_token = create_access_token(subject=user.id)\n    refresh_token = create_refresh_token(subject=user.id)\n{%- if cookiecutter.enable_session_management %}\n\n    # Create session to track this login\n    session_service.create_session(\n        user_id=user.id,\n        refresh_token=refresh_token,\n        ip_address=request.client.host if request.client else None,\n        user_agent=request.headers.get(\"User-Agent\"),\n    )\n{%- endif %}\n    return Token(access_token=access_token, refresh_token=refresh_token)\n\n\n@router.post(\"/register\", response_model=UserRead, status_code=status.HTTP_201_CREATED)\ndef register(\n    user_in: UserCreate,\n    user_service: UserSvc,\n):\n    \"\"\"Register a new user.\n\n    Raises AlreadyExistsError if email is already registered.\n    \"\"\"\n    user = user_service.register(user_in)\n    return user\n\n\n@router.post(\"/refresh\", response_model=Token)\ndef refresh_token(\n{%- if cookiecutter.enable_session_management %}\n    request: Request,\n{%- endif %}\n    body: RefreshTokenRequest,\n    user_service: UserSvc,\n{%- if cookiecutter.enable_session_management %}\n    session_service: SessionSvc,\n{%- endif %}\n):\n    \"\"\"Get new access token using refresh token.\n\n    Raises AuthenticationError if refresh token is invalid or expired.\n    \"\"\"\n{%- if cookiecutter.enable_session_management %}\n    # Validate refresh token against stored session\n    session = session_service.validate_refresh_token(body.refresh_token)\n    if not session:\n        raise AuthenticationError(message=\"Invalid or expired refresh token\")\n\n    user = user_service.get_by_id(session.user_id)\n{%- else %}\n    payload = verify_token(body.refresh_token)\n    if payload is None:\n        raise AuthenticationError(message=\"Invalid or expired refresh token\")\n\n    if payload.get(\"type\") != \"refresh\":\n        raise AuthenticationError(message=\"Invalid token type\")\n\n    user_id = payload.get(\"sub\")\n    if user_id is None:\n        raise AuthenticationError(message=\"Invalid token payload\")\n\n    # Verify user still exists and is active\n    user = user_service.get_by_id(user_id)\n{%- endif %}\n    if not user.is_active:\n        raise AuthenticationError(message=\"User account is disabled\")\n\n    access_token = create_access_token(subject=user.id)\n    new_refresh_token = create_refresh_token(subject=user.id)\n{%- if cookiecutter.enable_session_management %}\n\n    # Invalidate old session and create new one\n    session_service.logout_by_refresh_token(body.refresh_token)\n    session_service.create_session(\n        user_id=user.id,\n        refresh_token=new_refresh_token,\n        ip_address=request.client.host if request.client else None,\n        user_agent=request.headers.get(\"User-Agent\"),\n    )\n{%- endif %}\n    return Token(access_token=access_token, refresh_token=new_refresh_token)\n\n{%- if cookiecutter.enable_session_management %}\n\n\n@router.post(\"/logout\", status_code=status.HTTP_204_NO_CONTENT)\ndef logout(\n    body: RefreshTokenRequest,\n    session_service: SessionSvc,\n):\n    \"\"\"Logout and invalidate the current session.\n\n    Invalidates the refresh token, preventing further token refresh.\n    \"\"\"\n    session_service.logout_by_refresh_token(body.refresh_token)\n{%- endif %}\n\n\n@router.get(\"/me\", response_model=UserRead)\ndef get_current_user_info(current_user: CurrentUser):\n    \"\"\"Get current authenticated user information.\"\"\"\n    return current_user\n{%- endif %}\n{%- else %}\n\"\"\"Auth routes - not configured.\"\"\"\n{%- endif %}\n","backend/app/api/routes/v1/sessions.py":"{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\n\"\"\"Session management routes.\"\"\"\n\nfrom fastapi import APIRouter, status\n{%- if cookiecutter.use_postgresql %}\nfrom uuid import UUID\n{%- endif %}\n\nfrom app.api.deps import CurrentUser, SessionSvc\nfrom app.schemas.session import LogoutAllResponse, SessionListResponse, SessionRead\n\nrouter = APIRouter()\n\n\n{%- if cookiecutter.use_postgresql %}\n\n\n@router.get(\"\", response_model=SessionListResponse)\nasync def list_sessions(\n    current_user: CurrentUser,\n    session_service: SessionSvc,\n):\n    \"\"\"Get all active sessions for the current user.\"\"\"\n    sessions = await session_service.get_user_sessions(current_user.id)\n    return SessionListResponse(\n        sessions=[\n            SessionRead(\n                id=s.id,\n                device_name=s.device_name,\n                device_type=s.device_type,\n                ip_address=s.ip_address,\n                is_current=False,  # TODO: compare with current session\n                created_at=s.created_at,\n                last_used_at=s.last_used_at,\n            )\n            for s in sessions\n        ],\n        total=len(sessions),\n    )\n\n\n@router.delete(\"/{session_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def logout_session(\n    session_id: UUID,\n    current_user: CurrentUser,\n    session_service: SessionSvc,\n):\n    \"\"\"Logout a specific session.\"\"\"\n    await session_service.logout_session(session_id, current_user.id)\n\n\n@router.delete(\"\", response_model=LogoutAllResponse)\nasync def logout_all_sessions(\n    current_user: CurrentUser,\n    session_service: SessionSvc,\n):\n    \"\"\"Logout from all sessions (logout from all devices).\"\"\"\n    count = await session_service.logout_all_sessions(current_user.id)\n    return LogoutAllResponse(\n        message=\"Successfully logged out from all sessions\",\n        sessions_logged_out=count,\n    )\n\n\n{%- elif cookiecutter.use_mongodb %}\n\n\n@router.get(\"\", response_model=SessionListResponse)\nasync def list_sessions(\n    current_user: CurrentUser,\n    session_service: SessionSvc,\n):\n    \"\"\"Get all active sessions for the current user.\"\"\"\n    sessions = await session_service.get_user_sessions(str(current_user.id))\n    return SessionListResponse(\n        sessions=[\n            SessionRead(\n                id=str(s.id),\n                device_name=s.device_name,\n                device_type=s.device_type,\n                ip_address=s.ip_address,\n                is_current=False,\n                created_at=s.created_at,\n                last_used_at=s.last_used_at,\n            )\n            for s in sessions\n        ],\n        total=len(sessions),\n    )\n\n\n@router.delete(\"/{session_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def logout_session(\n    session_id: str,\n    current_user: CurrentUser,\n    session_service: SessionSvc,\n):\n    \"\"\"Logout a specific session.\"\"\"\n    await session_service.logout_session(session_id, str(current_user.id))\n\n\n@router.delete(\"\", response_model=LogoutAllResponse)\nasync def logout_all_sessions(\n    current_user: CurrentUser,\n    session_service: SessionSvc,\n):\n    \"\"\"Logout from all sessions (logout from all devices).\"\"\"\n    count = await session_service.logout_all_sessions(str(current_user.id))\n    return LogoutAllResponse(\n        message=\"Successfully logged out from all sessions\",\n        sessions_logged_out=count,\n    )\n\n\n{%- elif cookiecutter.use_sqlite %}\n\n\n@router.get(\"\", response_model=SessionListResponse)\ndef list_sessions(\n    current_user: CurrentUser,\n    session_service: SessionSvc,\n):\n    \"\"\"Get all active sessions for the current user.\"\"\"\n    sessions = session_service.get_user_sessions(current_user.id)\n    return SessionListResponse(\n        sessions=[\n            SessionRead(\n                id=s.id,\n                device_name=s.device_name,\n                device_type=s.device_type,\n                ip_address=s.ip_address,\n                is_current=False,\n                created_at=s.created_at,\n                last_used_at=s.last_used_at,\n            )\n            for s in sessions\n        ],\n        total=len(sessions),\n    )\n\n\n@router.delete(\"/{session_id}\", status_code=status.HTTP_204_NO_CONTENT)\ndef logout_session(\n    session_id: str,\n    current_user: CurrentUser,\n    session_service: SessionSvc,\n):\n    \"\"\"Logout a specific session.\"\"\"\n    session_service.logout_session(session_id, current_user.id)\n\n\n@router.delete(\"\", response_model=LogoutAllResponse)\ndef logout_all_sessions(\n    current_user: CurrentUser,\n    session_service: SessionSvc,\n):\n    \"\"\"Logout from all sessions (logout from all devices).\"\"\"\n    count = session_service.logout_all_sessions(current_user.id)\n    return LogoutAllResponse(\n        message=\"Successfully logged out from all sessions\",\n        sessions_logged_out=count,\n    )\n\n\n{%- endif %}\n{%- else %}\n\"\"\"Session routes - not configured.\"\"\"\n{%- endif %}\n","backend/app/api/routes/v1/users.py":"{%- if cookiecutter.use_jwt %}\n# ruff: noqa: I001 - Imports structured for Jinja2 template conditionals\n\"\"\"User management routes.\"\"\"\n\nfrom typing import Annotated\n{%- if cookiecutter.use_postgresql %}\n\nfrom uuid import UUID\n{%- endif %}\n\nfrom fastapi import APIRouter, Depends, status\n{%- if cookiecutter.enable_pagination %}\nfrom fastapi_pagination import Page\nfrom fastapi_pagination.ext.sqlalchemy import paginate\nfrom sqlalchemy import select\n{%- endif %}\n\nfrom app.api.deps import (\n    DBSession,\n    RoleChecker,\n    UserSvc,\n    get_current_user,\n)\nfrom app.db.models.user import User, UserRole\nfrom app.schemas.user import UserRead, UserUpdate\n\nrouter = APIRouter()\n\n\n{%- if cookiecutter.use_postgresql %}\n\n\n@router.get(\"/me\", response_model=UserRead)\nasync def read_current_user(\n    current_user: Annotated[User, Depends(get_current_user)],\n):\n    \"\"\"Get current user.\n\n    Returns the authenticated user's profile including their role.\n    \"\"\"\n    return current_user\n\n\n@router.patch(\"/me\", response_model=UserRead)\nasync def update_current_user(\n    user_in: UserUpdate,\n    current_user: Annotated[User, Depends(get_current_user)],\n    user_service: UserSvc,\n):\n    \"\"\"Update current user.\n\n    Users can update their own profile (email, full_name).\n    Role changes require admin privileges.\n    \"\"\"\n    # Prevent non-admin users from changing their own role\n    if user_in.role is not None and not current_user.has_role(UserRole.ADMIN):\n        user_in.role = None\n    user = await user_service.update(current_user.id, user_in)\n    return user\n\n\n{%- if cookiecutter.enable_pagination %}\n\n\n@router.get(\"\", response_model=Page[UserRead])\nasync def read_users(\n    db: DBSession,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n):\n    \"\"\"Get all users (admin only).\"\"\"\n    return await paginate(db, select(User))\n\n\n{%- else %}\n\n\n@router.get(\"\", response_model=list[UserRead])\nasync def read_users(\n    user_service: UserSvc,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n    skip: int = 0,\n    limit: int = 100,\n):\n    \"\"\"Get all users (admin only).\"\"\"\n    users = await user_service.get_multi(skip=skip, limit=limit)\n    return users\n\n\n{%- endif %}\n\n\n@router.get(\"/{user_id}\", response_model=UserRead)\nasync def read_user(\n    user_id: UUID,\n    user_service: UserSvc,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n):\n    \"\"\"Get user by ID (admin only).\n\n    Raises NotFoundError if user does not exist.\n    \"\"\"\n    user = await user_service.get_by_id(user_id)\n    return user\n\n\n@router.patch(\"/{user_id}\", response_model=UserRead)\nasync def update_user_by_id(\n    user_id: UUID,\n    user_in: UserUpdate,\n    user_service: UserSvc,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n):\n    \"\"\"Update user by ID (admin only).\n\n    Admins can update any user including their role.\n\n    Raises NotFoundError if user does not exist.\n    \"\"\"\n    user = await user_service.update(user_id, user_in)\n    return user\n\n\n@router.delete(\"/{user_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_user_by_id(\n    user_id: UUID,\n    user_service: UserSvc,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n):\n    \"\"\"Delete user by ID (admin only).\n\n    Raises NotFoundError if user does not exist.\n    \"\"\"\n    await user_service.delete(user_id)\n\n\n{%- elif cookiecutter.use_mongodb %}\n\n\n@router.get(\"/me\", response_model=UserRead)\nasync def read_current_user(\n    current_user: Annotated[User, Depends(get_current_user)],\n):\n    \"\"\"Get current user.\n\n    Returns the authenticated user's profile including their role.\n    \"\"\"\n    return current_user\n\n\n@router.patch(\"/me\", response_model=UserRead)\nasync def update_current_user(\n    user_in: UserUpdate,\n    current_user: Annotated[User, Depends(get_current_user)],\n    user_service: UserSvc,\n):\n    \"\"\"Update current user.\n\n    Users can update their own profile (email, full_name).\n    Role changes require admin privileges.\n    \"\"\"\n    # Prevent non-admin users from changing their own role\n    if user_in.role is not None and not current_user.has_role(UserRole.ADMIN):\n        user_in.role = None\n    user = await user_service.update(str(current_user.id), user_in)\n    return user\n\n\n@router.get(\"\", response_model=list[UserRead])\nasync def read_users(\n    user_service: UserSvc,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n    skip: int = 0,\n    limit: int = 100,\n):\n    \"\"\"Get all users (admin only).\"\"\"\n    users = await user_service.get_multi(skip=skip, limit=limit)\n    return users\n\n\n@router.get(\"/{user_id}\", response_model=UserRead)\nasync def read_user(\n    user_id: str,\n    user_service: UserSvc,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n):\n    \"\"\"Get user by ID (admin only).\n\n    Raises NotFoundError if user does not exist.\n    \"\"\"\n    user = await user_service.get_by_id(user_id)\n    return user\n\n\n@router.patch(\"/{user_id}\", response_model=UserRead)\nasync def update_user_by_id(\n    user_id: str,\n    user_in: UserUpdate,\n    user_service: UserSvc,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n):\n    \"\"\"Update user by ID (admin only).\n\n    Admins can update any user including their role.\n\n    Raises NotFoundError if user does not exist.\n    \"\"\"\n    user = await user_service.update(user_id, user_in)\n    return user\n\n\n@router.delete(\"/{user_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_user_by_id(\n    user_id: str,\n    user_service: UserSvc,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n):\n    \"\"\"Delete user by ID (admin only).\n\n    Raises NotFoundError if user does not exist.\n    \"\"\"\n    await user_service.delete(user_id)\n\n\n{%- elif cookiecutter.use_sqlite %}\n\n\n@router.get(\"/me\", response_model=UserRead)\ndef read_current_user(\n    current_user: Annotated[User, Depends(get_current_user)],\n):\n    \"\"\"Get current user.\n\n    Returns the authenticated user's profile including their role.\n    \"\"\"\n    return current_user\n\n\n@router.patch(\"/me\", response_model=UserRead)\ndef update_current_user(\n    user_in: UserUpdate,\n    current_user: Annotated[User, Depends(get_current_user)],\n    user_service: UserSvc,\n):\n    \"\"\"Update current user.\n\n    Users can update their own profile (email, full_name).\n    Role changes require admin privileges.\n    \"\"\"\n    # Prevent non-admin users from changing their own role\n    if user_in.role is not None and not current_user.has_role(UserRole.ADMIN):\n        user_in.role = None\n    user = user_service.update(current_user.id, user_in)\n    return user\n\n\n{%- if cookiecutter.enable_pagination %}\n\n\n@router.get(\"\", response_model=Page[UserRead])\ndef read_users(\n    db: DBSession,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n):\n    \"\"\"Get all users (admin only).\"\"\"\n    return paginate(db, select(User))\n\n\n{%- else %}\n\n\n@router.get(\"\", response_model=list[UserRead])\ndef read_users(\n    user_service: UserSvc,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n    skip: int = 0,\n    limit: int = 100,\n):\n    \"\"\"Get all users (admin only).\"\"\"\n    users = user_service.get_multi(skip=skip, limit=limit)\n    return users\n\n\n{%- endif %}\n\n\n@router.get(\"/{user_id}\", response_model=UserRead)\ndef read_user(\n    user_id: str,\n    user_service: UserSvc,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n):\n    \"\"\"Get user by ID (admin only).\n\n    Raises NotFoundError if user does not exist.\n    \"\"\"\n    user = user_service.get_by_id(user_id)\n    return user\n\n\n@router.patch(\"/{user_id}\", response_model=UserRead)\ndef update_user_by_id(\n    user_id: str,\n    user_in: UserUpdate,\n    user_service: UserSvc,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n):\n    \"\"\"Update user by ID (admin only).\n\n    Admins can update any user including their role.\n\n    Raises NotFoundError if user does not exist.\n    \"\"\"\n    user = user_service.update(user_id, user_in)\n    return user\n\n\n@router.delete(\"/{user_id}\", status_code=status.HTTP_204_NO_CONTENT)\ndef delete_user_by_id(\n    user_id: str,\n    user_service: UserSvc,\n    current_user: Annotated[User, Depends(RoleChecker(UserRole.ADMIN))],\n):\n    \"\"\"Delete user by ID (admin only).\n\n    Raises NotFoundError if user does not exist.\n    \"\"\"\n    user_service.delete(user_id)\n\n\n{%- endif %}\n{%- else %}\n\"\"\"User routes - not configured.\"\"\"\n{%- endif %}\n","backend/app/api/routes/v1/health.py":"\"\"\"Health check endpoints.\n\nProvides Kubernetes-compatible health check endpoints:\n- /health - Simple liveness check\n- /health/live - Detailed liveness probe\n- /health/ready - Readiness probe with dependency checks\n\"\"\"\n{%- if cookiecutter.use_database or cookiecutter.enable_redis %}\n# ruff: noqa: I001 - Imports structured for Jinja2 template conditionals\n{%- endif %}\n\nfrom datetime import UTC, datetime\nfrom typing import Any\n\nfrom fastapi import APIRouter\nfrom fastapi.responses import JSONResponse\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\nfrom sqlalchemy import text\n{%- endif %}\n\nfrom app.core.config import settings\n{%- if cookiecutter.use_database or cookiecutter.enable_redis %}\nfrom app.api.deps import {% if cookiecutter.use_database %}DBSession{% endif %}{% if cookiecutter.use_database and cookiecutter.enable_redis %}, {% endif %}{% if cookiecutter.enable_redis %}Redis{% endif %}\n\n{%- endif %}\n\nrouter = APIRouter()\n\n\ndef _build_health_response(\n    status: str,\n    checks: dict[str, Any] | None = None,\n    details: dict[str, Any] | None = None,\n) -> dict[str, Any]:\n    \"\"\"Build a structured health response.\"\"\"\n    response: dict[str, Any] = {\n        \"status\": status,\n        \"timestamp\": datetime.now(UTC).isoformat(),\n        \"service\": settings.PROJECT_NAME,\n    }\n    if checks is not None:\n        response[\"checks\"] = checks\n    if details is not None:\n        response[\"details\"] = details\n    return response\n\n\n@router.get(\"/health\")\nasync def health_check() -> dict[str, str]:\n    \"\"\"Simple liveness probe - check if application is running.\n\n    This is a lightweight check that should always succeed if the\n    application is running. Use this for basic connectivity tests.\n\n    Returns:\n        {\"status\": \"healthy\"}\n    \"\"\"\n    return {\"status\": \"healthy\"}\n\n\n@router.get(\"/health/live\")\nasync def liveness_probe() -> dict[str, Any]:\n    \"\"\"Detailed liveness probe for Kubernetes.\n\n    This endpoint is designed for Kubernetes liveness probes.\n    It checks if the application process is alive and responding.\n    Failure indicates the container should be restarted.\n\n    Returns:\n        Structured response with timestamp and service info.\n    \"\"\"\n    return _build_health_response(\n        status=\"alive\",\n        details={\n            \"version\": getattr(settings, \"VERSION\", \"1.0.0\"),\n            \"environment\": settings.ENVIRONMENT,\n        },\n    )\n\n\n@router.get(\"/health/ready\", response_model=None)\nasync def readiness_probe(\n{%- if cookiecutter.use_database %}\n    db: DBSession,\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n    redis: Redis,\n{%- endif %}\n) -> dict[str, Any] | JSONResponse:\n    \"\"\"Readiness probe for Kubernetes.\n\n    This endpoint checks if all dependencies are ready to handle traffic.\n    It verifies database connections, Redis, and other critical services.\n    Failure indicates traffic should be temporarily diverted.\n\n    Checks performed:\n    {%- if cookiecutter.use_database %}\n    - Database connectivity\n    {%- endif %}\n    {%- if cookiecutter.enable_redis %}\n    - Redis connectivity\n    {%- endif %}\n\n    Returns:\n        Structured response with individual check results.\n        Returns 503 if any critical check fails.\n    \"\"\"\n    checks: dict[str, dict[str, Any]] = {}\n\n{%- if cookiecutter.use_postgresql %}\n    # Database check\n    try:\n        start = datetime.now(UTC)\n        await db.execute(text(\"SELECT 1\"))\n        latency_ms = (datetime.now(UTC) - start).total_seconds() * 1000\n        checks[\"database\"] = {\n            \"status\": \"healthy\",\n            \"latency_ms\": round(latency_ms, 2),\n            \"type\": \"postgresql\",\n        }\n    except Exception as e:\n        checks[\"database\"] = {\n            \"status\": \"unhealthy\",\n            \"error\": str(e),\n            \"type\": \"postgresql\",\n        }\n{%- endif %}\n\n{%- if cookiecutter.use_mongodb %}\n    # Database check\n    try:\n        start = datetime.now(UTC)\n        await db.command(\"ping\")\n        latency_ms = (datetime.now(UTC) - start).total_seconds() * 1000\n        checks[\"database\"] = {\n            \"status\": \"healthy\",\n            \"latency_ms\": round(latency_ms, 2),\n            \"type\": \"mongodb\",\n        }\n    except Exception as e:\n        checks[\"database\"] = {\n            \"status\": \"unhealthy\",\n            \"error\": str(e),\n            \"type\": \"mongodb\",\n        }\n{%- endif %}\n\n{%- if cookiecutter.use_sqlite %}\n    # Database check\n    try:\n        start = datetime.now(UTC)\n        db.execute(text(\"SELECT 1\"))\n        latency_ms = (datetime.now(UTC) - start).total_seconds() * 1000\n        checks[\"database\"] = {\n            \"status\": \"healthy\",\n            \"latency_ms\": round(latency_ms, 2),\n            \"type\": \"sqlite\",\n        }\n    except Exception as e:\n        checks[\"database\"] = {\n            \"status\": \"unhealthy\",\n            \"error\": str(e),\n            \"type\": \"sqlite\",\n        }\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n    # Redis check\n    try:\n        start = datetime.now(UTC)\n        is_healthy = await redis.ping()\n        latency_ms = (datetime.now(UTC) - start).total_seconds() * 1000\n        if is_healthy:\n            checks[\"redis\"] = {\n                \"status\": \"healthy\",\n                \"latency_ms\": round(latency_ms, 2),\n            }\n        else:\n            checks[\"redis\"] = {\n                \"status\": \"unhealthy\",\n                \"error\": \"Ping failed\",\n            }\n    except Exception as e:\n        checks[\"redis\"] = {\n            \"status\": \"unhealthy\",\n            \"error\": str(e),\n        }\n{%- endif %}\n\n    # Determine overall health\n    all_healthy = all(\n        check.get(\"status\") == \"healthy\" for check in checks.values()\n    ) if checks else True\n\n    response_data = _build_health_response(\n        status=\"ready\" if all_healthy else \"not_ready\",\n        checks=checks,\n    )\n\n    if not all_healthy:\n        return JSONResponse(status_code=503, content=response_data)\n\n    return response_data\n\n\n# Backward compatibility - keep /ready endpoint\n@router.get(\"/ready\", response_model=None)\nasync def readiness_check(\n{%- if cookiecutter.use_database %}\n    db: DBSession,\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n    redis: Redis,\n{%- endif %}\n) -> dict[str, Any] | JSONResponse:\n    \"\"\"Readiness check (alias for /health/ready).\n\n    Deprecated: Use /health/ready instead.\n    \"\"\"\n    return await readiness_probe(\n{%- if cookiecutter.use_database %}\n        db=db,\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n        redis=redis,\n{%- endif %}\n    )\n","backend/app/api/routes/v1/__init__.py":"\"\"\"API v1 router aggregation.\"\"\"\n{%- if cookiecutter.use_jwt or cookiecutter.enable_oauth or cookiecutter.include_example_crud or cookiecutter.enable_conversation_persistence or cookiecutter.enable_webhooks or cookiecutter.enable_websockets or cookiecutter.enable_ai_agent %}\n# ruff: noqa: I001 - Imports structured for Jinja2 template conditionals\n{%- endif %}\n\nfrom fastapi import APIRouter\n\nfrom app.api.routes.v1 import health\n{%- if cookiecutter.use_jwt %}\nfrom app.api.routes.v1 import auth, users\n{%- endif %}\n{%- if cookiecutter.enable_oauth %}\nfrom app.api.routes.v1 import oauth\n{%- endif %}\n{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\nfrom app.api.routes.v1 import sessions\n{%- endif %}\n{%- if cookiecutter.include_example_crud and cookiecutter.use_database %}\nfrom app.api.routes.v1 import items\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nfrom app.api.routes.v1 import conversations\n{%- endif %}\n{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\nfrom app.api.routes.v1 import webhooks\n{%- endif %}\n{%- if cookiecutter.enable_websockets %}\nfrom app.api.routes.v1 import ws\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent %}\nfrom app.api.routes.v1 import agent\n{%- endif %}\n\nv1_router = APIRouter()\n\n# Health check routes (no auth required)\nv1_router.include_router(health.router, tags=[\"health\"])\n\n{%- if cookiecutter.use_jwt %}\n\n# Authentication routes\nv1_router.include_router(auth.router, prefix=\"/auth\", tags=[\"auth\"])\n\n# User routes\nv1_router.include_router(users.router, prefix=\"/users\", tags=[\"users\"])\n{%- endif %}\n\n{%- if cookiecutter.enable_oauth %}\n\n# OAuth2 routes\nv1_router.include_router(oauth.router, prefix=\"/oauth\", tags=[\"oauth\"])\n{%- endif %}\n\n{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\n\n# Session management routes\nv1_router.include_router(sessions.router, prefix=\"/sessions\", tags=[\"sessions\"])\n{%- endif %}\n\n{%- if cookiecutter.include_example_crud and cookiecutter.use_database %}\n\n# Example CRUD routes (items)\nv1_router.include_router(items.router, prefix=\"/items\", tags=[\"items\"])\n{%- endif %}\n\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n\n# Conversation routes (AI chat persistence)\nv1_router.include_router(conversations.router, prefix=\"/conversations\", tags=[\"conversations\"])\n{%- endif %}\n\n{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\n\n# Webhook routes\nv1_router.include_router(webhooks.router, prefix=\"/webhooks\", tags=[\"webhooks\"])\n{%- endif %}\n\n{%- if cookiecutter.enable_websockets %}\n\n# WebSocket routes\nv1_router.include_router(ws.router, tags=[\"websocket\"])\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent %}\n\n# AI Agent routes\nv1_router.include_router(agent.router, tags=[\"agent\"])\n{%- endif %}\n","backend/app/api/routes/v1/ws.py":"{%- if cookiecutter.enable_websockets %}\n\"\"\"WebSocket routes.\"\"\"\n\nfrom fastapi import APIRouter, WebSocket\n\nrouter = APIRouter()\n\n\nclass ConnectionManager:\n    \"\"\"WebSocket connection manager.\"\"\"\n\n    def __init__(self):\n        self.active_connections: list[WebSocket] = []\n\n    async def connect(self, websocket: WebSocket) -> None:\n        \"\"\"Accept and store a new WebSocket connection.\"\"\"\n        await websocket.accept()\n        self.active_connections.append(websocket)\n\n    def disconnect(self, websocket: WebSocket) -> None:\n        \"\"\"Remove a WebSocket connection.\"\"\"\n        self.active_connections.remove(websocket)\n\n    async def send_personal_message(self, message: str, websocket: WebSocket) -> None:\n        \"\"\"Send a message to a specific WebSocket.\"\"\"\n        await websocket.send_text(message)\n\n    async def broadcast(self, message: str) -> None:\n        \"\"\"Broadcast a message to all connected WebSockets.\"\"\"\n        for connection in self.active_connections:\n            await connection.send_text(message)\n\n\nmanager = ConnectionManager()\n\n\n@router.websocket(\"/ws\")\nasync def websocket_endpoint(websocket: WebSocket):\n    \"\"\"WebSocket endpoint for real-time communication.\"\"\"\n    await manager.connect(websocket)\n    async for data in websocket.iter_text():\n        await manager.broadcast(f\"Message: {data}\")\n    manager.disconnect(websocket)\n{%- else %}\n\"\"\"WebSocket - not configured.\"\"\"\n{%- endif %}\n","backend/app/api/routes/v1/agent.py":"{%- if cookiecutter.enable_ai_agent and cookiecutter.use_pydantic_ai %}\n\"\"\"AI Agent WebSocket routes with streaming support (PydanticAI).\"\"\"\n\nimport logging\nfrom typing import Any\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nfrom datetime import datetime, UTC\n{%- if cookiecutter.use_postgresql %}\nfrom uuid import UUID\n{%- endif %}\n{%- endif %}\n\nfrom fastapi import APIRouter, WebSocket, WebSocketDisconnect{%- if cookiecutter.websocket_auth_jwt %}, Depends{%- endif %}{%- if cookiecutter.websocket_auth_api_key %}, Query{%- endif %}\n\nfrom pydantic_ai import (\n    Agent,\n    FinalResultEvent,\n    FunctionToolCallEvent,\n    FunctionToolResultEvent,\n    PartDeltaEvent,\n    PartStartEvent,\n    TextPartDelta,\n    ToolCallPartDelta,\n)\nfrom pydantic_ai.messages import (\n    ModelRequest,\n    ModelResponse,\n    SystemPromptPart,\n    TextPart,\n    UserPromptPart,\n)\n\nfrom app.agents.assistant import Deps, get_agent\n{%- if cookiecutter.websocket_auth_jwt %}\nfrom app.api.deps import get_current_user_ws\nfrom app.db.models.user import User\n{%- endif %}\n{%- if cookiecutter.websocket_auth_api_key %}\nfrom app.core.config import settings\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\nfrom app.db.session import get_db_context\nfrom app.api.deps import ConversationSvc, get_conversation_service\nfrom app.schemas.conversation import ConversationCreate, MessageCreate, ToolCallCreate, ToolCallComplete\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\nfrom app.api.deps import ConversationSvc, get_conversation_service\nfrom app.schemas.conversation import ConversationCreate, MessageCreate, ToolCallCreate, ToolCallComplete\n{%- endif %}\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter()\n\n\nclass AgentConnectionManager:\n    \"\"\"WebSocket connection manager for AI agent.\"\"\"\n\n    def __init__(self) -> None:\n        self.active_connections: list[WebSocket] = []\n\n    async def connect(self, websocket: WebSocket) -> None:\n        \"\"\"Accept and store a new WebSocket connection.\"\"\"\n        await websocket.accept()\n        self.active_connections.append(websocket)\n        logger.info(f\"Agent WebSocket connected. Total connections: {len(self.active_connections)}\")\n\n    def disconnect(self, websocket: WebSocket) -> None:\n        \"\"\"Remove a WebSocket connection.\"\"\"\n        if websocket in self.active_connections:\n            self.active_connections.remove(websocket)\n        logger.info(f\"Agent WebSocket disconnected. Total connections: {len(self.active_connections)}\")\n\n    async def send_event(self, websocket: WebSocket, event_type: str, data: Any) -> bool:\n        \"\"\"Send a JSON event to a specific WebSocket client.\n\n        Returns True if sent successfully, False if connection is closed.\n        \"\"\"\n        try:\n            await websocket.send_json({\"type\": event_type, \"data\": data})\n            return True\n        except (WebSocketDisconnect, RuntimeError):\n            # Connection already closed\n            return False\n\n\nmanager = AgentConnectionManager()\n\n\ndef build_message_history(history: list[dict[str, str]]) -> list[ModelRequest | ModelResponse]:\n    \"\"\"Convert conversation history to PydanticAI message format.\"\"\"\n    model_history: list[ModelRequest | ModelResponse] = []\n\n    for msg in history:\n        if msg[\"role\"] == \"user\":\n            model_history.append(ModelRequest(parts=[UserPromptPart(content=msg[\"content\"])]))\n        elif msg[\"role\"] == \"assistant\":\n            model_history.append(ModelResponse(parts=[TextPart(content=msg[\"content\"])]))\n        elif msg[\"role\"] == \"system\":\n            model_history.append(ModelRequest(parts=[SystemPromptPart(content=msg[\"content\"])]))\n\n    return model_history\n\n{%- if cookiecutter.websocket_auth_api_key %}\n\n\nasync def verify_api_key(api_key: str) -> bool:\n    \"\"\"Verify the API key for WebSocket authentication.\"\"\"\n    return api_key == settings.API_KEY\n{%- endif %}\n\n\n@router.websocket(\"/ws/agent\")\nasync def agent_websocket(\n    websocket: WebSocket,\n{%- if cookiecutter.websocket_auth_jwt %}\n    user: User = Depends(get_current_user_ws),\n{%- elif cookiecutter.websocket_auth_api_key %}\n    api_key: str = Query(..., alias=\"api_key\"),\n{%- endif %}\n) -> None:\n    \"\"\"WebSocket endpoint for AI agent with full event streaming.\n\n    Uses PydanticAI iter() to stream all agent events including:\n    - user_prompt: When user input is received\n    - model_request_start: When model request begins\n    - text_delta: Streaming text from the model\n    - tool_call_delta: Streaming tool call arguments\n    - tool_call: When a tool is called (with full args)\n    - tool_result: When a tool returns a result\n    - final_result: When the final result is ready\n    - complete: When processing is complete\n    - error: When an error occurs\n\n    Expected input message format:\n    {\n        \"message\": \"user message here\",\n        \"history\": [{\"role\": \"user|assistant|system\", \"content\": \"...\"}]{% if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %},\n        \"conversation_id\": \"optional-uuid-to-continue-existing-conversation\"{% endif %}\n    }\n{%- if cookiecutter.websocket_auth_jwt %}\n\n    Authentication: Requires a valid JWT token passed as a query parameter or header.\n{%- elif cookiecutter.websocket_auth_api_key %}\n\n    Authentication: Requires a valid API key passed as 'api_key' query parameter.\n    Example: ws://localhost:{{ cookiecutter.backend_port }}/api/v1/ws/agent?api_key=your-api-key\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n\n    Persistence: Set 'conversation_id' to continue an existing conversation.\n    If not provided, a new conversation is created. The conversation_id is\n    returned in the 'conversation_created' event.\n{%- endif %}\n    \"\"\"\n{%- if cookiecutter.websocket_auth_api_key %}\n    # Verify API key before accepting connection\n    if not await verify_api_key(api_key):\n        await websocket.close(code=4001, reason=\"Invalid API key\")\n        return\n{%- endif %}\n\n    await manager.connect(websocket)\n\n    # Conversation state per connection\n    conversation_history: list[dict[str, str]] = []\n    deps = Deps()\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n    current_conversation_id: str | None = None\n{%- endif %}\n\n    try:\n        while True:\n            # Receive user message\n            data = await websocket.receive_json()\n            user_message = data.get(\"message\", \"\")\n            # Optionally accept history from client (or use server-side tracking)\n            if \"history\" in data:\n                conversation_history = data[\"history\"]\n\n            if not user_message:\n                await manager.send_event(websocket, \"error\", {\"message\": \"Empty message\"})\n                continue\n\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\n\n            # Handle conversation persistence\n            try:\n{%- if cookiecutter.use_postgresql %}\n                async with get_db_context() as db:\n                    conv_service = get_conversation_service(db)\n\n                    # Get or create conversation\n                    requested_conv_id = data.get(\"conversation_id\")\n                    if requested_conv_id:\n                        current_conversation_id = requested_conv_id\n                        # Verify conversation exists\n                        await conv_service.get_conversation(UUID(requested_conv_id))\n                    elif not current_conversation_id:\n                        # Create new conversation\n                        conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                            user_id=user.id,\n{%- endif %}\n                            title=user_message[:50] if len(user_message) > 50 else user_message,\n                        )\n                        conversation = await conv_service.create_conversation(conv_data)\n                        current_conversation_id = str(conversation.id)\n                        await manager.send_event(\n                            websocket,\n                            \"conversation_created\",\n                            {\"conversation_id\": current_conversation_id},\n                        )\n\n                    # Save user message\n                    await conv_service.add_message(\n                        UUID(current_conversation_id),\n                        MessageCreate(role=\"user\", content=user_message),\n                    )\n{%- else %}\n                with get_db_session() as db:\n                    conv_service = get_conversation_service(db)\n\n                    # Get or create conversation\n                    requested_conv_id = data.get(\"conversation_id\")\n                    if requested_conv_id:\n                        current_conversation_id = requested_conv_id\n                        conv_service.get_conversation(requested_conv_id)\n                    elif not current_conversation_id:\n                        # Create new conversation\n                        conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                            user_id=str(user.id),\n{%- endif %}\n                            title=user_message[:50] if len(user_message) > 50 else user_message,\n                        )\n                        conversation = conv_service.create_conversation(conv_data)\n                        current_conversation_id = str(conversation.id)\n                        await manager.send_event(\n                            websocket,\n                            \"conversation_created\",\n                            {\"conversation_id\": current_conversation_id},\n                        )\n\n                    # Save user message\n                    conv_service.add_message(\n                        current_conversation_id,\n                        MessageCreate(role=\"user\", content=user_message),\n                    )\n{%- endif %}\n            except Exception as e:\n                logger.warning(f\"Failed to persist conversation: {e}\")\n                # Continue without persistence\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n\n            # Handle conversation persistence (MongoDB)\n            conv_service = get_conversation_service()\n\n            requested_conv_id = data.get(\"conversation_id\")\n            if requested_conv_id:\n                current_conversation_id = requested_conv_id\n                await conv_service.get_conversation(requested_conv_id)\n            elif not current_conversation_id:\n                conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                    user_id=str(user.id),\n{%- endif %}\n                    title=user_message[:50] if len(user_message) > 50 else user_message,\n                )\n                conversation = await conv_service.create_conversation(conv_data)\n                current_conversation_id = str(conversation.id)\n                await manager.send_event(\n                    websocket,\n                    \"conversation_created\",\n                    {\"conversation_id\": current_conversation_id},\n                )\n\n            # Save user message\n            await conv_service.add_message(\n                current_conversation_id,\n                MessageCreate(role=\"user\", content=user_message),\n            )\n{%- endif %}\n\n            await manager.send_event(websocket, \"user_prompt\", {\"content\": user_message})\n\n            try:\n                assistant = get_agent()\n                model_history = build_message_history(conversation_history)\n\n                # Use iter() on the underlying PydanticAI agent to stream all events\n                async with assistant.agent.iter(\n                    user_message,\n                    deps=deps,\n                    message_history=model_history,\n                ) as agent_run:\n                    async for node in agent_run:\n                        if Agent.is_user_prompt_node(node):\n                            await manager.send_event(\n                                websocket,\n                                \"user_prompt_processed\",\n                                {\"prompt\": node.user_prompt},\n                            )\n\n                        elif Agent.is_model_request_node(node):\n                            await manager.send_event(websocket, \"model_request_start\", {})\n\n                            async with node.stream(agent_run.ctx) as request_stream:\n                                async for event in request_stream:\n                                    if isinstance(event, PartStartEvent):\n                                        await manager.send_event(\n                                            websocket,\n                                            \"part_start\",\n                                            {\n                                                \"index\": event.index,\n                                                \"part_type\": type(event.part).__name__,\n                                            },\n                                        )\n                                        # Send initial content from TextPart if present\n                                        if isinstance(event.part, TextPart) and event.part.content:\n                                            await manager.send_event(\n                                                websocket,\n                                                \"text_delta\",\n                                                {\n                                                    \"index\": event.index,\n                                                    \"content\": event.part.content,\n                                                },\n                                            )\n\n                                    elif isinstance(event, PartDeltaEvent):\n                                        if isinstance(event.delta, TextPartDelta):\n                                            await manager.send_event(\n                                                websocket,\n                                                \"text_delta\",\n                                                {\n                                                    \"index\": event.index,\n                                                    \"content\": event.delta.content_delta,\n                                                },\n                                            )\n                                        elif isinstance(event.delta, ToolCallPartDelta):\n                                            await manager.send_event(\n                                                websocket,\n                                                \"tool_call_delta\",\n                                                {\n                                                    \"index\": event.index,\n                                                    \"args_delta\": event.delta.args_delta,\n                                                },\n                                            )\n\n                                    elif isinstance(event, FinalResultEvent):\n                                        await manager.send_event(\n                                            websocket,\n                                            \"final_result_start\",\n                                            {\"tool_name\": event.tool_name},\n                                        )\n\n                        elif Agent.is_call_tools_node(node):\n                            await manager.send_event(websocket, \"call_tools_start\", {})\n\n                            async with node.stream(agent_run.ctx) as handle_stream:\n                                async for event in handle_stream:\n                                    if isinstance(event, FunctionToolCallEvent):\n                                        await manager.send_event(\n                                            websocket,\n                                            \"tool_call\",\n                                            {\n                                                \"tool_name\": event.part.tool_name,\n                                                \"args\": event.part.args,\n                                                \"tool_call_id\": event.part.tool_call_id,\n                                            },\n                                        )\n\n                                    elif isinstance(event, FunctionToolResultEvent):\n                                        await manager.send_event(\n                                            websocket,\n                                            \"tool_result\",\n                                            {\n                                                \"tool_call_id\": event.tool_call_id,\n                                                \"content\": str(event.result.content),\n                                            },\n                                        )\n\n                        elif Agent.is_end_node(node) and agent_run.result is not None:\n                            await manager.send_event(\n                                websocket,\n                                \"final_result\",\n                                {\"output\": agent_run.result.output},\n                            )\n\n                # Update conversation history\n                conversation_history.append({\"role\": \"user\", \"content\": user_message})\n                if agent_run.result:\n                    conversation_history.append(\n                        {\"role\": \"assistant\", \"content\": agent_run.result.output}\n                    )\n\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\n\n                # Save assistant response to database\n                if current_conversation_id and agent_run.result:\n                    try:\n{%- if cookiecutter.use_postgresql %}\n                        async with get_db_context() as db:\n                            conv_service = get_conversation_service(db)\n                            await conv_service.add_message(\n                                UUID(current_conversation_id),\n                                MessageCreate(\n                                    role=\"assistant\",\n                                    content=agent_run.result.output,\n                                    model_name=assistant.model_name if hasattr(assistant, \"model_name\") else None,\n                                ),\n                            )\n{%- else %}\n                        with get_db_session() as db:\n                            conv_service = get_conversation_service(db)\n                            conv_service.add_message(\n                                current_conversation_id,\n                                MessageCreate(\n                                    role=\"assistant\",\n                                    content=agent_run.result.output,\n                                    model_name=assistant.model_name if hasattr(assistant, \"model_name\") else None,\n                                ),\n                            )\n{%- endif %}\n                    except Exception as e:\n                        logger.warning(f\"Failed to persist assistant response: {e}\")\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n\n                # Save assistant response to database\n                if current_conversation_id and agent_run.result:\n                    try:\n                        await conv_service.add_message(\n                            current_conversation_id,\n                            MessageCreate(\n                                role=\"assistant\",\n                                content=agent_run.result.output,\n                                model_name=assistant.model_name if hasattr(assistant, \"model_name\") else None,\n                            ),\n                        )\n                    except Exception as e:\n                        logger.warning(f\"Failed to persist assistant response: {e}\")\n{%- endif %}\n\n                await manager.send_event(websocket, \"complete\", {\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n                    \"conversation_id\": current_conversation_id,\n{%- endif %}\n                })\n\n            except WebSocketDisconnect:\n                # Client disconnected during processing - this is normal\n                logger.info(\"Client disconnected during agent processing\")\n                break\n            except Exception as e:\n                logger.exception(f\"Error processing agent request: {e}\")\n                # Try to send error, but don't fail if connection is closed\n                await manager.send_event(websocket, \"error\", {\"message\": str(e)})\n\n    except WebSocketDisconnect:\n        pass  # Normal disconnect\n    finally:\n        manager.disconnect(websocket)\n{%- elif cookiecutter.enable_ai_agent and cookiecutter.use_langchain %}\n\"\"\"AI Agent WebSocket routes with streaming support (LangChain).\"\"\"\n\nimport logging\nfrom typing import Any\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nfrom datetime import datetime, UTC\n{%- if cookiecutter.use_postgresql %}\nfrom uuid import UUID\n{%- endif %}\n{%- endif %}\n\nfrom fastapi import APIRouter, WebSocket, WebSocketDisconnect{%- if cookiecutter.websocket_auth_jwt %}, Depends{%- endif %}{%- if cookiecutter.websocket_auth_api_key %}, Query{%- endif %}\n\nfrom langchain.messages import AIMessage, AIMessageChunk, HumanMessage, SystemMessage, ToolMessage\n\nfrom app.agents.langchain_assistant import AgentContext, get_agent\n{%- if cookiecutter.websocket_auth_jwt %}\nfrom app.api.deps import get_current_user_ws\nfrom app.db.models.user import User\n{%- endif %}\n{%- if cookiecutter.websocket_auth_api_key %}\nfrom app.core.config import settings\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\nfrom app.db.session import get_db_context\nfrom app.api.deps import ConversationSvc, get_conversation_service\nfrom app.schemas.conversation import ConversationCreate, MessageCreate, ToolCallCreate, ToolCallComplete\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\nfrom app.api.deps import ConversationSvc, get_conversation_service\nfrom app.schemas.conversation import ConversationCreate, MessageCreate, ToolCallCreate, ToolCallComplete\n{%- endif %}\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter()\n\n\nclass AgentConnectionManager:\n    \"\"\"WebSocket connection manager for AI agent.\"\"\"\n\n    def __init__(self) -> None:\n        self.active_connections: list[WebSocket] = []\n\n    async def connect(self, websocket: WebSocket) -> None:\n        \"\"\"Accept and store a new WebSocket connection.\"\"\"\n        await websocket.accept()\n        self.active_connections.append(websocket)\n        logger.info(f\"Agent WebSocket connected. Total connections: {len(self.active_connections)}\")\n\n    def disconnect(self, websocket: WebSocket) -> None:\n        \"\"\"Remove a WebSocket connection.\"\"\"\n        if websocket in self.active_connections:\n            self.active_connections.remove(websocket)\n        logger.info(f\"Agent WebSocket disconnected. Total connections: {len(self.active_connections)}\")\n\n    async def send_event(self, websocket: WebSocket, event_type: str, data: Any) -> bool:\n        \"\"\"Send a JSON event to a specific WebSocket client.\n\n        Returns True if sent successfully, False if connection is closed.\n        \"\"\"\n        try:\n            await websocket.send_json({\"type\": event_type, \"data\": data})\n            return True\n        except (WebSocketDisconnect, RuntimeError):\n            # Connection already closed\n            return False\n\n\nmanager = AgentConnectionManager()\n\n\ndef build_message_history(\n    history: list[dict[str, str]]\n) -> list[HumanMessage | AIMessage | SystemMessage]:\n    \"\"\"Convert conversation history to LangChain message format.\"\"\"\n    messages: list[HumanMessage | AIMessage | SystemMessage] = []\n\n    for msg in history:\n        if msg[\"role\"] == \"user\":\n            messages.append(HumanMessage(content=msg[\"content\"]))\n        elif msg[\"role\"] == \"assistant\":\n            messages.append(AIMessage(content=msg[\"content\"]))\n        elif msg[\"role\"] == \"system\":\n            messages.append(SystemMessage(content=msg[\"content\"]))\n\n    return messages\n\n{%- if cookiecutter.websocket_auth_api_key %}\n\n\nasync def verify_api_key(api_key: str) -> bool:\n    \"\"\"Verify the API key for WebSocket authentication.\"\"\"\n    return api_key == settings.API_KEY\n{%- endif %}\n\n\n@router.websocket(\"/ws/agent\")\nasync def agent_websocket(\n    websocket: WebSocket,\n{%- if cookiecutter.websocket_auth_jwt %}\n    user: User = Depends(get_current_user_ws),\n{%- elif cookiecutter.websocket_auth_api_key %}\n    api_key: str = Query(..., alias=\"api_key\"),\n{%- endif %}\n) -> None:\n    \"\"\"WebSocket endpoint for AI agent with streaming support.\n\n    Uses LangChain stream() to stream agent events including:\n    - user_prompt: When user input is received\n    - text_delta: Streaming text from the model\n    - tool_call: When a tool is called\n    - tool_result: When a tool returns a result\n    - final_result: When the final result is ready\n    - complete: When processing is complete\n    - error: When an error occurs\n\n    Expected input message format:\n    {\n        \"message\": \"user message here\",\n        \"history\": [{\"role\": \"user|assistant|system\", \"content\": \"...\"}]{% if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %},\n        \"conversation_id\": \"optional-uuid-to-continue-existing-conversation\"{% endif %}\n    }\n{%- if cookiecutter.websocket_auth_jwt %}\n\n    Authentication: Requires a valid JWT token passed as a query parameter or header.\n{%- elif cookiecutter.websocket_auth_api_key %}\n\n    Authentication: Requires a valid API key passed as 'api_key' query parameter.\n    Example: ws://localhost:{{ cookiecutter.backend_port }}/api/v1/ws/agent?api_key=your-api-key\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n\n    Persistence: Set 'conversation_id' to continue an existing conversation.\n    If not provided, a new conversation is created. The conversation_id is\n    returned in the 'conversation_created' event.\n{%- endif %}\n    \"\"\"\n{%- if cookiecutter.websocket_auth_api_key %}\n    # Verify API key before accepting connection\n    if not await verify_api_key(api_key):\n        await websocket.close(code=4001, reason=\"Invalid API key\")\n        return\n{%- endif %}\n\n    await manager.connect(websocket)\n\n    # Conversation state per connection\n    conversation_history: list[dict[str, str]] = []\n    context: AgentContext = {}\n{%- if cookiecutter.websocket_auth_jwt %}\n    context[\"user_id\"] = str(user.id) if user else None\n    context[\"user_name\"] = user.email if user else None\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n    current_conversation_id: str | None = None\n{%- endif %}\n\n    try:\n        while True:\n            # Receive user message\n            data = await websocket.receive_json()\n            user_message = data.get(\"message\", \"\")\n            # Optionally accept history from client (or use server-side tracking)\n            if \"history\" in data:\n                conversation_history = data[\"history\"]\n\n            if not user_message:\n                await manager.send_event(websocket, \"error\", {\"message\": \"Empty message\"})\n                continue\n\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\n\n            # Handle conversation persistence\n            try:\n{%- if cookiecutter.use_postgresql %}\n                async with get_db_context() as db:\n                    conv_service = get_conversation_service(db)\n\n                    # Get or create conversation\n                    requested_conv_id = data.get(\"conversation_id\")\n                    if requested_conv_id:\n                        current_conversation_id = requested_conv_id\n                        # Verify conversation exists\n                        await conv_service.get_conversation(UUID(requested_conv_id))\n                    elif not current_conversation_id:\n                        # Create new conversation\n                        conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                            user_id=user.id,\n{%- endif %}\n                            title=user_message[:50] if len(user_message) > 50 else user_message,\n                        )\n                        conversation = await conv_service.create_conversation(conv_data)\n                        current_conversation_id = str(conversation.id)\n                        await manager.send_event(\n                            websocket,\n                            \"conversation_created\",\n                            {\"conversation_id\": current_conversation_id},\n                        )\n\n                    # Save user message\n                    await conv_service.add_message(\n                        UUID(current_conversation_id),\n                        MessageCreate(role=\"user\", content=user_message),\n                    )\n{%- else %}\n                with get_db_session() as db:\n                    conv_service = get_conversation_service(db)\n\n                    # Get or create conversation\n                    requested_conv_id = data.get(\"conversation_id\")\n                    if requested_conv_id:\n                        current_conversation_id = requested_conv_id\n                        conv_service.get_conversation(requested_conv_id)\n                    elif not current_conversation_id:\n                        # Create new conversation\n                        conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                            user_id=str(user.id),\n{%- endif %}\n                            title=user_message[:50] if len(user_message) > 50 else user_message,\n                        )\n                        conversation = conv_service.create_conversation(conv_data)\n                        current_conversation_id = str(conversation.id)\n                        await manager.send_event(\n                            websocket,\n                            \"conversation_created\",\n                            {\"conversation_id\": current_conversation_id},\n                        )\n\n                    # Save user message\n                    conv_service.add_message(\n                        current_conversation_id,\n                        MessageCreate(role=\"user\", content=user_message),\n                    )\n{%- endif %}\n            except Exception as e:\n                logger.warning(f\"Failed to persist conversation: {e}\")\n                # Continue without persistence\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n\n            # Handle conversation persistence (MongoDB)\n            conv_service = get_conversation_service()\n\n            requested_conv_id = data.get(\"conversation_id\")\n            if requested_conv_id:\n                current_conversation_id = requested_conv_id\n                await conv_service.get_conversation(requested_conv_id)\n            elif not current_conversation_id:\n                conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                    user_id=str(user.id),\n{%- endif %}\n                    title=user_message[:50] if len(user_message) > 50 else user_message,\n                )\n                conversation = await conv_service.create_conversation(conv_data)\n                current_conversation_id = str(conversation.id)\n                await manager.send_event(\n                    websocket,\n                    \"conversation_created\",\n                    {\"conversation_id\": current_conversation_id},\n                )\n\n            # Save user message\n            await conv_service.add_message(\n                current_conversation_id,\n                MessageCreate(role=\"user\", content=user_message),\n            )\n{%- endif %}\n\n            await manager.send_event(websocket, \"user_prompt\", {\"content\": user_message})\n\n            try:\n                assistant = get_agent()\n                model_history = build_message_history(conversation_history)\n                model_history.append(HumanMessage(content=user_message))\n\n                final_output = \"\"\n                tool_events: list[Any] = []\n                seen_tool_call_ids: set[str] = set()\n\n                await manager.send_event(websocket, \"model_request_start\", {})\n\n                for stream_mode, data in assistant.agent.stream(\n                    {\"messages\": model_history},\n                    stream_mode=[\"messages\", \"updates\"],\n                    config={\"configurable\": context} if context else None,\n                ):\n                    if stream_mode == \"messages\":\n                        token, metadata = data\n\n                        if isinstance(token, AIMessageChunk):\n                            if token.content:\n                                text_content = \"\"\n                                if isinstance(token.content, str):\n                                    text_content = token.content\n                                elif isinstance(token.content, list):\n                                    for block in token.content:\n                                        if isinstance(block, dict) and block.get(\"type\") == \"text\":\n                                            text_content += block.get(\"text\", \"\")\n                                        elif isinstance(block, str):\n                                            text_content += block\n\n                                if text_content:\n                                    await manager.send_event(\n                                        websocket,\n                                        \"text_delta\",\n                                        {\"content\": text_content},\n                                    )\n                                    final_output += text_content\n\n                            if token.tool_call_chunks:\n                                for tc_chunk in token.tool_call_chunks:\n                                    tc_id = tc_chunk.get(\"id\")\n                                    tc_name = tc_chunk.get(\"name\")\n                                    if tc_id and tc_name and tc_id not in seen_tool_call_ids:\n                                        seen_tool_call_ids.add(tc_id)\n                                        await manager.send_event(\n                                            websocket,\n                                            \"tool_call\",\n                                            {\n                                                \"tool_name\": tc_name,\n                                                \"args\": {},\n                                                \"tool_call_id\": tc_id,\n                                            },\n                                        )\n\n                    elif stream_mode == \"updates\":\n                        for node_name, update in data.items():\n                            if node_name == \"tools\":\n                                for msg in update.get(\"messages\", []):\n                                    if isinstance(msg, ToolMessage):\n                                        await manager.send_event(\n                                            websocket,\n                                            \"tool_result\",\n                                            {\n                                                \"tool_call_id\": msg.tool_call_id,\n                                                \"content\": msg.content,\n                                            },\n                                        )\n                            elif node_name == \"model\":\n                                for msg in update.get(\"messages\", []):\n                                    if isinstance(msg, AIMessage) and msg.tool_calls:\n                                        for tc in msg.tool_calls:\n                                            tc_id = tc.get(\"id\", \"\")\n                                            if tc_id not in seen_tool_call_ids:\n                                                seen_tool_call_ids.add(tc_id)\n                                                tool_events.append(tc)\n                                                await manager.send_event(\n                                                    websocket,\n                                                    \"tool_call\",\n                                                    {\n                                                        \"tool_name\": tc.get(\"name\", \"\"),\n                                                        \"args\": tc.get(\"args\", {}),\n                                                        \"tool_call_id\": tc_id,\n                                                    },\n                                                )\n\n                await manager.send_event(\n                    websocket,\n                    \"final_result\",\n                    {\"output\": final_output},\n                )\n\n                # Update conversation history\n                conversation_history.append({\"role\": \"user\", \"content\": user_message})\n                if final_output:\n                    conversation_history.append(\n                        {\"role\": \"assistant\", \"content\": final_output}\n                    )\n\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\n\n                # Save assistant response to database\n                if current_conversation_id and final_output:\n                    try:\n{%- if cookiecutter.use_postgresql %}\n                        async with get_db_context() as db:\n                            conv_service = get_conversation_service(db)\n                            await conv_service.add_message(\n                                UUID(current_conversation_id),\n                                MessageCreate(\n                                    role=\"assistant\",\n                                    content=final_output,\n                                    model_name=assistant.model_name if hasattr(assistant, \"model_name\") else None,\n                                ),\n                            )\n{%- else %}\n                        with get_db_session() as db:\n                            conv_service = get_conversation_service(db)\n                            conv_service.add_message(\n                                current_conversation_id,\n                                MessageCreate(\n                                    role=\"assistant\",\n                                    content=final_output,\n                                    model_name=assistant.model_name if hasattr(assistant, \"model_name\") else None,\n                                ),\n                            )\n{%- endif %}\n                    except Exception as e:\n                        logger.warning(f\"Failed to persist assistant response: {e}\")\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n\n                # Save assistant response to database\n                if current_conversation_id and final_output:\n                    try:\n                        await conv_service.add_message(\n                            current_conversation_id,\n                            MessageCreate(\n                                role=\"assistant\",\n                                content=final_output,\n                                model_name=assistant.model_name if hasattr(assistant, \"model_name\") else None,\n                            ),\n                        )\n                    except Exception as e:\n                        logger.warning(f\"Failed to persist assistant response: {e}\")\n{%- endif %}\n\n                await manager.send_event(websocket, \"complete\", {\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n                    \"conversation_id\": current_conversation_id,\n{%- endif %}\n                })\n\n            except WebSocketDisconnect:\n                # Client disconnected during processing - this is normal\n                logger.info(\"Client disconnected during agent processing\")\n                break\n            except Exception as e:\n                logger.exception(f\"Error processing agent request: {e}\")\n                # Try to send error, but don't fail if connection is closed\n                await manager.send_event(websocket, \"error\", {\"message\": str(e)})\n\n    except WebSocketDisconnect:\n        pass  # Normal disconnect\n    finally:\n        manager.disconnect(websocket)\n{%- elif cookiecutter.enable_ai_agent and cookiecutter.use_langgraph %}\n\"\"\"AI Agent WebSocket routes with streaming support (LangGraph ReAct Agent).\"\"\"\n\nimport logging\nfrom typing import Any\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nfrom datetime import datetime, UTC\n{%- if cookiecutter.use_postgresql %}\nfrom uuid import UUID\n{%- endif %}\n{%- endif %}\n\nfrom fastapi import APIRouter, WebSocket, WebSocketDisconnect{%- if cookiecutter.websocket_auth_jwt %}, Depends{%- endif %}{%- if cookiecutter.websocket_auth_api_key %}, Query{%- endif %}\n\nfrom langchain_core.messages import AIMessage, AIMessageChunk, HumanMessage, SystemMessage, ToolMessage\n\nfrom app.agents.langgraph_assistant import AgentContext, get_agent\n{%- if cookiecutter.websocket_auth_jwt %}\nfrom app.api.deps import get_current_user_ws\nfrom app.db.models.user import User\n{%- endif %}\n{%- if cookiecutter.websocket_auth_api_key %}\nfrom app.core.config import settings\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\nfrom app.db.session import get_db_context\nfrom app.api.deps import ConversationSvc, get_conversation_service\nfrom app.schemas.conversation import ConversationCreate, MessageCreate, ToolCallCreate, ToolCallComplete\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\nfrom app.api.deps import ConversationSvc, get_conversation_service\nfrom app.schemas.conversation import ConversationCreate, MessageCreate, ToolCallCreate, ToolCallComplete\n{%- endif %}\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter()\n\n\nclass AgentConnectionManager:\n    \"\"\"WebSocket connection manager for AI agent.\"\"\"\n\n    def __init__(self) -> None:\n        self.active_connections: list[WebSocket] = []\n\n    async def connect(self, websocket: WebSocket) -> None:\n        \"\"\"Accept and store a new WebSocket connection.\"\"\"\n        await websocket.accept()\n        self.active_connections.append(websocket)\n        logger.info(f\"Agent WebSocket connected. Total connections: {len(self.active_connections)}\")\n\n    def disconnect(self, websocket: WebSocket) -> None:\n        \"\"\"Remove a WebSocket connection.\"\"\"\n        if websocket in self.active_connections:\n            self.active_connections.remove(websocket)\n        logger.info(f\"Agent WebSocket disconnected. Total connections: {len(self.active_connections)}\")\n\n    async def send_event(self, websocket: WebSocket, event_type: str, data: Any) -> bool:\n        \"\"\"Send a JSON event to a specific WebSocket client.\n\n        Returns True if sent successfully, False if connection is closed.\n        \"\"\"\n        try:\n            await websocket.send_json({\"type\": event_type, \"data\": data})\n            return True\n        except (WebSocketDisconnect, RuntimeError):\n            # Connection already closed\n            return False\n\n\nmanager = AgentConnectionManager()\n\n\ndef build_message_history(\n    history: list[dict[str, str]]\n) -> list[HumanMessage | AIMessage | SystemMessage]:\n    \"\"\"Convert conversation history to LangChain message format.\"\"\"\n    messages: list[HumanMessage | AIMessage | SystemMessage] = []\n\n    for msg in history:\n        if msg[\"role\"] == \"user\":\n            messages.append(HumanMessage(content=msg[\"content\"]))\n        elif msg[\"role\"] == \"assistant\":\n            messages.append(AIMessage(content=msg[\"content\"]))\n        elif msg[\"role\"] == \"system\":\n            messages.append(SystemMessage(content=msg[\"content\"]))\n\n    return messages\n\n{%- if cookiecutter.websocket_auth_api_key %}\n\n\nasync def verify_api_key(api_key: str) -> bool:\n    \"\"\"Verify the API key for WebSocket authentication.\"\"\"\n    return api_key == settings.API_KEY\n{%- endif %}\n\n\n@router.websocket(\"/ws/agent\")\nasync def agent_websocket(\n    websocket: WebSocket,\n{%- if cookiecutter.websocket_auth_jwt %}\n    user: User = Depends(get_current_user_ws),\n{%- elif cookiecutter.websocket_auth_api_key %}\n    api_key: str = Query(..., alias=\"api_key\"),\n{%- endif %}\n) -> None:\n    \"\"\"WebSocket endpoint for LangGraph ReAct agent with streaming support.\n\n    Uses LangGraph astream_events() to stream all agent events including:\n    - user_prompt: When user input is received\n    - model_request_start: When model request begins\n    - text_delta: Streaming text from the model\n    - tool_call: When a tool is called\n    - tool_result: When a tool returns a result\n    - final_result: When the final result is ready\n    - complete: When processing is complete\n    - error: When an error occurs\n\n    Expected input message format:\n    {\n        \"message\": \"user message here\",\n        \"history\": [{\"role\": \"user|assistant|system\", \"content\": \"...\"}]{% if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %},\n        \"conversation_id\": \"optional-uuid-to-continue-existing-conversation\"{% endif %}\n    }\n{%- if cookiecutter.websocket_auth_jwt %}\n\n    Authentication: Requires a valid JWT token passed as a query parameter or header.\n{%- elif cookiecutter.websocket_auth_api_key %}\n\n    Authentication: Requires a valid API key passed as 'api_key' query parameter.\n    Example: ws://localhost:{{ cookiecutter.backend_port }}/api/v1/ws/agent?api_key=your-api-key\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n\n    Persistence: Set 'conversation_id' to continue an existing conversation.\n    If not provided, a new conversation is created. The conversation_id is\n    returned in the 'conversation_created' event.\n{%- endif %}\n    \"\"\"\n{%- if cookiecutter.websocket_auth_api_key %}\n    # Verify API key before accepting connection\n    if not await verify_api_key(api_key):\n        await websocket.close(code=4001, reason=\"Invalid API key\")\n        return\n{%- endif %}\n\n    await manager.connect(websocket)\n\n    # Conversation state per connection\n    conversation_history: list[dict[str, str]] = []\n    context: AgentContext = {}\n{%- if cookiecutter.websocket_auth_jwt %}\n    context[\"user_id\"] = str(user.id) if user else None\n    context[\"user_name\"] = user.email if user else None\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n    current_conversation_id: str | None = None\n{%- endif %}\n\n    try:\n        while True:\n            # Receive user message\n            data = await websocket.receive_json()\n            user_message = data.get(\"message\", \"\")\n            # Optionally accept history from client (or use server-side tracking)\n            if \"history\" in data:\n                conversation_history = data[\"history\"]\n\n            if not user_message:\n                await manager.send_event(websocket, \"error\", {\"message\": \"Empty message\"})\n                continue\n\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\n\n            # Handle conversation persistence\n            try:\n{%- if cookiecutter.use_postgresql %}\n                async with get_db_context() as db:\n                    conv_service = get_conversation_service(db)\n\n                    # Get or create conversation\n                    requested_conv_id = data.get(\"conversation_id\")\n                    if requested_conv_id:\n                        current_conversation_id = requested_conv_id\n                        # Verify conversation exists\n                        await conv_service.get_conversation(UUID(requested_conv_id))\n                    elif not current_conversation_id:\n                        # Create new conversation\n                        conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                            user_id=user.id,\n{%- endif %}\n                            title=user_message[:50] if len(user_message) > 50 else user_message,\n                        )\n                        conversation = await conv_service.create_conversation(conv_data)\n                        current_conversation_id = str(conversation.id)\n                        await manager.send_event(\n                            websocket,\n                            \"conversation_created\",\n                            {\"conversation_id\": current_conversation_id},\n                        )\n\n                    # Save user message\n                    await conv_service.add_message(\n                        UUID(current_conversation_id),\n                        MessageCreate(role=\"user\", content=user_message),\n                    )\n{%- else %}\n                with get_db_session() as db:\n                    conv_service = get_conversation_service(db)\n\n                    # Get or create conversation\n                    requested_conv_id = data.get(\"conversation_id\")\n                    if requested_conv_id:\n                        current_conversation_id = requested_conv_id\n                        conv_service.get_conversation(requested_conv_id)\n                    elif not current_conversation_id:\n                        # Create new conversation\n                        conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                            user_id=str(user.id),\n{%- endif %}\n                            title=user_message[:50] if len(user_message) > 50 else user_message,\n                        )\n                        conversation = conv_service.create_conversation(conv_data)\n                        current_conversation_id = str(conversation.id)\n                        await manager.send_event(\n                            websocket,\n                            \"conversation_created\",\n                            {\"conversation_id\": current_conversation_id},\n                        )\n\n                    # Save user message\n                    conv_service.add_message(\n                        current_conversation_id,\n                        MessageCreate(role=\"user\", content=user_message),\n                    )\n{%- endif %}\n            except Exception as e:\n                logger.warning(f\"Failed to persist conversation: {e}\")\n                # Continue without persistence\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n\n            # Handle conversation persistence (MongoDB)\n            conv_service = get_conversation_service()\n\n            requested_conv_id = data.get(\"conversation_id\")\n            if requested_conv_id:\n                current_conversation_id = requested_conv_id\n                await conv_service.get_conversation(requested_conv_id)\n            elif not current_conversation_id:\n                conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                    user_id=str(user.id),\n{%- endif %}\n                    title=user_message[:50] if len(user_message) > 50 else user_message,\n                )\n                conversation = await conv_service.create_conversation(conv_data)\n                current_conversation_id = str(conversation.id)\n                await manager.send_event(\n                    websocket,\n                    \"conversation_created\",\n                    {\"conversation_id\": current_conversation_id},\n                )\n\n            # Save user message\n            await conv_service.add_message(\n                current_conversation_id,\n                MessageCreate(role=\"user\", content=user_message),\n            )\n{%- endif %}\n\n            await manager.send_event(websocket, \"user_prompt\", {\"content\": user_message})\n\n            try:\n                assistant = get_agent()\n\n                final_output = \"\"\n                tool_events: list[Any] = []\n                seen_tool_call_ids: set[str] = set()\n\n                await manager.send_event(websocket, \"model_request_start\", {})\n\n                # Use LangGraph's astream with messages and updates modes\n                async for stream_mode, data in assistant.stream(\n                    user_message,\n                    history=conversation_history,\n                    context=context,\n                ):\n                    if stream_mode == \"messages\":\n                        chunk, _metadata = data\n\n                        if isinstance(chunk, AIMessageChunk):\n                            if chunk.content:\n                                text_content = \"\"\n                                if isinstance(chunk.content, str):\n                                    text_content = chunk.content\n                                elif isinstance(chunk.content, list):\n                                    for block in chunk.content:\n                                        if isinstance(block, dict) and block.get(\"type\") == \"text\":\n                                            text_content += block.get(\"text\", \"\")\n                                        elif isinstance(block, str):\n                                            text_content += block\n\n                                if text_content:\n                                    await manager.send_event(\n                                        websocket,\n                                        \"text_delta\",\n                                        {\"content\": text_content},\n                                    )\n                                    final_output += text_content\n\n                            # Handle tool call chunks\n                            if chunk.tool_call_chunks:\n                                for tc_chunk in chunk.tool_call_chunks:\n                                    tc_id = tc_chunk.get(\"id\")\n                                    tc_name = tc_chunk.get(\"name\")\n                                    if tc_id and tc_name and tc_id not in seen_tool_call_ids:\n                                        seen_tool_call_ids.add(tc_id)\n                                        await manager.send_event(\n                                            websocket,\n                                            \"tool_call\",\n                                            {\n                                                \"tool_name\": tc_name,\n                                                \"args\": {},\n                                                \"tool_call_id\": tc_id,\n                                            },\n                                        )\n\n                    elif stream_mode == \"updates\":\n                        # Handle state updates from nodes\n                        for node_name, update in data.items():\n                            if node_name == \"tools\":\n                                # Tool node completed - extract tool results\n                                for msg in update.get(\"messages\", []):\n                                    if isinstance(msg, ToolMessage):\n                                        await manager.send_event(\n                                            websocket,\n                                            \"tool_result\",\n                                            {\n                                                \"tool_call_id\": msg.tool_call_id,\n                                                \"content\": msg.content,\n                                            },\n                                        )\n                            elif node_name == \"agent\":\n                                # Agent node completed - check for tool calls\n                                for msg in update.get(\"messages\", []):\n                                    if isinstance(msg, AIMessage) and msg.tool_calls:\n                                        for tc in msg.tool_calls:\n                                            tc_id = tc.get(\"id\", \"\")\n                                            if tc_id not in seen_tool_call_ids:\n                                                seen_tool_call_ids.add(tc_id)\n                                                tool_events.append(tc)\n                                                await manager.send_event(\n                                                    websocket,\n                                                    \"tool_call\",\n                                                    {\n                                                        \"tool_name\": tc.get(\"name\", \"\"),\n                                                        \"args\": tc.get(\"args\", {}),\n                                                        \"tool_call_id\": tc_id,\n                                                    },\n                                                )\n\n                await manager.send_event(\n                    websocket,\n                    \"final_result\",\n                    {\"output\": final_output},\n                )\n\n                # Update conversation history\n                conversation_history.append({\"role\": \"user\", \"content\": user_message})\n                if final_output:\n                    conversation_history.append(\n                        {\"role\": \"assistant\", \"content\": final_output}\n                    )\n\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\n\n                # Save assistant response to database\n                if current_conversation_id and final_output:\n                    try:\n{%- if cookiecutter.use_postgresql %}\n                        async with get_db_context() as db:\n                            conv_service = get_conversation_service(db)\n                            await conv_service.add_message(\n                                UUID(current_conversation_id),\n                                MessageCreate(\n                                    role=\"assistant\",\n                                    content=final_output,\n                                    model_name=assistant.model_name if hasattr(assistant, \"model_name\") else None,\n                                ),\n                            )\n{%- else %}\n                        with get_db_session() as db:\n                            conv_service = get_conversation_service(db)\n                            conv_service.add_message(\n                                current_conversation_id,\n                                MessageCreate(\n                                    role=\"assistant\",\n                                    content=final_output,\n                                    model_name=assistant.model_name if hasattr(assistant, \"model_name\") else None,\n                                ),\n                            )\n{%- endif %}\n                    except Exception as e:\n                        logger.warning(f\"Failed to persist assistant response: {e}\")\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n\n                # Save assistant response to database\n                if current_conversation_id and final_output:\n                    try:\n                        await conv_service.add_message(\n                            current_conversation_id,\n                            MessageCreate(\n                                role=\"assistant\",\n                                content=final_output,\n                                model_name=assistant.model_name if hasattr(assistant, \"model_name\") else None,\n                            ),\n                        )\n                    except Exception as e:\n                        logger.warning(f\"Failed to persist assistant response: {e}\")\n{%- endif %}\n\n                await manager.send_event(websocket, \"complete\", {\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n                    \"conversation_id\": current_conversation_id,\n{%- endif %}\n                })\n\n            except WebSocketDisconnect:\n                # Client disconnected during processing - this is normal\n                logger.info(\"Client disconnected during agent processing\")\n                break\n            except Exception as e:\n                logger.exception(f\"Error processing agent request: {e}\")\n                # Try to send error, but don't fail if connection is closed\n                await manager.send_event(websocket, \"error\", {\"message\": str(e)})\n\n    except WebSocketDisconnect:\n        pass  # Normal disconnect\n    finally:\n        manager.disconnect(websocket)\n{%- elif cookiecutter.enable_ai_agent and cookiecutter.use_crewai %}\n\"\"\"AI Agent WebSocket routes with streaming support (CrewAI Multi-Agent).\"\"\"\n\nimport logging\nfrom typing import Any\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nfrom datetime import datetime, UTC\n{%- if cookiecutter.use_postgresql %}\nfrom uuid import UUID\n{%- endif %}\n{%- endif %}\n\nfrom fastapi import APIRouter, WebSocket, WebSocketDisconnect{%- if cookiecutter.websocket_auth_jwt %}, Depends{%- endif %}{%- if cookiecutter.websocket_auth_api_key %}, Query{%- endif %}\n\nfrom app.agents.crewai_assistant import CrewContext, get_crew\n{%- if cookiecutter.websocket_auth_jwt %}\nfrom app.api.deps import get_current_user_ws\nfrom app.db.models.user import User\n{%- endif %}\n{%- if cookiecutter.websocket_auth_api_key %}\nfrom app.core.config import settings\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\nfrom app.db.session import get_db_context\nfrom app.api.deps import ConversationSvc, get_conversation_service\nfrom app.schemas.conversation import ConversationCreate, MessageCreate\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\nfrom app.api.deps import ConversationSvc, get_conversation_service\nfrom app.schemas.conversation import ConversationCreate, MessageCreate\n{%- endif %}\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter()\n\n\nclass AgentConnectionManager:\n    \"\"\"WebSocket connection manager for AI agent.\"\"\"\n\n    def __init__(self) -> None:\n        self.active_connections: list[WebSocket] = []\n\n    async def connect(self, websocket: WebSocket) -> None:\n        \"\"\"Accept and store a new WebSocket connection.\"\"\"\n        await websocket.accept()\n        self.active_connections.append(websocket)\n        logger.info(f\"Agent WebSocket connected. Total connections: {len(self.active_connections)}\")\n\n    def disconnect(self, websocket: WebSocket) -> None:\n        \"\"\"Remove a WebSocket connection.\"\"\"\n        if websocket in self.active_connections:\n            self.active_connections.remove(websocket)\n        logger.info(f\"Agent WebSocket disconnected. Total connections: {len(self.active_connections)}\")\n\n    async def send_event(self, websocket: WebSocket, event_type: str, data: Any) -> bool:\n        \"\"\"Send a JSON event to a specific WebSocket client.\n\n        Returns True if sent successfully, False if connection is closed.\n        \"\"\"\n        try:\n            await websocket.send_json({\"type\": event_type, \"data\": data})\n            return True\n        except (WebSocketDisconnect, RuntimeError):\n            # Connection already closed\n            return False\n\n\nmanager = AgentConnectionManager()\n\n{%- if cookiecutter.websocket_auth_api_key %}\n\n\nasync def verify_api_key(api_key: str) -> bool:\n    \"\"\"Verify the API key for WebSocket authentication.\"\"\"\n    return api_key == settings.API_KEY\n{%- endif %}\n\n\n@router.websocket(\"/ws/agent\")\nasync def agent_websocket(\n    websocket: WebSocket,\n{%- if cookiecutter.websocket_auth_jwt %}\n    user: User = Depends(get_current_user_ws),\n{%- elif cookiecutter.websocket_auth_api_key %}\n    api_key: str = Query(..., alias=\"api_key\"),\n{%- endif %}\n) -> None:\n    \"\"\"WebSocket endpoint for CrewAI multi-agent with streaming support.\n\n    Uses CrewAI to stream crew execution events including:\n    - user_prompt: When user input is received\n    - task_start: When a task begins execution\n    - agent_action: When an agent takes an action\n    - task_complete: When a task finishes\n    - crew_complete: When all tasks are done\n    - final_result: When the final result is ready\n    - complete: When processing is complete\n    - error: When an error occurs\n\n    Expected input message format:\n    {\n        \"message\": \"user message here\",\n        \"history\": [{\"role\": \"user|assistant|system\", \"content\": \"...\"}]{% if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %},\n        \"conversation_id\": \"optional-uuid-to-continue-existing-conversation\"{% endif %}\n    }\n{%- if cookiecutter.websocket_auth_jwt %}\n\n    Authentication: Requires a valid JWT token passed as a query parameter or header.\n{%- elif cookiecutter.websocket_auth_api_key %}\n\n    Authentication: Requires a valid API key passed as 'api_key' query parameter.\n    Example: ws://localhost:{{ cookiecutter.backend_port }}/api/v1/ws/agent?api_key=your-api-key\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n\n    Persistence: Set 'conversation_id' to continue an existing conversation.\n    If not provided, a new conversation is created. The conversation_id is\n    returned in the 'conversation_created' event.\n{%- endif %}\n    \"\"\"\n{%- if cookiecutter.websocket_auth_api_key %}\n    # Verify API key before accepting connection\n    if not await verify_api_key(api_key):\n        await websocket.close(code=4001, reason=\"Invalid API key\")\n        return\n{%- endif %}\n\n    await manager.connect(websocket)\n\n    # Conversation state per connection\n    conversation_history: list[dict[str, str]] = []\n    context: CrewContext = {}\n{%- if cookiecutter.websocket_auth_jwt %}\n    context[\"user_id\"] = str(user.id) if user else None\n    context[\"user_name\"] = user.email if user else None\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n    current_conversation_id: str | None = None\n{%- endif %}\n\n    try:\n        while True:\n            # Receive user message\n            data = await websocket.receive_json()\n            user_message = data.get(\"message\", \"\")\n            # Optionally accept history from client (or use server-side tracking)\n            if \"history\" in data:\n                conversation_history = data[\"history\"]\n\n            if not user_message:\n                await manager.send_event(websocket, \"error\", {\"message\": \"Empty message\"})\n                continue\n\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\n\n            # Handle conversation persistence\n            try:\n{%- if cookiecutter.use_postgresql %}\n                async with get_db_context() as db:\n                    conv_service = get_conversation_service(db)\n\n                    # Get or create conversation\n                    requested_conv_id = data.get(\"conversation_id\")\n                    if requested_conv_id:\n                        current_conversation_id = requested_conv_id\n                        # Verify conversation exists\n                        await conv_service.get_conversation(UUID(requested_conv_id))\n                    elif not current_conversation_id:\n                        # Create new conversation\n                        conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                            user_id=user.id,\n{%- endif %}\n                            title=user_message[:50] if len(user_message) > 50 else user_message,\n                        )\n                        conversation = await conv_service.create_conversation(conv_data)\n                        current_conversation_id = str(conversation.id)\n                        await manager.send_event(\n                            websocket,\n                            \"conversation_created\",\n                            {\"conversation_id\": current_conversation_id},\n                        )\n\n                    # Save user message\n                    await conv_service.add_message(\n                        UUID(current_conversation_id),\n                        MessageCreate(role=\"user\", content=user_message),\n                    )\n{%- else %}\n                with get_db_session() as db:\n                    conv_service = get_conversation_service(db)\n\n                    # Get or create conversation\n                    requested_conv_id = data.get(\"conversation_id\")\n                    if requested_conv_id:\n                        current_conversation_id = requested_conv_id\n                        conv_service.get_conversation(requested_conv_id)\n                    elif not current_conversation_id:\n                        # Create new conversation\n                        conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                            user_id=str(user.id),\n{%- endif %}\n                            title=user_message[:50] if len(user_message) > 50 else user_message,\n                        )\n                        conversation = conv_service.create_conversation(conv_data)\n                        current_conversation_id = str(conversation.id)\n                        await manager.send_event(\n                            websocket,\n                            \"conversation_created\",\n                            {\"conversation_id\": current_conversation_id},\n                        )\n\n                    # Save user message\n                    conv_service.add_message(\n                        current_conversation_id,\n                        MessageCreate(role=\"user\", content=user_message),\n                    )\n{%- endif %}\n            except Exception as e:\n                logger.warning(f\"Failed to persist conversation: {e}\")\n                # Continue without persistence\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n\n            # Handle conversation persistence (MongoDB)\n            conv_service = get_conversation_service()\n\n            requested_conv_id = data.get(\"conversation_id\")\n            if requested_conv_id:\n                current_conversation_id = requested_conv_id\n                await conv_service.get_conversation(requested_conv_id)\n            elif not current_conversation_id:\n                conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                    user_id=str(user.id),\n{%- endif %}\n                    title=user_message[:50] if len(user_message) > 50 else user_message,\n                )\n                conversation = await conv_service.create_conversation(conv_data)\n                current_conversation_id = str(conversation.id)\n                await manager.send_event(\n                    websocket,\n                    \"conversation_created\",\n                    {\"conversation_id\": current_conversation_id},\n                )\n\n            # Save user message\n            await conv_service.add_message(\n                current_conversation_id,\n                MessageCreate(role=\"user\", content=user_message),\n            )\n{%- endif %}\n\n            await manager.send_event(websocket, \"user_prompt\", {\"content\": user_message})\n\n            try:\n                crew_assistant = get_crew()\n\n                final_output = \"\"\n\n                await manager.send_event(websocket, \"crew_start\", {\n                    \"crew_name\": crew_assistant.config.name,\n                    \"process\": crew_assistant.config.process,\n                })\n\n                # Stream crew execution events\n                async for event in crew_assistant.stream(\n                    user_message,\n                    history=conversation_history,\n                    context=context,\n                ):\n                    event_type = event.get(\"type\", \"unknown\")\n\n                    # Crew lifecycle events\n                    if event_type == \"crew_started\":\n                        await manager.send_event(\n                            websocket,\n                            \"crew_started\",\n                            {\n                                \"crew_name\": event.get(\"crew_name\", \"\"),\n                                \"crew_id\": event.get(\"crew_id\", \"\"),\n                            },\n                        )\n\n                    # Agent events\n                    elif event_type == \"agent_started\":\n                        await manager.send_event(\n                            websocket,\n                            \"agent_started\",\n                            {\n                                \"agent\": event.get(\"agent\", \"\"),\n                                \"task\": event.get(\"task\", \"\"),\n                            },\n                        )\n\n                    elif event_type == \"agent_completed\":\n                        agent_name = event.get(\"agent\", \"\")\n                        agent_output = event.get(\"output\", \"\")\n                        await manager.send_event(\n                            websocket,\n                            \"agent_completed\",\n                            {\n                                \"agent\": agent_name,\n                                \"output\": agent_output,\n                            },\n                        )\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\n                        # Save agent's output as a separate message\n                        if current_conversation_id and agent_output:\n                            try:\n{%- if cookiecutter.use_postgresql %}\n                                async with get_db_context() as db:\n                                    conv_service = get_conversation_service(db)\n                                    await conv_service.add_message(\n                                        UUID(current_conversation_id),\n                                        MessageCreate(\n                                            role=\"assistant\",\n                                            content=f\"‚úÖ **{agent_name}**\\n\\n{agent_output}\",\n                                        ),\n                                    )\n{%- else %}\n                                with get_db_session() as db:\n                                    conv_service = get_conversation_service(db)\n                                    conv_service.add_message(\n                                        current_conversation_id,\n                                        MessageCreate(\n                                            role=\"assistant\",\n                                            content=f\"‚úÖ **{agent_name}**\\n\\n{agent_output}\",\n                                        ),\n                                    )\n{%- endif %}\n                            except Exception as e:\n                                logger.warning(f\"Failed to persist agent response: {e}\")\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n                        # Save agent's output as a separate message\n                        if current_conversation_id and agent_output:\n                            try:\n                                await conv_service.add_message(\n                                    current_conversation_id,\n                                    MessageCreate(\n                                        role=\"assistant\",\n                                        content=f\"‚úÖ **{agent_name}**\\n\\n{agent_output}\",\n                                    ),\n                                )\n                            except Exception as e:\n                                logger.warning(f\"Failed to persist agent response: {e}\")\n{%- endif %}\n\n                    # Task events\n                    elif event_type == \"task_started\":\n                        await manager.send_event(\n                            websocket,\n                            \"task_started\",\n                            {\n                                \"task_id\": event.get(\"task_id\", \"\"),\n                                \"description\": event.get(\"description\", \"\"),\n                                \"agent\": event.get(\"agent\", \"\"),\n                            },\n                        )\n\n                    elif event_type == \"task_completed\":\n                        await manager.send_event(\n                            websocket,\n                            \"task_completed\",\n                            {\n                                \"task_id\": event.get(\"task_id\", \"\"),\n                                \"output\": event.get(\"output\", \"\"),\n                                \"agent\": event.get(\"agent\", \"\"),\n                            },\n                        )\n\n                    # Tool events\n                    elif event_type == \"tool_started\":\n                        await manager.send_event(\n                            websocket,\n                            \"tool_started\",\n                            {\n                                \"tool_name\": event.get(\"tool_name\", \"\"),\n                                \"tool_args\": event.get(\"tool_args\", \"\"),\n                                \"agent\": event.get(\"agent\", \"\"),\n                            },\n                        )\n\n                    elif event_type == \"tool_finished\":\n                        await manager.send_event(\n                            websocket,\n                            \"tool_finished\",\n                            {\n                                \"tool_name\": event.get(\"tool_name\", \"\"),\n                                \"tool_result\": event.get(\"tool_result\", \"\"),\n                                \"agent\": event.get(\"agent\", \"\"),\n                            },\n                        )\n\n                    # LLM events\n                    elif event_type == \"llm_started\":\n                        await manager.send_event(\n                            websocket,\n                            \"llm_started\",\n                            {\n                                \"agent\": event.get(\"agent\", \"\"),\n                            },\n                        )\n\n                    elif event_type == \"llm_completed\":\n                        await manager.send_event(\n                            websocket,\n                            \"llm_completed\",\n                            {\n                                \"agent\": event.get(\"agent\", \"\"),\n                                \"response\": event.get(\"response\", \"\"),\n                            },\n                        )\n\n                    # Final result\n                    elif event_type == \"crew_complete\":\n                        final_output = event.get(\"result\", \"\")\n                        await manager.send_event(\n                            websocket,\n                            \"final_result\",\n                            {\"output\": final_output},\n                        )\n\n                    # Error\n                    elif event_type == \"error\":\n                        await manager.send_event(\n                            websocket,\n                            \"error\",\n                            {\"message\": event.get(\"error\", \"Unknown error\")},\n                        )\n\n                # Update conversation history\n                conversation_history.append({\"role\": \"user\", \"content\": user_message})\n                if final_output:\n                    conversation_history.append(\n                        {\"role\": \"assistant\", \"content\": final_output}\n                    )\n\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n                # Note: Agent outputs are saved individually in agent_completed events above\n{%- endif %}\n\n                await manager.send_event(websocket, \"complete\", {\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n                    \"conversation_id\": current_conversation_id,\n{%- endif %}\n                })\n\n            except WebSocketDisconnect:\n                # Client disconnected during processing - this is normal\n                logger.info(\"Client disconnected during agent processing\")\n                break\n            except Exception as e:\n                logger.exception(f\"Error processing agent request: {e}\")\n                # Try to send error, but don't fail if connection is closed\n                await manager.send_event(websocket, \"error\", {\"message\": str(e)})\n\n    except WebSocketDisconnect:\n        pass  # Normal disconnect\n    finally:\n        manager.disconnect(websocket)\n{%- elif cookiecutter.enable_ai_agent and cookiecutter.use_deepagents %}\n\"\"\"AI Agent WebSocket routes with streaming and human-in-the-loop support (DeepAgents).\"\"\"\n\nimport logging\nimport uuid\nfrom typing import Any\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\nfrom datetime import datetime, UTC\n{%- if cookiecutter.use_postgresql %}\nfrom uuid import UUID\n{%- endif %}\n{%- endif %}\n\nfrom fastapi import APIRouter, WebSocket, WebSocketDisconnect{%- if cookiecutter.websocket_auth_jwt %}, Depends{%- endif %}{%- if cookiecutter.websocket_auth_api_key %}, Query{%- endif %}\n\nfrom langchain_core.messages import AIMessage, AIMessageChunk, HumanMessage, SystemMessage, ToolMessage\n\nfrom app.agents.deepagents_assistant import AgentContext, Decision, InterruptData, get_agent\n{%- if cookiecutter.websocket_auth_jwt %}\nfrom app.api.deps import get_current_user_ws\nfrom app.db.models.user import User\n{%- endif %}\n{%- if cookiecutter.websocket_auth_api_key %}\nfrom app.core.config import settings\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\nfrom app.db.session import get_db_context\nfrom app.api.deps import ConversationSvc, get_conversation_service\nfrom app.schemas.conversation import ConversationCreate, MessageCreate, ToolCallCreate, ToolCallComplete\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\nfrom app.api.deps import ConversationSvc, get_conversation_service\nfrom app.schemas.conversation import ConversationCreate, MessageCreate, ToolCallCreate, ToolCallComplete\n{%- endif %}\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter()\n\n\nclass AgentConnectionManager:\n    \"\"\"WebSocket connection manager for AI agent.\"\"\"\n\n    def __init__(self) -> None:\n        self.active_connections: list[WebSocket] = []\n\n    async def connect(self, websocket: WebSocket) -> None:\n        \"\"\"Accept and store a new WebSocket connection.\"\"\"\n        await websocket.accept()\n        self.active_connections.append(websocket)\n        logger.info(f\"Agent WebSocket connected. Total connections: {len(self.active_connections)}\")\n\n    def disconnect(self, websocket: WebSocket) -> None:\n        \"\"\"Remove a WebSocket connection.\"\"\"\n        if websocket in self.active_connections:\n            self.active_connections.remove(websocket)\n        logger.info(f\"Agent WebSocket disconnected. Total connections: {len(self.active_connections)}\")\n\n    async def send_event(self, websocket: WebSocket, event_type: str, data: Any) -> bool:\n        \"\"\"Send a JSON event to a specific WebSocket client.\n\n        Returns True if sent successfully, False if connection is closed.\n        \"\"\"\n        try:\n            await websocket.send_json({\"type\": event_type, \"data\": data})\n            return True\n        except (WebSocketDisconnect, RuntimeError):\n            # Connection already closed\n            return False\n\n\nmanager = AgentConnectionManager()\n\n\ndef build_message_history(\n    history: list[dict[str, str]]\n) -> list[HumanMessage | AIMessage | SystemMessage]:\n    \"\"\"Convert conversation history to LangChain message format.\"\"\"\n    messages: list[HumanMessage | AIMessage | SystemMessage] = []\n\n    for msg in history:\n        if msg[\"role\"] == \"user\":\n            messages.append(HumanMessage(content=msg[\"content\"]))\n        elif msg[\"role\"] == \"assistant\":\n            messages.append(AIMessage(content=msg[\"content\"]))\n        elif msg[\"role\"] == \"system\":\n            messages.append(SystemMessage(content=msg[\"content\"]))\n\n    return messages\n\n{%- if cookiecutter.websocket_auth_api_key %}\n\n\nasync def verify_api_key(api_key: str) -> bool:\n    \"\"\"Verify the API key for WebSocket authentication.\"\"\"\n    return api_key == settings.API_KEY\n{%- endif %}\n\n\n@router.websocket(\"/ws/agent\")\nasync def agent_websocket(\n    websocket: WebSocket,\n{%- if cookiecutter.websocket_auth_jwt %}\n    user: User = Depends(get_current_user_ws),\n{%- elif cookiecutter.websocket_auth_api_key %}\n    api_key: str = Query(..., alias=\"api_key\"),\n{%- endif %}\n) -> None:\n    \"\"\"WebSocket endpoint for DeepAgents with streaming and human-in-the-loop support.\n\n    Uses DeepAgents (LangGraph-based) to stream agent events including:\n    - user_prompt: When user input is received\n    - model_request_start: When model request begins\n    - text_delta: Streaming text from the model\n    - tool_call: When a tool is called (ls, read_file, write_file, edit_file, etc.)\n    - tool_result: When a tool returns a result\n    - tool_approval_required: When human approval is needed for tool execution\n    - final_result: When the final result is ready\n    - complete: When processing is complete\n    - error: When an error occurs\n\n    Human-in-the-loop:\n    When DEEPAGENTS_INTERRUPT_TOOLS is configured, certain tools will require\n    approval before execution. The frontend receives a 'tool_approval_required'\n    event and should respond with a 'resume' message containing decisions.\n\n    Expected input message formats:\n\n    Regular message:\n    {\n        \"type\": \"message\",  // optional, default\n        \"message\": \"user message here\",\n        \"history\": [{\"role\": \"user|assistant|system\", \"content\": \"...\"}]{% if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %},\n        \"conversation_id\": \"optional-uuid\"{% endif %}\n    }\n\n    Resume after interrupt:\n    {\n        \"type\": \"resume\",\n        \"decisions\": [\n            {\"type\": \"approve\"},\n            {\"type\": \"reject\"},\n            {\"type\": \"edit\", \"edited_action\": {\"name\": \"tool_name\", \"args\": {...}}}\n        ]\n    }\n{%- if cookiecutter.websocket_auth_jwt %}\n\n    Authentication: Requires a valid JWT token passed as a query parameter or header.\n{%- elif cookiecutter.websocket_auth_api_key %}\n\n    Authentication: Requires a valid API key passed as 'api_key' query parameter.\n    Example: ws://localhost:{{ cookiecutter.backend_port }}/api/v1/ws/agent?api_key=your-api-key\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n\n    Persistence: Set 'conversation_id' to continue an existing conversation.\n    If not provided, a new conversation is created. The conversation_id is\n    returned in the 'conversation_created' event.\n{%- endif %}\n    \"\"\"\n{%- if cookiecutter.websocket_auth_api_key %}\n    # Verify API key before accepting connection\n    if not await verify_api_key(api_key):\n        await websocket.close(code=4001, reason=\"Invalid API key\")\n        return\n{%- endif %}\n\n    await manager.connect(websocket)\n\n    # Conversation state per connection\n    conversation_history: list[dict[str, str]] = []\n    context: AgentContext = {}\n    # Thread ID for LangGraph state persistence (required for HITL)\n    thread_id: str = str(uuid.uuid4())\n    # Track pending interrupt for resume\n    pending_interrupt: InterruptData | None = None\n{%- if cookiecutter.websocket_auth_jwt %}\n    context[\"user_id\"] = str(user.id) if user else None\n    context[\"user_name\"] = user.email if user else None\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n    current_conversation_id: str | None = None\n{%- endif %}\n\n    # Create assistant instance (reused for the connection)\n    assistant = get_agent()\n\n    try:\n        while True:\n            # Receive message from client\n            raw_data = await websocket.receive_json()\n            message_type = raw_data.get(\"type\", \"message\")\n\n            # Handle resume after interrupt\n            if message_type == \"resume\":\n                if not pending_interrupt:\n                    await manager.send_event(websocket, \"error\", {\"message\": \"No pending interrupt to resume\"})\n                    continue\n\n                decisions: list[Decision] = raw_data.get(\"decisions\", [])\n                if len(decisions) != len(pending_interrupt[\"action_requests\"]):\n                    await manager.send_event(\n                        websocket,\n                        \"error\",\n                        {\"message\": f\"Expected {len(pending_interrupt['action_requests'])} decisions, got {len(decisions)}\"},\n                    )\n                    continue\n\n                # Clear pending interrupt\n                pending_interrupt = None\n\n                try:\n                    await manager.send_event(websocket, \"resume_start\", {})\n\n                    final_output = \"\"\n                    seen_tool_call_ids: set[str] = set()\n\n                    # Stream resume\n                    async for stream_mode, stream_data in assistant.stream_resume(\n                        decisions=decisions,\n                        thread_id=thread_id,\n                        context=context,\n                    ):\n                        if stream_mode == \"interrupt\":\n                            # Another interrupt occurred\n                            pending_interrupt = stream_data\n                            await manager.send_event(\n                                websocket,\n                                \"tool_approval_required\",\n                                {\n                                    \"action_requests\": pending_interrupt[\"action_requests\"],\n                                    \"review_configs\": pending_interrupt[\"review_configs\"],\n                                },\n                            )\n                            break\n\n                        if stream_mode == \"messages\":\n                            chunk, _metadata = stream_data\n                            if isinstance(chunk, AIMessageChunk) and chunk.content:\n                                text_content = \"\"\n                                if isinstance(chunk.content, str):\n                                    text_content = chunk.content\n                                elif isinstance(chunk.content, list):\n                                    for block in chunk.content:\n                                        if isinstance(block, dict) and block.get(\"type\") == \"text\":\n                                            text_content += block.get(\"text\", \"\")\n                                        elif isinstance(block, str):\n                                            text_content += block\n                                if text_content:\n                                    await manager.send_event(websocket, \"text_delta\", {\"content\": text_content})\n                                    final_output += text_content\n\n                        elif stream_mode == \"updates\":\n                            for node_name, update in stream_data.items():\n                                if node_name == \"tools\":\n                                    for msg in update.get(\"messages\", []):\n                                        if isinstance(msg, ToolMessage):\n                                            await manager.send_event(\n                                                websocket,\n                                                \"tool_result\",\n                                                {\"tool_call_id\": msg.tool_call_id, \"content\": msg.content},\n                                            )\n\n                    if not pending_interrupt:\n                        # No interrupt, send final result\n                        if final_output:\n                            conversation_history.append({\"role\": \"assistant\", \"content\": final_output})\n                        await manager.send_event(websocket, \"final_result\", {\"output\": final_output})\n                        await manager.send_event(websocket, \"complete\", {})\n\n                except Exception as e:\n                    logger.exception(f\"Error resuming agent: {e}\")\n                    await manager.send_event(websocket, \"error\", {\"message\": str(e)})\n\n                continue\n\n            # Regular message handling\n            user_message = raw_data.get(\"message\", \"\")\n            # Optionally accept history from client (or use server-side tracking)\n            if \"history\" in raw_data:\n                conversation_history = raw_data[\"history\"]\n\n            if not user_message:\n                await manager.send_event(websocket, \"error\", {\"message\": \"Empty message\"})\n                continue\n\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\n\n            # Handle conversation persistence\n            try:\n{%- if cookiecutter.use_postgresql %}\n                async with get_db_context() as db:\n                    conv_service = get_conversation_service(db)\n\n                    # Get or create conversation\n                    requested_conv_id = raw_data.get(\"conversation_id\")\n                    if requested_conv_id:\n                        current_conversation_id = requested_conv_id\n                        # Verify conversation exists\n                        await conv_service.get_conversation(UUID(requested_conv_id))\n                    elif not current_conversation_id:\n                        # Create new conversation\n                        conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                            user_id=user.id,\n{%- endif %}\n                            title=user_message[:50] if len(user_message) > 50 else user_message,\n                        )\n                        conversation = await conv_service.create_conversation(conv_data)\n                        current_conversation_id = str(conversation.id)\n                        await manager.send_event(\n                            websocket,\n                            \"conversation_created\",\n                            {\"conversation_id\": current_conversation_id},\n                        )\n\n                    # Save user message\n                    await conv_service.add_message(\n                        UUID(current_conversation_id),\n                        MessageCreate(role=\"user\", content=user_message),\n                    )\n{%- else %}\n                with get_db_session() as db:\n                    conv_service = get_conversation_service(db)\n\n                    # Get or create conversation\n                    requested_conv_id = raw_data.get(\"conversation_id\")\n                    if requested_conv_id:\n                        current_conversation_id = requested_conv_id\n                        conv_service.get_conversation(requested_conv_id)\n                    elif not current_conversation_id:\n                        # Create new conversation\n                        conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                            user_id=str(user.id),\n{%- endif %}\n                            title=user_message[:50] if len(user_message) > 50 else user_message,\n                        )\n                        conversation = conv_service.create_conversation(conv_data)\n                        current_conversation_id = str(conversation.id)\n                        await manager.send_event(\n                            websocket,\n                            \"conversation_created\",\n                            {\"conversation_id\": current_conversation_id},\n                        )\n\n                    # Save user message\n                    conv_service.add_message(\n                        current_conversation_id,\n                        MessageCreate(role=\"user\", content=user_message),\n                    )\n{%- endif %}\n            except Exception as e:\n                logger.warning(f\"Failed to persist conversation: {e}\")\n                # Continue without persistence\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n\n            # Handle conversation persistence (MongoDB)\n            conv_service = get_conversation_service()\n\n            requested_conv_id = raw_data.get(\"conversation_id\")\n            if requested_conv_id:\n                current_conversation_id = requested_conv_id\n                await conv_service.get_conversation(requested_conv_id)\n            elif not current_conversation_id:\n                conv_data = ConversationCreate(\n{%- if cookiecutter.websocket_auth_jwt %}\n                    user_id=str(user.id),\n{%- endif %}\n                    title=user_message[:50] if len(user_message) > 50 else user_message,\n                )\n                conversation = await conv_service.create_conversation(conv_data)\n                current_conversation_id = str(conversation.id)\n                await manager.send_event(\n                    websocket,\n                    \"conversation_created\",\n                    {\"conversation_id\": current_conversation_id},\n                )\n\n            # Save user message\n            await conv_service.add_message(\n                current_conversation_id,\n                MessageCreate(role=\"user\", content=user_message),\n            )\n{%- endif %}\n\n            await manager.send_event(websocket, \"user_prompt\", {\"content\": user_message})\n\n            try:\n                final_output = \"\"\n                tool_events: list[Any] = []\n                seen_tool_call_ids: set[str] = set()\n\n                await manager.send_event(websocket, \"model_request_start\", {})\n\n                # Use DeepAgents' stream() which wraps LangGraph's astream\n                async for stream_mode, stream_data in assistant.stream(\n                    user_message,\n                    history=conversation_history,\n                    context=context,\n                    thread_id=thread_id,\n                ):\n                    # Handle interrupt - human approval required\n                    if stream_mode == \"interrupt\":\n                        pending_interrupt = stream_data\n                        await manager.send_event(\n                            websocket,\n                            \"tool_approval_required\",\n                            {\n                                \"action_requests\": pending_interrupt[\"action_requests\"],\n                                \"review_configs\": pending_interrupt[\"review_configs\"],\n                            },\n                        )\n                        break\n\n                    if stream_mode == \"messages\":\n                        chunk, _metadata = stream_data\n\n                        if isinstance(chunk, AIMessageChunk):\n                            if chunk.content:\n                                text_content = \"\"\n                                if isinstance(chunk.content, str):\n                                    text_content = chunk.content\n                                elif isinstance(chunk.content, list):\n                                    for block in chunk.content:\n                                        if isinstance(block, dict) and block.get(\"type\") == \"text\":\n                                            text_content += block.get(\"text\", \"\")\n                                        elif isinstance(block, str):\n                                            text_content += block\n\n                                if text_content:\n                                    await manager.send_event(\n                                        websocket,\n                                        \"text_delta\",\n                                        {\"content\": text_content},\n                                    )\n                                    final_output += text_content\n\n                            # Handle tool call chunks\n                            if chunk.tool_call_chunks:\n                                for tc_chunk in chunk.tool_call_chunks:\n                                    tc_id = tc_chunk.get(\"id\")\n                                    tc_name = tc_chunk.get(\"name\")\n                                    if tc_id and tc_name and tc_id not in seen_tool_call_ids:\n                                        seen_tool_call_ids.add(tc_id)\n                                        await manager.send_event(\n                                            websocket,\n                                            \"tool_call\",\n                                            {\n                                                \"tool_name\": tc_name,\n                                                \"args\": {},\n                                                \"tool_call_id\": tc_id,\n                                            },\n                                        )\n\n                    elif stream_mode == \"updates\":\n                        # Handle state updates from nodes\n                        for node_name, update in stream_data.items():\n                            if node_name == \"tools\":\n                                # Tool node completed - extract tool results\n                                for msg in update.get(\"messages\", []):\n                                    if isinstance(msg, ToolMessage):\n                                        await manager.send_event(\n                                            websocket,\n                                            \"tool_result\",\n                                            {\n                                                \"tool_call_id\": msg.tool_call_id,\n                                                \"content\": msg.content,\n                                            },\n                                        )\n                            elif node_name == \"agent\":\n                                # Agent node completed - check for tool calls\n                                for msg in update.get(\"messages\", []):\n                                    if isinstance(msg, AIMessage) and msg.tool_calls:\n                                        for tc in msg.tool_calls:\n                                            tc_id = tc.get(\"id\", \"\")\n                                            if tc_id not in seen_tool_call_ids:\n                                                seen_tool_call_ids.add(tc_id)\n                                                tool_events.append(tc)\n                                                await manager.send_event(\n                                                    websocket,\n                                                    \"tool_call\",\n                                                    {\n                                                        \"tool_name\": tc.get(\"name\", \"\"),\n                                                        \"args\": tc.get(\"args\", {}),\n                                                        \"tool_call_id\": tc_id,\n                                                    },\n                                                )\n\n                # Only send final result if not interrupted\n                if not pending_interrupt:\n                    await manager.send_event(\n                        websocket,\n                        \"final_result\",\n                        {\"output\": final_output},\n                    )\n\n                    # Update conversation history\n                    conversation_history.append({\"role\": \"user\", \"content\": user_message})\n                    if final_output:\n                        conversation_history.append(\n                            {\"role\": \"assistant\", \"content\": final_output}\n                        )\n\n{%- if cookiecutter.enable_conversation_persistence and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\n\n                    # Save assistant response to database\n                    if current_conversation_id and final_output:\n                        try:\n{%- if cookiecutter.use_postgresql %}\n                            async with get_db_context() as db:\n                                conv_service = get_conversation_service(db)\n                                await conv_service.add_message(\n                                    UUID(current_conversation_id),\n                                    MessageCreate(\n                                        role=\"assistant\",\n                                        content=final_output,\n                                        model_name=assistant.model_name if hasattr(assistant, \"model_name\") else None,\n                                    ),\n                                )\n{%- else %}\n                            with get_db_session() as db:\n                                conv_service = get_conversation_service(db)\n                                conv_service.add_message(\n                                    current_conversation_id,\n                                    MessageCreate(\n                                        role=\"assistant\",\n                                        content=final_output,\n                                        model_name=assistant.model_name if hasattr(assistant, \"model_name\") else None,\n                                    ),\n                                )\n{%- endif %}\n                        except Exception as e:\n                            logger.warning(f\"Failed to persist assistant response: {e}\")\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n\n                    # Save assistant response to database\n                    if current_conversation_id and final_output:\n                        try:\n                            await conv_service.add_message(\n                                current_conversation_id,\n                                MessageCreate(\n                                    role=\"assistant\",\n                                    content=final_output,\n                                    model_name=assistant.model_name if hasattr(assistant, \"model_name\") else None,\n                                ),\n                            )\n                        except Exception as e:\n                            logger.warning(f\"Failed to persist assistant response: {e}\")\n{%- endif %}\n\n                    await manager.send_event(websocket, \"complete\", {\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n                        \"conversation_id\": current_conversation_id,\n{%- endif %}\n                    })\n\n            except WebSocketDisconnect:\n                # Client disconnected during processing - this is normal\n                logger.info(\"Client disconnected during agent processing\")\n                break\n            except Exception as e:\n                logger.exception(f\"Error processing agent request: {e}\")\n                # Try to send error, but don't fail if connection is closed\n                await manager.send_event(websocket, \"error\", {\"message\": str(e)})\n\n    except WebSocketDisconnect:\n        pass  # Normal disconnect\n    finally:\n        manager.disconnect(websocket)\n{%- else %}\n\"\"\"AI Agent routes - not configured.\"\"\"\n{%- endif %}\n","backend/app/api/routes/v1/webhooks.py":"{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\n\"\"\"Webhook management routes.\"\"\"\n\nfrom fastapi import APIRouter, Query, status\n{%- if cookiecutter.use_postgresql %}\nfrom uuid import UUID\n{%- endif %}\n\nfrom app.api.deps import WebhookSvc\n{%- if cookiecutter.use_jwt %}\nfrom app.api.deps import CurrentUser\n{%- endif %}\nfrom app.schemas.webhook import (\n    WebhookCreate,\n    WebhookDeliveryListResponse,\n    WebhookListResponse,\n    WebhookRead,\n    WebhookTestResponse,\n    WebhookUpdate,\n)\n\nrouter = APIRouter()\n\n\n{%- if cookiecutter.use_postgresql %}\n\n\n@router.post(\"\", response_model=WebhookRead, status_code=status.HTTP_201_CREATED)\nasync def create_webhook(\n    data: WebhookCreate,\n    webhook_service: WebhookSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Create a new webhook subscription.\"\"\"\n    webhook = await webhook_service.create_webhook(\n        data,\n{%- if cookiecutter.use_jwt %}\n        user_id=current_user.id,\n{%- endif %}\n    )\n    return WebhookRead(\n        id=webhook.id,\n        name=webhook.name,\n        url=webhook.url,\n        events=webhook.events,\n        is_active=webhook.is_active,\n        description=webhook.description,\n        created_at=webhook.created_at,\n        updated_at=webhook.updated_at,\n    )\n\n\n@router.get(\"\", response_model=WebhookListResponse)\nasync def list_webhooks(\n    webhook_service: WebhookSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n    skip: int = Query(0, ge=0),\n    limit: int = Query(50, ge=1, le=100),\n):\n    \"\"\"List all webhooks.\"\"\"\n    webhooks, total = await webhook_service.list_webhooks(\n{%- if cookiecutter.use_jwt %}\n        user_id=current_user.id,\n{%- endif %}\n        skip=skip,\n        limit=limit,\n    )\n    return WebhookListResponse(\n        items=[\n            WebhookRead(\n                id=w.id,\n                name=w.name,\n                url=w.url,\n                events=w.events,\n                is_active=w.is_active,\n                description=w.description,\n                created_at=w.created_at,\n                updated_at=w.updated_at,\n            )\n            for w in webhooks\n        ],\n        total=total,\n    )\n\n\n@router.get(\"/{webhook_id}\", response_model=WebhookRead)\nasync def get_webhook(\n    webhook_id: UUID,\n    webhook_service: WebhookSvc,\n):\n    \"\"\"Get a webhook by ID.\"\"\"\n    webhook = await webhook_service.get_webhook(webhook_id)\n    return WebhookRead(\n        id=webhook.id,\n        name=webhook.name,\n        url=webhook.url,\n        events=webhook.events,\n        is_active=webhook.is_active,\n        description=webhook.description,\n        created_at=webhook.created_at,\n        updated_at=webhook.updated_at,\n    )\n\n\n@router.patch(\"/{webhook_id}\", response_model=WebhookRead)\nasync def update_webhook(\n    webhook_id: UUID,\n    data: WebhookUpdate,\n    webhook_service: WebhookSvc,\n):\n    \"\"\"Update a webhook.\"\"\"\n    webhook = await webhook_service.update_webhook(webhook_id, data)\n    return WebhookRead(\n        id=webhook.id,\n        name=webhook.name,\n        url=webhook.url,\n        events=webhook.events,\n        is_active=webhook.is_active,\n        description=webhook.description,\n        created_at=webhook.created_at,\n        updated_at=webhook.updated_at,\n    )\n\n\n@router.delete(\"/{webhook_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_webhook(\n    webhook_id: UUID,\n    webhook_service: WebhookSvc,\n):\n    \"\"\"Delete a webhook.\"\"\"\n    await webhook_service.delete_webhook(webhook_id)\n\n\n@router.post(\"/{webhook_id}/test\", response_model=WebhookTestResponse)\nasync def test_webhook(\n    webhook_id: UUID,\n    webhook_service: WebhookSvc,\n):\n    \"\"\"Send a test event to the webhook.\"\"\"\n    result = await webhook_service.test_webhook(webhook_id)\n    return WebhookTestResponse(**result)\n\n\n@router.post(\"/{webhook_id}/regenerate-secret\")\nasync def regenerate_webhook_secret(\n    webhook_id: UUID,\n    webhook_service: WebhookSvc,\n):\n    \"\"\"Regenerate the webhook secret.\"\"\"\n    new_secret = await webhook_service.regenerate_secret(webhook_id)\n    return {\"secret\": new_secret}\n\n\n@router.get(\"/{webhook_id}/deliveries\", response_model=WebhookDeliveryListResponse)\nasync def list_webhook_deliveries(\n    webhook_id: UUID,\n    webhook_service: WebhookSvc,\n    skip: int = Query(0, ge=0),\n    limit: int = Query(50, ge=1, le=100),\n):\n    \"\"\"Get delivery history for a webhook.\"\"\"\n    from app.schemas.webhook import WebhookDeliveryRead\n\n    deliveries, total = await webhook_service.get_deliveries(webhook_id, skip=skip, limit=limit)\n    return WebhookDeliveryListResponse(\n        items=[\n            WebhookDeliveryRead(\n                id=d.id,\n                webhook_id=d.webhook_id,\n                event_type=d.event_type,\n                response_status=d.response_status,\n                error_message=d.error_message,\n                attempt_count=d.attempt_count,\n                success=d.success,\n                created_at=d.created_at,\n                delivered_at=d.delivered_at,\n            )\n            for d in deliveries\n        ],\n        total=total,\n    )\n\n\n{%- elif cookiecutter.use_sqlite %}\n\n\n@router.post(\"\", response_model=WebhookRead, status_code=status.HTTP_201_CREATED)\ndef create_webhook(\n    data: WebhookCreate,\n    webhook_service: WebhookSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Create a new webhook subscription.\"\"\"\n    webhook = webhook_service.create_webhook(\n        data,\n{%- if cookiecutter.use_jwt %}\n        user_id=current_user.id,\n{%- endif %}\n    )\n    return WebhookRead(\n        id=webhook.id,\n        name=webhook.name,\n        url=webhook.url,\n        events=webhook.events,\n        is_active=webhook.is_active,\n        description=webhook.description,\n        created_at=webhook.created_at,\n        updated_at=webhook.updated_at,\n    )\n\n\n@router.get(\"\", response_model=WebhookListResponse)\ndef list_webhooks(\n    webhook_service: WebhookSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n    skip: int = Query(0, ge=0),\n    limit: int = Query(50, ge=1, le=100),\n):\n    \"\"\"List all webhooks.\"\"\"\n    webhooks, total = webhook_service.list_webhooks(\n{%- if cookiecutter.use_jwt %}\n        user_id=current_user.id,\n{%- endif %}\n        skip=skip,\n        limit=limit,\n    )\n    return WebhookListResponse(\n        items=[\n            WebhookRead(\n                id=w.id,\n                name=w.name,\n                url=w.url,\n                events=w.events,\n                is_active=w.is_active,\n                description=w.description,\n                created_at=w.created_at,\n                updated_at=w.updated_at,\n            )\n            for w in webhooks\n        ],\n        total=total,\n    )\n\n\n@router.get(\"/{webhook_id}\", response_model=WebhookRead)\ndef get_webhook(\n    webhook_id: str,\n    webhook_service: WebhookSvc,\n):\n    \"\"\"Get a webhook by ID.\"\"\"\n    webhook = webhook_service.get_webhook(webhook_id)\n    return WebhookRead(\n        id=webhook.id,\n        name=webhook.name,\n        url=webhook.url,\n        events=webhook.events,\n        is_active=webhook.is_active,\n        description=webhook.description,\n        created_at=webhook.created_at,\n        updated_at=webhook.updated_at,\n    )\n\n\n@router.patch(\"/{webhook_id}\", response_model=WebhookRead)\ndef update_webhook(\n    webhook_id: str,\n    data: WebhookUpdate,\n    webhook_service: WebhookSvc,\n):\n    \"\"\"Update a webhook.\"\"\"\n    webhook = webhook_service.update_webhook(webhook_id, data)\n    return WebhookRead(\n        id=webhook.id,\n        name=webhook.name,\n        url=webhook.url,\n        events=webhook.events,\n        is_active=webhook.is_active,\n        description=webhook.description,\n        created_at=webhook.created_at,\n        updated_at=webhook.updated_at,\n    )\n\n\n@router.delete(\"/{webhook_id}\", status_code=status.HTTP_204_NO_CONTENT)\ndef delete_webhook(\n    webhook_id: str,\n    webhook_service: WebhookSvc,\n):\n    \"\"\"Delete a webhook.\"\"\"\n    webhook_service.delete_webhook(webhook_id)\n\n\n@router.get(\"/{webhook_id}/deliveries\", response_model=WebhookDeliveryListResponse)\ndef list_webhook_deliveries(\n    webhook_id: str,\n    webhook_service: WebhookSvc,\n    skip: int = Query(0, ge=0),\n    limit: int = Query(50, ge=1, le=100),\n):\n    \"\"\"Get delivery history for a webhook.\"\"\"\n    from app.schemas.webhook import WebhookDeliveryRead\n\n    deliveries, total = webhook_service.get_deliveries(webhook_id, skip=skip, limit=limit)\n    return WebhookDeliveryListResponse(\n        items=[\n            WebhookDeliveryRead(\n                id=d.id,\n                webhook_id=d.webhook_id,\n                event_type=d.event_type,\n                response_status=d.response_status,\n                error_message=d.error_message,\n                attempt_count=d.attempt_count,\n                success=d.success,\n                created_at=d.created_at,\n                delivered_at=d.delivered_at,\n            )\n            for d in deliveries\n        ],\n        total=total,\n    )\n\n\n{%- elif cookiecutter.use_mongodb %}\n\n\n@router.post(\"\", response_model=WebhookRead, status_code=status.HTTP_201_CREATED)\nasync def create_webhook(\n    data: WebhookCreate,\n    webhook_service: WebhookSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Create a new webhook subscription.\"\"\"\n    webhook = await webhook_service.create_webhook(\n        data,\n{%- if cookiecutter.use_jwt %}\n        user_id=str(current_user.id),\n{%- endif %}\n    )\n    return WebhookRead(\n        id=str(webhook.id),\n        name=webhook.name,\n        url=webhook.url,\n        events=webhook.events,\n        is_active=webhook.is_active,\n        description=webhook.description,\n        created_at=webhook.created_at,\n        updated_at=webhook.updated_at or webhook.created_at,\n    )\n\n\n@router.get(\"\", response_model=WebhookListResponse)\nasync def list_webhooks(\n    webhook_service: WebhookSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n    skip: int = Query(0, ge=0),\n    limit: int = Query(50, ge=1, le=100),\n):\n    \"\"\"List all webhooks.\"\"\"\n    webhooks, total = await webhook_service.list_webhooks(\n{%- if cookiecutter.use_jwt %}\n        user_id=str(current_user.id),\n{%- endif %}\n        skip=skip,\n        limit=limit,\n    )\n    return WebhookListResponse(\n        items=[\n            WebhookRead(\n                id=str(w.id),\n                name=w.name,\n                url=w.url,\n                events=w.events,\n                is_active=w.is_active,\n                description=w.description,\n                created_at=w.created_at,\n                updated_at=w.updated_at or w.created_at,\n            )\n            for w in webhooks\n        ],\n        total=total,\n    )\n\n\n@router.get(\"/{webhook_id}\", response_model=WebhookRead)\nasync def get_webhook(\n    webhook_id: str,\n    webhook_service: WebhookSvc,\n):\n    \"\"\"Get a webhook by ID.\"\"\"\n    webhook = await webhook_service.get_webhook(webhook_id)\n    return WebhookRead(\n        id=str(webhook.id),\n        name=webhook.name,\n        url=webhook.url,\n        events=webhook.events,\n        is_active=webhook.is_active,\n        description=webhook.description,\n        created_at=webhook.created_at,\n        updated_at=webhook.updated_at or webhook.created_at,\n    )\n\n\n@router.patch(\"/{webhook_id}\", response_model=WebhookRead)\nasync def update_webhook(\n    webhook_id: str,\n    data: WebhookUpdate,\n    webhook_service: WebhookSvc,\n):\n    \"\"\"Update a webhook.\"\"\"\n    webhook = await webhook_service.update_webhook(webhook_id, data)\n    return WebhookRead(\n        id=str(webhook.id),\n        name=webhook.name,\n        url=webhook.url,\n        events=webhook.events,\n        is_active=webhook.is_active,\n        description=webhook.description,\n        created_at=webhook.created_at,\n        updated_at=webhook.updated_at or webhook.created_at,\n    )\n\n\n@router.delete(\"/{webhook_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_webhook(\n    webhook_id: str,\n    webhook_service: WebhookSvc,\n):\n    \"\"\"Delete a webhook.\"\"\"\n    await webhook_service.delete_webhook(webhook_id)\n\n\n@router.get(\"/{webhook_id}/deliveries\", response_model=WebhookDeliveryListResponse)\nasync def list_webhook_deliveries(\n    webhook_id: str,\n    webhook_service: WebhookSvc,\n    skip: int = Query(0, ge=0),\n    limit: int = Query(50, ge=1, le=100),\n):\n    \"\"\"Get delivery history for a webhook.\"\"\"\n    from app.schemas.webhook import WebhookDeliveryRead\n\n    deliveries, total = await webhook_service.get_deliveries(webhook_id, skip=skip, limit=limit)\n    return WebhookDeliveryListResponse(\n        items=[\n            WebhookDeliveryRead(\n                id=str(d.id),\n                webhook_id=d.webhook_id,\n                event_type=d.event_type,\n                response_status=d.response_status,\n                error_message=d.error_message,\n                attempt_count=d.attempt_count,\n                success=d.success,\n                created_at=d.created_at,\n                delivered_at=d.delivered_at,\n            )\n            for d in deliveries\n        ],\n        total=total,\n    )\n\n\n{%- endif %}\n{%- else %}\n\"\"\"Webhook routes - not configured.\"\"\"\n{%- endif %}\n","backend/app/api/routes/v1/items.py":"{%- if cookiecutter.include_example_crud and cookiecutter.use_database %}\n# ruff: noqa: I001 - Imports structured for Jinja2 template conditionals\n\"\"\"Item CRUD routes - example API endpoints.\n\nThis module demonstrates a complete CRUD API for the Item entity.\nYou can use it as a template for creating your own endpoints.\n\nThe endpoints are:\n- GET /items - List all items (with pagination if enabled)\n- POST /items - Create a new item\n- GET /items/{item_id} - Get a single item by ID\n- PATCH /items/{item_id} - Update an item\n- DELETE /items/{item_id} - Delete an item\n\"\"\"\n{%- if cookiecutter.use_postgresql %}\n\nfrom uuid import UUID\n{%- endif %}\n\nfrom fastapi import APIRouter, status\n{%- if cookiecutter.enable_pagination and cookiecutter.use_postgresql %}\nfrom fastapi_pagination import Page\nfrom fastapi_pagination.ext.sqlalchemy import paginate\nfrom sqlalchemy import select\n{%- elif cookiecutter.enable_pagination and cookiecutter.use_sqlite %}\nfrom fastapi_pagination import Page\nfrom fastapi_pagination.ext.sqlalchemy import paginate\nfrom sqlalchemy import select\n{%- endif %}\n\n{%- if cookiecutter.use_mongodb %}\nfrom app.api.deps import ItemSvc\n{%- elif cookiecutter.enable_pagination %}\nfrom app.api.deps import DBSession, ItemSvc\n{%- else %}\nfrom app.api.deps import ItemSvc\n{%- endif %}\n{%- if cookiecutter.enable_pagination and (cookiecutter.use_postgresql or cookiecutter.use_sqlite) %}\nfrom app.db.models.item import Item\n{%- endif %}\nfrom app.schemas.item import ItemCreate, ItemRead, ItemUpdate\n\nrouter = APIRouter()\n\n\n{%- if cookiecutter.use_postgresql %}\n\n{%- if cookiecutter.enable_pagination %}\n\n\n@router.get(\"\", response_model=Page[ItemRead])\nasync def list_items(db: DBSession):\n    \"\"\"List all items with pagination.\n\n    Returns a paginated list of items. Use query parameters\n    `page` and `size` to control pagination.\n    \"\"\"\n    return await paginate(db, select(Item))\n{%- else %}\n\n\n@router.get(\"\", response_model=list[ItemRead])\nasync def list_items(\n    item_service: ItemSvc,\n    skip: int = 0,\n    limit: int = 100,\n):\n    \"\"\"List all items.\n\n    Returns a list of items with offset-based pagination.\n    \"\"\"\n    return await item_service.get_multi(skip=skip, limit=limit)\n{%- endif %}\n\n\n@router.post(\"\", response_model=ItemRead, status_code=status.HTTP_201_CREATED)\nasync def create_item(\n    item_in: ItemCreate,\n    item_service: ItemSvc,\n):\n    \"\"\"Create a new item.\n\n    Creates an item with the provided title and optional description.\n    \"\"\"\n    return await item_service.create(item_in)\n\n\n@router.get(\"/{item_id}\", response_model=ItemRead)\nasync def get_item(\n    item_id: UUID,\n    item_service: ItemSvc,\n):\n    \"\"\"Get a single item by ID.\n\n    Raises 404 if the item does not exist.\n    \"\"\"\n    return await item_service.get_by_id(item_id)\n\n\n@router.patch(\"/{item_id}\", response_model=ItemRead)\nasync def update_item(\n    item_id: UUID,\n    item_in: ItemUpdate,\n    item_service: ItemSvc,\n):\n    \"\"\"Update an item.\n\n    Supports partial updates - only provided fields are updated.\n    Raises 404 if the item does not exist.\n    \"\"\"\n    return await item_service.update(item_id, item_in)\n\n\n@router.delete(\"/{item_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_item(\n    item_id: UUID,\n    item_service: ItemSvc,\n):\n    \"\"\"Delete an item.\n\n    Raises 404 if the item does not exist.\n    \"\"\"\n    await item_service.delete(item_id)\n\n\n{%- elif cookiecutter.use_sqlite %}\n\n{%- if cookiecutter.enable_pagination %}\n\n\n@router.get(\"\", response_model=Page[ItemRead])\ndef list_items(db: DBSession):\n    \"\"\"List all items with pagination.\n\n    Returns a paginated list of items. Use query parameters\n    `page` and `size` to control pagination.\n    \"\"\"\n    return paginate(db, select(Item))\n{%- else %}\n\n\n@router.get(\"\", response_model=list[ItemRead])\ndef list_items(\n    item_service: ItemSvc,\n    skip: int = 0,\n    limit: int = 100,\n):\n    \"\"\"List all items.\n\n    Returns a list of items with offset-based pagination.\n    \"\"\"\n    return item_service.get_multi(skip=skip, limit=limit)\n{%- endif %}\n\n\n@router.post(\"\", response_model=ItemRead, status_code=status.HTTP_201_CREATED)\ndef create_item(\n    item_in: ItemCreate,\n    item_service: ItemSvc,\n):\n    \"\"\"Create a new item.\n\n    Creates an item with the provided title and optional description.\n    \"\"\"\n    return item_service.create(item_in)\n\n\n@router.get(\"/{item_id}\", response_model=ItemRead)\ndef get_item(\n    item_id: str,\n    item_service: ItemSvc,\n):\n    \"\"\"Get a single item by ID.\n\n    Raises 404 if the item does not exist.\n    \"\"\"\n    return item_service.get_by_id(item_id)\n\n\n@router.patch(\"/{item_id}\", response_model=ItemRead)\ndef update_item(\n    item_id: str,\n    item_in: ItemUpdate,\n    item_service: ItemSvc,\n):\n    \"\"\"Update an item.\n\n    Supports partial updates - only provided fields are updated.\n    Raises 404 if the item does not exist.\n    \"\"\"\n    return item_service.update(item_id, item_in)\n\n\n@router.delete(\"/{item_id}\", status_code=status.HTTP_204_NO_CONTENT)\ndef delete_item(\n    item_id: str,\n    item_service: ItemSvc,\n):\n    \"\"\"Delete an item.\n\n    Raises 404 if the item does not exist.\n    \"\"\"\n    item_service.delete(item_id)\n\n\n{%- elif cookiecutter.use_mongodb %}\n\n\n@router.get(\"\", response_model=list[ItemRead])\nasync def list_items(\n    item_service: ItemSvc,\n    skip: int = 0,\n    limit: int = 100,\n):\n    \"\"\"List all items.\n\n    Returns a list of items with offset-based pagination.\n    \"\"\"\n    return await item_service.get_multi(skip=skip, limit=limit)\n\n\n@router.post(\"\", response_model=ItemRead, status_code=status.HTTP_201_CREATED)\nasync def create_item(\n    item_in: ItemCreate,\n    item_service: ItemSvc,\n):\n    \"\"\"Create a new item.\n\n    Creates an item with the provided title and optional description.\n    \"\"\"\n    return await item_service.create(item_in)\n\n\n@router.get(\"/{item_id}\", response_model=ItemRead)\nasync def get_item(\n    item_id: str,\n    item_service: ItemSvc,\n):\n    \"\"\"Get a single item by ID.\n\n    Raises 404 if the item does not exist.\n    \"\"\"\n    return await item_service.get_by_id(item_id)\n\n\n@router.patch(\"/{item_id}\", response_model=ItemRead)\nasync def update_item(\n    item_id: str,\n    item_in: ItemUpdate,\n    item_service: ItemSvc,\n):\n    \"\"\"Update an item.\n\n    Supports partial updates - only provided fields are updated.\n    Raises 404 if the item does not exist.\n    \"\"\"\n    return await item_service.update(item_id, item_in)\n\n\n@router.delete(\"/{item_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_item(\n    item_id: str,\n    item_service: ItemSvc,\n):\n    \"\"\"Delete an item.\n\n    Raises 404 if the item does not exist.\n    \"\"\"\n    await item_service.delete(item_id)\n\n\n{%- endif %}\n{%- else %}\n\"\"\"Item routes - not configured.\"\"\"\n{%- endif %}\n","backend/app/api/routes/v1/conversations.py":"{%- if cookiecutter.enable_conversation_persistence %}\n\"\"\"Conversation API routes for AI chat persistence.\n\nProvides CRUD operations for conversations and messages.\n\nThe endpoints are:\n- GET /conversations - List user's conversations\n- POST /conversations - Create a new conversation\n- GET /conversations/{id} - Get a conversation with messages\n- PATCH /conversations/{id} - Update conversation title/archived status\n- DELETE /conversations/{id} - Delete a conversation\n- POST /conversations/{id}/messages - Add a message to conversation\n- GET /conversations/{id}/messages - List messages in conversation\n\"\"\"\n\n{%- if cookiecutter.use_postgresql %}\nfrom uuid import UUID\n{%- endif %}\n\nfrom fastapi import APIRouter, Query, status\n\n{%- if cookiecutter.use_mongodb %}\nfrom app.api.deps import ConversationSvc\n{%- else %}\nfrom app.api.deps import DBSession, ConversationSvc\n{%- endif %}\n{%- if cookiecutter.use_jwt %}\nfrom app.api.deps import CurrentUser\n{%- endif %}\nfrom app.schemas.conversation import (\n    ConversationCreate,\n    ConversationList,\n    ConversationRead,\n    ConversationReadWithMessages,\n    ConversationUpdate,\n    MessageCreate,\n    MessageList,\n    MessageRead,\n    MessageReadSimple,\n)\n\nrouter = APIRouter()\n\n\n{%- if cookiecutter.use_postgresql %}\n\n\n@router.get(\"\", response_model=ConversationList)\nasync def list_conversations(\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n    skip: int = Query(0, ge=0, description=\"Number of conversations to skip\"),\n    limit: int = Query(50, ge=1, le=100, description=\"Maximum conversations to return\"),\n    include_archived: bool = Query(False, description=\"Include archived conversations\"),\n):\n    \"\"\"List conversations for the current user.\n\n    Returns conversations ordered by most recently updated.\n    \"\"\"\n    items, total = await conversation_service.list_conversations(\n{%- if cookiecutter.use_jwt %}\n        user_id=current_user.id,\n{%- endif %}\n        skip=skip,\n        limit=limit,\n        include_archived=include_archived,\n    )\n    return ConversationList(items=items, total=total)\n\n\n@router.post(\"\", response_model=ConversationRead, status_code=status.HTTP_201_CREATED)\nasync def create_conversation(\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n    data: ConversationCreate | None = None,\n):\n    \"\"\"Create a new conversation.\n\n    The title is optional and can be set later.\n    \"\"\"\n    if data is None:\n        data = ConversationCreate()\n{%- if cookiecutter.use_jwt %}\n    data.user_id = current_user.id\n{%- endif %}\n    return await conversation_service.create_conversation(data)\n\n\n@router.get(\"/{conversation_id}\", response_model=ConversationReadWithMessages)\nasync def get_conversation(\n    conversation_id: UUID,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Get a conversation with all its messages.\n\n    Raises 404 if the conversation does not exist.\n    \"\"\"\n    return await conversation_service.get_conversation(conversation_id, include_messages=True)\n\n\n@router.patch(\"/{conversation_id}\", response_model=ConversationRead)\nasync def update_conversation(\n    conversation_id: UUID,\n    data: ConversationUpdate,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Update a conversation's title or archived status.\n\n    Raises 404 if the conversation does not exist.\n    \"\"\"\n    return await conversation_service.update_conversation(conversation_id, data)\n\n\n@router.delete(\"/{conversation_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_conversation(\n    conversation_id: UUID,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Delete a conversation and all its messages.\n\n    Raises 404 if the conversation does not exist.\n    \"\"\"\n    await conversation_service.delete_conversation(conversation_id)\n\n\n@router.post(\n    \"/{conversation_id}/archive\",\n    response_model=ConversationRead,\n)\nasync def archive_conversation(\n    conversation_id: UUID,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Archive a conversation.\n\n    Archived conversations are hidden from the default list view.\n    \"\"\"\n    return await conversation_service.archive_conversation(conversation_id)\n\n\n@router.get(\"/{conversation_id}/messages\", response_model=MessageList)\nasync def list_messages(\n    conversation_id: UUID,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n    skip: int = Query(0, ge=0),\n    limit: int = Query(100, ge=1, le=500),\n):\n    \"\"\"List messages in a conversation.\n\n    Returns messages ordered by creation time (oldest first).\n    \"\"\"\n    items, total = await conversation_service.list_messages(conversation_id, skip=skip, limit=limit)\n    return MessageList(items=items, total=total)\n\n\n@router.post(\n    \"/{conversation_id}/messages\",\n    response_model=MessageRead,\n    status_code=status.HTTP_201_CREATED,\n)\nasync def add_message(\n    conversation_id: UUID,\n    data: MessageCreate,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Add a message to a conversation.\n\n    Raises 404 if the conversation does not exist.\n    \"\"\"\n    return await conversation_service.add_message(conversation_id, data)\n\n\n{%- elif cookiecutter.use_sqlite %}\n\n\n@router.get(\"\", response_model=ConversationList)\ndef list_conversations(\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n    skip: int = Query(0, ge=0, description=\"Number of conversations to skip\"),\n    limit: int = Query(50, ge=1, le=100, description=\"Maximum conversations to return\"),\n    include_archived: bool = Query(False, description=\"Include archived conversations\"),\n):\n    \"\"\"List conversations for the current user.\n\n    Returns conversations ordered by most recently updated.\n    \"\"\"\n    items, total = conversation_service.list_conversations(\n{%- if cookiecutter.use_jwt %}\n        user_id=str(current_user.id),\n{%- endif %}\n        skip=skip,\n        limit=limit,\n        include_archived=include_archived,\n    )\n    return ConversationList(items=items, total=total)\n\n\n@router.post(\"\", response_model=ConversationRead, status_code=status.HTTP_201_CREATED)\ndef create_conversation(\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n    data: ConversationCreate | None = None,\n):\n    \"\"\"Create a new conversation.\n\n    The title is optional and can be set later.\n    \"\"\"\n    if data is None:\n        data = ConversationCreate()\n{%- if cookiecutter.use_jwt %}\n    data.user_id = str(current_user.id)\n{%- endif %}\n    return conversation_service.create_conversation(data)\n\n\n@router.get(\"/{conversation_id}\", response_model=ConversationReadWithMessages)\ndef get_conversation(\n    conversation_id: str,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Get a conversation with all its messages.\n\n    Raises 404 if the conversation does not exist.\n    \"\"\"\n    return conversation_service.get_conversation(conversation_id, include_messages=True)\n\n\n@router.patch(\"/{conversation_id}\", response_model=ConversationRead)\ndef update_conversation(\n    conversation_id: str,\n    data: ConversationUpdate,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Update a conversation's title or archived status.\n\n    Raises 404 if the conversation does not exist.\n    \"\"\"\n    return conversation_service.update_conversation(conversation_id, data)\n\n\n@router.delete(\"/{conversation_id}\", status_code=status.HTTP_204_NO_CONTENT)\ndef delete_conversation(\n    conversation_id: str,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Delete a conversation and all its messages.\n\n    Raises 404 if the conversation does not exist.\n    \"\"\"\n    conversation_service.delete_conversation(conversation_id)\n\n\n@router.post(\n    \"/{conversation_id}/archive\",\n    response_model=ConversationRead,\n)\ndef archive_conversation(\n    conversation_id: str,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Archive a conversation.\n\n    Archived conversations are hidden from the default list view.\n    \"\"\"\n    return conversation_service.archive_conversation(conversation_id)\n\n\n@router.get(\"/{conversation_id}/messages\", response_model=MessageList)\ndef list_messages(\n    conversation_id: str,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n    skip: int = Query(0, ge=0),\n    limit: int = Query(100, ge=1, le=500),\n):\n    \"\"\"List messages in a conversation.\n\n    Returns messages ordered by creation time (oldest first).\n    \"\"\"\n    items, total = conversation_service.list_messages(conversation_id, skip=skip, limit=limit)\n    return MessageList(items=items, total=total)\n\n\n@router.post(\n    \"/{conversation_id}/messages\",\n    response_model=MessageRead,\n    status_code=status.HTTP_201_CREATED,\n)\ndef add_message(\n    conversation_id: str,\n    data: MessageCreate,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Add a message to a conversation.\n\n    Raises 404 if the conversation does not exist.\n    \"\"\"\n    return conversation_service.add_message(conversation_id, data)\n\n\n{%- elif cookiecutter.use_mongodb %}\n\n\n@router.get(\"\", response_model=ConversationList)\nasync def list_conversations(\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n    skip: int = Query(0, ge=0, description=\"Number of conversations to skip\"),\n    limit: int = Query(50, ge=1, le=100, description=\"Maximum conversations to return\"),\n    include_archived: bool = Query(False, description=\"Include archived conversations\"),\n):\n    \"\"\"List conversations for the current user.\n\n    Returns conversations ordered by most recently updated.\n    \"\"\"\n    items, total = await conversation_service.list_conversations(\n{%- if cookiecutter.use_jwt %}\n        user_id=str(current_user.id),\n{%- endif %}\n        skip=skip,\n        limit=limit,\n        include_archived=include_archived,\n    )\n    return ConversationList(items=items, total=total)\n\n\n@router.post(\"\", response_model=ConversationRead, status_code=status.HTTP_201_CREATED)\nasync def create_conversation(\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n    data: ConversationCreate | None = None,\n):\n    \"\"\"Create a new conversation.\n\n    The title is optional and can be set later.\n    \"\"\"\n    if data is None:\n        data = ConversationCreate()\n{%- if cookiecutter.use_jwt %}\n    data.user_id = str(current_user.id)\n{%- endif %}\n    return await conversation_service.create_conversation(data)\n\n\n@router.get(\"/{conversation_id}\", response_model=ConversationReadWithMessages)\nasync def get_conversation(\n    conversation_id: str,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Get a conversation with all its messages.\n\n    Raises 404 if the conversation does not exist.\n    \"\"\"\n    return await conversation_service.get_conversation(conversation_id, include_messages=True)\n\n\n@router.patch(\"/{conversation_id}\", response_model=ConversationRead)\nasync def update_conversation(\n    conversation_id: str,\n    data: ConversationUpdate,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Update a conversation's title or archived status.\n\n    Raises 404 if the conversation does not exist.\n    \"\"\"\n    return await conversation_service.update_conversation(conversation_id, data)\n\n\n@router.delete(\"/{conversation_id}\", status_code=status.HTTP_204_NO_CONTENT)\nasync def delete_conversation(\n    conversation_id: str,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Delete a conversation and all its messages.\n\n    Raises 404 if the conversation does not exist.\n    \"\"\"\n    await conversation_service.delete_conversation(conversation_id)\n\n\n@router.post(\n    \"/{conversation_id}/archive\",\n    response_model=ConversationRead,\n)\nasync def archive_conversation(\n    conversation_id: str,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Archive a conversation.\n\n    Archived conversations are hidden from the default list view.\n    \"\"\"\n    return await conversation_service.archive_conversation(conversation_id)\n\n\n@router.get(\"/{conversation_id}/messages\", response_model=MessageList)\nasync def list_messages(\n    conversation_id: str,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n    skip: int = Query(0, ge=0),\n    limit: int = Query(100, ge=1, le=500),\n):\n    \"\"\"List messages in a conversation.\n\n    Returns messages ordered by creation time (oldest first).\n    \"\"\"\n    items, total = await conversation_service.list_messages(conversation_id, skip=skip, limit=limit)\n    return MessageList(items=items, total=total)\n\n\n@router.post(\n    \"/{conversation_id}/messages\",\n    response_model=MessageRead,\n    status_code=status.HTTP_201_CREATED,\n)\nasync def add_message(\n    conversation_id: str,\n    data: MessageCreate,\n    conversation_service: ConversationSvc,\n{%- if cookiecutter.use_jwt %}\n    current_user: CurrentUser,\n{%- endif %}\n):\n    \"\"\"Add a message to a conversation.\n\n    Raises 404 if the conversation does not exist.\n    \"\"\"\n    return await conversation_service.add_message(conversation_id, data)\n\n\n{%- endif %}\n{%- else %}\n\"\"\"Conversation routes - not configured.\"\"\"\n{%- endif %}\n","backend/app/api/routes/v1/oauth.py":"{%- if cookiecutter.enable_oauth %}\n\"\"\"OAuth2 authentication routes.\"\"\"\n\nfrom urllib.parse import urlencode\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import RedirectResponse\n\nfrom app.api.deps import UserSvc\nfrom app.core.oauth import oauth\nfrom app.core.security import create_access_token, create_refresh_token\n\nrouter = APIRouter()\n\n# Frontend URL for OAuth callback redirect\nFRONTEND_URL = \"http://localhost:{{ cookiecutter.frontend_port }}\"\n\n{%- if cookiecutter.enable_oauth_google %}\n\n\n@router.get(\"/google/login\")\nasync def google_login(request: Request):\n    \"\"\"Redirect to Google OAuth2 login page.\"\"\"\n    from app.core.config import settings\n\n    redirect_uri = settings.GOOGLE_REDIRECT_URI\n    return await oauth.google.authorize_redirect(request, redirect_uri)\n\n\n{%- if cookiecutter.use_postgresql %}\n\n\n@router.get(\"/google/callback\")\nasync def google_callback(request: Request, user_service: UserSvc):\n    \"\"\"Handle Google OAuth2 callback.\n\n    Creates a new user if one doesn't exist with the Google email,\n    or returns tokens for existing user. Redirects to frontend with tokens.\n    \"\"\"\n    try:\n        token = await oauth.google.authorize_access_token(request)\n        user_info = token.get(\"userinfo\")\n\n        if not user_info:\n            params = urlencode({\"error\": \"Failed to get user info from Google\"})\n            return RedirectResponse(url=f\"{FRONTEND_URL}/login?{params}\")\n\n        email = user_info.get(\"email\")\n        google_id = user_info.get(\"sub\")\n        full_name = user_info.get(\"name\")\n\n        # Try to find existing user by OAuth ID\n        user = await user_service.get_by_oauth(\"google\", google_id)\n\n        if not user:\n            # Try to find by email (link existing account)\n            user = await user_service.get_by_email(email)\n            if user:\n                # Link OAuth to existing account\n                user = await user_service.link_oauth(user.id, \"google\", google_id)\n            else:\n                # Create new user\n                user = await user_service.create_oauth_user(\n                    email=email,\n                    full_name=full_name,\n                    oauth_provider=\"google\",\n                    oauth_id=google_id,\n                )\n\n        access_token = create_access_token(subject=str(user.id))\n        refresh_token = create_refresh_token(subject=str(user.id))\n\n        # Redirect to frontend with tokens\n        params = urlencode({\n            \"access_token\": access_token,\n            \"refresh_token\": refresh_token,\n        })\n        return RedirectResponse(url=f\"{FRONTEND_URL}/auth/callback?{params}\")\n\n    except Exception as e:\n        params = urlencode({\"error\": str(e)})\n        return RedirectResponse(url=f\"{FRONTEND_URL}/login?{params}\")\n\n\n{%- elif cookiecutter.use_mongodb %}\n\n\n@router.get(\"/google/callback\")\nasync def google_callback(request: Request, user_service: UserSvc):\n    \"\"\"Handle Google OAuth2 callback.\n\n    Creates a new user if one doesn't exist with the Google email,\n    or returns tokens for existing user. Redirects to frontend with tokens.\n    \"\"\"\n    try:\n        token = await oauth.google.authorize_access_token(request)\n        user_info = token.get(\"userinfo\")\n\n        if not user_info:\n            params = urlencode({\"error\": \"Failed to get user info from Google\"})\n            return RedirectResponse(url=f\"{FRONTEND_URL}/login?{params}\")\n\n        email = user_info.get(\"email\")\n        google_id = user_info.get(\"sub\")\n        full_name = user_info.get(\"name\")\n\n        # Try to find existing user by OAuth ID\n        user = await user_service.get_by_oauth(\"google\", google_id)\n\n        if not user:\n            # Try to find by email (link existing account)\n            user = await user_service.get_by_email(email)\n            if user:\n                # Link OAuth to existing account\n                user = await user_service.link_oauth(str(user.id), \"google\", google_id)\n            else:\n                # Create new user\n                user = await user_service.create_oauth_user(\n                    email=email,\n                    full_name=full_name,\n                    oauth_provider=\"google\",\n                    oauth_id=google_id,\n                )\n\n        access_token = create_access_token(subject=str(user.id))\n        refresh_token = create_refresh_token(subject=str(user.id))\n\n        # Redirect to frontend with tokens\n        params = urlencode({\n            \"access_token\": access_token,\n            \"refresh_token\": refresh_token,\n        })\n        return RedirectResponse(url=f\"{FRONTEND_URL}/auth/callback?{params}\")\n\n    except Exception as e:\n        params = urlencode({\"error\": str(e)})\n        return RedirectResponse(url=f\"{FRONTEND_URL}/login?{params}\")\n\n\n{%- elif cookiecutter.use_sqlite %}\n\n\n@router.get(\"/google/callback\")\nasync def google_callback(request: Request, user_service: UserSvc):\n    \"\"\"Handle Google OAuth2 callback.\n\n    Creates a new user if one doesn't exist with the Google email,\n    or returns tokens for existing user. Redirects to frontend with tokens.\n    \"\"\"\n    try:\n        # OAuth token exchange is async\n        token = await oauth.google.authorize_access_token(request)\n\n        user_info = token.get(\"userinfo\")\n\n        if not user_info:\n            params = urlencode({\"error\": \"Failed to get user info from Google\"})\n            return RedirectResponse(url=f\"{FRONTEND_URL}/login?{params}\")\n\n        email = user_info.get(\"email\")\n        google_id = user_info.get(\"sub\")\n        full_name = user_info.get(\"name\")\n\n        # Try to find existing user by OAuth ID\n        user = user_service.get_by_oauth(\"google\", google_id)\n\n        if not user:\n            # Try to find by email (link existing account)\n            user = user_service.get_by_email(email)\n            if user:\n                # Link OAuth to existing account\n                user = user_service.link_oauth(user.id, \"google\", google_id)\n            else:\n                # Create new user\n                user = user_service.create_oauth_user(\n                    email=email,\n                    full_name=full_name,\n                    oauth_provider=\"google\",\n                    oauth_id=google_id,\n                )\n\n        access_token = create_access_token(subject=user.id)\n        refresh_token = create_refresh_token(subject=user.id)\n\n        # Redirect to frontend with tokens\n        params = urlencode({\n            \"access_token\": access_token,\n            \"refresh_token\": refresh_token,\n        })\n        return RedirectResponse(url=f\"{FRONTEND_URL}/auth/callback?{params}\")\n\n    except Exception as e:\n        params = urlencode({\"error\": str(e)})\n        return RedirectResponse(url=f\"{FRONTEND_URL}/login?{params}\")\n\n\n{%- endif %}\n{%- endif %}\n{%- else %}\n\"\"\"OAuth routes - not configured.\"\"\"\n{%- endif %}\n","backend/app/api/routes/__init__.py":"\"\"\"API routes.\n\nThis package contains versioned API routes.\nAdd new versions by creating new folders (e.g., v2/) and updating router.py.\n\"\"\"\n\nfrom app.api.routes.v1 import v1_router\n\n__all__ = [\"v1_router\"]\n","backend/app/commands/__init__.py":"\"\"\"\nCustom commands system with auto-discovery.\n\nThis module provides a Django-like custom commands system for FastAPI + Click.\nCommands are auto-discovered from this package and registered to the CLI.\n\nUsage:\n    # In app/commands/my_command.py\n    from app.commands import command\n    import click\n\n    @command(\"my-command\", help=\"Description of my command\")\n    @click.option(\"--option\", \"-o\", help=\"Some option\")\n    def my_command(option: str):\n        click.echo(f\"Running with {option}\")\n\n    # Then use it:\n    # project cmd my-command --option value\n\"\"\"\n\nimport importlib\nimport pkgutil\nfrom collections.abc import Callable\nfrom pathlib import Path\n\nimport click\n\n# Registry for custom commands\n_commands: list[click.Command] = []\n_discovered = False\n\n\ndef command(name: str | None = None, **kwargs) -> Callable:\n    \"\"\"\n    Decorator to register a custom command.\n\n    Args:\n        name: Command name (defaults to function name with underscores replaced by hyphens)\n        **kwargs: Additional arguments passed to click.command()\n\n    Example:\n        @command(\"seed\", help=\"Seed database with initial data\")\n        @click.option(\"--count\", \"-c\", default=10)\n        def seed_data(count: int):\n            click.echo(f\"Seeding {count} records...\")\n    \"\"\"\n\n    def decorator(func: Callable) -> click.Command:\n        cmd_name = name or func.__name__.replace(\"_\", \"-\")\n        cmd = click.command(cmd_name, **kwargs)(func)\n        _commands.append(cmd)\n        return cmd\n\n    return decorator\n\n\ndef discover_commands() -> list[click.Command]:\n    \"\"\"\n    Auto-discover all commands in this package.\n\n    Imports all modules in the app.commands package (except those starting with _)\n    which triggers the @command decorator to register them.\n\n    Returns:\n        List of discovered click.Command objects\n    \"\"\"\n    global _discovered\n\n    if _discovered:\n        return _commands\n\n    package_dir = Path(__file__).parent\n\n    for _, module_name, _ in pkgutil.iter_modules([str(package_dir)]):\n        if module_name.startswith(\"_\"):\n            continue\n\n        try:\n            importlib.import_module(f\"app.commands.{module_name}\")\n        except ImportError as e:\n            click.secho(f\"Warning: Failed to import command module '{module_name}': {e}\", fg=\"yellow\")\n\n    _discovered = True\n    return _commands\n\n\ndef register_commands(cli: click.Group) -> None:\n    \"\"\"\n    Register all discovered commands to a CLI group.\n\n    Args:\n        cli: The click.Group to add commands to\n    \"\"\"\n    commands = discover_commands()\n\n    for cmd in commands:\n        cli.add_command(cmd)\n\n\ndef success(message: str) -> None:\n    \"\"\"Print success message in green.\"\"\"\n    click.secho(message, fg=\"green\")\n\n\ndef error(message: str) -> None:\n    \"\"\"Print error message in red.\"\"\"\n    click.secho(message, fg=\"red\")\n\n\ndef warning(message: str) -> None:\n    \"\"\"Print warning message in yellow.\"\"\"\n    click.secho(message, fg=\"yellow\")\n\n\ndef info(message: str) -> None:\n    \"\"\"Print info message.\"\"\"\n    click.echo(message)\n","backend/app/commands/cleanup.py":"{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite -%}\n\"\"\"\nCleanup old or stale data from the database.\n\nThis command is useful for maintenance tasks.\n\"\"\"\n\nimport asyncio\nfrom datetime import UTC, datetime, timedelta\n\nimport click\n\nfrom app.commands import command, info, success, warning\n\n\n@command(\"cleanup\", help=\"Clean up old data from the database\")\n@click.option(\"--days\", \"-d\", default=30, type=int, help=\"Delete records older than N days\")\n@click.option(\"--dry-run\", is_flag=True, help=\"Show what would be deleted without making changes\")\n@click.option(\"--force\", \"-f\", is_flag=True, help=\"Skip confirmation prompt\")\ndef cleanup(days: int, dry_run: bool, force: bool) -> None:\n    \"\"\"\n    Remove old records from the database.\n\n    Example:\n        project cmd cleanup --days 90\n        project cmd cleanup --days 30 --dry-run\n        project cmd cleanup --days 7 --force\n    \"\"\"\n    cutoff_date = datetime.now(UTC) - timedelta(days=days)\n\n    if dry_run:\n        info(f\"[DRY RUN] Would delete records older than {cutoff_date}\")\n        return\n\n    if not force and not click.confirm(f\"Delete all records older than {days} days ({cutoff_date})?\"):\n        warning(\"Aborted.\")\n        return\n\n{%- if cookiecutter.use_postgresql %}\n    from app.db.session import async_session_maker\n\n    async def _cleanup():\n        async with async_session_maker() as _session:\n            info(f\"Cleaning up records older than {cutoff_date}...\")\n\n            # Add your cleanup logic here\n            # Example:\n            # result = await session.execute(\n            #     delete(YourModel).where(YourModel.created_at < cutoff_date)\n            # )\n            # await session.commit()\n            # deleted_count = result.rowcount\n\n            deleted_count = 0  # Replace with actual count\n            success(f\"Deleted {deleted_count} records.\")\n\n    asyncio.run(_cleanup())\n{%- elif cookiecutter.use_sqlite %}\n    from app.db.session import SessionLocal\n\n    with SessionLocal() as _session:\n        info(f\"Cleaning up records older than {cutoff_date}...\")\n\n        # Add your cleanup logic here\n        # Example:\n        # result = session.execute(\n        #     delete(YourModel).where(YourModel.created_at < cutoff_date)\n        # )\n        # session.commit()\n        # deleted_count = result.rowcount\n\n        deleted_count = 0  # Replace with actual count\n        success(f\"Deleted {deleted_count} records.\")\n{%- endif %}\n{%- endif %}\n","backend/app/commands/seed.py":"{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite -%}\n# ruff: noqa: I001 - Imports structured for Jinja2 template conditionals\n\"\"\"\nSeed database with sample data.\n\nThis command is useful for development and testing.\nUses random data generation - install faker for better data:\n    uv add faker --group dev\n\"\"\"\n{% if cookiecutter.use_postgresql %}\nimport asyncio\n{% endif %}\nimport random\nimport string\n\nimport click\n{% if cookiecutter.use_jwt or cookiecutter.include_example_crud %}\nfrom sqlalchemy import delete, select\n{% endif %}\n\nfrom app.commands import command, info, success, warning\n\n# Try to import Faker for better data generation\ntry:\n    from faker import Faker\n    fake = Faker()\n    HAS_FAKER = True\nexcept ImportError:\n    HAS_FAKER = False\n    fake = None\n\n\ndef random_email() -> str:\n    \"\"\"Generate a random email address.\"\"\"\n    if HAS_FAKER:\n        return fake.email()\n    random_str = ''.join(random.choices(string.ascii_lowercase, k=8))\n    return f\"{random_str}@example.com\"\n\n\ndef random_name() -> str:\n    \"\"\"Generate a random full name.\"\"\"\n    if HAS_FAKER:\n        return fake.name()\n    first_names = [\"John\", \"Jane\", \"Bob\", \"Alice\", \"Charlie\", \"Diana\", \"Eve\", \"Frank\"]\n    last_names = [\"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\"]\n    return f\"{random.choice(first_names)} {random.choice(last_names)}\"\n\n\ndef random_title() -> str:\n    \"\"\"Generate a random item title.\"\"\"\n    if HAS_FAKER:\n        return fake.sentence(nb_words=4).rstrip('.')\n    adjectives = [\"Amazing\", \"Great\", \"Awesome\", \"Fantastic\", \"Incredible\", \"Beautiful\"]\n    nouns = [\"Widget\", \"Gadget\", \"Thing\", \"Product\", \"Item\", \"Object\"]\n    return f\"{random.choice(adjectives)} {random.choice(nouns)}\"\n\n\ndef random_description() -> str:\n    \"\"\"Generate a random description.\"\"\"\n    if HAS_FAKER:\n        return fake.paragraph(nb_sentences=3)\n    return \"This is a sample description for development purposes.\"\n\n\n@command(\"seed\", help=\"Seed database with sample data\")\n@click.option(\"--count\", \"-c\", default=10, type=int, help=\"Number of records to create\")\n@click.option(\"--clear\", is_flag=True, help=\"Clear existing data before seeding\")\n@click.option(\"--dry-run\", is_flag=True, help=\"Show what would be created without making changes\")\n{%- if cookiecutter.use_jwt %}\n@click.option(\"--users/--no-users\", default=True, help=\"Seed users (default: True)\")\n{%- endif %}\n{%- if cookiecutter.include_example_crud %}\n@click.option(\"--items/--no-items\", default=True, help=\"Seed items (default: True)\")\n{%- endif %}\ndef seed(\n    count: int,\n    clear: bool,\n    dry_run: bool,\n{%- if cookiecutter.use_jwt %}\n    users: bool,\n{%- endif %}\n{%- if cookiecutter.include_example_crud %}\n    items: bool,\n{%- endif %}\n) -> None:\n    \"\"\"\n    Seed the database with sample data for development.\n\n    Example:\n        project cmd seed --count 50\n        project cmd seed --clear --count 100\n        project cmd seed --dry-run\n    {%- if cookiecutter.use_jwt %}\n        project cmd seed --no-users --items  # Only seed items\n    {%- endif %}\n    \"\"\"\n    if not HAS_FAKER:\n        warning(\"Faker not installed. Using basic random data. For better data: uv add faker --group dev\")\n\n    if dry_run:\n        info(f\"[DRY RUN] Would create {count} sample records per entity\")\n        if clear:\n            info(\"[DRY RUN] Would clear existing data first\")\n{%- if cookiecutter.use_jwt %}\n        if users:\n            info(\"[DRY RUN] Would create users\")\n{%- endif %}\n{%- if cookiecutter.include_example_crud %}\n        if items:\n            info(\"[DRY RUN] Would create items\")\n{%- endif %}\n        return\n\n{%- if not cookiecutter.use_jwt and not cookiecutter.include_example_crud %}\n    info(\"No entities configured to seed. Enable JWT users or example CRUD to use this command.\")\n{%- elif cookiecutter.use_postgresql %}\n    from app.db.session import async_session_maker\n{%- if cookiecutter.use_jwt %}\n    from app.db.models.user import User\n    from app.core.security import get_password_hash\n{%- endif %}\n{%- if cookiecutter.include_example_crud %}\n    from app.db.models.item import Item\n{%- endif %}\n\n    async def _seed():\n        async with async_session_maker() as session:\n            created_counts = {}\n\n{%- if cookiecutter.use_jwt %}\n            # Seed users\n            if users:\n                if clear:\n                    info(\"Clearing existing users (except superusers)...\")\n                    await session.execute(delete(User).where(User.is_superuser == False))  # noqa: E712\n                    await session.commit()\n\n                # Check how many users already exist\n                result = await session.execute(select(User).limit(1))\n                existing = result.scalars().first()\n\n                if existing and not clear:\n                    info(\"Users already exist. Use --clear to replace them.\")\n                else:\n                    info(f\"Creating {count} sample users...\")\n                    for _ in range(count):\n                        user = User(\n                            email=random_email(),\n                            hashed_password=get_password_hash(\"password123\"),\n                            full_name=random_name(),\n                            is_active=True,\n                            is_superuser=False,\n                            role=\"user\",\n                        )\n                        session.add(user)\n                    await session.commit()\n                    created_counts[\"users\"] = count\n{%- endif %}\n\n{%- if cookiecutter.include_example_crud %}\n            # Seed items\n            if items:\n                if clear:\n                    info(\"Clearing existing items...\")\n                    await session.execute(delete(Item))\n                    await session.commit()\n\n                # Check how many items already exist\n                result = await session.execute(select(Item).limit(1))\n                existing = result.scalars().first()\n\n                if existing and not clear:\n                    info(\"Items already exist. Use --clear to replace them.\")\n                else:\n                    info(f\"Creating {count} sample items...\")\n                    for _ in range(count):\n                        item = Item(\n                            title=random_title(),\n                            description=random_description(),\n                            is_active=random.choice([True, True, True, False]),  # 75% active\n                        )\n                        session.add(item)\n                    await session.commit()\n                    created_counts[\"items\"] = count\n{%- endif %}\n\n            if created_counts:\n                summary = \", \".join(f\"{v} {k}\" for k, v in created_counts.items())\n                success(f\"Created: {summary}\")\n            else:\n                info(\"No records created.\")\n\n    asyncio.run(_seed())\n{%- elif cookiecutter.use_sqlite %}\n    from app.db.session import SessionLocal\n{%- if cookiecutter.use_jwt %}\n    from app.db.models.user import User\n    from app.core.security import get_password_hash\n{%- endif %}\n{%- if cookiecutter.include_example_crud %}\n    from app.db.models.item import Item\n{%- endif %}\n\n    with SessionLocal() as session:\n        created_counts = {}\n\n{%- if cookiecutter.use_jwt %}\n        # Seed users\n        if users:\n            if clear:\n                info(\"Clearing existing users (except superusers)...\")\n                session.execute(delete(User).where(User.is_superuser == False))  # noqa: E712\n                session.commit()\n\n            # Check how many users already exist\n            result = session.execute(select(User).limit(1))\n            existing = result.scalars().first()\n\n            if existing and not clear:\n                info(\"Users already exist. Use --clear to replace them.\")\n            else:\n                info(f\"Creating {count} sample users...\")\n                for _ in range(count):\n                    user = User(\n                        email=random_email(),\n                        hashed_password=get_password_hash(\"password123\"),\n                        full_name=random_name(),\n                        is_active=True,\n                        is_superuser=False,\n                        role=\"user\",\n                    )\n                    session.add(user)\n                session.commit()\n                created_counts[\"users\"] = count\n{%- endif %}\n\n{%- if cookiecutter.include_example_crud %}\n        # Seed items\n        if items:\n            if clear:\n                info(\"Clearing existing items...\")\n                session.execute(delete(Item))\n                session.commit()\n\n            # Check how many items already exist\n            result = session.execute(select(Item).limit(1))\n            existing = result.scalars().first()\n\n            if existing and not clear:\n                info(\"Items already exist. Use --clear to replace them.\")\n            else:\n                info(f\"Creating {count} sample items...\")\n                for _ in range(count):\n                    item = Item(\n                        title=random_title(),\n                        description=random_description(),\n                        is_active=random.choice([True, True, True, False]),  # 75% active\n                    )\n                    session.add(item)\n                session.commit()\n                created_counts[\"items\"] = count\n{%- endif %}\n\n        if created_counts:\n            summary = \", \".join(f\"{v} {k}\" for k, v in created_counts.items())\n            success(f\"Created: {summary}\")\n        else:\n            info(\"No records created.\")\n{%- endif %}\n{%- endif %}\n","backend/app/commands/example.py":"\"\"\"\nExample custom command.\n\nThis is a template showing how to create custom CLI commands.\nCopy this file and modify it to create your own commands.\n\"\"\"\n\nimport click\n\nfrom app.commands import command, info, success\n\n\n@command(\"hello\", help=\"Example command that greets the user\")\n@click.option(\"--name\", \"-n\", default=\"World\", help=\"Name to greet\")\n@click.option(\"--count\", \"-c\", default=1, type=int, help=\"Number of greetings\")\ndef hello(name: str, count: int) -> None:\n    \"\"\"\n    Greet someone multiple times.\n\n    Example:\n        project cmd hello --name Alice --count 3\n    \"\"\"\n    info(f\"Greeting {name} {count} time(s)...\")\n\n    for i in range(count):\n        click.echo(f\"  [{i + 1}] Hello, {name}!\")\n\n    success(\"Done!\")\n","backend/app/worker/arq_app.py":"{%- if cookiecutter.use_arq %}\n\"\"\"ARQ (Async Redis Queue) application configuration.\"\"\"\n\nimport asyncio\nimport logging\nfrom typing import Any\n\nfrom arq import cron\nfrom arq.connections import RedisSettings\n\nfrom app.core.config import settings\n\nlogger = logging.getLogger(__name__)\n\n\nasync def startup(ctx: dict[str, Any]) -> None:\n    \"\"\"Initialize resources on worker startup.\"\"\"\n    logger.info(\"ARQ worker starting up...\")\n    # Add any startup initialization here\n    # e.g., database connections, external clients\n\n\nasync def shutdown(ctx: dict[str, Any]) -> None:\n    \"\"\"Cleanup resources on worker shutdown.\"\"\"\n    logger.info(\"ARQ worker shutting down...\")\n    # Add any cleanup here\n\n\n# === Example Tasks ===\n# Tasks are defined as regular async functions\n\n\nasync def example_task(ctx: dict[str, Any], message: str) -> dict[str, Any]:\n    \"\"\"\n    Example task that processes a message.\n\n    Args:\n        ctx: ARQ context dictionary (contains redis connection, job info, etc.)\n        message: Message to process\n\n    Returns:\n        Result dictionary with processed message\n    \"\"\"\n    logger.info(f\"Processing message: {message}\")\n\n    # Simulate async work\n    await asyncio.sleep(1)\n\n    result = {\n        \"status\": \"completed\",\n        \"message\": f\"Processed: {message}\",\n        \"job_id\": ctx.get(\"job_id\"),\n    }\n    logger.info(f\"Task completed: {result}\")\n    return result\n\n\nasync def long_running_task(ctx: dict[str, Any], duration: int = 10) -> dict[str, Any]:\n    \"\"\"\n    Example long-running async task.\n\n    Args:\n        ctx: ARQ context dictionary\n        duration: Duration in seconds\n\n    Returns:\n        Result dictionary\n    \"\"\"\n    logger.info(f\"Starting long-running task for {duration} seconds\")\n\n    for i in range(duration):\n        await asyncio.sleep(1)\n        logger.info(f\"Progress: {i + 1}/{duration}\")\n\n    return {\n        \"status\": \"completed\",\n        \"duration\": duration,\n        \"job_id\": ctx.get(\"job_id\"),\n    }\n\n\nasync def send_email_task(\n    ctx: dict[str, Any], to: str, subject: str, body: str\n) -> dict[str, Any]:\n    \"\"\"\n    Example email sending task.\n\n    Replace with actual email sending logic (e.g., using aiosmtplib, sendgrid, etc.)\n\n    Args:\n        ctx: ARQ context dictionary\n        to: Recipient email\n        subject: Email subject\n        body: Email body\n\n    Returns:\n        Result dictionary\n    \"\"\"\n    logger.info(f\"Sending email to {to}: {subject}\")\n\n    # TODO: Implement actual email sending\n    # Example with aiosmtplib:\n    # import aiosmtplib\n    # ...\n\n    # Simulate sending\n    await asyncio.sleep(0.5)\n\n    return {\n        \"status\": \"sent\",\n        \"to\": to,\n        \"subject\": subject,\n    }\n\n\n# === Scheduled Task (runs periodically) ===\n\n\nasync def scheduled_example(ctx: dict[str, Any]) -> dict[str, Any]:\n    \"\"\"Example scheduled task that runs every minute.\"\"\"\n    logger.info(\"Running scheduled example task\")\n    return await example_task(ctx, \"scheduled\")\n\n\n# === Worker Settings ===\n# This class is used by the ARQ CLI: arq app.worker.arq_app.WorkerSettings\n\n\nclass WorkerSettings:\n    \"\"\"ARQ Worker configuration.\"\"\"\n\n    # Redis connection settings\n    redis_settings = RedisSettings(\n        host=settings.ARQ_REDIS_HOST,\n        port=settings.ARQ_REDIS_PORT,\n        password=settings.ARQ_REDIS_PASSWORD or None,\n        database=settings.ARQ_REDIS_DB,\n    )\n\n    # Register task functions\n    functions = [\n        example_task,\n        long_running_task,\n        send_email_task,\n    ]\n\n    # Scheduled/cron jobs\n    cron_jobs = [\n        cron(scheduled_example, minute={0, 15, 30, 45}),  # Every 15 minutes\n        # cron(scheduled_example, minute=0, hour=0),  # Daily at midnight\n    ]\n\n    # Worker lifecycle hooks\n    on_startup = startup\n    on_shutdown = shutdown\n\n    # Worker settings\n    max_jobs = 10  # Maximum concurrent jobs\n    job_timeout = 300  # Job timeout in seconds (5 minutes)\n    keep_result = 3600  # Keep results for 1 hour\n    poll_delay = 0.5  # Polling delay in seconds\n    queue_read_limit = 100  # Number of jobs to read at once\n{%- else %}\n# ARQ not enabled for this project\n{%- endif %}\n","backend/app/worker/tasks/__init__.py":"{%- if cookiecutter.use_celery or cookiecutter.use_taskiq or cookiecutter.use_arq %}\n\"\"\"Background tasks.\"\"\"\n\n{%- if cookiecutter.use_celery %}\nfrom app.worker.tasks.examples import example_task, long_running_task\n{%- endif %}\n\n{%- if cookiecutter.use_taskiq %}\nfrom app.worker.tasks.taskiq_examples import example_task as taskiq_example_task\nfrom app.worker.tasks.taskiq_examples import long_running_task as taskiq_long_running_task\n{%- endif %}\n\n{%- if cookiecutter.use_arq %}\nfrom app.worker.arq_app import example_task as arq_example_task\nfrom app.worker.arq_app import long_running_task as arq_long_running_task\n{%- endif %}\n\n__all__ = [\n{%- if cookiecutter.use_celery %}\n    \"example_task\",\n    \"long_running_task\",\n{%- endif %}\n{%- if cookiecutter.use_taskiq %}\n    \"taskiq_example_task\",\n    \"taskiq_long_running_task\",\n{%- endif %}\n{%- if cookiecutter.use_arq %}\n    \"arq_example_task\",\n    \"arq_long_running_task\",\n{%- endif %}\n]\n{%- else %}\n# Background tasks not enabled\n{%- endif %}\n","backend/app/worker/tasks/taskiq_examples.py":"{%- if cookiecutter.use_taskiq %}\n\"\"\"Example Taskiq tasks.\"\"\"\n\nimport asyncio\nimport logging\nfrom typing import Any\n\nfrom app.worker.taskiq_app import broker\n\nlogger = logging.getLogger(__name__)\n\n\n@broker.task\nasync def example_task(message: str) -> dict[str, Any]:\n    \"\"\"\n    Example async task that processes a message.\n\n    Args:\n        message: Message to process\n\n    Returns:\n        Result dictionary with processed message\n    \"\"\"\n    logger.info(f\"Processing message: {message}\")\n\n    # Simulate async work\n    await asyncio.sleep(1)\n\n    result = {\n        \"status\": \"completed\",\n        \"message\": f\"Processed: {message}\",\n    }\n    logger.info(f\"Task completed: {result}\")\n    return result\n\n\n@broker.task\nasync def long_running_task(duration: int = 10) -> dict[str, Any]:\n    \"\"\"\n    Example long-running async task.\n\n    Args:\n        duration: Duration in seconds\n\n    Returns:\n        Result dictionary\n    \"\"\"\n    logger.info(f\"Starting long-running task for {duration} seconds\")\n\n    for i in range(duration):\n        await asyncio.sleep(1)\n        logger.info(f\"Progress: {i + 1}/{duration}\")\n\n    return {\n        \"status\": \"completed\",\n        \"duration\": duration,\n    }\n\n\n@broker.task\nasync def send_email_task(to: str, subject: str, body: str) -> dict[str, Any]:\n    \"\"\"\n    Example email sending task.\n\n    Replace with actual email sending logic (e.g., using aiosmtplib, sendgrid, etc.)\n\n    Args:\n        to: Recipient email\n        subject: Email subject\n        body: Email body\n\n    Returns:\n        Result dictionary\n    \"\"\"\n    logger.info(f\"Sending email to {to}: {subject}\")\n\n    # TODO: Implement actual email sending\n    # Example with aiosmtplib:\n    # import aiosmtplib\n    # ...\n\n    # Simulate sending\n    await asyncio.sleep(0.5)\n\n    return {\n        \"status\": \"sent\",\n        \"to\": to,\n        \"subject\": subject,\n    }\n{%- else %}\n# Taskiq not enabled for this project\n{%- endif %}\n","backend/app/worker/tasks/examples.py":"{%- if cookiecutter.use_celery %}\n\"\"\"Example Celery tasks.\"\"\"\n\nimport logging\nimport time\nfrom typing import Any\n\nfrom celery import shared_task\n\nlogger = logging.getLogger(__name__)\n\n\n@shared_task(bind=True, max_retries=3)\ndef example_task(self, message: str) -> dict[str, Any]:\n    \"\"\"\n    Example task that processes a message.\n\n    Args:\n        message: Message to process\n\n    Returns:\n        Result dictionary with processed message\n    \"\"\"\n    logger.info(f\"Processing message: {message}\")\n\n    try:\n        # Simulate some work\n        time.sleep(1)\n\n        result = {\n            \"status\": \"completed\",\n            \"message\": f\"Processed: {message}\",\n            \"task_id\": self.request.id,\n        }\n        logger.info(f\"Task completed: {result}\")\n        return result\n\n    except Exception as exc:\n        logger.error(f\"Task failed: {exc}\")\n        # Retry with exponential backoff\n        raise self.retry(exc=exc, countdown=2 ** self.request.retries) from exc\n\n\n@shared_task(bind=True)\ndef long_running_task(self, duration: int = 10) -> dict[str, Any]:\n    \"\"\"\n    Example long-running task with progress updates.\n\n    Args:\n        duration: Duration in seconds\n\n    Returns:\n        Result dictionary\n    \"\"\"\n    logger.info(f\"Starting long-running task for {duration} seconds\")\n\n    for i in range(duration):\n        time.sleep(1)\n        # Update task state with progress\n        self.update_state(\n            state=\"PROGRESS\",\n            meta={\"current\": i + 1, \"total\": duration}\n        )\n        logger.info(f\"Progress: {i + 1}/{duration}\")\n\n    return {\n        \"status\": \"completed\",\n        \"duration\": duration,\n        \"task_id\": self.request.id,\n    }\n\n\n@shared_task\ndef send_email_task(to: str, subject: str, body: str) -> dict[str, Any]:\n    \"\"\"\n    Example email sending task.\n\n    Replace with actual email sending logic (e.g., using smtp, sendgrid, etc.)\n\n    Args:\n        to: Recipient email\n        subject: Email subject\n        body: Email body\n\n    Returns:\n        Result dictionary\n    \"\"\"\n    logger.info(f\"Sending email to {to}: {subject}\")\n\n    # TODO: Implement actual email sending\n    # Example with SMTP:\n    # import smtplib\n    # from email.mime.text import MIMEText\n    # ...\n\n    # Simulate sending\n    time.sleep(0.5)\n\n    return {\n        \"status\": \"sent\",\n        \"to\": to,\n        \"subject\": subject,\n    }\n{%- else %}\n# Celery not enabled for this project\n{%- endif %}\n","backend/app/worker/tasks/schedules.py":"{%- if cookiecutter.use_taskiq %}\n\"\"\"Taskiq scheduled tasks (cron-like).\"\"\"\n\nfrom app.worker.taskiq_app import broker\nfrom app.worker.tasks.taskiq_examples import example_task\n\n\n# Define scheduled tasks using labels\n# These are picked up by the scheduler\n\n@broker.task(schedule=[{\"cron\": \"* * * * *\"}])  # Every minute\nasync def scheduled_example() -> dict:\n    \"\"\"Example scheduled task that runs every minute.\"\"\"\n    result = await example_task.kiq(\"scheduled\")\n    return {\"scheduled\": True, \"task_id\": str(result.task_id)}\n\n\n# Alternative: Define schedules in scheduler source\n# The scheduler will read these when started with --source flag\nSCHEDULES = [\n    {\n        \"task\": \"app.worker.tasks.taskiq_examples:example_task\",\n        \"cron\": \"*/5 * * * *\",  # Every 5 minutes\n        \"args\": [\"periodic-5min\"],\n    },\n]\n{%- else %}\n# Taskiq not enabled for this project\n{%- endif %}\n","backend/app/worker/celery_app.py":"{%- if cookiecutter.use_celery %}\n\"\"\"Celery application configuration.\"\"\"\n\nfrom celery import Celery\nfrom celery.schedules import crontab\n\nfrom app.core.config import settings\n{%- if cookiecutter.enable_logfire and cookiecutter.logfire_celery %}\nfrom app.core.logfire_setup import instrument_celery\n{%- endif %}\n\n# Create Celery app\ncelery_app = Celery(\n    \"{{ cookiecutter.project_slug }}\",\n    broker=settings.CELERY_BROKER_URL,\n    backend=settings.CELERY_RESULT_BACKEND,\n)\n\n# Celery configuration\ncelery_app.conf.update(\n    # Task settings\n    task_serializer=\"json\",\n    accept_content=[\"json\"],\n    result_serializer=\"json\",\n    timezone=\"UTC\",\n    enable_utc=True,\n    # Task execution settings\n    task_acks_late=True,\n    task_reject_on_worker_lost=True,\n    # Result settings\n    result_expires=3600,  # 1 hour\n    # Worker settings\n    worker_prefetch_multiplier=1,\n    worker_concurrency=4,\n)\n\n# Autodiscover tasks from app.worker.tasks module\ncelery_app.autodiscover_tasks([\"app.worker.tasks\"])\n\n\n# === Beat Schedule ===\n# Add periodic tasks here\ncelery_app.conf.beat_schedule = {\n    \"example-every-minute\": {\n        \"task\": \"app.worker.tasks.examples.example_task\",\n        \"schedule\": 60.0,  # Every 60 seconds\n        \"args\": (\"periodic\",),\n    },\n    # Example with crontab (runs at 00:00 every day)\n    # \"daily-cleanup\": {\n    #     \"task\": \"app.worker.tasks.examples.cleanup_task\",\n    #     \"schedule\": crontab(hour=0, minute=0),\n    # },\n}\n\n{%- if cookiecutter.enable_logfire and cookiecutter.logfire_celery %}\n\n\n# Instrument Celery with Logfire\ninstrument_celery()\n{%- endif %}\n{%- else %}\n# Celery not enabled for this project\n{%- endif %}\n","backend/app/worker/taskiq_app.py":"{%- if cookiecutter.use_taskiq %}\n\"\"\"Taskiq application configuration.\"\"\"\n\nfrom taskiq import TaskiqScheduler\nfrom taskiq_redis import ListQueueBroker, RedisAsyncResultBackend\n\nfrom app.core.config import settings\n\n# Create Taskiq broker with Redis\nbroker = ListQueueBroker(\n    url=settings.TASKIQ_BROKER_URL,\n).with_result_backend(\n    RedisAsyncResultBackend(\n        redis_url=settings.TASKIQ_RESULT_BACKEND,\n    )\n)\n\n# Create scheduler for periodic tasks\nscheduler = TaskiqScheduler(\n    broker=broker,\n    sources=[\"app.worker.tasks.schedules\"],\n)\n\n\n# Startup/shutdown hooks\n@broker.on_event(\"startup\")\nasync def startup() -> None:\n    \"\"\"Initialize broker on startup.\"\"\"\n    pass\n\n\n@broker.on_event(\"shutdown\")\nasync def shutdown() -> None:\n    \"\"\"Cleanup on shutdown.\"\"\"\n    pass\n{%- else %}\n# Taskiq not enabled for this project\n{%- endif %}\n","backend/app/worker/__init__.py":"{%- if cookiecutter.use_celery or cookiecutter.use_taskiq or cookiecutter.use_arq %}\n\"\"\"Background workers.\"\"\"\n{%- else %}\n# Background workers not enabled\n{%- endif %}\n","backend/app/main.py":"\"\"\"FastAPI application entry point.\"\"\"\n\nfrom collections.abc import AsyncGenerator\nfrom contextlib import asynccontextmanager\n{%- if cookiecutter.enable_redis %}\nfrom typing import TypedDict\n{%- endif %}\n\nfrom fastapi import FastAPI\n{%- if cookiecutter.enable_orjson %}\nfrom fastapi.responses import ORJSONResponse\n{%- endif %}\n{%- if cookiecutter.enable_pagination %}\nfrom fastapi_pagination import add_pagination\n{%- endif %}\n\nfrom app.api.exception_handlers import register_exception_handlers\nfrom app.api.router import api_router\nfrom app.core.config import settings\n{%- if cookiecutter.enable_logfire %}\nfrom app.core.logfire_setup import instrument_app, setup_logfire\n{%- endif %}\nfrom app.core.middleware import RequestIDMiddleware\n\n{%- if cookiecutter.enable_redis %}\nfrom app.clients.redis import RedisClient\n\n\nclass LifespanState(TypedDict):\n    \"\"\"Lifespan state - resources available via request.state.\"\"\"\n\n    redis: RedisClient\n{%- endif %}\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI) -> AsyncGenerator[{% if cookiecutter.enable_redis %}LifespanState{% else %}None{% endif %}, None]:\n    \"\"\"Application lifespan - startup and shutdown events.\n\n    Resources yielded here are available via request.state in route handlers.\n    See: https://asgi.readthedocs.io/en/latest/specs/lifespan.html#lifespan-state\n    \"\"\"\n    # === Startup ===\n{%- if cookiecutter.enable_logfire %}\n    setup_logfire()\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql and cookiecutter.enable_logfire and cookiecutter.logfire_database %}\n    from app.core.logfire_setup import instrument_asyncpg\n    instrument_asyncpg()\n{%- endif %}\n\n{%- if cookiecutter.use_mongodb and cookiecutter.enable_logfire and cookiecutter.logfire_database %}\n    from app.core.logfire_setup import instrument_pymongo\n    instrument_pymongo()\n{%- endif %}\n\n{%- if cookiecutter.enable_redis and cookiecutter.enable_logfire and cookiecutter.logfire_redis %}\n    from app.core.logfire_setup import instrument_redis\n    instrument_redis()\n{%- endif %}\n\n{%- if cookiecutter.enable_logfire and cookiecutter.logfire_httpx %}\n    from app.core.logfire_setup import instrument_httpx\n    instrument_httpx()\n{%- endif %}\n\n{%- if cookiecutter.enable_logfire and cookiecutter.enable_ai_agent and cookiecutter.use_pydantic_ai %}\n    from app.core.logfire_setup import instrument_pydantic_ai\n    instrument_pydantic_ai()\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n    redis_client = RedisClient()\n    await redis_client.connect()\n{%- endif %}\n\n{%- if cookiecutter.enable_caching and cookiecutter.enable_redis %}\n    from app.core.cache import setup_cache\n    setup_cache(redis_client)\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n\n    yield {\"redis\": redis_client}\n\n    # === Shutdown ===\n    await redis_client.close()\n{%- else %}\n\n    yield\n\n    # === Shutdown ===\n{%- endif %}\n{%- if cookiecutter.use_postgresql %}\n    from app.db.session import close_db\n    await close_db()\n{%- endif %}\n\n{%- if cookiecutter.use_mongodb %}\n    from app.db.session import close_db\n    await close_db()\n{%- endif %}\n\n{%- if cookiecutter.use_sqlite %}\n    from app.db.session import close_db\n    close_db()\n{%- endif %}\n\n\n# Environments where API docs should be visible\nSHOW_DOCS_ENVIRONMENTS = (\"local\", \"staging\", \"development\")\n\n\ndef create_app() -> FastAPI:\n    \"\"\"Create and configure the FastAPI application.\"\"\"\n    # Only show docs in allowed environments (hide in production)\n    show_docs = settings.ENVIRONMENT in SHOW_DOCS_ENVIRONMENTS\n    openapi_url = f\"{settings.API_V1_STR}/openapi.json\" if show_docs else None\n    docs_url = \"/docs\" if show_docs else None\n    redoc_url = \"/redoc\" if show_docs else None\n\n    # OpenAPI tags for better documentation organization\n    openapi_tags = [\n        {\n            \"name\": \"health\",\n            \"description\": \"Health check endpoints for monitoring and Kubernetes probes\",\n        },\n{%- if cookiecutter.use_jwt %}\n        {\n            \"name\": \"auth\",\n            \"description\": \"Authentication endpoints - login, register, token refresh\",\n        },\n        {\n            \"name\": \"users\",\n            \"description\": \"User management endpoints\",\n        },\n{%- endif %}\n{%- if cookiecutter.enable_oauth %}\n        {\n            \"name\": \"oauth\",\n            \"description\": \"OAuth2 social login endpoints (Google, etc.)\",\n        },\n{%- endif %}\n{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\n        {\n            \"name\": \"sessions\",\n            \"description\": \"Session management - view and manage active login sessions\",\n        },\n{%- endif %}\n{%- if cookiecutter.include_example_crud %}\n        {\n            \"name\": \"items\",\n            \"description\": \"Example CRUD endpoints demonstrating the API pattern\",\n        },\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence %}\n        {\n            \"name\": \"conversations\",\n            \"description\": \"AI conversation persistence - manage chat history\",\n        },\n{%- endif %}\n{%- if cookiecutter.enable_webhooks %}\n        {\n            \"name\": \"webhooks\",\n            \"description\": \"Webhook management - subscribe to events and manage deliveries\",\n        },\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent %}\n        {\n            \"name\": \"agent\",\n            \"description\": \"AI agent WebSocket endpoint for real-time chat\",\n        },\n{%- endif %}\n{%- if cookiecutter.enable_websockets %}\n        {\n            \"name\": \"websocket\",\n            \"description\": \"WebSocket endpoints for real-time communication\",\n        },\n{%- endif %}\n    ]\n\n    app = FastAPI(\n        title=settings.PROJECT_NAME,\n        summary=\"FastAPI application{% if cookiecutter.enable_logfire %} with Logfire observability{% endif %}\",\n        description=\"\"\"\n{{ cookiecutter.project_description }}\n\n## Features\n\n{%- if cookiecutter.use_jwt %}\n- **Authentication**: JWT-based authentication with refresh tokens\n{%- endif %}\n{%- if cookiecutter.use_api_key %}\n- **API Key**: Header-based API key authentication\n{%- endif %}\n{%- if cookiecutter.use_database %}\n- **Database**: Async database operations\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n- **Redis**: Caching and session storage\n{%- endif %}\n{%- if cookiecutter.enable_rate_limiting %}\n- **Rate Limiting**: Request rate limiting per client\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_pydantic_ai %}\n- **AI Agent**: PydanticAI-powered conversational assistant\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_langchain %}\n- **AI Agent**: LangChain-powered conversational assistant\n{%- endif %}\n{%- if cookiecutter.enable_logfire %}\n- **Observability**: Logfire integration for tracing and monitoring\n{%- endif %}\n\n## Documentation\n\n- [Swagger UI](/docs) - Interactive API documentation\n- [ReDoc](/redoc) - Alternative documentation view\n        \"\"\".strip(),\n        version=\"0.1.0\",\n        openapi_url=openapi_url,\n        docs_url=docs_url,\n        redoc_url=redoc_url,\n        openapi_tags=openapi_tags,\n        contact={\n            \"name\": \"{{ cookiecutter.author_name }}\",\n            \"email\": \"{{ cookiecutter.author_email }}\",\n        },\n        license_info={\n            \"name\": \"MIT\",\n            \"identifier\": \"MIT\",\n        },\n        lifespan=lifespan,\n{%- if cookiecutter.enable_orjson %}\n        default_response_class=ORJSONResponse,\n{%- endif %}\n    )\n\n{%- if cookiecutter.enable_logfire %}\n    # Logfire instrumentation\n    instrument_app(app)\n{%- endif %}\n\n    # Request ID middleware (for request correlation/debugging)\n    app.add_middleware(RequestIDMiddleware)\n\n    # Exception handlers\n    register_exception_handlers(app)\n\n{%- if cookiecutter.enable_cors %}\n\n    # CORS middleware\n    from starlette.middleware.cors import CORSMiddleware\n    app.add_middleware(\n        CORSMiddleware,\n        allow_origins=settings.CORS_ORIGINS,\n        allow_credentials=settings.CORS_ALLOW_CREDENTIALS,\n        allow_methods=settings.CORS_ALLOW_METHODS,\n        allow_headers=settings.CORS_ALLOW_HEADERS,\n    )\n{%- endif %}\n\n{%- if cookiecutter.enable_sentry %}\n\n    # Sentry\n    if settings.SENTRY_DSN:\n        import sentry_sdk\n        sentry_sdk.init(dsn=settings.SENTRY_DSN, enable_tracing=True)\n{%- endif %}\n\n{%- if cookiecutter.enable_prometheus %}\n\n    # Prometheus metrics\n    from prometheus_fastapi_instrumentator import Instrumentator\n\n    instrumentator = Instrumentator(\n        should_group_status_codes=True,\n        should_ignore_untemplated=True,\n        should_respect_env_var=True,\n        should_instrument_requests_inprogress=True,\n        excluded_handlers=[\"/health\", \"/health/ready\", \"/health/live\", settings.PROMETHEUS_METRICS_PATH],\n        inprogress_name=\"http_requests_inprogress\",\n        inprogress_labels=True,\n    )\n    instrumentator.instrument(app).expose(\n        app,\n        endpoint=settings.PROMETHEUS_METRICS_PATH,\n        include_in_schema=settings.PROMETHEUS_INCLUDE_IN_SCHEMA,\n    )\n{%- endif %}\n\n{%- if cookiecutter.enable_rate_limiting %}\n\n    # Rate limiting\n    # Note: slowapi requires app.state.limiter - this is a library requirement,\n    # not suitable for lifespan state pattern which is for request-scoped access\n    from app.core.rate_limit import limiter\n    from slowapi import _rate_limit_exceeded_handler\n    from slowapi.errors import RateLimitExceeded\n    app.state.limiter = limiter\n    app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n{%- endif %}\n\n{%- if (cookiecutter.enable_admin_panel and cookiecutter.use_postgresql and cookiecutter.admin_require_auth and not cookiecutter.admin_env_disabled) or cookiecutter.enable_oauth %}\n\n    # Session middleware (for admin authentication and/or OAuth)\n    from starlette.middleware.sessions import SessionMiddleware\n    app.add_middleware(SessionMiddleware, secret_key=settings.SECRET_KEY)\n{%- endif %}\n\n{%- if cookiecutter.enable_admin_panel and cookiecutter.use_postgresql %}\n{%- if cookiecutter.admin_env_disabled %}\n    # Admin panel - disabled\n{%- elif cookiecutter.admin_env_all %}\n\n    # Admin panel (all environments)\n    from app.admin import setup_admin\n    setup_admin(app)\n{%- else %}\n\n    # Admin panel (environment restricted)\n    {%- if cookiecutter.admin_env_dev_only %}\n    ADMIN_ALLOWED_ENVIRONMENTS = [\"development\", \"local\"]\n    {%- elif cookiecutter.admin_env_dev_staging %}\n    ADMIN_ALLOWED_ENVIRONMENTS = [\"development\", \"local\", \"staging\"]\n    {%- endif %}\n\n    if settings.ENVIRONMENT in ADMIN_ALLOWED_ENVIRONMENTS:\n        from app.admin import setup_admin\n        setup_admin(app)\n{%- endif %}\n{%- endif %}\n\n    # API Version Deprecation (uncomment when deprecating old versions)\n    # Example: Mark v1 as deprecated when v2 is ready\n    # from app.api.versioning import VersionDeprecationMiddleware\n    # app.add_middleware(\n    #     VersionDeprecationMiddleware,\n    #     deprecated_versions={\n    #         \"v1\": {\n    #             \"sunset\": \"2025-12-31\",\n    #             \"link\": \"/docs/migration/v2\",\n    #             \"message\": \"Please migrate to API v2\",\n    #         }\n    #     },\n    # )\n\n    # Include API router\n    app.include_router(api_router, prefix=settings.API_V1_STR)\n\n{%- if cookiecutter.enable_pagination %}\n\n    # Pagination\n    add_pagination(app)\n{%- endif %}\n\n    return app\n\n\napp = create_app()\n","backend/app/services/user.py":"{%- if cookiecutter.use_jwt and cookiecutter.use_postgresql %}\n\"\"\"User service (PostgreSQL async).\n\nContains business logic for user operations. Uses UserRepository for database access.\n\"\"\"\n\nfrom uuid import UUID\n\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.core.exceptions import AlreadyExistsError, AuthenticationError, NotFoundError\nfrom app.core.security import get_password_hash, verify_password\nfrom app.db.models.user import User\nfrom app.repositories import user_repo\nfrom app.schemas.user import UserCreate, UserUpdate\n\n\nclass UserService:\n    \"\"\"Service for user-related business logic.\"\"\"\n\n    def __init__(self, db: AsyncSession):\n        self.db = db\n\n    async def get_by_id(self, user_id: UUID) -> User:\n        \"\"\"Get user by ID.\n\n        Raises:\n            NotFoundError: If user does not exist.\n        \"\"\"\n        user = await user_repo.get_by_id(self.db, user_id)\n        if not user:\n            raise NotFoundError(\n                message=\"User not found\",\n                details={\"user_id\": user_id},\n            )\n        return user\n\n    async def get_by_email(self, email: str) -> User | None:\n        \"\"\"Get user by email. Returns None if not found.\"\"\"\n        return await user_repo.get_by_email(self.db, email)\n\n    async def get_multi(\n        self,\n        *,\n        skip: int = 0,\n        limit: int = 100,\n    ) -> list[User]:\n        \"\"\"Get multiple users with pagination.\"\"\"\n        return await user_repo.get_multi(self.db, skip=skip, limit=limit)\n\n    async def register(self, user_in: UserCreate) -> User:\n        \"\"\"Register a new user.\n\n        Raises:\n            AlreadyExistsError: If email is already registered.\n        \"\"\"\n        existing = await user_repo.get_by_email(self.db, user_in.email)\n        if existing:\n            raise AlreadyExistsError(\n                message=\"Email already registered\",\n                details={\"email\": user_in.email},\n            )\n\n        hashed_password = get_password_hash(user_in.password)\n        return await user_repo.create(\n            self.db,\n            email=user_in.email,\n            hashed_password=hashed_password,\n            full_name=user_in.full_name,\n            role=user_in.role.value,\n        )\n\n    async def authenticate(self, email: str, password: str) -> User:\n        \"\"\"Authenticate user by email and password.\n\n        Raises:\n            AuthenticationError: If credentials are invalid or user is inactive.\n        \"\"\"\n        user = await user_repo.get_by_email(self.db, email)\n        if not user or not verify_password(password, user.hashed_password):\n            raise AuthenticationError(message=\"Invalid email or password\")\n        if not user.is_active:\n            raise AuthenticationError(message=\"User account is disabled\")\n        return user\n\n    async def update(self, user_id: UUID, user_in: UserUpdate) -> User:\n        \"\"\"Update user.\n\n        Raises:\n            NotFoundError: If user does not exist.\n        \"\"\"\n        user = await self.get_by_id(user_id)\n\n        update_data = user_in.model_dump(exclude_unset=True)\n        if \"password\" in update_data:\n            update_data[\"hashed_password\"] = get_password_hash(update_data.pop(\"password\"))\n\n        return await user_repo.update(self.db, db_user=user, update_data=update_data)\n\n    async def delete(self, user_id: UUID) -> User:\n        \"\"\"Delete user.\n\n        Raises:\n            NotFoundError: If user does not exist.\n        \"\"\"\n        user = await user_repo.delete(self.db, user_id)\n        if not user:\n            raise NotFoundError(\n                message=\"User not found\",\n                details={\"user_id\": str(user_id)},\n            )\n        return user\n\n{%- if cookiecutter.enable_oauth %}\n\n    async def get_by_oauth(self, provider: str, oauth_id: str) -> User | None:\n        \"\"\"Get user by OAuth provider and ID.\"\"\"\n        return await user_repo.get_by_oauth(self.db, provider, oauth_id)\n\n    async def link_oauth(self, user_id: UUID, provider: str, oauth_id: str) -> User:\n        \"\"\"Link OAuth account to existing user.\"\"\"\n        user = await self.get_by_id(user_id)\n        return await user_repo.update(\n            self.db,\n            db_user=user,\n            update_data={\"oauth_provider\": provider, \"oauth_id\": oauth_id},\n        )\n\n    async def create_oauth_user(\n        self,\n        email: str,\n        full_name: str | None,\n        oauth_provider: str,\n        oauth_id: str,\n    ) -> User:\n        \"\"\"Create a new user from OAuth data.\"\"\"\n        return await user_repo.create(\n            self.db,\n            email=email,\n            hashed_password=None,\n            full_name=full_name,\n            oauth_provider=oauth_provider,\n            oauth_id=oauth_id,\n        )\n{%- endif %}\n\n\n{%- elif cookiecutter.use_jwt and cookiecutter.use_sqlite %}\n\"\"\"User service (SQLite sync).\n\nContains business logic for user operations. Uses UserRepository for database access.\n\"\"\"\n\nfrom sqlalchemy.orm import Session\n\nfrom app.core.exceptions import AlreadyExistsError, AuthenticationError, NotFoundError\nfrom app.core.security import get_password_hash, verify_password\nfrom app.db.models.user import User\nfrom app.repositories import user_repo\nfrom app.schemas.user import UserCreate, UserUpdate\n\n\nclass UserService:\n    \"\"\"Service for user-related business logic.\"\"\"\n\n    def __init__(self, db: Session):\n        self.db = db\n\n    def get_by_id(self, user_id: str) -> User:\n        \"\"\"Get user by ID.\n\n        Raises:\n            NotFoundError: If user does not exist.\n        \"\"\"\n        user = user_repo.get_by_id(self.db, user_id)\n        if not user:\n            raise NotFoundError(\n                message=\"User not found\",\n                details={\"user_id\": user_id},\n            )\n        return user\n\n    def get_by_email(self, email: str) -> User | None:\n        \"\"\"Get user by email. Returns None if not found.\"\"\"\n        return user_repo.get_by_email(self.db, email)\n\n    def get_multi(\n        self,\n        *,\n        skip: int = 0,\n        limit: int = 100,\n    ) -> list[User]:\n        \"\"\"Get multiple users with pagination.\"\"\"\n        return user_repo.get_multi(self.db, skip=skip, limit=limit)\n\n    def register(self, user_in: UserCreate) -> User:\n        \"\"\"Register a new user.\n\n        Raises:\n            AlreadyExistsError: If email is already registered.\n        \"\"\"\n        existing = user_repo.get_by_email(self.db, user_in.email)\n        if existing:\n            raise AlreadyExistsError(\n                message=\"Email already registered\",\n                details={\"email\": user_in.email},\n            )\n\n        hashed_password = get_password_hash(user_in.password)\n        return user_repo.create(\n            self.db,\n            email=user_in.email,\n            hashed_password=hashed_password,\n            full_name=user_in.full_name,\n            role=user_in.role.value,\n        )\n\n    def authenticate(self, email: str, password: str) -> User:\n        \"\"\"Authenticate user by email and password.\n\n        Raises:\n            AuthenticationError: If credentials are invalid or user is inactive.\n        \"\"\"\n        user = user_repo.get_by_email(self.db, email)\n        if not user or not verify_password(password, user.hashed_password):\n            raise AuthenticationError(message=\"Invalid email or password\")\n        if not user.is_active:\n            raise AuthenticationError(message=\"User account is disabled\")\n        return user\n\n    def update(self, user_id: str, user_in: UserUpdate) -> User:\n        \"\"\"Update user.\n\n        Raises:\n            NotFoundError: If user does not exist.\n        \"\"\"\n        user = self.get_by_id(user_id)\n\n        update_data = user_in.model_dump(exclude_unset=True)\n        if \"password\" in update_data:\n            update_data[\"hashed_password\"] = get_password_hash(update_data.pop(\"password\"))\n\n        return user_repo.update(self.db, db_user=user, update_data=update_data)\n\n    def delete(self, user_id: str) -> User:\n        \"\"\"Delete user.\n\n        Raises:\n            NotFoundError: If user does not exist.\n        \"\"\"\n        user = user_repo.delete(self.db, user_id)\n        if not user:\n            raise NotFoundError(\n                message=\"User not found\",\n                details={\"user_id\": user_id},\n            )\n        return user\n\n{%- if cookiecutter.enable_oauth %}\n\n    def get_by_oauth(self, provider: str, oauth_id: str) -> User | None:\n        \"\"\"Get user by OAuth provider and ID.\"\"\"\n        return user_repo.get_by_oauth(self.db, provider, oauth_id)\n\n    def link_oauth(self, user_id: str, provider: str, oauth_id: str) -> User:\n        \"\"\"Link OAuth account to existing user.\"\"\"\n        user = self.get_by_id(user_id)\n        return user_repo.update(\n            self.db,\n            db_user=user,\n            update_data={\"oauth_provider\": provider, \"oauth_id\": oauth_id},\n        )\n\n    def create_oauth_user(\n        self,\n        email: str,\n        full_name: str | None,\n        oauth_provider: str,\n        oauth_id: str,\n    ) -> User:\n        \"\"\"Create a new user from OAuth data.\"\"\"\n        return user_repo.create(\n            self.db,\n            email=email,\n            hashed_password=None,\n            full_name=full_name,\n            oauth_provider=oauth_provider,\n            oauth_id=oauth_id,\n        )\n{%- endif %}\n\n\n{%- elif cookiecutter.use_jwt and cookiecutter.use_mongodb %}\n\"\"\"User service (MongoDB).\n\nContains business logic for user operations. Uses UserRepository for database access.\n\"\"\"\n\nfrom app.core.exceptions import AlreadyExistsError, AuthenticationError, NotFoundError\nfrom app.core.security import get_password_hash, verify_password\nfrom app.db.models.user import User\nfrom app.repositories import user_repo\nfrom app.schemas.user import UserCreate, UserUpdate\n\n\nclass UserService:\n    \"\"\"Service for user-related business logic.\"\"\"\n\n    async def get_by_id(self, user_id: str) -> User:\n        \"\"\"Get user by ID.\n\n        Raises:\n            NotFoundError: If user does not exist.\n        \"\"\"\n        user = await user_repo.get_by_id(user_id)\n        if not user:\n            raise NotFoundError(\n                message=\"User not found\",\n                details={\"user_id\": user_id},\n            )\n        return user\n\n    async def get_by_email(self, email: str) -> User | None:\n        \"\"\"Get user by email. Returns None if not found.\"\"\"\n        return await user_repo.get_by_email(email)\n\n    async def get_multi(\n        self,\n        *,\n        skip: int = 0,\n        limit: int = 100,\n    ) -> list[User]:\n        \"\"\"Get multiple users with pagination.\"\"\"\n        return await user_repo.get_multi(skip=skip, limit=limit)\n\n    async def register(self, user_in: UserCreate) -> User:\n        \"\"\"Register a new user.\n\n        Raises:\n            AlreadyExistsError: If email is already registered.\n        \"\"\"\n        existing = await user_repo.get_by_email(user_in.email)\n        if existing:\n            raise AlreadyExistsError(\n                message=\"Email already registered\",\n                details={\"email\": user_in.email},\n            )\n\n        hashed_password = get_password_hash(user_in.password)\n        return await user_repo.create(\n            email=user_in.email,\n            hashed_password=hashed_password,\n            full_name=user_in.full_name,\n            role=user_in.role.value,\n        )\n\n    async def authenticate(self, email: str, password: str) -> User:\n        \"\"\"Authenticate user by email and password.\n\n        Raises:\n            AuthenticationError: If credentials are invalid or user is inactive.\n        \"\"\"\n        user = await user_repo.get_by_email(email)\n        if not user or not verify_password(password, user.hashed_password):\n            raise AuthenticationError(message=\"Invalid email or password\")\n        if not user.is_active:\n            raise AuthenticationError(message=\"User account is disabled\")\n        return user\n\n    async def update(self, user_id: str, user_in: UserUpdate) -> User:\n        \"\"\"Update user.\n\n        Raises:\n            NotFoundError: If user does not exist.\n        \"\"\"\n        user = await self.get_by_id(user_id)\n\n        update_data = user_in.model_dump(exclude_unset=True)\n        if \"password\" in update_data:\n            update_data[\"hashed_password\"] = get_password_hash(update_data.pop(\"password\"))\n\n        return await user_repo.update(db_user=user, update_data=update_data)\n\n    async def delete(self, user_id: str) -> User:\n        \"\"\"Delete user.\n\n        Raises:\n            NotFoundError: If user does not exist.\n        \"\"\"\n        user = await user_repo.delete(user_id)\n        if not user:\n            raise NotFoundError(\n                message=\"User not found\",\n                details={\"user_id\": user_id},\n            )\n        return user\n\n{%- if cookiecutter.enable_oauth %}\n\n    async def get_by_oauth(self, provider: str, oauth_id: str) -> User | None:\n        \"\"\"Get user by OAuth provider and ID.\"\"\"\n        return await user_repo.get_by_oauth(provider, oauth_id)\n\n    async def link_oauth(self, user_id: str, provider: str, oauth_id: str) -> User:\n        \"\"\"Link OAuth account to existing user.\"\"\"\n        user = await self.get_by_id(user_id)\n        return await user_repo.update(\n            db_user=user,\n            update_data={\"oauth_provider\": provider, \"oauth_id\": oauth_id},\n        )\n\n    async def create_oauth_user(\n        self,\n        email: str,\n        full_name: str | None,\n        oauth_provider: str,\n        oauth_id: str,\n    ) -> User:\n        \"\"\"Create a new user from OAuth data.\"\"\"\n        return await user_repo.create(\n            email=email,\n            hashed_password=None,\n            full_name=full_name,\n            oauth_provider=oauth_provider,\n            oauth_id=oauth_id,\n        )\n{%- endif %}\n\n\n{%- else %}\n\"\"\"User service - not configured.\"\"\"\n{%- endif %}\n","backend/app/services/webhook.py":"{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\n{%- if cookiecutter.use_postgresql %}\n\"\"\"Webhook service (PostgreSQL async).\"\"\"\n\nimport hashlib\nimport hmac\nimport json\nimport secrets\nfrom datetime import UTC, datetime\nfrom uuid import UUID\n\nimport httpx\nimport logfire\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.core.exceptions import NotFoundError\nfrom app.db.models.webhook import Webhook, WebhookDelivery\nfrom app.repositories import webhook_repo\nfrom app.schemas.webhook import WebhookCreate, WebhookUpdate\n\n\nclass WebhookService:\n    \"\"\"Service for webhook management and delivery.\"\"\"\n\n    def __init__(self, db: AsyncSession):\n        self.db = db\n\n    async def create_webhook(\n        self,\n        data: WebhookCreate,\n        user_id: UUID | None = None,\n    ) -> Webhook:\n        \"\"\"Create a new webhook subscription.\"\"\"\n        # Generate a secure secret for HMAC signing\n        secret = secrets.token_urlsafe(32)\n\n        return await webhook_repo.create(\n            self.db,\n            name=data.name,\n            url=str(data.url),\n            secret=secret,\n            events=data.events,\n            description=data.description,\n            user_id=user_id,\n        )\n\n    async def get_webhook(self, webhook_id: UUID) -> Webhook:\n        \"\"\"Get a webhook by ID.\"\"\"\n        webhook = await webhook_repo.get_by_id(self.db, webhook_id)\n        if not webhook:\n            raise NotFoundError(message=\"Webhook not found\")\n        return webhook\n\n    async def list_webhooks(\n        self,\n        user_id: UUID | None = None,\n        skip: int = 0,\n        limit: int = 50,\n    ) -> tuple[list[Webhook], int]:\n        \"\"\"List webhooks, optionally filtered by user.\"\"\"\n        return await webhook_repo.get_list(\n            self.db, user_id=user_id, skip=skip, limit=limit\n        )\n\n    async def update_webhook(\n        self,\n        webhook_id: UUID,\n        data: WebhookUpdate,\n    ) -> Webhook:\n        \"\"\"Update a webhook.\"\"\"\n        webhook = await self.get_webhook(webhook_id)\n        return await webhook_repo.update(self.db, webhook, data)\n\n    async def delete_webhook(self, webhook_id: UUID) -> None:\n        \"\"\"Delete a webhook.\"\"\"\n        webhook = await self.get_webhook(webhook_id)\n        await webhook_repo.delete(self.db, webhook)\n\n    async def regenerate_secret(self, webhook_id: UUID) -> str:\n        \"\"\"Regenerate the webhook secret.\"\"\"\n        webhook = await self.get_webhook(webhook_id)\n        new_secret = secrets.token_urlsafe(32)\n        await webhook_repo.update_secret(self.db, webhook, new_secret)\n        return new_secret\n\n    async def test_webhook(self, webhook_id: UUID) -> dict:\n        \"\"\"Send a test event to the webhook.\"\"\"\n        webhook = await self.get_webhook(webhook_id)\n\n        test_payload = {\n            \"event\": \"webhook.test\",\n            \"timestamp\": datetime.now(UTC).isoformat(),\n            \"data\": {\"message\": \"This is a test webhook delivery\"},\n        }\n\n        result = await self._deliver(webhook, \"webhook.test\", test_payload)\n        return result\n\n    async def dispatch_event(\n        self,\n        event_type: str,\n        data: dict,\n    ) -> None:\n        \"\"\"Dispatch an event to all subscribed webhooks.\"\"\"\n        webhooks = await webhook_repo.get_by_event(self.db, event_type)\n\n        payload = {\n            \"event\": event_type,\n            \"timestamp\": datetime.now(UTC).isoformat(),\n            \"data\": data,\n        }\n\n        for webhook in webhooks:\n            # In production, you'd want to queue this for background processing\n            try:\n                await self._deliver(webhook, event_type, payload)\n            except Exception as e:\n                logfire.error(\n                    \"Webhook delivery failed\",\n                    webhook_id=str(webhook.id),\n                    event_type=event_type,\n                    error=str(e),\n                )\n\n    async def _deliver(\n        self,\n        webhook: Webhook,\n        event_type: str,\n        payload: dict,\n    ) -> dict:\n        \"\"\"Deliver a payload to a webhook with HMAC signature.\"\"\"\n        payload_json = json.dumps(payload, default=str)\n\n        # Create HMAC signature\n        signature = self._create_signature(webhook.secret, payload_json)\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"X-Webhook-Signature\": signature,\n            \"X-Webhook-Event\": event_type,\n        }\n\n        delivery = WebhookDelivery(\n            webhook_id=webhook.id,\n            event_type=event_type,\n            payload=payload_json,\n        )\n        self.db.add(delivery)\n        await self.db.flush()\n\n        try:\n            async with httpx.AsyncClient(timeout=30.0) as client:\n                response = await client.post(\n                    webhook.url,\n                    content=payload_json,\n                    headers=headers,\n                )\n\n            delivery.response_status = response.status_code\n            delivery.response_body = response.text[:10000]  # Limit size\n            delivery.success = 200 <= response.status_code < 300\n            delivery.delivered_at = datetime.now(UTC)\n\n            logfire.info(\n                \"Webhook delivered\",\n                webhook_id=str(webhook.id),\n                event_type=event_type,\n                status_code=response.status_code,\n                success=delivery.success,\n            )\n\n        except Exception as e:\n            delivery.error_message = str(e)\n            delivery.success = False\n\n            logfire.error(\n                \"Webhook delivery error\",\n                webhook_id=str(webhook.id),\n                event_type=event_type,\n                error=str(e),\n            )\n\n        await self.db.flush()\n\n        return {\n            \"success\": delivery.success,\n            \"status_code\": delivery.response_status,\n            \"message\": delivery.error_message or \"Delivered successfully\",\n        }\n\n    def _create_signature(self, secret: str, payload: str) -> str:\n        \"\"\"Create HMAC-SHA256 signature for the payload.\"\"\"\n        signature = hmac.new(\n            secret.encode(\"utf-8\"),\n            payload.encode(\"utf-8\"),\n            hashlib.sha256,\n        ).hexdigest()\n        return f\"sha256={signature}\"\n\n    async def get_deliveries(\n        self,\n        webhook_id: UUID,\n        *,\n        skip: int = 0,\n        limit: int = 50,\n    ) -> tuple[list[WebhookDelivery], int]:\n        \"\"\"Get delivery history for a webhook.\"\"\"\n        # Verify webhook exists\n        await self.get_webhook(webhook_id)\n        return await webhook_repo.get_deliveries(self.db, webhook_id, skip=skip, limit=limit)\n\n    @staticmethod\n    def verify_signature(secret: str, payload: str, signature: str) -> bool:\n        \"\"\"Verify a webhook signature.\"\"\"\n        expected = hmac.new(\n            secret.encode(\"utf-8\"),\n            payload.encode(\"utf-8\"),\n            hashlib.sha256,\n        ).hexdigest()\n        expected_signature = f\"sha256={expected}\"\n        return hmac.compare_digest(expected_signature, signature)\n\n\n{%- elif cookiecutter.use_sqlite %}\n\"\"\"Webhook service (SQLite sync).\"\"\"\n\nimport hashlib\nimport hmac\nimport json\nimport secrets\nfrom datetime import UTC, datetime\n\nimport httpx\nimport logfire\nfrom sqlalchemy.orm import Session as DBSession\n\nfrom app.core.exceptions import NotFoundError\nfrom app.db.models.webhook import Webhook, WebhookDelivery\nfrom app.repositories import webhook_repo\nfrom app.schemas.webhook import WebhookCreate, WebhookUpdate\n\n\nclass WebhookService:\n    \"\"\"Service for webhook management and delivery.\"\"\"\n\n    def __init__(self, db: DBSession):\n        self.db = db\n\n    def create_webhook(\n        self,\n        data: WebhookCreate,\n        user_id: str | None = None,\n    ) -> Webhook:\n        \"\"\"Create a new webhook subscription.\"\"\"\n        secret = secrets.token_urlsafe(32)\n\n        return webhook_repo.create(\n            self.db,\n            name=data.name,\n            url=str(data.url),\n            secret=secret,\n            events=data.events,\n            description=data.description,\n            user_id=user_id,\n        )\n\n    def get_webhook(self, webhook_id: str) -> Webhook:\n        \"\"\"Get a webhook by ID.\"\"\"\n        webhook = webhook_repo.get_by_id(self.db, webhook_id)\n        if not webhook:\n            raise NotFoundError(message=\"Webhook not found\")\n        return webhook\n\n    def list_webhooks(\n        self,\n        user_id: str | None = None,\n        skip: int = 0,\n        limit: int = 50,\n    ) -> tuple[list[Webhook], int]:\n        \"\"\"List webhooks, optionally filtered by user.\"\"\"\n        return webhook_repo.get_list(\n            self.db, user_id=user_id, skip=skip, limit=limit\n        )\n\n    def update_webhook(\n        self,\n        webhook_id: str,\n        data: WebhookUpdate,\n    ) -> Webhook:\n        \"\"\"Update a webhook.\"\"\"\n        webhook = self.get_webhook(webhook_id)\n        return webhook_repo.update(self.db, webhook, data)\n\n    def delete_webhook(self, webhook_id: str) -> None:\n        \"\"\"Delete a webhook.\"\"\"\n        webhook = self.get_webhook(webhook_id)\n        webhook_repo.delete(self.db, webhook)\n\n    def dispatch_event(\n        self,\n        event_type: str,\n        data: dict,\n    ) -> None:\n        \"\"\"Dispatch an event to all subscribed webhooks.\"\"\"\n        webhooks = webhook_repo.get_by_event(self.db, event_type)\n\n        payload = {\n            \"event\": event_type,\n            \"timestamp\": datetime.now(UTC).isoformat(),\n            \"data\": data,\n        }\n\n        for webhook in webhooks:\n            try:\n                self._deliver(webhook, event_type, payload)\n            except Exception as e:\n                logfire.error(\n                    \"Webhook delivery failed\",\n                    webhook_id=str(webhook.id),\n                    event_type=event_type,\n                    error=str(e),\n                )\n\n    def _deliver(\n        self,\n        webhook: Webhook,\n        event_type: str,\n        payload: dict,\n    ) -> dict:\n        \"\"\"Deliver a payload to a webhook with HMAC signature.\"\"\"\n        payload_json = json.dumps(payload, default=str)\n        signature = self._create_signature(webhook.secret, payload_json)\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"X-Webhook-Signature\": signature,\n            \"X-Webhook-Event\": event_type,\n        }\n\n        delivery = WebhookDelivery(\n            webhook_id=webhook.id,\n            event_type=event_type,\n            payload=payload_json,\n        )\n        self.db.add(delivery)\n        self.db.flush()\n\n        try:\n            with httpx.Client(timeout=30.0) as client:\n                response = client.post(\n                    webhook.url,\n                    content=payload_json,\n                    headers=headers,\n                )\n\n            delivery.response_status = response.status_code\n            delivery.response_body = response.text[:10000]\n            delivery.success = 200 <= response.status_code < 300\n            delivery.delivered_at = datetime.now(UTC)\n\n        except Exception as e:\n            delivery.error_message = str(e)\n            delivery.success = False\n\n        self.db.flush()\n\n        return {\n            \"success\": delivery.success,\n            \"status_code\": delivery.response_status,\n            \"message\": delivery.error_message or \"Delivered successfully\",\n        }\n\n    def _create_signature(self, secret: str, payload: str) -> str:\n        \"\"\"Create HMAC-SHA256 signature for the payload.\"\"\"\n        signature = hmac.new(\n            secret.encode(\"utf-8\"),\n            payload.encode(\"utf-8\"),\n            hashlib.sha256,\n        ).hexdigest()\n        return f\"sha256={signature}\"\n\n    def get_deliveries(\n        self,\n        webhook_id: str,\n        *,\n        skip: int = 0,\n        limit: int = 50,\n    ) -> tuple[list[WebhookDelivery], int]:\n        \"\"\"Get delivery history for a webhook.\"\"\"\n        # Verify webhook exists\n        self.get_webhook(webhook_id)\n        return webhook_repo.get_deliveries(self.db, webhook_id, skip=skip, limit=limit)\n\n\n{%- elif cookiecutter.use_mongodb %}\n\"\"\"Webhook service (MongoDB).\"\"\"\n\nimport hashlib\nimport hmac\nimport json\nimport secrets\nfrom datetime import UTC, datetime\n\nimport httpx\nimport logfire\n\nfrom app.core.exceptions import NotFoundError\nfrom app.db.models.webhook import Webhook, WebhookDelivery\nfrom app.repositories import webhook_repo\nfrom app.schemas.webhook import WebhookCreate, WebhookUpdate\n\n\nclass WebhookService:\n    \"\"\"Service for webhook management and delivery.\"\"\"\n\n    async def create_webhook(\n        self,\n        data: WebhookCreate,\n        user_id: str | None = None,\n    ) -> Webhook:\n        \"\"\"Create a new webhook subscription.\"\"\"\n        secret = secrets.token_urlsafe(32)\n\n        return await webhook_repo.create(\n            name=data.name,\n            url=str(data.url),\n            secret=secret,\n            events=data.events,\n            description=data.description,\n            user_id=user_id,\n        )\n\n    async def get_webhook(self, webhook_id: str) -> Webhook:\n        \"\"\"Get a webhook by ID.\"\"\"\n        webhook = await webhook_repo.get_by_id(webhook_id)\n        if not webhook:\n            raise NotFoundError(message=\"Webhook not found\")\n        return webhook\n\n    async def list_webhooks(\n        self,\n        user_id: str | None = None,\n        skip: int = 0,\n        limit: int = 50,\n    ) -> tuple[list[Webhook], int]:\n        \"\"\"List webhooks, optionally filtered by user.\"\"\"\n        return await webhook_repo.get_list(user_id=user_id, skip=skip, limit=limit)\n\n    async def update_webhook(\n        self,\n        webhook_id: str,\n        data: WebhookUpdate,\n    ) -> Webhook:\n        \"\"\"Update a webhook.\"\"\"\n        webhook = await self.get_webhook(webhook_id)\n        return await webhook_repo.update(webhook, data)\n\n    async def delete_webhook(self, webhook_id: str) -> None:\n        \"\"\"Delete a webhook.\"\"\"\n        webhook = await self.get_webhook(webhook_id)\n        await webhook_repo.delete(webhook)\n\n    async def dispatch_event(\n        self,\n        event_type: str,\n        data: dict,\n    ) -> None:\n        \"\"\"Dispatch an event to all subscribed webhooks.\"\"\"\n        webhooks = await webhook_repo.get_by_event(event_type)\n\n        payload = {\n            \"event\": event_type,\n            \"timestamp\": datetime.now(UTC).isoformat(),\n            \"data\": data,\n        }\n\n        for webhook in webhooks:\n            try:\n                await self._deliver(webhook, event_type, payload)\n            except Exception as e:\n                logfire.error(\n                    \"Webhook delivery failed\",\n                    webhook_id=str(webhook.id),\n                    event_type=event_type,\n                    error=str(e),\n                )\n\n    async def _deliver(\n        self,\n        webhook: Webhook,\n        event_type: str,\n        payload: dict,\n    ) -> dict:\n        \"\"\"Deliver a payload to a webhook with HMAC signature.\"\"\"\n        payload_json = json.dumps(payload, default=str)\n        signature = self._create_signature(webhook.secret, payload_json)\n\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"X-Webhook-Signature\": signature,\n            \"X-Webhook-Event\": event_type,\n        }\n\n        delivery = WebhookDelivery(\n            webhook_id=str(webhook.id),\n            event_type=event_type,\n            payload=payload_json,\n        )\n        await delivery.insert()\n\n        try:\n            async with httpx.AsyncClient(timeout=30.0) as client:\n                response = await client.post(\n                    webhook.url,\n                    content=payload_json,\n                    headers=headers,\n                )\n\n            delivery.response_status = response.status_code\n            delivery.response_body = response.text[:10000]\n            delivery.success = 200 <= response.status_code < 300\n            delivery.delivered_at = datetime.now(UTC)\n\n        except Exception as e:\n            delivery.error_message = str(e)\n            delivery.success = False\n\n        await delivery.save()\n\n        return {\n            \"success\": delivery.success,\n            \"status_code\": delivery.response_status,\n            \"message\": delivery.error_message or \"Delivered successfully\",\n        }\n\n    def _create_signature(self, secret: str, payload: str) -> str:\n        \"\"\"Create HMAC-SHA256 signature for the payload.\"\"\"\n        signature = hmac.new(\n            secret.encode(\"utf-8\"),\n            payload.encode(\"utf-8\"),\n            hashlib.sha256,\n        ).hexdigest()\n        return f\"sha256={signature}\"\n\n    async def get_deliveries(\n        self,\n        webhook_id: str,\n        *,\n        skip: int = 0,\n        limit: int = 50,\n    ) -> tuple[list[WebhookDelivery], int]:\n        \"\"\"Get delivery history for a webhook.\"\"\"\n        # Verify webhook exists\n        await self.get_webhook(webhook_id)\n        return await webhook_repo.get_deliveries(webhook_id, skip=skip, limit=limit)\n\n\n{%- endif %}\n{%- else %}\n\"\"\"Webhook service - not configured.\"\"\"\n{%- endif %}\n","backend/app/services/conversation.py":"{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_postgresql %}\n\"\"\"Conversation service (PostgreSQL async).\n\nContains business logic for conversation, message, and tool call operations.\n\"\"\"\n\nfrom datetime import UTC, datetime\nfrom uuid import UUID\n\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.core.exceptions import NotFoundError\nfrom app.db.models.conversation import Conversation, Message, ToolCall\nfrom app.repositories import conversation_repo\nfrom app.schemas.conversation import (\n    ConversationCreate,\n    ConversationUpdate,\n    MessageCreate,\n    ToolCallCreate,\n    ToolCallComplete,\n)\n\n\nclass ConversationService:\n    \"\"\"Service for conversation-related business logic.\"\"\"\n\n    def __init__(self, db: AsyncSession):\n        self.db = db\n\n    # =========================================================================\n    # Conversation Methods\n    # =========================================================================\n\n    async def get_conversation(\n        self,\n        conversation_id: UUID,\n        *,\n        include_messages: bool = False,\n    ) -> Conversation:\n        \"\"\"Get conversation by ID.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        conversation = await conversation_repo.get_conversation_by_id(\n            self.db, conversation_id, include_messages=include_messages\n        )\n        if not conversation:\n            raise NotFoundError(\n                message=\"Conversation not found\",\n                details={\"conversation_id\": str(conversation_id)},\n            )\n        return conversation\n\n    async def list_conversations(\n        self,\n{%- if cookiecutter.use_jwt %}\n        user_id: UUID | None = None,\n{%- endif %}\n        *,\n        skip: int = 0,\n        limit: int = 50,\n        include_archived: bool = False,\n    ) -> tuple[list[Conversation], int]:\n        \"\"\"List conversations with pagination.\n\n        Returns:\n            Tuple of (conversations, total_count).\n        \"\"\"\n        items = await conversation_repo.get_conversations_by_user(\n            self.db,\n{%- if cookiecutter.use_jwt %}\n            user_id=user_id,\n{%- endif %}\n            skip=skip,\n            limit=limit,\n            include_archived=include_archived,\n        )\n        total = await conversation_repo.count_conversations(\n            self.db,\n{%- if cookiecutter.use_jwt %}\n            user_id=user_id,\n{%- endif %}\n            include_archived=include_archived,\n        )\n        return items, total\n\n    async def create_conversation(\n        self,\n        data: ConversationCreate,\n    ) -> Conversation:\n        \"\"\"Create a new conversation.\"\"\"\n        return await conversation_repo.create_conversation(\n            self.db,\n{%- if cookiecutter.use_jwt %}\n            user_id=data.user_id,\n{%- endif %}\n            title=data.title,\n        )\n\n    async def update_conversation(\n        self,\n        conversation_id: UUID,\n        data: ConversationUpdate,\n    ) -> Conversation:\n        \"\"\"Update a conversation.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        conversation = await self.get_conversation(conversation_id)\n        update_data = data.model_dump(exclude_unset=True)\n        return await conversation_repo.update_conversation(\n            self.db, db_conversation=conversation, update_data=update_data\n        )\n\n    async def archive_conversation(self, conversation_id: UUID) -> Conversation:\n        \"\"\"Archive a conversation.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        conversation = await conversation_repo.archive_conversation(\n            self.db, conversation_id\n        )\n        if not conversation:\n            raise NotFoundError(\n                message=\"Conversation not found\",\n                details={\"conversation_id\": str(conversation_id)},\n            )\n        return conversation\n\n    async def delete_conversation(self, conversation_id: UUID) -> bool:\n        \"\"\"Delete a conversation.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        deleted = await conversation_repo.delete_conversation(self.db, conversation_id)\n        if not deleted:\n            raise NotFoundError(\n                message=\"Conversation not found\",\n                details={\"conversation_id\": str(conversation_id)},\n            )\n        return True\n\n    # =========================================================================\n    # Message Methods\n    # =========================================================================\n\n    async def get_message(self, message_id: UUID) -> Message:\n        \"\"\"Get message by ID.\n\n        Raises:\n            NotFoundError: If message does not exist.\n        \"\"\"\n        message = await conversation_repo.get_message_by_id(self.db, message_id)\n        if not message:\n            raise NotFoundError(\n                message=\"Message not found\",\n                details={\"message_id\": str(message_id)},\n            )\n        return message\n\n    async def list_messages(\n        self,\n        conversation_id: UUID,\n        *,\n        skip: int = 0,\n        limit: int = 100,\n        include_tool_calls: bool = False,\n    ) -> tuple[list[Message], int]:\n        \"\"\"List messages in a conversation.\n\n        Returns:\n            Tuple of (messages, total_count).\n        \"\"\"\n        # Verify conversation exists\n        await self.get_conversation(conversation_id)\n        items = await conversation_repo.get_messages_by_conversation(\n            self.db,\n            conversation_id,\n            skip=skip,\n            limit=limit,\n            include_tool_calls=include_tool_calls,\n        )\n        total = await conversation_repo.count_messages(self.db, conversation_id)\n        return items, total\n\n    async def add_message(\n        self,\n        conversation_id: UUID,\n        data: MessageCreate,\n    ) -> Message:\n        \"\"\"Add a message to a conversation.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        # Verify conversation exists\n        await self.get_conversation(conversation_id)\n        return await conversation_repo.create_message(\n            self.db,\n            conversation_id=conversation_id,\n            role=data.role,\n            content=data.content,\n            model_name=data.model_name,\n            tokens_used=data.tokens_used,\n        )\n\n    async def delete_message(self, message_id: UUID) -> bool:\n        \"\"\"Delete a message.\n\n        Raises:\n            NotFoundError: If message does not exist.\n        \"\"\"\n        deleted = await conversation_repo.delete_message(self.db, message_id)\n        if not deleted:\n            raise NotFoundError(\n                message=\"Message not found\",\n                details={\"message_id\": str(message_id)},\n            )\n        return True\n\n    # =========================================================================\n    # Tool Call Methods\n    # =========================================================================\n\n    async def get_tool_call(self, tool_call_id: UUID) -> ToolCall:\n        \"\"\"Get tool call by ID.\n\n        Raises:\n            NotFoundError: If tool call does not exist.\n        \"\"\"\n        tool_call = await conversation_repo.get_tool_call_by_id(self.db, tool_call_id)\n        if not tool_call:\n            raise NotFoundError(\n                message=\"Tool call not found\",\n                details={\"tool_call_id\": str(tool_call_id)},\n            )\n        return tool_call\n\n    async def list_tool_calls(self, message_id: UUID) -> list[ToolCall]:\n        \"\"\"List tool calls for a message.\"\"\"\n        # Verify message exists\n        await self.get_message(message_id)\n        return await conversation_repo.get_tool_calls_by_message(self.db, message_id)\n\n    async def start_tool_call(\n        self,\n        message_id: UUID,\n        data: ToolCallCreate,\n    ) -> ToolCall:\n        \"\"\"Record the start of a tool call.\n\n        Raises:\n            NotFoundError: If message does not exist.\n        \"\"\"\n        # Verify message exists\n        await self.get_message(message_id)\n        return await conversation_repo.create_tool_call(\n            self.db,\n            message_id=message_id,\n            tool_call_id=data.tool_call_id,\n            tool_name=data.tool_name,\n            args=data.args,\n            started_at=data.started_at or datetime.now(UTC),\n        )\n\n    async def complete_tool_call(\n        self,\n        tool_call_id: UUID,\n        data: ToolCallComplete,\n    ) -> ToolCall:\n        \"\"\"Mark a tool call as completed.\n\n        Raises:\n            NotFoundError: If tool call does not exist.\n        \"\"\"\n        tool_call = await self.get_tool_call(tool_call_id)\n        return await conversation_repo.complete_tool_call(\n            self.db,\n            db_tool_call=tool_call,\n            result=data.result,\n            completed_at=data.completed_at or datetime.now(UTC),\n            success=data.success,\n        )\n\n\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_sqlite %}\n\"\"\"Conversation service (SQLite sync).\n\nContains business logic for conversation, message, and tool call operations.\n\"\"\"\n\nfrom datetime import UTC, datetime\n\nfrom sqlalchemy.orm import Session\n\nfrom app.core.exceptions import NotFoundError\nfrom app.db.models.conversation import Conversation, Message, ToolCall\nfrom app.repositories import conversation_repo\nfrom app.schemas.conversation import (\n    ConversationCreate,\n    ConversationUpdate,\n    MessageCreate,\n    ToolCallCreate,\n    ToolCallComplete,\n)\n\n\nclass ConversationService:\n    \"\"\"Service for conversation-related business logic.\"\"\"\n\n    def __init__(self, db: Session):\n        self.db = db\n\n    # =========================================================================\n    # Conversation Methods\n    # =========================================================================\n\n    def get_conversation(\n        self,\n        conversation_id: str,\n        *,\n        include_messages: bool = False,\n    ) -> Conversation:\n        \"\"\"Get conversation by ID.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        conversation = conversation_repo.get_conversation_by_id(\n            self.db, conversation_id, include_messages=include_messages\n        )\n        if not conversation:\n            raise NotFoundError(\n                message=\"Conversation not found\",\n                details={\"conversation_id\": conversation_id},\n            )\n        return conversation\n\n    def list_conversations(\n        self,\n{%- if cookiecutter.use_jwt %}\n        user_id: str | None = None,\n{%- endif %}\n        *,\n        skip: int = 0,\n        limit: int = 50,\n        include_archived: bool = False,\n    ) -> tuple[list[Conversation], int]:\n        \"\"\"List conversations with pagination.\n\n        Returns:\n            Tuple of (conversations, total_count).\n        \"\"\"\n        items = conversation_repo.get_conversations_by_user(\n            self.db,\n{%- if cookiecutter.use_jwt %}\n            user_id=user_id,\n{%- endif %}\n            skip=skip,\n            limit=limit,\n            include_archived=include_archived,\n        )\n        total = conversation_repo.count_conversations(\n            self.db,\n{%- if cookiecutter.use_jwt %}\n            user_id=user_id,\n{%- endif %}\n            include_archived=include_archived,\n        )\n        return items, total\n\n    def create_conversation(\n        self,\n        data: ConversationCreate,\n    ) -> Conversation:\n        \"\"\"Create a new conversation.\"\"\"\n        return conversation_repo.create_conversation(\n            self.db,\n{%- if cookiecutter.use_jwt %}\n            user_id=data.user_id,\n{%- endif %}\n            title=data.title,\n        )\n\n    def update_conversation(\n        self,\n        conversation_id: str,\n        data: ConversationUpdate,\n    ) -> Conversation:\n        \"\"\"Update a conversation.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        conversation = self.get_conversation(conversation_id)\n        update_data = data.model_dump(exclude_unset=True)\n        return conversation_repo.update_conversation(\n            self.db, db_conversation=conversation, update_data=update_data\n        )\n\n    def archive_conversation(self, conversation_id: str) -> Conversation:\n        \"\"\"Archive a conversation.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        conversation = conversation_repo.archive_conversation(self.db, conversation_id)\n        if not conversation:\n            raise NotFoundError(\n                message=\"Conversation not found\",\n                details={\"conversation_id\": conversation_id},\n            )\n        return conversation\n\n    def delete_conversation(self, conversation_id: str) -> bool:\n        \"\"\"Delete a conversation.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        deleted = conversation_repo.delete_conversation(self.db, conversation_id)\n        if not deleted:\n            raise NotFoundError(\n                message=\"Conversation not found\",\n                details={\"conversation_id\": conversation_id},\n            )\n        return True\n\n    # =========================================================================\n    # Message Methods\n    # =========================================================================\n\n    def get_message(self, message_id: str) -> Message:\n        \"\"\"Get message by ID.\n\n        Raises:\n            NotFoundError: If message does not exist.\n        \"\"\"\n        message = conversation_repo.get_message_by_id(self.db, message_id)\n        if not message:\n            raise NotFoundError(\n                message=\"Message not found\",\n                details={\"message_id\": message_id},\n            )\n        return message\n\n    def list_messages(\n        self,\n        conversation_id: str,\n        *,\n        skip: int = 0,\n        limit: int = 100,\n        include_tool_calls: bool = False,\n    ) -> tuple[list[Message], int]:\n        \"\"\"List messages in a conversation.\n\n        Returns:\n            Tuple of (messages, total_count).\n        \"\"\"\n        # Verify conversation exists\n        self.get_conversation(conversation_id)\n        items = conversation_repo.get_messages_by_conversation(\n            self.db,\n            conversation_id,\n            skip=skip,\n            limit=limit,\n            include_tool_calls=include_tool_calls,\n        )\n        total = conversation_repo.count_messages(self.db, conversation_id)\n        return items, total\n\n    def add_message(\n        self,\n        conversation_id: str,\n        data: MessageCreate,\n    ) -> Message:\n        \"\"\"Add a message to a conversation.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        # Verify conversation exists\n        self.get_conversation(conversation_id)\n        return conversation_repo.create_message(\n            self.db,\n            conversation_id=conversation_id,\n            role=data.role,\n            content=data.content,\n            model_name=data.model_name,\n            tokens_used=data.tokens_used,\n        )\n\n    def delete_message(self, message_id: str) -> bool:\n        \"\"\"Delete a message.\n\n        Raises:\n            NotFoundError: If message does not exist.\n        \"\"\"\n        deleted = conversation_repo.delete_message(self.db, message_id)\n        if not deleted:\n            raise NotFoundError(\n                message=\"Message not found\",\n                details={\"message_id\": message_id},\n            )\n        return True\n\n    # =========================================================================\n    # Tool Call Methods\n    # =========================================================================\n\n    def get_tool_call(self, tool_call_id: str) -> ToolCall:\n        \"\"\"Get tool call by ID.\n\n        Raises:\n            NotFoundError: If tool call does not exist.\n        \"\"\"\n        tool_call = conversation_repo.get_tool_call_by_id(self.db, tool_call_id)\n        if not tool_call:\n            raise NotFoundError(\n                message=\"Tool call not found\",\n                details={\"tool_call_id\": tool_call_id},\n            )\n        return tool_call\n\n    def list_tool_calls(self, message_id: str) -> list[ToolCall]:\n        \"\"\"List tool calls for a message.\"\"\"\n        # Verify message exists\n        self.get_message(message_id)\n        return conversation_repo.get_tool_calls_by_message(self.db, message_id)\n\n    def start_tool_call(\n        self,\n        message_id: str,\n        data: ToolCallCreate,\n    ) -> ToolCall:\n        \"\"\"Record the start of a tool call.\n\n        Raises:\n            NotFoundError: If message does not exist.\n        \"\"\"\n        # Verify message exists\n        self.get_message(message_id)\n        return conversation_repo.create_tool_call(\n            self.db,\n            message_id=message_id,\n            tool_call_id=data.tool_call_id,\n            tool_name=data.tool_name,\n            args=data.args,\n            started_at=data.started_at or datetime.now(UTC),\n        )\n\n    def complete_tool_call(\n        self,\n        tool_call_id: str,\n        data: ToolCallComplete,\n    ) -> ToolCall:\n        \"\"\"Mark a tool call as completed.\n\n        Raises:\n            NotFoundError: If tool call does not exist.\n        \"\"\"\n        tool_call = self.get_tool_call(tool_call_id)\n        return conversation_repo.complete_tool_call(\n            self.db,\n            db_tool_call=tool_call,\n            result=data.result,\n            completed_at=data.completed_at or datetime.now(UTC),\n            success=data.success,\n        )\n\n\n{%- elif cookiecutter.enable_conversation_persistence and cookiecutter.use_mongodb %}\n\"\"\"Conversation service (MongoDB).\n\nContains business logic for conversation, message, and tool call operations.\n\"\"\"\n\nfrom datetime import UTC, datetime\n\nfrom app.core.exceptions import NotFoundError\nfrom app.db.models.conversation import Conversation, Message, ToolCall\nfrom app.repositories import conversation_repo\nfrom app.schemas.conversation import (\n    ConversationCreate,\n    ConversationUpdate,\n    MessageCreate,\n    ToolCallCreate,\n    ToolCallComplete,\n)\n\n\nclass ConversationService:\n    \"\"\"Service for conversation-related business logic.\"\"\"\n\n    # =========================================================================\n    # Conversation Methods\n    # =========================================================================\n\n    async def get_conversation(\n        self,\n        conversation_id: str,\n        *,\n        include_messages: bool = False,\n    ) -> Conversation:\n        \"\"\"Get conversation by ID.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        conversation = await conversation_repo.get_conversation_by_id(\n            conversation_id, include_messages=include_messages\n        )\n        if not conversation:\n            raise NotFoundError(\n                message=\"Conversation not found\",\n                details={\"conversation_id\": conversation_id},\n            )\n        return conversation\n\n    async def list_conversations(\n        self,\n{%- if cookiecutter.use_jwt %}\n        user_id: str | None = None,\n{%- endif %}\n        *,\n        skip: int = 0,\n        limit: int = 50,\n        include_archived: bool = False,\n    ) -> tuple[list[Conversation], int]:\n        \"\"\"List conversations with pagination.\n\n        Returns:\n            Tuple of (conversations, total_count).\n        \"\"\"\n        items = await conversation_repo.get_conversations_by_user(\n{%- if cookiecutter.use_jwt %}\n            user_id=user_id,\n{%- endif %}\n            skip=skip,\n            limit=limit,\n            include_archived=include_archived,\n        )\n        total = await conversation_repo.count_conversations(\n{%- if cookiecutter.use_jwt %}\n            user_id=user_id,\n{%- endif %}\n            include_archived=include_archived,\n        )\n        return items, total\n\n    async def create_conversation(\n        self,\n        data: ConversationCreate,\n    ) -> Conversation:\n        \"\"\"Create a new conversation.\"\"\"\n        return await conversation_repo.create_conversation(\n{%- if cookiecutter.use_jwt %}\n            user_id=data.user_id,\n{%- endif %}\n            title=data.title,\n        )\n\n    async def update_conversation(\n        self,\n        conversation_id: str,\n        data: ConversationUpdate,\n    ) -> Conversation:\n        \"\"\"Update a conversation.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        conversation = await self.get_conversation(conversation_id)\n        update_data = data.model_dump(exclude_unset=True)\n        return await conversation_repo.update_conversation(\n            db_conversation=conversation, update_data=update_data\n        )\n\n    async def archive_conversation(self, conversation_id: str) -> Conversation:\n        \"\"\"Archive a conversation.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        conversation = await conversation_repo.archive_conversation(conversation_id)\n        if not conversation:\n            raise NotFoundError(\n                message=\"Conversation not found\",\n                details={\"conversation_id\": conversation_id},\n            )\n        return conversation\n\n    async def delete_conversation(self, conversation_id: str) -> bool:\n        \"\"\"Delete a conversation.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        deleted = await conversation_repo.delete_conversation(conversation_id)\n        if not deleted:\n            raise NotFoundError(\n                message=\"Conversation not found\",\n                details={\"conversation_id\": conversation_id},\n            )\n        return True\n\n    # =========================================================================\n    # Message Methods\n    # =========================================================================\n\n    async def get_message(self, message_id: str) -> Message:\n        \"\"\"Get message by ID.\n\n        Raises:\n            NotFoundError: If message does not exist.\n        \"\"\"\n        message = await conversation_repo.get_message_by_id(message_id)\n        if not message:\n            raise NotFoundError(\n                message=\"Message not found\",\n                details={\"message_id\": message_id},\n            )\n        return message\n\n    async def list_messages(\n        self,\n        conversation_id: str,\n        *,\n        skip: int = 0,\n        limit: int = 100,\n    ) -> tuple[list[Message], int]:\n        \"\"\"List messages in a conversation.\n\n        Returns:\n            Tuple of (messages, total_count).\n        \"\"\"\n        # Verify conversation exists\n        await self.get_conversation(conversation_id)\n        items = await conversation_repo.get_messages_by_conversation(\n            conversation_id,\n            skip=skip,\n            limit=limit,\n        )\n        total = await conversation_repo.count_messages(conversation_id)\n        return items, total\n\n    async def add_message(\n        self,\n        conversation_id: str,\n        data: MessageCreate,\n    ) -> Message:\n        \"\"\"Add a message to a conversation.\n\n        Raises:\n            NotFoundError: If conversation does not exist.\n        \"\"\"\n        # Verify conversation exists\n        await self.get_conversation(conversation_id)\n        return await conversation_repo.create_message(\n            conversation_id=conversation_id,\n            role=data.role,\n            content=data.content,\n            model_name=data.model_name,\n            tokens_used=data.tokens_used,\n        )\n\n    async def delete_message(self, message_id: str) -> bool:\n        \"\"\"Delete a message.\n\n        Raises:\n            NotFoundError: If message does not exist.\n        \"\"\"\n        deleted = await conversation_repo.delete_message(message_id)\n        if not deleted:\n            raise NotFoundError(\n                message=\"Message not found\",\n                details={\"message_id\": message_id},\n            )\n        return True\n\n    # =========================================================================\n    # Tool Call Methods\n    # =========================================================================\n\n    async def get_tool_call(self, tool_call_id: str) -> ToolCall:\n        \"\"\"Get tool call by ID.\n\n        Raises:\n            NotFoundError: If tool call does not exist.\n        \"\"\"\n        tool_call = await conversation_repo.get_tool_call_by_id(tool_call_id)\n        if not tool_call:\n            raise NotFoundError(\n                message=\"Tool call not found\",\n                details={\"tool_call_id\": tool_call_id},\n            )\n        return tool_call\n\n    async def list_tool_calls(self, message_id: str) -> list[ToolCall]:\n        \"\"\"List tool calls for a message.\"\"\"\n        # Verify message exists\n        await self.get_message(message_id)\n        return await conversation_repo.get_tool_calls_by_message(message_id)\n\n    async def start_tool_call(\n        self,\n        message_id: str,\n        data: ToolCallCreate,\n    ) -> ToolCall:\n        \"\"\"Record the start of a tool call.\n\n        Raises:\n            NotFoundError: If message does not exist.\n        \"\"\"\n        # Verify message exists\n        await self.get_message(message_id)\n        return await conversation_repo.create_tool_call(\n            message_id=message_id,\n            tool_call_id=data.tool_call_id,\n            tool_name=data.tool_name,\n            args=data.args,\n            started_at=data.started_at or datetime.now(UTC),\n        )\n\n    async def complete_tool_call(\n        self,\n        tool_call_id: str,\n        data: ToolCallComplete,\n    ) -> ToolCall:\n        \"\"\"Mark a tool call as completed.\n\n        Raises:\n            NotFoundError: If tool call does not exist.\n        \"\"\"\n        tool_call = await self.get_tool_call(tool_call_id)\n        return await conversation_repo.complete_tool_call(\n            db_tool_call=tool_call,\n            result=data.result,\n            completed_at=data.completed_at or datetime.now(UTC),\n            success=data.success,\n        )\n\n\n{%- else %}\n\"\"\"Conversation service - not configured.\"\"\"\n{%- endif %}\n","backend/app/services/session.py":"{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\n{%- if cookiecutter.use_postgresql %}\n\"\"\"Session service (PostgreSQL async).\"\"\"\n\nimport hashlib\nfrom datetime import UTC, datetime, timedelta\nfrom uuid import UUID\n\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.core.config import settings\nfrom app.core.exceptions import NotFoundError\nfrom app.db.models.session import Session\nfrom app.repositories import session_repo\n\n\ndef _hash_token(token: str) -> str:\n    \"\"\"Hash a token for storage.\"\"\"\n    return hashlib.sha256(token.encode()).hexdigest()\n\n\ndef _parse_user_agent(user_agent: str | None) -> tuple[str | None, str | None]:\n    \"\"\"Parse user agent to extract device name and type.\"\"\"\n    if not user_agent:\n        return None, None\n\n    user_agent_lower = user_agent.lower()\n\n    # Detect device type\n    if \"mobile\" in user_agent_lower or \"android\" in user_agent_lower:\n        device_type = \"mobile\"\n    elif \"tablet\" in user_agent_lower or \"ipad\" in user_agent_lower:\n        device_type = \"tablet\"\n    else:\n        device_type = \"desktop\"\n\n    # Extract browser/device name\n    if \"chrome\" in user_agent_lower:\n        device_name = \"Chrome\"\n    elif \"firefox\" in user_agent_lower:\n        device_name = \"Firefox\"\n    elif \"safari\" in user_agent_lower:\n        device_name = \"Safari\"\n    elif \"edge\" in user_agent_lower:\n        device_name = \"Edge\"\n    else:\n        device_name = \"Unknown Browser\"\n\n    return device_name, device_type\n\n\nclass SessionService:\n    \"\"\"Service for session management.\"\"\"\n\n    def __init__(self, db: AsyncSession):\n        self.db = db\n\n    async def create_session(\n        self,\n        user_id: UUID,\n        refresh_token: str,\n        ip_address: str | None = None,\n        user_agent: str | None = None,\n    ) -> Session:\n        \"\"\"Create a new session for a user.\"\"\"\n        device_name, device_type = _parse_user_agent(user_agent)\n        expires_at = datetime.now(UTC) + timedelta(minutes=settings.REFRESH_TOKEN_EXPIRE_MINUTES)\n\n        return await session_repo.create(\n            self.db,\n            user_id=user_id,\n            refresh_token_hash=_hash_token(refresh_token),\n            expires_at=expires_at,\n            device_name=device_name,\n            device_type=device_type,\n            ip_address=ip_address,\n            user_agent=user_agent,\n        )\n\n    async def get_user_sessions(self, user_id: UUID) -> list[Session]:\n        \"\"\"Get all active sessions for a user.\"\"\"\n        return await session_repo.get_user_sessions(self.db, user_id, active_only=True)\n\n    async def validate_refresh_token(self, refresh_token: str) -> Session | None:\n        \"\"\"Validate a refresh token and return the session if valid.\"\"\"\n        token_hash = _hash_token(refresh_token)\n        session = await session_repo.get_by_refresh_token_hash(self.db, token_hash)\n\n        if session and session.expires_at > datetime.now(UTC):\n            await session_repo.update_last_used(self.db, session.id)\n            return session\n\n        return None\n\n    async def logout_session(self, session_id: UUID, user_id: UUID) -> Session:\n        \"\"\"Logout a specific session.\"\"\"\n        session = await session_repo.get_by_id(self.db, session_id)\n        if not session or session.user_id != user_id:\n            raise NotFoundError(message=\"Session not found\")\n\n        await session_repo.deactivate(self.db, session_id)\n        return session\n\n    async def logout_all_sessions(self, user_id: UUID) -> int:\n        \"\"\"Logout all sessions for a user. Returns count of logged out sessions.\"\"\"\n        return await session_repo.deactivate_all_user_sessions(self.db, user_id)\n\n    async def logout_by_refresh_token(self, refresh_token: str) -> Session | None:\n        \"\"\"Logout session by refresh token.\"\"\"\n        token_hash = _hash_token(refresh_token)\n        return await session_repo.deactivate_by_refresh_token_hash(self.db, token_hash)\n\n\n{%- elif cookiecutter.use_sqlite %}\n\"\"\"Session service (SQLite sync).\"\"\"\n\nimport hashlib\nfrom datetime import UTC, datetime, timedelta\n\nfrom sqlalchemy.orm import Session as DBSession\n\nfrom app.core.config import settings\nfrom app.core.exceptions import NotFoundError\nfrom app.db.models.session import Session\nfrom app.repositories import session_repo\n\n\ndef _hash_token(token: str) -> str:\n    \"\"\"Hash a token for storage.\"\"\"\n    return hashlib.sha256(token.encode()).hexdigest()\n\n\ndef _parse_user_agent(user_agent: str | None) -> tuple[str | None, str | None]:\n    \"\"\"Parse user agent to extract device name and type.\"\"\"\n    if not user_agent:\n        return None, None\n\n    user_agent_lower = user_agent.lower()\n\n    # Detect device type\n    if \"mobile\" in user_agent_lower or \"android\" in user_agent_lower:\n        device_type = \"mobile\"\n    elif \"tablet\" in user_agent_lower or \"ipad\" in user_agent_lower:\n        device_type = \"tablet\"\n    else:\n        device_type = \"desktop\"\n\n    # Extract browser/device name\n    if \"chrome\" in user_agent_lower:\n        device_name = \"Chrome\"\n    elif \"firefox\" in user_agent_lower:\n        device_name = \"Firefox\"\n    elif \"safari\" in user_agent_lower:\n        device_name = \"Safari\"\n    elif \"edge\" in user_agent_lower:\n        device_name = \"Edge\"\n    else:\n        device_name = \"Unknown Browser\"\n\n    return device_name, device_type\n\n\nclass SessionService:\n    \"\"\"Service for session management.\"\"\"\n\n    def __init__(self, db: DBSession):\n        self.db = db\n\n    def create_session(\n        self,\n        user_id: str,\n        refresh_token: str,\n        ip_address: str | None = None,\n        user_agent: str | None = None,\n    ) -> Session:\n        \"\"\"Create a new session for a user.\"\"\"\n        device_name, device_type = _parse_user_agent(user_agent)\n        expires_at = datetime.now(UTC) + timedelta(minutes=settings.REFRESH_TOKEN_EXPIRE_MINUTES)\n\n        return session_repo.create(\n            self.db,\n            user_id=user_id,\n            refresh_token_hash=_hash_token(refresh_token),\n            expires_at=expires_at,\n            device_name=device_name,\n            device_type=device_type,\n            ip_address=ip_address,\n            user_agent=user_agent,\n        )\n\n    def get_user_sessions(self, user_id: str) -> list[Session]:\n        \"\"\"Get all active sessions for a user.\"\"\"\n        return session_repo.get_user_sessions(self.db, user_id, active_only=True)\n\n    def validate_refresh_token(self, refresh_token: str) -> Session | None:\n        \"\"\"Validate a refresh token and return the session if valid.\"\"\"\n        token_hash = _hash_token(refresh_token)\n        session = session_repo.get_by_refresh_token_hash(self.db, token_hash)\n\n        if session and session.expires_at > datetime.now(UTC):\n            session_repo.update_last_used(self.db, session.id)\n            return session\n\n        return None\n\n    def logout_session(self, session_id: str, user_id: str) -> Session:\n        \"\"\"Logout a specific session.\"\"\"\n        session = session_repo.get_by_id(self.db, session_id)\n        if not session or session.user_id != user_id:\n            raise NotFoundError(message=\"Session not found\")\n\n        session_repo.deactivate(self.db, session_id)\n        return session\n\n    def logout_all_sessions(self, user_id: str) -> int:\n        \"\"\"Logout all sessions for a user. Returns count of logged out sessions.\"\"\"\n        return session_repo.deactivate_all_user_sessions(self.db, user_id)\n\n    def logout_by_refresh_token(self, refresh_token: str) -> Session | None:\n        \"\"\"Logout session by refresh token.\"\"\"\n        token_hash = _hash_token(refresh_token)\n        return session_repo.deactivate_by_refresh_token_hash(self.db, token_hash)\n\n\n{%- elif cookiecutter.use_mongodb %}\n\"\"\"Session service (MongoDB).\"\"\"\n\nimport hashlib\nfrom datetime import UTC, datetime, timedelta\n\nfrom app.core.config import settings\nfrom app.core.exceptions import NotFoundError\nfrom app.db.models.session import Session\nfrom app.repositories import session_repo\n\n\ndef _hash_token(token: str) -> str:\n    \"\"\"Hash a token for storage.\"\"\"\n    return hashlib.sha256(token.encode()).hexdigest()\n\n\ndef _parse_user_agent(user_agent: str | None) -> tuple[str | None, str | None]:\n    \"\"\"Parse user agent to extract device name and type.\"\"\"\n    if not user_agent:\n        return None, None\n\n    user_agent_lower = user_agent.lower()\n\n    # Detect device type\n    if \"mobile\" in user_agent_lower or \"android\" in user_agent_lower:\n        device_type = \"mobile\"\n    elif \"tablet\" in user_agent_lower or \"ipad\" in user_agent_lower:\n        device_type = \"tablet\"\n    else:\n        device_type = \"desktop\"\n\n    # Extract browser/device name\n    if \"chrome\" in user_agent_lower:\n        device_name = \"Chrome\"\n    elif \"firefox\" in user_agent_lower:\n        device_name = \"Firefox\"\n    elif \"safari\" in user_agent_lower:\n        device_name = \"Safari\"\n    elif \"edge\" in user_agent_lower:\n        device_name = \"Edge\"\n    else:\n        device_name = \"Unknown Browser\"\n\n    return device_name, device_type\n\n\nclass SessionService:\n    \"\"\"Service for session management.\"\"\"\n\n    async def create_session(\n        self,\n        user_id: str,\n        refresh_token: str,\n        ip_address: str | None = None,\n        user_agent: str | None = None,\n    ) -> Session:\n        \"\"\"Create a new session for a user.\"\"\"\n        device_name, device_type = _parse_user_agent(user_agent)\n        expires_at = datetime.now(UTC) + timedelta(minutes=settings.REFRESH_TOKEN_EXPIRE_MINUTES)\n\n        return await session_repo.create(\n            user_id=user_id,\n            refresh_token_hash=_hash_token(refresh_token),\n            expires_at=expires_at,\n            device_name=device_name,\n            device_type=device_type,\n            ip_address=ip_address,\n            user_agent=user_agent,\n        )\n\n    async def get_user_sessions(self, user_id: str) -> list[Session]:\n        \"\"\"Get all active sessions for a user.\"\"\"\n        return await session_repo.get_user_sessions(user_id, active_only=True)\n\n    async def validate_refresh_token(self, refresh_token: str) -> Session | None:\n        \"\"\"Validate a refresh token and return the session if valid.\"\"\"\n        token_hash = _hash_token(refresh_token)\n        session = await session_repo.get_by_refresh_token_hash(token_hash)\n\n        if session and session.expires_at > datetime.now(UTC):\n            await session_repo.update_last_used(str(session.id))\n            return session\n\n        return None\n\n    async def logout_session(self, session_id: str, user_id: str) -> Session:\n        \"\"\"Logout a specific session.\"\"\"\n        session = await session_repo.get_by_id(session_id)\n        if not session or session.user_id != user_id:\n            raise NotFoundError(message=\"Session not found\")\n\n        await session_repo.deactivate(session_id)\n        return session\n\n    async def logout_all_sessions(self, user_id: str) -> int:\n        \"\"\"Logout all sessions for a user. Returns count of logged out sessions.\"\"\"\n        return await session_repo.deactivate_all_user_sessions(user_id)\n\n    async def logout_by_refresh_token(self, refresh_token: str) -> Session | None:\n        \"\"\"Logout session by refresh token.\"\"\"\n        token_hash = _hash_token(refresh_token)\n        return await session_repo.deactivate_by_refresh_token_hash(token_hash)\n\n\n{%- endif %}\n{%- else %}\n\"\"\"Session service - not configured.\"\"\"\n{%- endif %}\n","backend/app/services/__init__.py":"\"\"\"Services layer - business logic.\n\nServices orchestrate business operations, using repositories for data access\nand raising domain exceptions for error handling.\n\"\"\"\n{%- set services = [] %}\n{%- if cookiecutter.use_jwt or cookiecutter.include_example_crud or cookiecutter.enable_conversation_persistence or cookiecutter.enable_webhooks %}\n# ruff: noqa: I001, RUF022 - Imports structured for Jinja2 template conditionals\n{%- endif %}\n{%- if cookiecutter.use_jwt %}\n{%- set _ = services.append(\"UserService\") %}\n\nfrom app.services.user import UserService\n{%- endif %}\n{%- if cookiecutter.enable_session_management and cookiecutter.use_jwt %}\n{%- set _ = services.append(\"SessionService\") %}\n\nfrom app.services.session import SessionService\n{%- endif %}\n{%- if cookiecutter.include_example_crud and cookiecutter.use_database %}\n{%- set _ = services.append(\"ItemService\") %}\n\nfrom app.services.item import ItemService\n{%- endif %}\n{%- if cookiecutter.enable_conversation_persistence and cookiecutter.use_database %}\n{%- set _ = services.append(\"ConversationService\") %}\n\nfrom app.services.conversation import ConversationService\n{%- endif %}\n{%- if cookiecutter.enable_webhooks and cookiecutter.use_database %}\n{%- set _ = services.append(\"WebhookService\") %}\n\nfrom app.services.webhook import WebhookService\n{%- endif %}\n{%- if services %}\n\n__all__ = {{ services }}\n{%- endif %}\n","backend/app/services/item.py":"{%- if cookiecutter.include_example_crud and cookiecutter.use_postgresql %}\n\"\"\"Item service (PostgreSQL async).\n\nContains business logic for item operations. Uses ItemRepository for database access.\n\"\"\"\n\nfrom uuid import UUID\n\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom app.core.exceptions import NotFoundError\nfrom app.db.models.item import Item\nfrom app.repositories import item_repo\nfrom app.schemas.item import ItemCreate, ItemUpdate\n\n\nclass ItemService:\n    \"\"\"Service for item-related business logic.\n\n    This is an example service demonstrating the service layer pattern.\n    Services contain business logic and use repositories for database operations.\n    \"\"\"\n\n    def __init__(self, db: AsyncSession):\n        self.db = db\n\n    async def get_by_id(self, item_id: UUID) -> Item:\n        \"\"\"Get item by ID.\n\n        Raises:\n            NotFoundError: If item does not exist.\n        \"\"\"\n        item = await item_repo.get_by_id(self.db, item_id)\n        if not item:\n            raise NotFoundError(\n                message=\"Item not found\",\n                details={\"item_id\": str(item_id)},\n            )\n        return item\n\n    async def get_multi(\n        self,\n        *,\n        skip: int = 0,\n        limit: int = 100,\n        active_only: bool = False,\n    ) -> list[Item]:\n        \"\"\"Get multiple items with pagination.\"\"\"\n        return await item_repo.get_multi(\n            self.db, skip=skip, limit=limit, active_only=active_only\n        )\n\n    async def create(self, item_in: ItemCreate) -> Item:\n        \"\"\"Create a new item.\"\"\"\n        return await item_repo.create(\n            self.db,\n            title=item_in.title,\n            description=item_in.description,\n        )\n\n    async def update(self, item_id: UUID, item_in: ItemUpdate) -> Item:\n        \"\"\"Update an item.\n\n        Raises:\n            NotFoundError: If item does not exist.\n        \"\"\"\n        item = await self.get_by_id(item_id)\n        update_data = item_in.model_dump(exclude_unset=True)\n        return await item_repo.update(self.db, db_item=item, update_data=update_data)\n\n    async def delete(self, item_id: UUID) -> Item:\n        \"\"\"Delete an item.\n\n        Raises:\n            NotFoundError: If item does not exist.\n        \"\"\"\n        item = await item_repo.delete(self.db, item_id)\n        if not item:\n            raise NotFoundError(\n                message=\"Item not found\",\n                details={\"item_id\": str(item_id)},\n            )\n        return item\n\n\n{%- elif cookiecutter.include_example_crud and cookiecutter.use_sqlite %}\n\"\"\"Item service (SQLite sync).\n\nContains business logic for item operations. Uses ItemRepository for database access.\n\"\"\"\n\nfrom sqlalchemy.orm import Session\n\nfrom app.core.exceptions import NotFoundError\nfrom app.db.models.item import Item\nfrom app.repositories import item_repo\nfrom app.schemas.item import ItemCreate, ItemUpdate\n\n\nclass ItemService:\n    \"\"\"Service for item-related business logic.\n\n    This is an example service demonstrating the service layer pattern.\n    Services contain business logic and use repositories for database operations.\n    \"\"\"\n\n    def __init__(self, db: Session):\n        self.db = db\n\n    def get_by_id(self, item_id: str) -> Item:\n        \"\"\"Get item by ID.\n\n        Raises:\n            NotFoundError: If item does not exist.\n        \"\"\"\n        item = item_repo.get_by_id(self.db, item_id)\n        if not item:\n            raise NotFoundError(\n                message=\"Item not found\",\n                details={\"item_id\": item_id},\n            )\n        return item\n\n    def get_multi(\n        self,\n        *,\n        skip: int = 0,\n        limit: int = 100,\n        active_only: bool = False,\n    ) -> list[Item]:\n        \"\"\"Get multiple items with pagination.\"\"\"\n        return item_repo.get_multi(\n            self.db, skip=skip, limit=limit, active_only=active_only\n        )\n\n    def create(self, item_in: ItemCreate) -> Item:\n        \"\"\"Create a new item.\"\"\"\n        return item_repo.create(\n            self.db,\n            title=item_in.title,\n            description=item_in.description,\n        )\n\n    def update(self, item_id: str, item_in: ItemUpdate) -> Item:\n        \"\"\"Update an item.\n\n        Raises:\n            NotFoundError: If item does not exist.\n        \"\"\"\n        item = self.get_by_id(item_id)\n        update_data = item_in.model_dump(exclude_unset=True)\n        return item_repo.update(self.db, db_item=item, update_data=update_data)\n\n    def delete(self, item_id: str) -> Item:\n        \"\"\"Delete an item.\n\n        Raises:\n            NotFoundError: If item does not exist.\n        \"\"\"\n        item = item_repo.delete(self.db, item_id)\n        if not item:\n            raise NotFoundError(\n                message=\"Item not found\",\n                details={\"item_id\": item_id},\n            )\n        return item\n\n\n{%- elif cookiecutter.include_example_crud and cookiecutter.use_mongodb %}\n\"\"\"Item service (MongoDB).\n\nContains business logic for item operations. Uses ItemRepository for database access.\n\"\"\"\n\nfrom app.core.exceptions import NotFoundError\nfrom app.db.models.item import Item\nfrom app.repositories import item_repo\nfrom app.schemas.item import ItemCreate, ItemUpdate\n\n\nclass ItemService:\n    \"\"\"Service for item-related business logic.\n\n    This is an example service demonstrating the service layer pattern.\n    Services contain business logic and use repositories for database operations.\n    \"\"\"\n\n    async def get_by_id(self, item_id: str) -> Item:\n        \"\"\"Get item by ID.\n\n        Raises:\n            NotFoundError: If item does not exist.\n        \"\"\"\n        item = await item_repo.get_by_id(item_id)\n        if not item:\n            raise NotFoundError(\n                message=\"Item not found\",\n                details={\"item_id\": item_id},\n            )\n        return item\n\n    async def get_multi(\n        self,\n        *,\n        skip: int = 0,\n        limit: int = 100,\n        active_only: bool = False,\n    ) -> list[Item]:\n        \"\"\"Get multiple items with pagination.\"\"\"\n        return await item_repo.get_multi(skip=skip, limit=limit, active_only=active_only)\n\n    async def create(self, item_in: ItemCreate) -> Item:\n        \"\"\"Create a new item.\"\"\"\n        return await item_repo.create(\n            title=item_in.title,\n            description=item_in.description,\n        )\n\n    async def update(self, item_id: str, item_in: ItemUpdate) -> Item:\n        \"\"\"Update an item.\n\n        Raises:\n            NotFoundError: If item does not exist.\n        \"\"\"\n        item = await self.get_by_id(item_id)\n        update_data = item_in.model_dump(exclude_unset=True)\n        return await item_repo.update(db_item=item, update_data=update_data)\n\n    async def delete(self, item_id: str) -> Item:\n        \"\"\"Delete an item.\n\n        Raises:\n            NotFoundError: If item does not exist.\n        \"\"\"\n        item = await item_repo.delete(item_id)\n        if not item:\n            raise NotFoundError(\n                message=\"Item not found\",\n                details={\"item_id\": item_id},\n            )\n        return item\n\n\n{%- else %}\n\"\"\"Item service - not configured.\"\"\"\n{%- endif %}\n","backend/.pre-commit-config.yaml":"{%- if cookiecutter.enable_precommit %}\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v5.0.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-toml\n      - id: check-added-large-files\n        args: ['--maxkb=1000']\n      - id: check-merge-conflict\n      - id: detect-private-key\n\n  - repo: https://github.com/astral-sh/ruff-pre-commit\n    rev: v0.8.0\n    hooks:\n      - id: ruff\n        args: [--fix]\n      - id: ruff-format\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: v1.13.0\n    hooks:\n      - id: mypy\n        additional_dependencies:\n          - pydantic>=2.0.0\n          - pydantic-settings>=2.0.0\n        args: [--ignore-missing-imports]\n{%- else %}\n# Pre-commit is disabled for this project\n{%- endif %}\n","backend/alembic.ini":"{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n# Alembic Configuration\n\n[alembic]\nscript_location = alembic\nprepend_sys_path = .\nversion_path_separator = os\n# Human-readable migration file names: 2024-01-15_add_users_table.py\nfile_template = %%(year)d-%%(month).2d-%%(day).2d_%%(slug)s\n\n[post_write_hooks]\n\n[loggers]\nkeys = root,sqlalchemy,alembic\n\n[handlers]\nkeys = console\n\n[formatters]\nkeys = generic\n\n[logger_root]\nlevel = WARN\nhandlers = console\nqualname =\n\n[logger_sqlalchemy]\nlevel = WARN\nhandlers =\nqualname = sqlalchemy.engine\n\n[logger_alembic]\nlevel = INFO\nhandlers =\nqualname = alembic\n\n[handler_console]\nclass = StreamHandler\nargs = (sys.stderr,)\nlevel = NOTSET\nformatter = generic\n\n[formatter_generic]\nformat = %(levelname)-5.5s [%(name)s] %(message)s\ndatefmt = %H:%M:%S\n{%- else %}\n# Alembic - not configured (no SQL database)\n{%- endif %}\n","backend/Dockerfile":"{%- if cookiecutter.enable_docker %}\n# Build stage\nFROM python:{{ cookiecutter.python_version }}-slim AS builder\n\nENV PYTHONUNBUFFERED=1\nENV PYTHONDONTWRITEBYTECODE=1\nWORKDIR /app\n\n# Install uv\nCOPY --from=ghcr.io/astral-sh/uv:latest /uv /bin/uv\nENV UV_COMPILE_BYTECODE=1\nENV UV_LINK_MODE=copy\n\n# Install dependencies\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    --mount=type=bind,source=uv.lock,target=uv.lock \\\n    --mount=type=bind,source=pyproject.toml,target=pyproject.toml \\\n    uv sync --frozen --no-install-project --no-dev\n\n# Copy application\nCOPY . /app\n\n# Install project\nRUN --mount=type=cache,target=/root/.cache/uv \\\n    uv sync --frozen --no-dev\n\n\n# Runtime stage\nFROM python:{{ cookiecutter.python_version }}-slim\n\nENV PYTHONUNBUFFERED=1\nENV PYTHONDONTWRITEBYTECODE=1\nWORKDIR /app\n\n# Copy virtual environment from builder\nCOPY --from=builder /app/.venv /app/.venv\nCOPY --from=builder /app /app\n\n# Add venv to path\nENV PATH=\"/app/.venv/bin:$PATH\"\n\n# Create non-root user\nRUN adduser --disabled-password --gecos \"\" appuser && \\\n    chown -R appuser:appuser /app\nUSER appuser\n\nEXPOSE {{ cookiecutter.backend_port }}\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n    CMD python -c \"import httpx; httpx.get('http://localhost:{{ cookiecutter.backend_port }}/api/v1/health')\" || exit 1\n\nCMD [\"python\", \"-m\", \"cli.commands\", \"server\", \"run\", \"--host\", \"0.0.0.0\", \"--port\", \"{{ cookiecutter.backend_port }}\"]\n{%- else %}\n# Docker is disabled for this project\n{%- endif %}\n","backend/pyproject.toml":"[project]\nname = \"{{ cookiecutter.project_slug }}\"\nversion = \"0.1.0\"\ndescription = \"{{ cookiecutter.project_description }}\"\nrequires-python = \">={{ cookiecutter.python_version }}\"\nlicense = { text = \"MIT\" }\nauthors = [{ name = \"{{ cookiecutter.author_name }}\", email = \"{{ cookiecutter.author_email }}\" }]\n\ndependencies = [\n    \"fastapi>=0.115.0\",\n    \"uvicorn[standard]>=0.32.0\",\n    \"pydantic[email]>=2.10.0\",\n    \"pydantic-settings>=2.6.0\",\n{%- if cookiecutter.enable_orjson %}\n    \"orjson>=3.10.0\",\n{%- endif %}\n{%- if cookiecutter.enable_logfire %}\n{%- set logfire_extras = ['fastapi'] %}\n{%- if cookiecutter.use_postgresql and cookiecutter.logfire_database %}\n{%- set _ = logfire_extras.append('asyncpg') %}\n{%- endif %}\n{%- if cookiecutter.enable_redis and cookiecutter.logfire_redis %}\n{%- set _ = logfire_extras.append('redis') %}\n{%- endif %}\n{%- if cookiecutter.use_celery and cookiecutter.logfire_celery %}\n{%- set _ = logfire_extras.append('celery') %}\n{%- endif %}\n{%- if cookiecutter.logfire_httpx %}\n{%- set _ = logfire_extras.append('httpx') %}\n{%- endif %}\n    \"logfire[{{ logfire_extras | join(',') }}]>=2.0.0\",\n{%- endif %}\n{%- if cookiecutter.use_postgresql %}\n{%- if cookiecutter.use_sqlmodel %}\n    \"sqlmodel>=0.0.22\",\n{%- else %}\n    \"sqlalchemy[asyncio]>=2.0.0\",\n{%- endif %}\n    \"asyncpg>=0.30.0\",\n    \"psycopg2-binary>=2.9.0\",\n    \"alembic>=1.14.0\",\n    \"greenlet>=3.0.0\",\n{%- endif %}\n{%- if cookiecutter.use_mongodb %}\n    \"motor>=3.6.0\",\n    \"beanie>=1.27.0\",\n{%- endif %}\n{%- if cookiecutter.use_sqlite %}\n{%- if cookiecutter.use_sqlmodel %}\n    \"sqlmodel>=0.0.22\",\n{%- else %}\n    \"sqlalchemy>=2.0.0\",\n{%- endif %}\n    \"alembic>=1.14.0\",\n{%- endif %}\n{%- if cookiecutter.use_jwt %}\n    \"pyjwt>=2.9.0\",\n    \"bcrypt>=4.0.0\",\n    \"python-multipart>=0.0.12\",\n{%- endif %}\n{%- if cookiecutter.enable_oauth %}\n    \"authlib>=1.3.0\",\n    \"httpx>=0.27.0\",\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n    \"redis>=5.2.0\",\n{%- endif %}\n{%- if cookiecutter.enable_caching %}\n    \"fastapi-cache2>=0.2.2\",\n{%- endif %}\n{%- if cookiecutter.enable_rate_limiting %}\n    \"slowapi>=0.1.9\",\n{%- endif %}\n{%- if cookiecutter.enable_pagination %}\n    \"fastapi-pagination>=0.12.31\",\n{%- endif %}\n{%- if cookiecutter.enable_sentry %}\n    \"sentry-sdk[fastapi]>=2.18.0\",\n{%- endif %}\n{%- if cookiecutter.enable_prometheus %}\n    \"prometheus-fastapi-instrumentator>=7.0.0\",\n{%- endif %}\n{%- if cookiecutter.enable_admin_panel %}\n    \"sqladmin>=0.19.0\",\n{%- if cookiecutter.admin_require_auth %}\n    \"itsdangerous>=2.2.0\",\n{%- endif %}\n{%- endif %}\n{%- if cookiecutter.use_celery %}\n    \"celery[redis]>=5.4.0\",\n    \"flower>=2.0.0\",\n{%- endif %}\n{%- if cookiecutter.use_taskiq %}\n    \"taskiq>=0.11.0\",\n    \"taskiq-redis>=1.0.0\",\n    \"taskiq-dependencies>=0.1.0\",\n{%- endif %}\n{%- if cookiecutter.use_arq %}\n    \"arq>=0.26.0\",\n{%- endif %}\n{%- if cookiecutter.enable_file_storage %}\n    \"boto3>=1.35.0\",\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_pydantic_ai %}\n{%- if cookiecutter.use_openai %}\n    \"pydantic-ai>=0.0.39\",\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\n    \"pydantic-ai-slim[anthropic]>=0.0.39\",\n{%- endif %}\n{%- if cookiecutter.use_openrouter %}\n    \"pydantic-ai-slim[openrouter]>=0.0.39\",\n{%- endif %}\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_langchain %}\n    \"langchain>=0.3.0\",\n{%- if cookiecutter.use_openai %}\n    \"langchain-openai>=0.3.0\",\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\n    \"langchain-anthropic>=0.3.0\",\n{%- endif %}\n    \"langgraph>=0.2.0\",\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_langgraph %}\n    \"langchain-core>=0.3.0\",\n{%- if cookiecutter.use_openai %}\n    \"langchain-openai>=0.3.0\",\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\n    \"langchain-anthropic>=0.3.0\",\n{%- endif %}\n    \"langgraph>=0.2.0\",\n    \"langgraph-checkpoint>=2.0.0\",\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_crewai %}\n    \"crewai>=1.0.0\",\n{%- if cookiecutter.use_openai %}\n    \"langchain-openai>=0.3.0\",\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\n    \"langchain-anthropic>=0.3.0\",\n{%- endif %}\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_deepagents %}\n    \"deepagents>=0.1.0\",\n{%- if cookiecutter.use_openai %}\n    \"langchain-openai>=0.3.0\",\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\n    \"langchain-anthropic>=0.3.0\",\n{%- endif %}\n{%- endif %}\n{%- if cookiecutter.logfire_httpx or cookiecutter.enable_file_storage %}\n    \"httpx>=0.27.0\",\n{%- endif %}\n    \"click>=8.1.0\",\n    \"tabulate>=0.9.0\",\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest>=8.3.0\",\n    \"anyio[trio]>=4.0.0\",\n    \"pytest-cov>=6.0.0\",\n    \"httpx>=0.27.0\",\n    \"ruff>=0.8.0\",\n    \"mypy>=1.13.0\",\n{%- if cookiecutter.enable_precommit %}\n    \"pre-commit>=4.0.0\",\n{%- endif %}\n]\n\n[project.scripts]\n{{ cookiecutter.project_slug }} = \"cli.commands:main\"\n\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[tool.hatch.build.targets.wheel]\npackages = [\"app\", \"cli\"]\n\n[tool.ruff]\ntarget-version = \"py311\"\nline-length = 100\n\n[tool.ruff.lint]\nselect = [\n    \"E\",      # pycodestyle errors\n    \"W\",      # pycodestyle warnings\n    \"F\",      # pyflakes\n    \"I\",      # isort\n    \"B\",      # flake8-bugbear\n    \"C4\",     # flake8-comprehensions\n    \"UP\",     # pyupgrade\n    \"SIM\",    # flake8-simplify\n    \"RUF\",    # ruff-specific rules\n]\nignore = [\n    \"E501\",   # line too long (handled by formatter)\n    \"B008\",   # function call in default argument (needed for FastAPI Depends)\n]\n\n[tool.ruff.lint.isort]\nknown-first-party = [\"app\", \"cli\"]\n\n[tool.mypy]\npython_version = \"3.11\"\nstrict = true\nwarn_return_any = true\nwarn_unused_configs = true\nignore_missing_imports = true\n\n[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\n\n[tool.{{ cookiecutter.generator_name }}]\ngenerator_version = \"{{ cookiecutter.generator_version }}\"\ngenerated_at = \"{{ cookiecutter.generated_at }}\"\n","backend/tests/test_admin.py":"{%- if cookiecutter.enable_admin_panel and cookiecutter.use_postgresql %}\n\"\"\"Tests for admin panel with automatic model discovery.\"\"\"\n\nfrom typing import ClassVar\nfrom unittest.mock import MagicMock, patch, AsyncMock\n\nimport pytest\nfrom sqlalchemy import Boolean, Integer, String, DateTime, Text\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\n\nfrom app.admin import (\n    SENSITIVE_COLUMN_PATTERNS,\n    AUTO_GENERATED_COLUMNS,\n    MODEL_ICONS,\n    discover_models,\n    get_model_columns,\n    get_searchable_columns,\n    get_sortable_columns,\n    get_form_excluded_columns,\n    pluralize,\n    create_model_admin,\n    register_models_auto,\n    get_sync_engine,\n    setup_admin,\n)\n{%- if cookiecutter.admin_require_auth %}\nfrom app.admin import AdminAuth\n{%- endif %}\n\n\nclass MockBase(DeclarativeBase):\n    \"\"\"Mock base class for testing.\"\"\"\n\n    pass\n\n\nclass MockUser(MockBase):\n    \"\"\"Mock user model for testing.\"\"\"\n\n    __tablename__ = \"mock_users\"\n\n    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n    email: Mapped[str] = mapped_column(String(255), nullable=False)\n    full_name: Mapped[str] = mapped_column(String(255), nullable=True)\n    hashed_password: Mapped[str] = mapped_column(String(255), nullable=True)\n    is_active: Mapped[bool] = mapped_column(Boolean, default=True)\n    created_at: Mapped[str] = mapped_column(DateTime, nullable=True)\n    updated_at: Mapped[str] = mapped_column(DateTime, nullable=True)\n\n\nclass MockItem(MockBase):\n    \"\"\"Mock item model for testing.\"\"\"\n\n    __tablename__ = \"mock_items\"\n\n    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n    title: Mapped[str] = mapped_column(String(100), nullable=False)\n    description: Mapped[str] = mapped_column(Text, nullable=True)\n    price: Mapped[int] = mapped_column(Integer, nullable=True)\n\n\nclass MockSession(MockBase):\n    \"\"\"Mock session model with sensitive columns.\"\"\"\n\n    __tablename__ = \"mock_sessions\"\n\n    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n    user_id: Mapped[int] = mapped_column(Integer, nullable=False)\n    refresh_token_hash: Mapped[str] = mapped_column(String(255), nullable=True)\n    api_key: Mapped[str] = mapped_column(String(255), nullable=True)\n    secret: Mapped[str] = mapped_column(String(255), nullable=True)\n\n\nclass TestConstants:\n    \"\"\"Tests for module constants.\"\"\"\n\n    def test_sensitive_column_patterns_exist(self):\n        \"\"\"Test sensitive column patterns are defined.\"\"\"\n        assert isinstance(SENSITIVE_COLUMN_PATTERNS, list)\n        assert \"password\" in SENSITIVE_COLUMN_PATTERNS\n        assert \"hashed_password\" in SENSITIVE_COLUMN_PATTERNS\n        assert \"secret\" in SENSITIVE_COLUMN_PATTERNS\n        assert \"token\" in SENSITIVE_COLUMN_PATTERNS\n        assert \"api_key\" in SENSITIVE_COLUMN_PATTERNS\n\n    def test_auto_generated_columns_exist(self):\n        \"\"\"Test auto-generated columns are defined.\"\"\"\n        assert isinstance(AUTO_GENERATED_COLUMNS, list)\n        assert \"created_at\" in AUTO_GENERATED_COLUMNS\n        assert \"updated_at\" in AUTO_GENERATED_COLUMNS\n\n    def test_model_icons_exist(self):\n        \"\"\"Test model icons mapping is defined.\"\"\"\n        assert isinstance(MODEL_ICONS, dict)\n        assert \"User\" in MODEL_ICONS\n        assert MODEL_ICONS[\"User\"] == \"fa-solid fa-user\"\n\n\nclass TestDiscoverModels:\n    \"\"\"Tests for discover_models function.\"\"\"\n\n    def test_discovers_all_registered_models(self):\n        \"\"\"Test that discover_models finds all models in the registry.\"\"\"\n        models = discover_models(MockBase)\n        model_names = [m.__name__ for m in models]\n\n        assert \"MockUser\" in model_names\n        assert \"MockItem\" in model_names\n        assert \"MockSession\" in model_names\n\n    def test_returns_list(self):\n        \"\"\"Test that discover_models returns a list.\"\"\"\n        models = discover_models(MockBase)\n        assert isinstance(models, list)\n\n    def test_returns_model_classes(self):\n        \"\"\"Test that discovered items are model classes.\"\"\"\n        models = discover_models(MockBase)\n        for model in models:\n            assert hasattr(model, \"__tablename__\")\n\n\nclass TestGetModelColumns:\n    \"\"\"Tests for get_model_columns function.\"\"\"\n\n    def test_returns_all_columns(self):\n        \"\"\"Test that all columns are returned.\"\"\"\n        columns = get_model_columns(MockUser)\n\n        assert \"id\" in columns\n        assert \"email\" in columns\n        assert \"full_name\" in columns\n        assert \"hashed_password\" in columns\n        assert \"is_active\" in columns\n        assert \"created_at\" in columns\n        assert \"updated_at\" in columns\n\n    def test_returns_list_of_strings(self):\n        \"\"\"Test that column names are strings.\"\"\"\n        columns = get_model_columns(MockItem)\n\n        assert isinstance(columns, list)\n        for col in columns:\n            assert isinstance(col, str)\n\n\nclass TestGetSearchableColumns:\n    \"\"\"Tests for get_searchable_columns function.\"\"\"\n\n    def test_returns_string_columns(self):\n        \"\"\"Test that string columns are included.\"\"\"\n        columns = get_searchable_columns(MockUser)\n\n        assert \"email\" in columns\n        assert \"full_name\" in columns\n\n    def test_excludes_sensitive_columns(self):\n        \"\"\"Test that sensitive columns are excluded.\"\"\"\n        columns = get_searchable_columns(MockUser)\n\n        assert \"hashed_password\" not in columns\n\n    def test_excludes_non_string_columns(self):\n        \"\"\"Test that non-string columns are excluded.\"\"\"\n        columns = get_searchable_columns(MockUser)\n\n        assert \"id\" not in columns\n        assert \"is_active\" not in columns\n\n    def test_excludes_multiple_sensitive_patterns(self):\n        \"\"\"Test that all sensitive patterns are excluded.\"\"\"\n        columns = get_searchable_columns(MockSession)\n\n        assert \"refresh_token_hash\" not in columns\n        assert \"api_key\" not in columns\n        assert \"secret\" not in columns\n\n\nclass TestGetSortableColumns:\n    \"\"\"Tests for get_sortable_columns function.\"\"\"\n\n    def test_returns_all_columns(self):\n        \"\"\"Test that all columns are returned as sortable.\"\"\"\n        columns = get_sortable_columns(MockItem)\n\n        assert \"id\" in columns\n        assert \"title\" in columns\n        assert \"description\" in columns\n        assert \"price\" in columns\n\n    def test_returns_list(self):\n        \"\"\"Test that a list is returned.\"\"\"\n        columns = get_sortable_columns(MockUser)\n\n        assert isinstance(columns, list)\n\n\n# =============================================================================\n# Tests for get_form_excluded_columns\n# =============================================================================\n\n\nclass TestGetFormExcludedColumns:\n    \"\"\"Tests for get_form_excluded_columns function.\"\"\"\n\n    def test_excludes_sensitive_columns(self):\n        \"\"\"Test that sensitive columns are excluded from forms.\"\"\"\n        columns = get_form_excluded_columns(MockUser)\n\n        assert \"hashed_password\" in columns\n\n    def test_excludes_auto_generated_columns(self):\n        \"\"\"Test that auto-generated columns are excluded from forms.\"\"\"\n        columns = get_form_excluded_columns(MockUser)\n\n        assert \"created_at\" in columns\n        assert \"updated_at\" in columns\n\n    def test_does_not_exclude_regular_columns(self):\n        \"\"\"Test that regular columns are not excluded.\"\"\"\n        columns = get_form_excluded_columns(MockUser)\n\n        assert \"email\" not in columns\n        assert \"full_name\" not in columns\n        assert \"is_active\" not in columns\n\n    def test_excludes_all_sensitive_patterns(self):\n        \"\"\"Test that all sensitive patterns are matched.\"\"\"\n        columns = get_form_excluded_columns(MockSession)\n\n        assert \"refresh_token_hash\" in columns\n        assert \"api_key\" in columns\n        assert \"secret\" in columns\n\n\n# =============================================================================\n# Tests for pluralize\n# =============================================================================\n\n\nclass TestPluralize:\n    \"\"\"Tests for pluralize function.\"\"\"\n\n    def test_regular_pluralization(self):\n        \"\"\"Test regular word pluralization (add 's').\"\"\"\n        assert pluralize(\"User\") == \"Users\"\n        assert pluralize(\"Item\") == \"Items\"\n        assert pluralize(\"Model\") == \"Models\"\n\n    def test_words_ending_in_y(self):\n        \"\"\"Test words ending in 'y' (change to 'ies').\"\"\"\n        assert pluralize(\"Category\") == \"Categories\"\n        assert pluralize(\"Delivery\") == \"Deliveries\"\n        assert pluralize(\"Entry\") == \"Entries\"\n\n    def test_words_ending_in_s(self):\n        \"\"\"Test words ending in 's' (add 'es').\"\"\"\n        assert pluralize(\"Address\") == \"Addresses\"\n        assert pluralize(\"Class\") == \"Classes\"\n\n    def test_words_ending_in_x(self):\n        \"\"\"Test words ending in 'x' (add 'es').\"\"\"\n        assert pluralize(\"Box\") == \"Boxes\"\n        assert pluralize(\"Tax\") == \"Taxes\"\n\n    def test_words_ending_in_ch(self):\n        \"\"\"Test words ending in 'ch' (add 'es').\"\"\"\n        assert pluralize(\"Match\") == \"Matches\"\n        assert pluralize(\"Batch\") == \"Batches\"\n\n    def test_words_ending_in_sh(self):\n        \"\"\"Test words ending in 'sh' (add 'es').\"\"\"\n        assert pluralize(\"Dish\") == \"Dishes\"\n        assert pluralize(\"Wish\") == \"Wishes\"\n\n\n# =============================================================================\n# Tests for create_model_admin\n# =============================================================================\n\n\nclass TestCreateModelAdmin:\n    \"\"\"Tests for create_model_admin function.\"\"\"\n\n    def test_creates_model_view_class(self):\n        \"\"\"Test that a ModelView subclass is created.\"\"\"\n        from sqladmin import ModelView\n\n        admin_class = create_model_admin(MockItem)\n\n        assert admin_class is not None\n        assert issubclass(admin_class, ModelView)\n\n    def test_binds_model_via_metaclass(self):\n        \"\"\"Test that the model is properly bound via the metaclass.\"\"\"\n        admin_class = create_model_admin(MockItem)\n\n        # The model should be accessible after metaclass processing\n        assert hasattr(admin_class, \"model\")\n        assert admin_class.model == MockItem\n\n    def test_generates_class_name(self):\n        \"\"\"Test that the class name is generated correctly.\"\"\"\n        admin_class = create_model_admin(MockItem)\n\n        assert admin_class.__name__ == \"MockItemAdmin\"\n\n    def test_sets_display_name(self):\n        \"\"\"Test that the display name is set.\"\"\"\n        admin_class = create_model_admin(MockItem)\n\n        assert admin_class.name == \"MockItem\"\n\n    def test_sets_plural_name(self):\n        \"\"\"Test that the plural name is set.\"\"\"\n        admin_class = create_model_admin(MockItem)\n\n        assert admin_class.name_plural == \"MockItems\"\n\n    def test_custom_name_override(self):\n        \"\"\"Test that custom name can be provided.\"\"\"\n        admin_class = create_model_admin(MockItem, name=\"Product\")\n\n        assert admin_class.name == \"Product\"\n\n    def test_custom_name_plural_override(self):\n        \"\"\"Test that custom plural name can be provided.\"\"\"\n        admin_class = create_model_admin(MockItem, name_plural=\"Products\")\n\n        assert admin_class.name_plural == \"Products\"\n\n    def test_sets_icon_from_mapping(self):\n        \"\"\"Test that icon is set from MODEL_ICONS mapping.\"\"\"\n        admin_class = create_model_admin(MockUser)\n\n        # MockUser won't be in MODEL_ICONS, so it should get default\n        assert admin_class.icon == \"fa-solid fa-database\"\n\n    def test_custom_icon_override(self):\n        \"\"\"Test that custom icon can be provided.\"\"\"\n        admin_class = create_model_admin(MockItem, icon=\"fa-solid fa-star\")\n\n        assert admin_class.icon == \"fa-solid fa-star\"\n\n    def test_sets_column_list(self):\n        \"\"\"Test that column_list is populated.\"\"\"\n        admin_class = create_model_admin(MockItem)\n\n        assert admin_class.column_list is not None\n        assert len(admin_class.column_list) > 0\n\n    def test_custom_column_list(self):\n        \"\"\"Test that custom column_list can be provided.\"\"\"\n        admin_class = create_model_admin(\n            MockItem, column_list=[MockItem.id, MockItem.title]\n        )\n\n        assert len(admin_class.column_list) == 2\n\n    def test_sets_searchable_columns(self):\n        \"\"\"Test that searchable columns are set.\"\"\"\n        admin_class = create_model_admin(MockItem)\n\n        assert admin_class.column_searchable_list is not None\n\n    def test_sets_sortable_columns(self):\n        \"\"\"Test that sortable columns are set.\"\"\"\n        admin_class = create_model_admin(MockItem)\n\n        assert admin_class.column_sortable_list is not None\n\n    def test_sets_form_excluded_columns(self):\n        \"\"\"Test that form excluded columns are set.\"\"\"\n        admin_class = create_model_admin(MockUser)\n\n        assert admin_class.form_excluded_columns is not None\n\n    def test_crud_permissions_default_true(self):\n        \"\"\"Test that CRUD permissions default to True.\"\"\"\n        admin_class = create_model_admin(MockItem)\n\n        assert admin_class.can_create is True\n        assert admin_class.can_edit is True\n        assert admin_class.can_delete is True\n        assert admin_class.can_view_details is True\n\n    def test_crud_permissions_can_be_disabled(self):\n        \"\"\"Test that CRUD permissions can be disabled.\"\"\"\n        admin_class = create_model_admin(\n            MockItem,\n            can_create=False,\n            can_edit=False,\n            can_delete=False,\n            can_view_details=False,\n        )\n\n        assert admin_class.can_create is False\n        assert admin_class.can_edit is False\n        assert admin_class.can_delete is False\n        assert admin_class.can_view_details is False\n\n\n# =============================================================================\n# Tests for register_models_auto\n# =============================================================================\n\n\nclass TestRegisterModelsAuto:\n    \"\"\"Tests for register_models_auto function.\"\"\"\n\n    def test_registers_all_models(self):\n        \"\"\"Test that all models are registered.\"\"\"\n        mock_admin = MagicMock()\n\n        registered = register_models_auto(mock_admin, MockBase)\n\n        assert len(registered) >= 3  # MockUser, MockItem, MockSession\n        assert mock_admin.add_view.call_count >= 3\n\n    def test_excludes_specified_models(self):\n        \"\"\"Test that excluded models are not registered.\"\"\"\n        mock_admin = MagicMock()\n\n        registered = register_models_auto(\n            mock_admin, MockBase, exclude_models=[MockSession]\n        )\n\n        registered_names = [r.__name__ for r in registered]\n        assert \"MockSessionAdmin\" not in registered_names\n\n    def test_applies_custom_configs(self):\n        \"\"\"Test that custom configs are applied.\"\"\"\n        mock_admin = MagicMock()\n        custom_configs = {\n            MockItem: {\n                \"can_create\": False,\n                \"icon\": \"fa-solid fa-custom\",\n            }\n        }\n\n        registered = register_models_auto(\n            mock_admin, MockBase, custom_configs=custom_configs\n        )\n\n        # Find the MockItem admin class\n        item_admin = next(r for r in registered if r.model == MockItem)\n        assert item_admin.can_create is False\n        assert item_admin.icon == \"fa-solid fa-custom\"\n\n    def test_returns_list_of_model_views(self):\n        \"\"\"Test that a list of ModelView classes is returned.\"\"\"\n        from sqladmin import ModelView\n\n        mock_admin = MagicMock()\n\n        registered = register_models_auto(mock_admin, MockBase)\n\n        assert isinstance(registered, list)\n        for admin_class in registered:\n            assert issubclass(admin_class, ModelView)\n\n\n# =============================================================================\n# Tests for get_sync_engine\n# =============================================================================\n\n\nclass TestGetSyncEngine:\n    \"\"\"Tests for get_sync_engine function.\"\"\"\n\n    @patch(\"app.admin.create_engine\")\n    @patch(\"app.admin.settings\")\n    def test_creates_engine_with_settings(self, mock_settings, mock_create_engine):\n        \"\"\"Test that engine is created with correct settings.\"\"\"\n        import app.admin as admin_module\n\n        # Reset the cached engine\n        admin_module._sync_engine = None\n\n        mock_settings.DATABASE_URL_SYNC = \"postgresql://test\"\n        mock_settings.DEBUG = False\n        mock_engine = MagicMock()\n        mock_create_engine.return_value = mock_engine\n\n        engine = get_sync_engine()\n\n        mock_create_engine.assert_called_once_with(\n            \"postgresql://test\", echo=False\n        )\n        assert engine == mock_engine\n\n        # Reset for other tests\n        admin_module._sync_engine = None\n\n    @patch(\"app.admin.create_engine\")\n    @patch(\"app.admin.settings\")\n    def test_returns_cached_engine(self, mock_settings, mock_create_engine):\n        \"\"\"Test that engine is cached and reused.\"\"\"\n        import app.admin as admin_module\n\n        # Reset the cached engine\n        admin_module._sync_engine = None\n\n        mock_settings.DATABASE_URL_SYNC = \"postgresql://test\"\n        mock_settings.DEBUG = False\n        mock_engine = MagicMock()\n        mock_create_engine.return_value = mock_engine\n\n        engine1 = get_sync_engine()\n        engine2 = get_sync_engine()\n\n        # Should only create once\n        mock_create_engine.assert_called_once()\n        assert engine1 is engine2\n\n        # Reset for other tests\n        admin_module._sync_engine = None\n\n\n# =============================================================================\n# Tests for setup_admin\n# =============================================================================\n\n\nclass TestSetupAdmin:\n    \"\"\"Tests for setup_admin function.\"\"\"\n\n    @patch(\"app.admin.register_models_auto\")\n    @patch(\"app.admin.get_sync_engine\")\n    @patch(\"app.admin.Admin\")\n    def test_creates_admin_instance(\n        self, mock_admin_class, mock_get_engine, mock_register\n    ):\n        \"\"\"Test that Admin instance is created.\"\"\"\n        mock_engine = MagicMock()\n        mock_get_engine.return_value = mock_engine\n        mock_admin_instance = MagicMock()\n        mock_admin_class.return_value = mock_admin_instance\n        mock_app = MagicMock()\n\n        result = setup_admin(mock_app)\n\n        mock_admin_class.assert_called_once()\n        assert result == mock_admin_instance\n\n    @patch(\"app.admin.register_models_auto\")\n    @patch(\"app.admin.get_sync_engine\")\n    @patch(\"app.admin.Admin\")\n    def test_calls_register_models_auto(\n        self, mock_admin_class, mock_get_engine, mock_register\n    ):\n        \"\"\"Test that register_models_auto is called.\"\"\"\n        mock_engine = MagicMock()\n        mock_get_engine.return_value = mock_engine\n        mock_admin_instance = MagicMock()\n        mock_admin_class.return_value = mock_admin_instance\n        mock_app = MagicMock()\n\n        setup_admin(mock_app)\n\n        mock_register.assert_called_once()\n\n    @patch(\"app.admin.register_models_auto\")\n    @patch(\"app.admin.get_sync_engine\")\n    @patch(\"app.admin.Admin\")\n    def test_uses_correct_engine(\n        self, mock_admin_class, mock_get_engine, mock_register\n    ):\n        \"\"\"Test that the sync engine is used.\"\"\"\n        mock_engine = MagicMock()\n        mock_get_engine.return_value = mock_engine\n        mock_admin_instance = MagicMock()\n        mock_admin_class.return_value = mock_admin_instance\n        mock_app = MagicMock()\n\n        setup_admin(mock_app)\n\n        # Check that Admin was called with the engine\n        call_args = mock_admin_class.call_args\n        assert call_args[0][1] == mock_engine\n\n\n{%- if cookiecutter.admin_require_auth %}\n\n\n# =============================================================================\n# Tests for AdminAuth\n# =============================================================================\n\n\nclass TestAdminAuth:\n    \"\"\"Tests for AdminAuth authentication backend.\"\"\"\n\n    @pytest.fixture\n    def auth_backend(self):\n        \"\"\"Create an AdminAuth instance for testing.\"\"\"\n        return AdminAuth(secret_key=\"test-secret-key\")\n\n    @pytest.fixture\n    def mock_request(self):\n        \"\"\"Create a mock request object.\"\"\"\n        request = MagicMock()\n        request.session = {}\n        return request\n\n    @pytest.mark.anyio\n    async def test_login_returns_false_for_empty_credentials(\n        self, auth_backend, mock_request\n    ):\n        \"\"\"Test that login fails with empty credentials.\"\"\"\n        mock_request.form = AsyncMock(return_value={\"username\": \"\", \"password\": \"\"})\n\n        result = await auth_backend.login(mock_request)\n\n        assert result is False\n\n    @pytest.mark.anyio\n    async def test_login_returns_false_for_missing_email(\n        self, auth_backend, mock_request\n    ):\n        \"\"\"Test that login fails with missing email.\"\"\"\n        mock_request.form = AsyncMock(return_value={\"username\": None, \"password\": \"pass\"})\n\n        result = await auth_backend.login(mock_request)\n\n        assert result is False\n\n    @pytest.mark.anyio\n    async def test_login_returns_false_for_missing_password(\n        self, auth_backend, mock_request\n    ):\n        \"\"\"Test that login fails with missing password.\"\"\"\n        mock_request.form = AsyncMock(return_value={\"username\": \"test@test.com\", \"password\": None})\n\n        result = await auth_backend.login(mock_request)\n\n        assert result is False\n\n    @pytest.mark.anyio\n    @patch(\"app.admin.get_sync_engine\")\n    @patch(\"app.admin.verify_password\")\n    async def test_login_returns_false_for_nonexistent_user(\n        self, mock_verify, mock_get_engine, auth_backend, mock_request\n    ):\n        \"\"\"Test that login fails for non-existent user.\"\"\"\n        mock_request.form = AsyncMock(\n            return_value={\"username\": \"nonexistent@test.com\", \"password\": \"password\"}\n        )\n\n        mock_session = MagicMock()\n        mock_session.query.return_value.filter.return_value.first.return_value = None\n        mock_engine = MagicMock()\n        mock_get_engine.return_value = mock_engine\n\n        with patch(\"sqlalchemy.orm.Session\") as mock_session_class:\n            mock_session_class.return_value.__enter__ = MagicMock(\n                return_value=mock_session\n            )\n            mock_session_class.return_value.__exit__ = MagicMock(return_value=False)\n\n            result = await auth_backend.login(mock_request)\n\n        assert result is False\n\n    @pytest.mark.anyio\n    @patch(\"app.admin.get_sync_engine\")\n    @patch(\"app.admin.verify_password\")\n    async def test_login_returns_false_for_wrong_password(\n        self, mock_verify, mock_get_engine, auth_backend, mock_request\n    ):\n        \"\"\"Test that login fails for wrong password.\"\"\"\n        mock_request.form = AsyncMock(\n            return_value={\"username\": \"test@test.com\", \"password\": \"wrongpassword\"}\n        )\n        mock_verify.return_value = False\n\n        mock_user = MagicMock()\n        mock_user.is_superuser = True\n        mock_user.hashed_password = \"hashed\"\n\n        mock_session = MagicMock()\n        mock_session.query.return_value.filter.return_value.first.return_value = mock_user\n        mock_engine = MagicMock()\n        mock_get_engine.return_value = mock_engine\n\n        with patch(\"sqlalchemy.orm.Session\") as mock_session_class:\n            mock_session_class.return_value.__enter__ = MagicMock(\n                return_value=mock_session\n            )\n            mock_session_class.return_value.__exit__ = MagicMock(return_value=False)\n\n            result = await auth_backend.login(mock_request)\n\n        assert result is False\n\n    @pytest.mark.anyio\n    @patch(\"app.admin.get_sync_engine\")\n    @patch(\"app.admin.verify_password\")\n    async def test_login_returns_false_for_non_superuser(\n        self, mock_verify, mock_get_engine, auth_backend, mock_request\n    ):\n        \"\"\"Test that login fails for non-superuser.\"\"\"\n        mock_request.form = AsyncMock(\n            return_value={\"username\": \"test@test.com\", \"password\": \"password\"}\n        )\n        mock_verify.return_value = True\n\n        mock_user = MagicMock()\n        mock_user.is_superuser = False\n        mock_user.hashed_password = \"hashed\"\n\n        mock_session = MagicMock()\n        mock_session.query.return_value.filter.return_value.first.return_value = mock_user\n        mock_engine = MagicMock()\n        mock_get_engine.return_value = mock_engine\n\n        with patch(\"sqlalchemy.orm.Session\") as mock_session_class:\n            mock_session_class.return_value.__enter__ = MagicMock(\n                return_value=mock_session\n            )\n            mock_session_class.return_value.__exit__ = MagicMock(return_value=False)\n\n            result = await auth_backend.login(mock_request)\n\n        assert result is False\n\n    @pytest.mark.anyio\n    @patch(\"app.admin.get_sync_engine\")\n    @patch(\"app.admin.verify_password\")\n    async def test_login_success_for_valid_superuser(\n        self, mock_verify, mock_get_engine, auth_backend, mock_request\n    ):\n        \"\"\"Test that login succeeds for valid superuser.\"\"\"\n        mock_request.form = AsyncMock(\n            return_value={\"username\": \"admin@test.com\", \"password\": \"password\"}\n        )\n        mock_verify.return_value = True\n\n        mock_user = MagicMock()\n        mock_user.id = \"user-123\"\n        mock_user.email = \"admin@test.com\"\n        mock_user.is_superuser = True\n        mock_user.hashed_password = \"hashed\"\n\n        mock_session = MagicMock()\n        mock_session.query.return_value.filter.return_value.first.return_value = mock_user\n        mock_engine = MagicMock()\n        mock_get_engine.return_value = mock_engine\n\n        with patch(\"sqlalchemy.orm.Session\") as mock_session_class:\n            mock_session_class.return_value.__enter__ = MagicMock(\n                return_value=mock_session\n            )\n            mock_session_class.return_value.__exit__ = MagicMock(return_value=False)\n\n            result = await auth_backend.login(mock_request)\n\n        assert result is True\n        assert mock_request.session[\"admin_user_id\"] == \"user-123\"\n        assert mock_request.session[\"admin_email\"] == \"admin@test.com\"\n\n    @pytest.mark.anyio\n    async def test_logout_clears_session(self, auth_backend, mock_request):\n        \"\"\"Test that logout clears the session.\"\"\"\n        mock_request.session[\"admin_user_id\"] = \"user-123\"\n        mock_request.session[\"admin_email\"] = \"test@test.com\"\n\n        result = await auth_backend.logout(mock_request)\n\n        assert result is True\n        mock_request.session.clear.assert_called_once()\n\n    @pytest.mark.anyio\n    async def test_authenticate_returns_false_without_session(\n        self, auth_backend, mock_request\n    ):\n        \"\"\"Test that authenticate fails without session.\"\"\"\n        mock_request.session = {}\n\n        result = await auth_backend.authenticate(mock_request)\n\n        assert result is False\n\n    @pytest.mark.anyio\n    @patch(\"app.admin.get_sync_engine\")\n    async def test_authenticate_returns_false_for_invalid_user(\n        self, mock_get_engine, auth_backend, mock_request\n    ):\n        \"\"\"Test that authenticate fails for invalid user.\"\"\"\n        mock_request.session = {\"admin_user_id\": \"user-123\"}\n\n        mock_session = MagicMock()\n        mock_session.query.return_value.filter.return_value.first.return_value = None\n        mock_engine = MagicMock()\n        mock_get_engine.return_value = mock_engine\n\n        with patch(\"sqlalchemy.orm.Session\") as mock_session_class:\n            mock_session_class.return_value.__enter__ = MagicMock(\n                return_value=mock_session\n            )\n            mock_session_class.return_value.__exit__ = MagicMock(return_value=False)\n\n            result = await auth_backend.authenticate(mock_request)\n\n        assert result is False\n\n    @pytest.mark.anyio\n    @patch(\"app.admin.get_sync_engine\")\n    async def test_authenticate_returns_false_for_inactive_user(\n        self, mock_get_engine, auth_backend, mock_request\n    ):\n        \"\"\"Test that authenticate fails for inactive user.\"\"\"\n        mock_request.session = {\"admin_user_id\": \"user-123\"}\n\n        mock_user = MagicMock()\n        mock_user.is_superuser = True\n        mock_user.is_active = False\n\n        mock_session = MagicMock()\n        mock_session.query.return_value.filter.return_value.first.return_value = mock_user\n        mock_engine = MagicMock()\n        mock_get_engine.return_value = mock_engine\n\n        with patch(\"sqlalchemy.orm.Session\") as mock_session_class:\n            mock_session_class.return_value.__enter__ = MagicMock(\n                return_value=mock_session\n            )\n            mock_session_class.return_value.__exit__ = MagicMock(return_value=False)\n\n            result = await auth_backend.authenticate(mock_request)\n\n        assert result is False\n\n    @pytest.mark.anyio\n    @patch(\"app.admin.get_sync_engine\")\n    async def test_authenticate_returns_false_for_non_superuser(\n        self, mock_get_engine, auth_backend, mock_request\n    ):\n        \"\"\"Test that authenticate fails for non-superuser.\"\"\"\n        mock_request.session = {\"admin_user_id\": \"user-123\"}\n\n        mock_user = MagicMock()\n        mock_user.is_superuser = False\n        mock_user.is_active = True\n\n        mock_session = MagicMock()\n        mock_session.query.return_value.filter.return_value.first.return_value = mock_user\n        mock_engine = MagicMock()\n        mock_get_engine.return_value = mock_engine\n\n        with patch(\"sqlalchemy.orm.Session\") as mock_session_class:\n            mock_session_class.return_value.__enter__ = MagicMock(\n                return_value=mock_session\n            )\n            mock_session_class.return_value.__exit__ = MagicMock(return_value=False)\n\n            result = await auth_backend.authenticate(mock_request)\n\n        assert result is False\n\n    @pytest.mark.anyio\n    @patch(\"app.admin.get_sync_engine\")\n    async def test_authenticate_success_for_valid_superuser(\n        self, mock_get_engine, auth_backend, mock_request\n    ):\n        \"\"\"Test that authenticate succeeds for valid superuser.\"\"\"\n        mock_request.session = {\"admin_user_id\": \"user-123\"}\n\n        mock_user = MagicMock()\n        mock_user.is_superuser = True\n        mock_user.is_active = True\n\n        mock_session = MagicMock()\n        mock_session.query.return_value.filter.return_value.first.return_value = mock_user\n        mock_engine = MagicMock()\n        mock_get_engine.return_value = mock_engine\n\n        with patch(\"sqlalchemy.orm.Session\") as mock_session_class:\n            mock_session_class.return_value.__enter__ = MagicMock(\n                return_value=mock_session\n            )\n            mock_session_class.return_value.__exit__ = MagicMock(return_value=False)\n\n            result = await auth_backend.authenticate(mock_request)\n\n        assert result is True\n{%- endif %}\n{%- else %}\n\"\"\"Admin panel tests - not configured.\"\"\"\n{%- endif %}\n","backend/tests/test_security.py":"{%- if cookiecutter.use_jwt %}\n\"\"\"Tests for security module.\"\"\"\n\nfrom datetime import timedelta\n\nfrom app.core.security import (\n    create_access_token,\n    create_refresh_token,\n    get_password_hash,\n    verify_password,\n    verify_token,\n)\n\n\nclass TestPasswordHashing:\n    \"\"\"Tests for password hashing functions.\"\"\"\n\n    def test_hash_password(self):\n        \"\"\"Test password hashing.\"\"\"\n        password = \"mysecretpassword\"\n        hashed = get_password_hash(password)\n\n        assert hashed != password\n        assert len(hashed) > 0\n        assert hashed.startswith(\"$2\")  # bcrypt prefix\n\n    def test_verify_password_correct(self):\n        \"\"\"Test verifying correct password.\"\"\"\n        password = \"mysecretpassword\"\n        hashed = get_password_hash(password)\n\n        assert verify_password(password, hashed) is True\n\n    def test_verify_password_incorrect(self):\n        \"\"\"Test verifying incorrect password.\"\"\"\n        password = \"mysecretpassword\"\n        wrong_password = \"wrongpassword\"\n        hashed = get_password_hash(password)\n\n        assert verify_password(wrong_password, hashed) is False\n\n\nclass TestAccessToken:\n    \"\"\"Tests for access token functions.\"\"\"\n\n    def test_create_access_token(self):\n        \"\"\"Test creating access token.\"\"\"\n        subject = \"user123\"\n        token = create_access_token(subject)\n\n        assert isinstance(token, str)\n        assert len(token) > 0\n\n    def test_create_access_token_with_expires_delta(self):\n        \"\"\"Test creating access token with custom expiration.\"\"\"\n        subject = \"user123\"\n        expires = timedelta(hours=2)\n        token = create_access_token(subject, expires_delta=expires)\n\n        assert isinstance(token, str)\n        payload = verify_token(token)\n        assert payload is not None\n        assert payload[\"sub\"] == subject\n        assert payload[\"type\"] == \"access\"\n\n    def test_verify_access_token(self):\n        \"\"\"Test verifying access token.\"\"\"\n        subject = \"user123\"\n        token = create_access_token(subject)\n        payload = verify_token(token)\n\n        assert payload is not None\n        assert payload[\"sub\"] == subject\n        assert payload[\"type\"] == \"access\"\n\n    def test_verify_invalid_token(self):\n        \"\"\"Test verifying invalid token.\"\"\"\n        payload = verify_token(\"invalid.token.here\")\n\n        assert payload is None\n\n    def test_verify_expired_token(self):\n        \"\"\"Test verifying expired token.\"\"\"\n        subject = \"user123\"\n        # Create token that expires immediately\n        token = create_access_token(subject, expires_delta=timedelta(seconds=-1))\n        payload = verify_token(token)\n\n        assert payload is None\n\n\nclass TestRefreshToken:\n    \"\"\"Tests for refresh token functions.\"\"\"\n\n    def test_create_refresh_token(self):\n        \"\"\"Test creating refresh token.\"\"\"\n        subject = \"user123\"\n        token = create_refresh_token(subject)\n\n        assert isinstance(token, str)\n        assert len(token) > 0\n\n    def test_create_refresh_token_with_expires_delta(self):\n        \"\"\"Test creating refresh token with custom expiration.\"\"\"\n        subject = \"user123\"\n        expires = timedelta(days=7)\n        token = create_refresh_token(subject, expires_delta=expires)\n\n        assert isinstance(token, str)\n        payload = verify_token(token)\n        assert payload is not None\n        assert payload[\"sub\"] == subject\n        assert payload[\"type\"] == \"refresh\"\n\n    def test_verify_refresh_token(self):\n        \"\"\"Test verifying refresh token.\"\"\"\n        subject = \"user123\"\n        token = create_refresh_token(subject)\n        payload = verify_token(token)\n\n        assert payload is not None\n        assert payload[\"sub\"] == subject\n        assert payload[\"type\"] == \"refresh\"\n{%- endif %}\n","backend/tests/conftest.py":"\"\"\"Test configuration and fixtures.\n\nUses anyio for async testing instead of pytest-asyncio.\nThis allows using the same async primitives that Starlette uses internally.\nSee: https://anyio.readthedocs.io/en/stable/testing.html\n\"\"\"\n{%- if cookiecutter.enable_redis or cookiecutter.use_database or cookiecutter.use_api_key %}\n# ruff: noqa: I001 - Imports structured for Jinja2 template conditionals\n{%- endif %}\n\nfrom collections.abc import AsyncGenerator\n{%- if cookiecutter.enable_redis %}\nfrom unittest.mock import AsyncMock, MagicMock\n{%- elif cookiecutter.use_postgresql or cookiecutter.use_mongodb %}\nfrom unittest.mock import AsyncMock\n{%- elif cookiecutter.use_sqlite %}\nfrom unittest.mock import MagicMock\n{%- endif %}\n\nimport pytest\nfrom httpx import ASGITransport, AsyncClient\n\nfrom app.main import app\n{%- if cookiecutter.use_api_key %}\nfrom app.core.config import settings\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\nfrom app.api.deps import get_redis\nfrom app.clients.redis import RedisClient\n{%- endif %}\n{%- if cookiecutter.use_database %}\nfrom app.api.deps import get_db_session\n{%- endif %}\n\n\n@pytest.fixture\ndef anyio_backend() -> str:\n    \"\"\"Specify the async backend for anyio tests.\n\n    Options: \"asyncio\" or \"trio\". We use asyncio since that's what uvicorn uses.\n    \"\"\"\n    return \"asyncio\"\n\n\n{%- if cookiecutter.enable_redis %}\n\n\n@pytest.fixture\ndef mock_redis() -> MagicMock:\n    \"\"\"Create a mock Redis client for testing.\"\"\"\n    mock = MagicMock(spec=RedisClient)\n    mock.ping = AsyncMock(return_value=True)\n    mock.get = AsyncMock(return_value=None)\n    mock.set = AsyncMock(return_value=True)\n    mock.delete = AsyncMock(return_value=1)\n    mock.exists = AsyncMock(return_value=0)\n    mock.incr = AsyncMock(return_value=1)\n    mock.expire = AsyncMock(return_value=True)\n    return mock\n{%- endif %}\n\n\n{%- if cookiecutter.use_postgresql %}\n\n\n@pytest.fixture\nasync def mock_db_session() -> AsyncGenerator[AsyncMock, None]:\n    \"\"\"Create a mock database session for testing.\"\"\"\n    mock = AsyncMock()\n    mock.execute = AsyncMock()\n    mock.commit = AsyncMock()\n    mock.rollback = AsyncMock()\n    mock.close = AsyncMock()\n    yield mock\n{%- endif %}\n\n\n{%- if cookiecutter.use_sqlite %}\n\n\n@pytest.fixture\ndef mock_db_session() -> MagicMock:\n    \"\"\"Create a mock database session for testing.\"\"\"\n    mock = MagicMock()\n    mock.execute = MagicMock()\n    mock.commit = MagicMock()\n    mock.rollback = MagicMock()\n    mock.close = MagicMock()\n    return mock\n{%- endif %}\n\n\n{%- if cookiecutter.use_mongodb %}\n\n\n@pytest.fixture\nasync def mock_db_session() -> AsyncMock:\n    \"\"\"Create a mock MongoDB session for testing.\"\"\"\n    mock = AsyncMock()\n    mock.command = AsyncMock(return_value={\"ok\": 1})\n    return mock\n{%- endif %}\n\n\n@pytest.fixture\nasync def client(\n{%- if cookiecutter.enable_redis %}\n    mock_redis: MagicMock,\n{%- endif %}\n{%- if cookiecutter.use_database %}\n    mock_db_session,\n{%- endif %}\n) -> AsyncGenerator[AsyncClient, None]:\n    \"\"\"Async HTTP client for testing.\n\n    Uses HTTPX AsyncClient with ASGITransport instead of Starlette's TestClient.\n    This allows proper async testing without thread pool overhead.\n    \"\"\"\n    # Override dependencies for testing\n{%- if cookiecutter.enable_redis %}\n    app.dependency_overrides[get_redis] = lambda: mock_redis\n{%- endif %}\n{%- if cookiecutter.use_database %}\n    app.dependency_overrides[get_db_session] = lambda: mock_db_session\n{%- endif %}\n\n    async with AsyncClient(\n        transport=ASGITransport(app=app),\n        base_url=\"http://test\",\n    ) as ac:\n        yield ac\n\n    # Clear overrides after test\n    app.dependency_overrides.clear()\n\n\n{%- if cookiecutter.use_api_key %}\n\n\n@pytest.fixture\ndef api_key_headers() -> dict[str, str]:\n    \"\"\"Headers with valid API key.\"\"\"\n    return {settings.API_KEY_HEADER: settings.API_KEY}\n{%- endif %}\n\n\n{%- if cookiecutter.use_jwt %}\n# Note: For integration tests requiring authenticated users,\n# use dependency overrides with mock users instead of test_user fixture.\n# See tests/api/test_auth.py and tests/api/test_users.py for examples.\n{%- endif %}\n","backend/tests/test_services.py":"{%- if cookiecutter.use_jwt %}\n\"\"\"Tests for service layer.\"\"\"\n{%- if cookiecutter.use_postgresql or cookiecutter.use_mongodb %}\n\nfrom unittest.mock import AsyncMock, patch\n{%- elif cookiecutter.use_sqlite %}\n\nfrom unittest.mock import MagicMock, patch\n{%- endif %}\nfrom uuid import uuid4\n\nimport pytest\n\nfrom app.core.exceptions import AlreadyExistsError, AuthenticationError, NotFoundError\nfrom app.schemas.user import UserCreate, UserUpdate\nfrom app.services.user import UserService\n\n\nclass MockUser:\n    \"\"\"Mock user for testing.\"\"\"\n\n    def __init__(\n        self,\n        id=None,\n        email=\"test@example.com\",\n        full_name=\"Test User\",\n        hashed_password=\"$2b$12$hashedpassword\",\n        is_active=True,\n        is_superuser=False,\n    ):\n{%- if cookiecutter.use_postgresql %}\n        self.id = id or uuid4()\n{%- else %}\n        self.id = id or str(uuid4())\n{%- endif %}\n        self.email = email\n        self.full_name = full_name\n        self.hashed_password = hashed_password\n        self.is_active = is_active\n        self.is_superuser = is_superuser\n\n\n{%- if cookiecutter.use_postgresql %}\n\n\nclass TestUserServicePostgresql:\n    \"\"\"Tests for UserService with PostgreSQL.\"\"\"\n\n    @pytest.fixture\n    def mock_db(self) -> AsyncMock:\n        \"\"\"Create mock database session.\"\"\"\n        return AsyncMock()\n\n    @pytest.fixture\n    def user_service(self, mock_db: AsyncMock) -> UserService:\n        \"\"\"Create UserService instance with mock db.\"\"\"\n        return UserService(mock_db)\n\n    @pytest.fixture\n    def mock_user(self) -> MockUser:\n        \"\"\"Create a mock user.\"\"\"\n        return MockUser()\n\n    @pytest.mark.anyio\n    async def test_get_by_id_success(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test getting user by ID successfully.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_id = AsyncMock(return_value=mock_user)\n\n            result = await user_service.get_by_id(mock_user.id)\n\n            assert result == mock_user\n            mock_repo.get_by_id.assert_called_once()\n\n    @pytest.mark.anyio\n    async def test_get_by_id_not_found(self, user_service: UserService):\n        \"\"\"Test getting non-existent user raises NotFoundError.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_id = AsyncMock(return_value=None)\n\n            with pytest.raises(NotFoundError):\n                await user_service.get_by_id(uuid4())\n\n    @pytest.mark.anyio\n    async def test_get_by_email(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test getting user by email.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_email = AsyncMock(return_value=mock_user)\n\n            result = await user_service.get_by_email(\"test@example.com\")\n\n            assert result == mock_user\n\n    @pytest.mark.anyio\n    async def test_get_multi(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test getting multiple users.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_multi = AsyncMock(return_value=[mock_user])\n\n            result = await user_service.get_multi(skip=0, limit=10)\n\n            assert len(result) == 1\n            assert result[0] == mock_user\n\n    @pytest.mark.anyio\n    async def test_register_success(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test registering a new user.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_email = AsyncMock(return_value=None)\n            mock_repo.create = AsyncMock(return_value=mock_user)\n\n            user_in = UserCreate(\n                email=\"new@example.com\",\n                password=\"password123\",\n                full_name=\"New User\",\n            )\n            result = await user_service.register(user_in)\n\n            assert result == mock_user\n            mock_repo.create.assert_called_once()\n\n    @pytest.mark.anyio\n    async def test_register_duplicate_email(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test registering with existing email raises AlreadyExistsError.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_email = AsyncMock(return_value=mock_user)\n\n            user_in = UserCreate(\n                email=\"existing@example.com\",\n                password=\"password123\",\n                full_name=\"Test\",\n            )\n\n            with pytest.raises(AlreadyExistsError):\n                await user_service.register(user_in)\n\n    @pytest.mark.anyio\n    async def test_authenticate_success(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test successful authentication.\"\"\"\n        with (\n            patch(\"app.services.user.user_repo\") as mock_repo,\n            patch(\"app.services.user.verify_password\", return_value=True),\n        ):\n            mock_repo.get_by_email = AsyncMock(return_value=mock_user)\n\n            result = await user_service.authenticate(\"test@example.com\", \"password123\")\n\n            assert result == mock_user\n\n    @pytest.mark.anyio\n    async def test_authenticate_invalid_password(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test authentication with wrong password.\"\"\"\n        with (\n            patch(\"app.services.user.user_repo\") as mock_repo,\n            patch(\"app.services.user.verify_password\", return_value=False),\n        ):\n            mock_repo.get_by_email = AsyncMock(return_value=mock_user)\n\n            with pytest.raises(AuthenticationError):\n                await user_service.authenticate(\"test@example.com\", \"wrongpassword\")\n\n    @pytest.mark.anyio\n    async def test_authenticate_user_not_found(self, user_service: UserService):\n        \"\"\"Test authentication with non-existent user.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_email = AsyncMock(return_value=None)\n\n            with pytest.raises(AuthenticationError):\n                await user_service.authenticate(\"unknown@example.com\", \"password\")\n\n    @pytest.mark.anyio\n    async def test_authenticate_inactive_user(self, user_service: UserService):\n        \"\"\"Test authentication with inactive user.\"\"\"\n        inactive_user = MockUser(is_active=False)\n        with (\n            patch(\"app.services.user.user_repo\") as mock_repo,\n            patch(\"app.services.user.verify_password\", return_value=True),\n        ):\n            mock_repo.get_by_email = AsyncMock(return_value=inactive_user)\n\n            with pytest.raises(AuthenticationError):\n                await user_service.authenticate(\"test@example.com\", \"password\")\n\n    @pytest.mark.anyio\n    async def test_update_success(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test updating user.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_id = AsyncMock(return_value=mock_user)\n            mock_repo.update = AsyncMock(return_value=mock_user)\n\n            user_update = UserUpdate(full_name=\"Updated Name\")\n            result = await user_service.update(mock_user.id, user_update)\n\n            assert result == mock_user\n\n    @pytest.mark.anyio\n    async def test_update_with_password(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test updating user with password change.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_id = AsyncMock(return_value=mock_user)\n            mock_repo.update = AsyncMock(return_value=mock_user)\n\n            user_update = UserUpdate(password=\"newpassword123\")\n            result = await user_service.update(mock_user.id, user_update)\n\n            assert result == mock_user\n            # Verify hashed_password was passed to update\n            call_args = mock_repo.update.call_args\n            assert \"hashed_password\" in call_args[1][\"update_data\"]\n\n    @pytest.mark.anyio\n    async def test_delete_success(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test deleting user.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.delete = AsyncMock(return_value=mock_user)\n\n            result = await user_service.delete(mock_user.id)\n\n            assert result == mock_user\n\n    @pytest.mark.anyio\n    async def test_delete_not_found(self, user_service: UserService):\n        \"\"\"Test deleting non-existent user.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.delete = AsyncMock(return_value=None)\n\n            with pytest.raises(NotFoundError):\n                await user_service.delete(uuid4())\n{%- endif %}\n\n\n{%- if cookiecutter.use_sqlite %}\n\n\nclass TestUserServiceSQLite:\n    \"\"\"Tests for UserService with SQLite.\"\"\"\n\n    @pytest.fixture\n    def mock_db(self) -> MagicMock:\n        \"\"\"Create mock database session.\"\"\"\n        return MagicMock()\n\n    @pytest.fixture\n    def user_service(self, mock_db: MagicMock) -> UserService:\n        \"\"\"Create UserService instance with mock db.\"\"\"\n        return UserService(mock_db)\n\n    @pytest.fixture\n    def mock_user(self) -> MockUser:\n        \"\"\"Create a mock user.\"\"\"\n        return MockUser()\n\n    def test_get_by_id_success(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test getting user by ID successfully.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_id = MagicMock(return_value=mock_user)\n\n            result = user_service.get_by_id(mock_user.id)\n\n            assert result == mock_user\n\n    def test_get_by_id_not_found(self, user_service: UserService):\n        \"\"\"Test getting non-existent user raises NotFoundError.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_id = MagicMock(return_value=None)\n\n            with pytest.raises(NotFoundError):\n                user_service.get_by_id(\"nonexistent\")\n\n    def test_authenticate_success(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test successful authentication.\"\"\"\n        with (\n            patch(\"app.services.user.user_repo\") as mock_repo,\n            patch(\"app.services.user.verify_password\", return_value=True),\n        ):\n            mock_repo.get_by_email = MagicMock(return_value=mock_user)\n\n            result = user_service.authenticate(\"test@example.com\", \"password123\")\n\n            assert result == mock_user\n\n    def test_register_success(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test registering a new user.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_email = MagicMock(return_value=None)\n            mock_repo.create = MagicMock(return_value=mock_user)\n\n            user_in = UserCreate(\n                email=\"new@example.com\",\n                password=\"password123\",\n                full_name=\"New User\",\n            )\n            result = user_service.register(user_in)\n\n            assert result == mock_user\n{%- endif %}\n\n\n{%- if cookiecutter.use_mongodb %}\n\n\nclass TestUserServiceMongoDB:\n    \"\"\"Tests for UserService with MongoDB.\"\"\"\n\n    @pytest.fixture\n    def user_service(self) -> UserService:\n        \"\"\"Create UserService instance.\"\"\"\n        return UserService()\n\n    @pytest.fixture\n    def mock_user(self) -> MockUser:\n        \"\"\"Create a mock user.\"\"\"\n        return MockUser()\n\n    @pytest.mark.anyio\n    async def test_get_by_id_success(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test getting user by ID successfully.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_id = AsyncMock(return_value=mock_user)\n\n            result = await user_service.get_by_id(mock_user.id)\n\n            assert result == mock_user\n\n    @pytest.mark.anyio\n    async def test_get_by_id_not_found(self, user_service: UserService):\n        \"\"\"Test getting non-existent user raises NotFoundError.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_id = AsyncMock(return_value=None)\n\n            with pytest.raises(NotFoundError):\n                await user_service.get_by_id(\"nonexistent\")\n\n    @pytest.mark.anyio\n    async def test_authenticate_success(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test successful authentication.\"\"\"\n        with (\n            patch(\"app.services.user.user_repo\") as mock_repo,\n            patch(\"app.services.user.verify_password\", return_value=True),\n        ):\n            mock_repo.get_by_email = AsyncMock(return_value=mock_user)\n\n            result = await user_service.authenticate(\"test@example.com\", \"password123\")\n\n            assert result == mock_user\n\n    @pytest.mark.anyio\n    async def test_register_success(self, user_service: UserService, mock_user: MockUser):\n        \"\"\"Test registering a new user.\"\"\"\n        with patch(\"app.services.user.user_repo\") as mock_repo:\n            mock_repo.get_by_email = AsyncMock(return_value=None)\n            mock_repo.create = AsyncMock(return_value=mock_user)\n\n            user_in = UserCreate(\n                email=\"new@example.com\",\n                password=\"password123\",\n                full_name=\"New User\",\n            )\n            result = await user_service.register(user_in)\n\n            assert result == mock_user\n{%- endif %}\n{%- endif %}\n","backend/tests/test_core.py":"\"\"\"Tests for core modules.\"\"\"\n\nfrom app.core.config import settings\nfrom app.core.exceptions import (\n    AlreadyExistsError,\n    AppException,\n    AuthenticationError,\n    AuthorizationError,\n    NotFoundError,\n    ValidationError,\n)\n\n\nclass TestSettings:\n    \"\"\"Tests for settings configuration.\"\"\"\n\n    def test_project_name_is_set(self):\n        \"\"\"Test project name is configured.\"\"\"\n        assert settings.PROJECT_NAME == \"{{ cookiecutter.project_name }}\"\n\n    def test_api_v1_str_is_set(self):\n        \"\"\"Test API version string is set.\"\"\"\n        assert settings.API_V1_STR == \"/api/v1\"\n\n    def test_debug_mode_default(self):\n        \"\"\"Test debug mode has default value.\"\"\"\n        assert isinstance(settings.DEBUG, bool)\n\n{%- if cookiecutter.enable_cors %}\n    def test_cors_origins_is_list(self):\n        \"\"\"Test CORS origins is a list.\"\"\"\n        assert isinstance(settings.CORS_ORIGINS, list)\n{%- endif %}\n\n\nclass TestExceptions:\n    \"\"\"Tests for custom exceptions.\"\"\"\n\n    def test_app_exception(self):\n        \"\"\"Test AppException initialization.\"\"\"\n        error = AppException(message=\"Test error\", code=\"TEST_ERROR\")\n        assert error.message == \"Test error\"\n        assert error.code == \"TEST_ERROR\"\n        assert str(error) == \"Test error\"\n\n    def test_not_found_error(self):\n        \"\"\"Test NotFoundError.\"\"\"\n        error = NotFoundError(message=\"Item not found\")\n        assert error.status_code == 404\n        assert error.code == \"NOT_FOUND\"\n\n    def test_already_exists_error(self):\n        \"\"\"Test AlreadyExistsError.\"\"\"\n        error = AlreadyExistsError(message=\"Item already exists\")\n        assert error.status_code == 409\n        assert error.code == \"ALREADY_EXISTS\"\n\n    def test_authentication_error(self):\n        \"\"\"Test AuthenticationError.\"\"\"\n        error = AuthenticationError(message=\"Invalid credentials\")\n        assert error.status_code == 401\n        assert error.code == \"AUTHENTICATION_ERROR\"\n\n    def test_authorization_error(self):\n        \"\"\"Test AuthorizationError.\"\"\"\n        error = AuthorizationError(message=\"Not authorized\")\n        assert error.status_code == 403\n        assert error.code == \"AUTHORIZATION_ERROR\"\n\n    def test_validation_error(self):\n        \"\"\"Test ValidationError.\"\"\"\n        error = ValidationError(message=\"Invalid input\")\n        assert error.status_code == 422\n        assert error.code == \"VALIDATION_ERROR\"\n\n\n{%- if cookiecutter.enable_redis %}\n\n\nclass TestCacheSetup:\n    \"\"\"Tests for cache setup.\"\"\"\n\n    def test_setup_cache_function_exists(self):\n        \"\"\"Test setup_cache function exists.\"\"\"\n        from app.core.cache import setup_cache\n\n        assert setup_cache is not None\n        assert callable(setup_cache)\n{%- endif %}\n\n\nclass TestMiddleware:\n    \"\"\"Tests for middleware.\"\"\"\n\n    def test_request_id_middleware_exists(self):\n        \"\"\"Test request ID middleware is configured.\"\"\"\n        from app.core.middleware import RequestIDMiddleware\n\n        assert RequestIDMiddleware is not None\n\n\n{%- if cookiecutter.enable_rate_limiting %}\n\n\nclass TestRateLimit:\n    \"\"\"Tests for rate limiting.\"\"\"\n\n    def test_limiter_exists(self):\n        \"\"\"Test rate limiter is configured.\"\"\"\n        from app.core.rate_limit import limiter\n\n        assert limiter is not None\n{%- endif %}\n\n\n{%- if cookiecutter.enable_logfire %}\n\n\nfrom unittest.mock import patch  # noqa: E402\n\n\nclass TestLogfireSetup:\n    \"\"\"Tests for Logfire setup.\"\"\"\n\n    @patch(\"app.core.logfire_setup.logfire\")\n    def test_setup_logfire_configures(self, mock_logfire):\n        \"\"\"Test setup_logfire calls configure.\"\"\"\n        from app.core.logfire_setup import setup_logfire\n\n        setup_logfire()\n        mock_logfire.configure.assert_called_once()\n\n    @patch(\"app.core.logfire_setup.logfire\")\n    def test_instrument_app_instruments_fastapi(self, mock_logfire):\n        \"\"\"Test instrument_app instruments FastAPI.\"\"\"\n        from fastapi import FastAPI\n\n        from app.core.logfire_setup import instrument_app\n\n        app = FastAPI()\n        instrument_app(app)\n        mock_logfire.instrument_fastapi.assert_called()\n{%- endif %}\n","backend/tests/test_pipelines.py":"\"\"\"Tests for pipeline infrastructure.\"\"\"\n\nimport pytest\n\nfrom app.pipelines.base import BasePipeline, PipelineResult\n\n\nclass TestPipelineResult:\n    \"\"\"Tests for PipelineResult dataclass.\"\"\"\n\n    def test_success_rate_all_processed(self):\n        \"\"\"Test success rate when all items processed.\"\"\"\n        result = PipelineResult(processed=10, failed=0)\n        assert result.success_rate == 100.0\n\n    def test_success_rate_with_failures(self):\n        \"\"\"Test success rate with some failures.\"\"\"\n        result = PipelineResult(processed=8, failed=2)\n        assert result.success_rate == 80.0\n\n    def test_success_rate_all_failed(self):\n        \"\"\"Test success rate when all items failed.\"\"\"\n        result = PipelineResult(processed=0, failed=10)\n        assert result.success_rate == 0.0\n\n    def test_success_rate_empty(self):\n        \"\"\"Test success rate with no items.\"\"\"\n        result = PipelineResult(processed=0, failed=0)\n        assert result.success_rate == 100.0\n\n    def test_has_errors_with_failures(self):\n        \"\"\"Test has_errors returns True when failures exist.\"\"\"\n        result = PipelineResult(processed=5, failed=1)\n        assert result.has_errors is True\n\n    def test_has_errors_with_error_messages(self):\n        \"\"\"Test has_errors returns True when error messages exist.\"\"\"\n        result = PipelineResult(processed=5, failed=0, errors=[\"Error 1\"])\n        assert result.has_errors is True\n\n    def test_has_errors_no_errors(self):\n        \"\"\"Test has_errors returns False when no errors.\"\"\"\n        result = PipelineResult(processed=5, failed=0)\n        assert result.has_errors is False\n\n    def test_default_values(self):\n        \"\"\"Test default values are set correctly.\"\"\"\n        result = PipelineResult(processed=5)\n        assert result.failed == 0\n        assert result.errors == []\n        assert result.metadata == {}\n\n\nclass TestBasePipeline:\n    \"\"\"Tests for BasePipeline abstract class.\"\"\"\n\n    @pytest.mark.anyio\n    async def test_validate_returns_true_by_default(self):\n        \"\"\"Test validate method returns True by default.\"\"\"\n\n        class TestPipeline(BasePipeline):\n            async def run(self) -> PipelineResult:\n                return PipelineResult(processed=0)\n\n        pipeline = TestPipeline()\n        assert await pipeline.validate() is True\n\n    @pytest.mark.anyio\n    async def test_cleanup_does_nothing_by_default(self):\n        \"\"\"Test cleanup method does nothing by default.\"\"\"\n\n        class TestPipeline(BasePipeline):\n            async def run(self) -> PipelineResult:\n                return PipelineResult(processed=0)\n\n        pipeline = TestPipeline()\n        await pipeline.cleanup()  # Should not raise\n\n    @pytest.mark.anyio\n    async def test_run_must_be_implemented(self):\n        \"\"\"Test that run method must be implemented by subclasses.\"\"\"\n        # This test verifies the abstract method requirement\n        with pytest.raises(TypeError, match=\"Can't instantiate abstract class\"):\n            BasePipeline()\n\n    @pytest.mark.anyio\n    async def test_custom_pipeline_implementation(self):\n        \"\"\"Test a custom pipeline implementation.\"\"\"\n\n        class MyPipeline(BasePipeline):\n            def __init__(self, items: list):\n                self.items = items\n\n            async def run(self) -> PipelineResult:\n                processed = 0\n                failed = 0\n                errors = []\n\n                for item in self.items:\n                    if item > 0:\n                        processed += 1\n                    else:\n                        failed += 1\n                        errors.append(f\"Invalid item: {item}\")\n\n                return PipelineResult(\n                    processed=processed,\n                    failed=failed,\n                    errors=errors,\n                )\n\n        pipeline = MyPipeline([1, 2, 3, -1, 5])\n        result = await pipeline.run()\n\n        assert result.processed == 4\n        assert result.failed == 1\n        assert len(result.errors) == 1\n        assert result.success_rate == 80.0\n","backend/tests/__init__.py":"\"\"\"Tests package.\"\"\"\n","backend/tests/test_repositories.py":"{%- if cookiecutter.use_database %}\n\"\"\"Tests for repository layer.\"\"\"\n\nfrom unittest.mock import AsyncMock, MagicMock\nfrom uuid import uuid4\n\nimport pytest\nfrom pydantic import BaseModel\n\nfrom app.repositories.base import BaseRepository\n\n\nclass MockModel:\n    \"\"\"Mock SQLAlchemy model for testing.\"\"\"\n\n    def __init__(self, **kwargs):\n        self.id = kwargs.get(\"id\", uuid4())\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\n\nclass MockCreateSchema(BaseModel):\n    \"\"\"Mock create schema.\"\"\"\n\n    name: str\n\n\nclass MockUpdateSchema(BaseModel):\n    \"\"\"Mock update schema.\"\"\"\n\n    name: str | None = None\n\n\nclass TestBaseRepository:\n    \"\"\"Tests for BaseRepository.\"\"\"\n\n    @pytest.fixture\n    def repository(self):\n        \"\"\"Create a test repository.\"\"\"\n        return BaseRepository[MockModel, MockCreateSchema, MockUpdateSchema](MockModel)\n\n    @pytest.fixture\n    def mock_session(self):\n        \"\"\"Create a mock async session.\"\"\"\n        session = MagicMock()\n        session.get = AsyncMock()\n        session.execute = AsyncMock()\n        session.add = MagicMock()\n        session.flush = AsyncMock()\n        session.refresh = AsyncMock()\n        session.delete = AsyncMock()\n        return session\n\n    @pytest.mark.anyio\n    async def test_get_returns_model(self, repository, mock_session):\n        \"\"\"Test get returns a model by ID.\"\"\"\n        mock_obj = MockModel(name=\"test\")\n        mock_session.get.return_value = mock_obj\n\n        result = await repository.get(mock_session, mock_obj.id)\n\n        assert result == mock_obj\n        mock_session.get.assert_called_once_with(MockModel, mock_obj.id)\n\n    @pytest.mark.anyio\n    async def test_get_returns_none_when_not_found(self, repository, mock_session):\n        \"\"\"Test get returns None when not found.\"\"\"\n        mock_session.get.return_value = None\n\n        result = await repository.get(mock_session, uuid4())\n\n        assert result is None\n\n    # Note: test_get_multi_returns_list is skipped because it requires a real\n    # SQLAlchemy model. The select() function cannot work with a mock class.\n    # For proper integration testing, use actual SQLAlchemy models with a test DB.\n\n    @pytest.mark.anyio\n    async def test_create_adds_and_returns_model(self, repository, mock_session):\n        \"\"\"Test create adds a new model.\"\"\"\n        create_data = MockCreateSchema(name=\"new item\")\n\n        # Mock the model creation\n        async def refresh_side_effect(obj):\n            obj.id = uuid4()\n\n        mock_session.refresh.side_effect = refresh_side_effect\n\n        result = await repository.create(mock_session, obj_in=create_data)\n\n        assert result.name == \"new item\"\n        mock_session.add.assert_called_once()\n        mock_session.flush.assert_called_once()\n        mock_session.refresh.assert_called_once()\n\n    @pytest.mark.anyio\n    async def test_update_with_schema(self, repository, mock_session):\n        \"\"\"Test update with Pydantic schema.\"\"\"\n        db_obj = MockModel(name=\"old name\")\n        update_data = MockUpdateSchema(name=\"new name\")\n\n        result = await repository.update(mock_session, db_obj=db_obj, obj_in=update_data)\n\n        assert result.name == \"new name\"\n        mock_session.add.assert_called_once()\n        mock_session.flush.assert_called_once()\n\n    @pytest.mark.anyio\n    async def test_update_with_dict(self, repository, mock_session):\n        \"\"\"Test update with dictionary.\"\"\"\n        db_obj = MockModel(name=\"old name\")\n        update_data = {\"name\": \"new name\"}\n\n        result = await repository.update(mock_session, db_obj=db_obj, obj_in=update_data)\n\n        assert result.name == \"new name\"\n\n    @pytest.mark.anyio\n    async def test_delete_removes_and_returns_model(self, repository, mock_session):\n        \"\"\"Test delete removes and returns model.\"\"\"\n        mock_obj = MockModel(name=\"to delete\")\n        mock_session.get.return_value = mock_obj\n\n        result = await repository.delete(mock_session, id=mock_obj.id)\n\n        assert result == mock_obj\n        mock_session.delete.assert_called_once_with(mock_obj)\n        mock_session.flush.assert_called_once()\n\n    @pytest.mark.anyio\n    async def test_delete_returns_none_when_not_found(self, repository, mock_session):\n        \"\"\"Test delete returns None when not found.\"\"\"\n        mock_session.get.return_value = None\n\n        result = await repository.delete(mock_session, id=uuid4())\n\n        assert result is None\n        mock_session.delete.assert_not_called()\n\n\n{%- if cookiecutter.use_jwt %}\n\n\nclass TestUserRepository:\n    \"\"\"Tests for user repository functions.\"\"\"\n\n    @pytest.fixture\n    def mock_session(self):\n        \"\"\"Create a mock async session.\"\"\"\n        session = MagicMock()\n        session.execute = AsyncMock()\n        return session\n\n    @pytest.mark.anyio\n    async def test_get_by_email(self, mock_session):\n        \"\"\"Test get_by_email returns user.\"\"\"\n        from app.repositories import user as user_repo\n\n        mock_user = MagicMock()\n        mock_result = MagicMock()\n        mock_result.scalar_one_or_none.return_value = mock_user\n        mock_session.execute.return_value = mock_result\n\n        result = await user_repo.get_by_email(mock_session, \"test@example.com\")\n\n        assert result == mock_user\n\n    @pytest.mark.anyio\n    async def test_get_by_email_not_found(self, mock_session):\n        \"\"\"Test get_by_email returns None when not found.\"\"\"\n        from app.repositories import user as user_repo\n\n        mock_result = MagicMock()\n        mock_result.scalar_one_or_none.return_value = None\n        mock_session.execute.return_value = mock_result\n\n        result = await user_repo.get_by_email(mock_session, \"notfound@example.com\")\n\n        assert result is None\n{%- endif %}\n{%- endif %}\n","backend/tests/test_clients.py":"{%- if cookiecutter.enable_redis %}\n\"\"\"Tests for client modules.\"\"\"\n\nfrom unittest.mock import AsyncMock, MagicMock, patch\n\nimport pytest\n\nfrom app.clients.redis import RedisClient\n\n\nclass TestRedisClient:\n    \"\"\"Tests for RedisClient.\"\"\"\n\n    @pytest.fixture\n    def redis_client(self) -> RedisClient:\n        \"\"\"Create a RedisClient instance.\"\"\"\n        return RedisClient(url=\"redis://localhost:6379\")\n\n    @pytest.fixture\n    def mock_aioredis(self) -> MagicMock:\n        \"\"\"Create a mock aioredis client.\"\"\"\n        mock = MagicMock()\n        mock.get = AsyncMock(return_value=\"value\")\n        mock.set = AsyncMock()\n        mock.delete = AsyncMock(return_value=1)\n        mock.exists = AsyncMock(return_value=1)\n        mock.ping = AsyncMock()\n        mock.close = AsyncMock()\n        return mock\n\n    @pytest.mark.anyio\n    async def test_connect(self, redis_client: RedisClient):\n        \"\"\"Test Redis connection.\"\"\"\n        with patch(\"app.clients.redis.aioredis\") as mock_aioredis:\n            mock_client = MagicMock()\n            mock_aioredis.from_url.return_value = mock_client\n\n            await redis_client.connect()\n\n            assert redis_client.client is not None\n            mock_aioredis.from_url.assert_called_once()\n\n    @pytest.mark.anyio\n    async def test_close(self, redis_client: RedisClient, mock_aioredis: MagicMock):\n        \"\"\"Test closing Redis connection.\"\"\"\n        redis_client.client = mock_aioredis\n\n        await redis_client.close()\n\n        mock_aioredis.close.assert_called_once()\n        assert redis_client.client is None\n\n    @pytest.mark.anyio\n    async def test_close_when_not_connected(self, redis_client: RedisClient):\n        \"\"\"Test closing when not connected does nothing.\"\"\"\n        redis_client.client = None\n\n        await redis_client.close()  # Should not raise\n\n    @pytest.mark.anyio\n    async def test_get(self, redis_client: RedisClient, mock_aioredis: MagicMock):\n        \"\"\"Test getting a value.\"\"\"\n        redis_client.client = mock_aioredis\n\n        result = await redis_client.get(\"test_key\")\n\n        assert result == \"value\"\n        mock_aioredis.get.assert_called_once_with(\"test_key\")\n\n    @pytest.mark.anyio\n    async def test_get_not_connected(self, redis_client: RedisClient):\n        \"\"\"Test getting when not connected raises error.\"\"\"\n        redis_client.client = None\n\n        with pytest.raises(RuntimeError, match=\"not connected\"):\n            await redis_client.get(\"test_key\")\n\n    @pytest.mark.anyio\n    async def test_set(self, redis_client: RedisClient, mock_aioredis: MagicMock):\n        \"\"\"Test setting a value.\"\"\"\n        redis_client.client = mock_aioredis\n\n        await redis_client.set(\"test_key\", \"test_value\")\n\n        mock_aioredis.set.assert_called_once_with(\"test_key\", \"test_value\", ex=None)\n\n    @pytest.mark.anyio\n    async def test_set_with_ttl(self, redis_client: RedisClient, mock_aioredis: MagicMock):\n        \"\"\"Test setting a value with TTL.\"\"\"\n        redis_client.client = mock_aioredis\n\n        await redis_client.set(\"test_key\", \"test_value\", ttl=60)\n\n        mock_aioredis.set.assert_called_once_with(\"test_key\", \"test_value\", ex=60)\n\n    @pytest.mark.anyio\n    async def test_set_not_connected(self, redis_client: RedisClient):\n        \"\"\"Test setting when not connected raises error.\"\"\"\n        redis_client.client = None\n\n        with pytest.raises(RuntimeError, match=\"not connected\"):\n            await redis_client.set(\"test_key\", \"test_value\")\n\n    @pytest.mark.anyio\n    async def test_delete(self, redis_client: RedisClient, mock_aioredis: MagicMock):\n        \"\"\"Test deleting a key.\"\"\"\n        redis_client.client = mock_aioredis\n\n        result = await redis_client.delete(\"test_key\")\n\n        assert result == 1\n        mock_aioredis.delete.assert_called_once_with(\"test_key\")\n\n    @pytest.mark.anyio\n    async def test_delete_not_connected(self, redis_client: RedisClient):\n        \"\"\"Test deleting when not connected raises error.\"\"\"\n        redis_client.client = None\n\n        with pytest.raises(RuntimeError, match=\"not connected\"):\n            await redis_client.delete(\"test_key\")\n\n    @pytest.mark.anyio\n    async def test_exists(self, redis_client: RedisClient, mock_aioredis: MagicMock):\n        \"\"\"Test checking if key exists.\"\"\"\n        redis_client.client = mock_aioredis\n\n        result = await redis_client.exists(\"test_key\")\n\n        assert result is True\n        mock_aioredis.exists.assert_called_once_with(\"test_key\")\n\n    @pytest.mark.anyio\n    async def test_exists_not_connected(self, redis_client: RedisClient):\n        \"\"\"Test exists when not connected raises error.\"\"\"\n        redis_client.client = None\n\n        with pytest.raises(RuntimeError, match=\"not connected\"):\n            await redis_client.exists(\"test_key\")\n\n    @pytest.mark.anyio\n    async def test_ping_connected(self, redis_client: RedisClient, mock_aioredis: MagicMock):\n        \"\"\"Test ping when connected.\"\"\"\n        redis_client.client = mock_aioredis\n\n        result = await redis_client.ping()\n\n        assert result is True\n        mock_aioredis.ping.assert_called_once()\n\n    @pytest.mark.anyio\n    async def test_ping_not_connected(self, redis_client: RedisClient):\n        \"\"\"Test ping when not connected returns False.\"\"\"\n        redis_client.client = None\n\n        result = await redis_client.ping()\n\n        assert result is False\n\n    @pytest.mark.anyio\n    async def test_ping_exception(self, redis_client: RedisClient, mock_aioredis: MagicMock):\n        \"\"\"Test ping when exception occurs returns False.\"\"\"\n        redis_client.client = mock_aioredis\n        mock_aioredis.ping = AsyncMock(side_effect=Exception(\"Connection error\"))\n\n        result = await redis_client.ping()\n\n        assert result is False\n\n    def test_raw_property(self, redis_client: RedisClient, mock_aioredis: MagicMock):\n        \"\"\"Test accessing raw client.\"\"\"\n        redis_client.client = mock_aioredis\n\n        result = redis_client.raw\n\n        assert result == mock_aioredis\n\n    def test_raw_property_not_connected(self, redis_client: RedisClient):\n        \"\"\"Test accessing raw client when not connected raises error.\"\"\"\n        redis_client.client = None\n\n        with pytest.raises(RuntimeError, match=\"not connected\"):\n            _ = redis_client.raw\n{%- endif %}\n","backend/tests/test_worker.py":"{%- if cookiecutter.use_celery %}\n\"\"\"Tests for Celery worker tasks.\"\"\"\n\nfrom unittest.mock import MagicMock, patch\n\nimport pytest\n\n\nclass TestExampleTask:\n    \"\"\"Tests for example_task.\"\"\"\n\n    def test_example_task_success(self):\n        \"\"\"Test example_task completes successfully.\"\"\"\n        from app.worker.tasks.examples import example_task\n\n        # Create a mock for self (the task)\n        mock_self = MagicMock()\n        mock_self.request.id = \"test-task-id\"\n\n        with patch(\"app.worker.tasks.examples.time.sleep\"):\n            result = example_task.run(mock_self, \"test message\")\n\n        assert result[\"status\"] == \"completed\"\n        assert \"test message\" in result[\"message\"]\n        assert result[\"task_id\"] == \"test-task-id\"\n\n    def test_example_task_retry_on_error(self):\n        \"\"\"Test example_task retries on error.\"\"\"\n        from app.worker.tasks.examples import example_task\n\n        mock_self = MagicMock()\n        mock_self.request.id = \"test-task-id\"\n        mock_self.request.retries = 0\n\n        with patch(\"app.worker.tasks.examples.time.sleep\", side_effect=Exception(\"Test error\")):\n            mock_self.retry = MagicMock(side_effect=Exception(\"Retry\"))\n            with pytest.raises(Exception, match=\"Retry\"):\n                example_task.run(mock_self, \"test message\")\n            mock_self.retry.assert_called_once()\n\n\nclass TestLongRunningTask:\n    \"\"\"Tests for long_running_task.\"\"\"\n\n    def test_long_running_task_completes(self):\n        \"\"\"Test long_running_task completes with progress.\"\"\"\n        from app.worker.tasks.examples import long_running_task\n\n        mock_self = MagicMock()\n        mock_self.request.id = \"test-task-id\"\n\n        with patch(\"app.worker.tasks.examples.time.sleep\"):\n            result = long_running_task.run(mock_self, duration=3)\n\n        assert result[\"status\"] == \"completed\"\n        assert result[\"duration\"] == 3\n        # Check progress updates were made\n        assert mock_self.update_state.call_count == 3\n\n\nclass TestSendEmailTask:\n    \"\"\"Tests for send_email_task.\"\"\"\n\n    def test_send_email_task_success(self):\n        \"\"\"Test send_email_task sends email.\"\"\"\n        from app.worker.tasks.examples import send_email_task\n\n        with patch(\"app.worker.tasks.examples.time.sleep\"):\n            result = send_email_task(\"test@example.com\", \"Subject\", \"Body\")\n\n        assert result[\"status\"] == \"sent\"\n        assert result[\"to\"] == \"test@example.com\"\n        assert result[\"subject\"] == \"Subject\"\n\n\nclass TestCeleryAppConfiguration:\n    \"\"\"Tests for Celery app configuration.\"\"\"\n\n    def test_celery_app_exists(self):\n        \"\"\"Test Celery app is configured.\"\"\"\n        from app.worker.celery_app import celery_app\n\n        assert celery_app is not None\n        assert celery_app.main == \"{{ cookiecutter.project_slug }}\"\n{%- endif %}\n","backend/tests/test_commands.py":"\"\"\"Tests for CLI commands module.\"\"\"\n\nimport click\nfrom click.testing import CliRunner\n\nfrom app.commands import (\n    command,\n    discover_commands,\n    error,\n    info,\n    register_commands,\n    success,\n    warning,\n)\n\n\nclass TestCommandDecorator:\n    \"\"\"Tests for the command decorator.\"\"\"\n\n    def test_command_registers_function(self):\n        \"\"\"Test that @command decorator registers a click command.\"\"\"\n        from app.commands import _commands\n\n        initial_count = len(_commands)\n\n        @command(\"test-cmd\", help=\"Test command\")\n        def test_func():\n            pass\n\n        assert len(_commands) == initial_count + 1\n        assert _commands[-1].name == \"test-cmd\"\n\n    def test_command_uses_function_name_as_default(self):\n        \"\"\"Test that command name defaults to function name.\"\"\"\n        from app.commands import _commands\n\n        @command()\n        def my_test_command():\n            pass\n\n        assert _commands[-1].name == \"my-test-command\"\n\n\nclass TestHelperFunctions:\n    \"\"\"Tests for helper output functions.\"\"\"\n\n    def test_success_prints_green(self, capsys):\n        \"\"\"Test success prints in green.\"\"\"\n        success(\"Test message\")\n        # Click uses escape codes for colors\n        captured = capsys.readouterr()\n        assert \"Test message\" in captured.out\n\n    def test_error_prints_red(self, capsys):\n        \"\"\"Test error prints in red.\"\"\"\n        error(\"Error message\")\n        captured = capsys.readouterr()\n        assert \"Error message\" in captured.out\n\n    def test_warning_prints_yellow(self, capsys):\n        \"\"\"Test warning prints in yellow.\"\"\"\n        warning(\"Warning message\")\n        captured = capsys.readouterr()\n        assert \"Warning message\" in captured.out\n\n    def test_info_prints_plain(self, capsys):\n        \"\"\"Test info prints plain text.\"\"\"\n        info(\"Info message\")\n        captured = capsys.readouterr()\n        assert \"Info message\" in captured.out\n\n\nclass TestDiscoverCommands:\n    \"\"\"Tests for command discovery.\"\"\"\n\n    def test_discover_commands_returns_list(self):\n        \"\"\"Test that discover_commands returns a list.\"\"\"\n        commands = discover_commands()\n        assert isinstance(commands, list)\n\n    def test_discover_commands_caches_results(self):\n        \"\"\"Test that discover_commands caches on second call.\"\"\"\n        commands1 = discover_commands()\n        commands2 = discover_commands()\n        assert commands1 is commands2\n\n\nclass TestRegisterCommands:\n    \"\"\"Tests for registering commands.\"\"\"\n\n    def test_register_commands_adds_to_group(self):\n        \"\"\"Test that register_commands adds discovered commands to CLI group.\"\"\"\n        @click.group()\n        def cli():\n            pass\n\n        register_commands(cli)\n        # After registration, cli should have commands\n        # We can't assert exact count since it depends on what's discovered\n\n\n{%- if cookiecutter.use_database %}\n\n\nclass TestSeedCommand:\n    \"\"\"Tests for the seed command.\"\"\"\n\n    def test_seed_dry_run(self):\n        \"\"\"Test seed command with --dry-run.\"\"\"\n        from app.commands.seed import seed\n\n        runner = CliRunner()\n        result = runner.invoke(seed, [\"--dry-run\", \"--count\", \"5\"])\n        assert result.exit_code == 0\n        assert \"[DRY RUN]\" in result.output\n        assert \"5\" in result.output\n\n    def test_seed_dry_run_with_clear(self):\n        \"\"\"Test seed command with --dry-run and --clear.\"\"\"\n        from app.commands.seed import seed\n\n        runner = CliRunner()\n        result = runner.invoke(seed, [\"--dry-run\", \"--clear\"])\n        assert result.exit_code == 0\n        assert \"Would clear existing data\" in result.output\n{%- endif %}\n\n\nclass TestHelloCommand:\n    \"\"\"Tests for the hello command.\"\"\"\n\n    def test_hello_command_runs(self):\n        \"\"\"Test hello command executes.\"\"\"\n        from app.commands.example import hello\n\n        runner = CliRunner()\n        result = runner.invoke(hello)\n        assert result.exit_code == 0\n        assert \"Hello\" in result.output\n\n    def test_hello_command_with_name(self):\n        \"\"\"Test hello command with --name option.\"\"\"\n        from app.commands.example import hello\n\n        runner = CliRunner()\n        result = runner.invoke(hello, [\"--name\", \"Alice\"])\n        assert result.exit_code == 0\n        assert \"Alice\" in result.output\n\n\n{%- if cookiecutter.use_database %}\n\n\nclass TestCleanupCommand:\n    \"\"\"Tests for the cleanup command.\"\"\"\n\n    def test_cleanup_dry_run(self):\n        \"\"\"Test cleanup command with --dry-run.\"\"\"\n        from app.commands.cleanup import cleanup\n\n        runner = CliRunner()\n        result = runner.invoke(cleanup, [\"--dry-run\"])\n        assert result.exit_code == 0\n        assert \"[DRY RUN]\" in result.output\n\n    def test_cleanup_with_days_option(self):\n        \"\"\"Test cleanup command with --days option.\"\"\"\n        from app.commands.cleanup import cleanup\n\n        runner = CliRunner()\n        result = runner.invoke(cleanup, [\"--dry-run\", \"--days\", \"7\"])\n        assert result.exit_code == 0\n{%- endif %}\n","backend/tests/api/test_metrics.py":"{%- if cookiecutter.enable_prometheus %}\n\"\"\"Prometheus metrics endpoint tests.\"\"\"\n\nimport pytest\nfrom httpx import AsyncClient\n\nfrom app.core.config import settings\n\n\n@pytest.mark.anyio\nasync def test_metrics_endpoint(client: AsyncClient):\n    \"\"\"Test that /metrics endpoint returns Prometheus metrics.\"\"\"\n    response = await client.get(settings.PROMETHEUS_METRICS_PATH)\n    assert response.status_code == 200\n    assert response.headers[\"content-type\"].startswith(\"text/plain\")\n\n    # Check for standard prometheus-fastapi-instrumentator metrics\n    content = response.text\n    assert \"http_requests_total\" in content\n    assert \"http_request_duration_seconds\" in content\n\n\n@pytest.mark.anyio\nasync def test_metrics_increments_on_request(client: AsyncClient):\n    \"\"\"Test that metrics are incremented after making requests.\"\"\"\n    # Make a health check request first\n    await client.get(f\"{settings.API_V1_STR}/health\")\n\n    # Then check metrics\n    response = await client.get(settings.PROMETHEUS_METRICS_PATH)\n    assert response.status_code == 200\n\n    content = response.text\n    # Should have recorded the health check request\n    assert \"http_requests_total\" in content\n\n\n@pytest.mark.anyio\nasync def test_metrics_excluded_from_own_metrics(client: AsyncClient):\n    \"\"\"Test that /metrics endpoint doesn't count itself in metrics.\"\"\"\n    # Make multiple requests to /metrics\n    for _ in range(3):\n        await client.get(settings.PROMETHEUS_METRICS_PATH)\n\n    response = await client.get(settings.PROMETHEUS_METRICS_PATH)\n    content = response.text\n\n    # The /metrics endpoint should be excluded from instrumentation\n    # so we shouldn't see it in the metrics path labels\n    assert f'path=\"{settings.PROMETHEUS_METRICS_PATH}\"' not in content\n{%- else %}\n# Prometheus metrics are not enabled for this project\n{%- endif %}\n","backend/tests/api/test_auth.py":"{%- if cookiecutter.use_jwt %}\n# ruff: noqa: I001 - Imports structured for Jinja2 template conditionals\n\"\"\"Tests for authentication routes.\"\"\"\n\nfrom datetime import UTC, datetime\nfrom unittest.mock import AsyncMock, MagicMock\nfrom uuid import uuid4\n\nimport pytest\nfrom httpx import AsyncClient\n\nfrom app.api.deps import get_user_service\nfrom app.core.config import settings\nfrom app.core.security import create_access_token, create_refresh_token\nfrom app.main import app\n\n\nclass MockUser:\n    \"\"\"Mock user for testing.\"\"\"\n\n    def __init__(\n        self,\n        id=None,\n        email=\"test@example.com\",\n        full_name=\"Test User\",\n        is_active=True,\n        is_superuser=False,\n    ):\n        self.id = id or uuid4()\n        self.email = email\n        self.full_name = full_name\n        self.is_active = is_active\n        self.is_superuser = is_superuser\n        self.hashed_password = \"hashed\"\n        self.created_at = datetime.now(UTC)\n        self.updated_at = datetime.now(UTC)\n\n\n@pytest.fixture\ndef mock_user() -> MockUser:\n    \"\"\"Create a mock user.\"\"\"\n    return MockUser()\n\n\n@pytest.fixture\ndef mock_user_service(mock_user: MockUser) -> MagicMock:\n    \"\"\"Create a mock user service.\"\"\"\n    service = MagicMock()\n    service.authenticate = AsyncMock(return_value=mock_user)\n    service.register = AsyncMock(return_value=mock_user)\n    service.get_by_id = AsyncMock(return_value=mock_user)\n    service.get_by_email = AsyncMock(return_value=mock_user)\n    return service\n\n\n@pytest.fixture\nasync def client_with_mock_service(\n    mock_user_service: MagicMock,\n{%- if cookiecutter.enable_redis %}\n    mock_redis: MagicMock,\n{%- endif %}\n{%- if cookiecutter.use_database %}\n    mock_db_session,\n{%- endif %}\n) -> AsyncClient:\n    \"\"\"Client with mocked user service.\"\"\"\n{%- if cookiecutter.enable_redis %}\n    from app.api.deps import get_redis\n{%- endif %}\n{%- if cookiecutter.use_database %}\n    from app.api.deps import get_db_session\n{%- endif %}\n    from httpx import ASGITransport\n\n    app.dependency_overrides[get_user_service] = lambda: mock_user_service\n{%- if cookiecutter.enable_redis %}\n    app.dependency_overrides[get_redis] = lambda: mock_redis\n{%- endif %}\n{%- if cookiecutter.use_database %}\n    app.dependency_overrides[get_db_session] = lambda: mock_db_session\n{%- endif %}\n\n    async with AsyncClient(\n        transport=ASGITransport(app=app),\n        base_url=\"http://test\",\n    ) as ac:\n        yield ac\n\n    app.dependency_overrides.clear()\n\n\n@pytest.mark.anyio\nasync def test_login_success(client_with_mock_service: AsyncClient):\n    \"\"\"Test successful login.\"\"\"\n    response = await client_with_mock_service.post(\n        f\"{settings.API_V1_STR}/auth/login\",\n        data={\"username\": \"test@example.com\", \"password\": \"password123\"},\n    )\n    assert response.status_code == 200\n    data = response.json()\n    assert \"access_token\" in data\n    assert \"refresh_token\" in data\n    assert data[\"token_type\"] == \"bearer\"\n\n\n@pytest.mark.anyio\nasync def test_login_invalid_credentials(\n    client_with_mock_service: AsyncClient,\n    mock_user_service: MagicMock,\n):\n    \"\"\"Test login with invalid credentials.\"\"\"\n    from app.core.exceptions import AuthenticationError\n\n    mock_user_service.authenticate = AsyncMock(\n        side_effect=AuthenticationError(message=\"Invalid credentials\")\n    )\n\n    response = await client_with_mock_service.post(\n        f\"{settings.API_V1_STR}/auth/login\",\n        data={\"username\": \"test@example.com\", \"password\": \"wrongpassword\"},\n    )\n    assert response.status_code == 401\n\n\n@pytest.mark.anyio\nasync def test_register_success(client_with_mock_service: AsyncClient):\n    \"\"\"Test successful registration.\"\"\"\n    response = await client_with_mock_service.post(\n        f\"{settings.API_V1_STR}/auth/register\",\n        json={\n            \"email\": \"new@example.com\",\n            \"password\": \"password123\",\n            \"full_name\": \"New User\",\n        },\n    )\n    assert response.status_code == 201\n    data = response.json()\n    assert data[\"email\"] == \"test@example.com\"  # From mock\n\n\n@pytest.mark.anyio\nasync def test_register_duplicate_email(\n    client_with_mock_service: AsyncClient,\n    mock_user_service: MagicMock,\n):\n    \"\"\"Test registration with duplicate email.\"\"\"\n    from app.core.exceptions import AlreadyExistsError\n\n    mock_user_service.register = AsyncMock(\n        side_effect=AlreadyExistsError(message=\"Email already registered\")\n    )\n\n    response = await client_with_mock_service.post(\n        f\"{settings.API_V1_STR}/auth/register\",\n        json={\n            \"email\": \"existing@example.com\",\n            \"password\": \"password123\",\n            \"full_name\": \"Test User\",\n        },\n    )\n    assert response.status_code == 409\n\n\n@pytest.mark.anyio\nasync def test_refresh_token_success(\n    client_with_mock_service: AsyncClient,\n    mock_user: MockUser,\n):\n    \"\"\"Test successful token refresh.\"\"\"\n    refresh_token = create_refresh_token(subject=str(mock_user.id))\n\n    response = await client_with_mock_service.post(\n        f\"{settings.API_V1_STR}/auth/refresh\",\n        json={\"refresh_token\": refresh_token},\n    )\n    assert response.status_code == 200\n    data = response.json()\n    assert \"access_token\" in data\n    assert \"refresh_token\" in data\n\n\n@pytest.mark.anyio\nasync def test_refresh_token_invalid(client_with_mock_service: AsyncClient):\n    \"\"\"Test refresh with invalid token.\"\"\"\n    response = await client_with_mock_service.post(\n        f\"{settings.API_V1_STR}/auth/refresh\",\n        json={\"refresh_token\": \"invalid.token.here\"},\n    )\n    assert response.status_code == 401\n\n\n@pytest.mark.anyio\nasync def test_refresh_token_wrong_type(\n    client_with_mock_service: AsyncClient,\n    mock_user: MockUser,\n):\n    \"\"\"Test refresh with access token instead of refresh token.\"\"\"\n    access_token = create_access_token(subject=str(mock_user.id))\n\n    response = await client_with_mock_service.post(\n        f\"{settings.API_V1_STR}/auth/refresh\",\n        json={\"refresh_token\": access_token},\n    )\n    assert response.status_code == 401\n\n\n@pytest.mark.anyio\nasync def test_refresh_token_inactive_user(\n    client_with_mock_service: AsyncClient,\n    mock_user_service: MagicMock,\n):\n    \"\"\"Test refresh token for inactive user.\"\"\"\n    inactive_user = MockUser(is_active=False)\n    mock_user_service.get_by_id = AsyncMock(return_value=inactive_user)\n    refresh_token = create_refresh_token(subject=str(inactive_user.id))\n\n    response = await client_with_mock_service.post(\n        f\"{settings.API_V1_STR}/auth/refresh\",\n        json={\"refresh_token\": refresh_token},\n    )\n    assert response.status_code == 401\n\n\n@pytest.mark.anyio\nasync def test_get_current_user(\n    client_with_mock_service: AsyncClient,\n    mock_user: MockUser,\n    mock_user_service: MagicMock,\n):\n    \"\"\"Test getting current user info.\"\"\"\n    from app.api.deps import get_current_user\n\n    # Override get_current_user to return mock user\n    app.dependency_overrides[get_current_user] = lambda: mock_user\n\n    response = await client_with_mock_service.get(\n        f\"{settings.API_V1_STR}/auth/me\",\n    )\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"email\"] == mock_user.email\n{%- endif %}\n","backend/tests/api/test_exceptions.py":"\"\"\"Exception handler tests.\"\"\"\n{%- if cookiecutter.use_jwt or cookiecutter.use_api_key %}\n# ruff: noqa: I001, E402 - Imports structured for Jinja2 template conditionals\n{%- endif %}\n\nimport pytest\nfrom httpx import AsyncClient\n\nfrom app.core.config import settings\n\n\n@pytest.mark.anyio\nasync def test_not_found_error_format(client: AsyncClient):\n    \"\"\"Test that 404 errors return proper JSON format.\"\"\"\n    response = await client.get(f\"{settings.API_V1_STR}/nonexistent-endpoint\")\n    assert response.status_code == 404\n    # FastAPI returns 404 for unknown routes\n\n\n{%- if cookiecutter.use_jwt %}\n\nfrom unittest.mock import AsyncMock, MagicMock\n\nfrom httpx import ASGITransport\n\n{%- if cookiecutter.enable_redis %}\nfrom app.api.deps import get_redis\n{%- endif %}\n{%- if cookiecutter.use_database %}\nfrom app.api.deps import get_db_session\n{%- endif %}\nfrom app.main import app\n\n\n@pytest.mark.anyio\nasync def test_authentication_error_returns_401(client: AsyncClient):\n    \"\"\"Test that authentication errors return 401 with proper headers.\"\"\"\n    response = await client.get(\n        f\"{settings.API_V1_STR}/users/me\",\n        headers={\"Authorization\": \"Bearer invalid-token\"},\n    )\n    assert response.status_code == 401\n    assert \"WWW-Authenticate\" in response.headers\n\n\n@pytest.mark.anyio\nasync def test_missing_auth_returns_401(client: AsyncClient):\n    \"\"\"Test that missing authentication returns 401.\"\"\"\n    response = await client.get(f\"{settings.API_V1_STR}/users/me\")\n    assert response.status_code == 401\n\n\n@pytest.fixture\ndef mock_user_service_with_errors() -> MagicMock:\n    \"\"\"Create mock user service that raises errors.\"\"\"\n    from app.core.exceptions import AlreadyExistsError, AuthenticationError\n\n    service = MagicMock()\n    service.register = AsyncMock(\n        side_effect=AlreadyExistsError(message=\"Email already registered\")\n    )\n    service.authenticate = AsyncMock(\n        side_effect=AuthenticationError(message=\"Invalid credentials\")\n    )\n    return service\n\n\n@pytest.fixture\nasync def error_client(\n    mock_user_service_with_errors: MagicMock,\n{%- if cookiecutter.enable_redis %}\n    mock_redis: MagicMock,\n{%- endif %}\n{%- if cookiecutter.use_database %}\n    mock_db_session,\n{%- endif %}\n) -> AsyncClient:\n    \"\"\"Client with mocked services that raise errors.\"\"\"\n    from app.api.deps import get_user_service\n\n    app.dependency_overrides[get_user_service] = lambda: mock_user_service_with_errors\n{%- if cookiecutter.enable_redis %}\n    app.dependency_overrides[get_redis] = lambda: mock_redis\n{%- endif %}\n{%- if cookiecutter.use_database %}\n    app.dependency_overrides[get_db_session] = lambda: mock_db_session\n{%- endif %}\n\n    async with AsyncClient(\n        transport=ASGITransport(app=app),\n        base_url=\"http://test\",\n    ) as ac:\n        yield ac\n\n    app.dependency_overrides.clear()\n\n\n@pytest.mark.anyio\nasync def test_register_duplicate_email_returns_409(error_client: AsyncClient):\n    \"\"\"Test that registering with existing email returns 409.\"\"\"\n    response = await error_client.post(\n        f\"{settings.API_V1_STR}/auth/register\",\n        json={\n            \"email\": \"existing@example.com\",\n            \"password\": \"password123\",\n            \"full_name\": \"Test User\",\n        },\n    )\n    assert response.status_code == 409\n    data = response.json()\n    assert \"error\" in data\n    assert data[\"error\"][\"code\"] == \"ALREADY_EXISTS\"\n\n\n@pytest.mark.anyio\nasync def test_invalid_login_returns_401(error_client: AsyncClient):\n    \"\"\"Test that invalid login credentials return 401.\"\"\"\n    response = await error_client.post(\n        f\"{settings.API_V1_STR}/auth/login\",\n        data={\n            \"username\": \"nonexistent@example.com\",\n            \"password\": \"wrongpassword\",\n        },\n    )\n    assert response.status_code == 401\n    data = response.json()\n    assert \"error\" in data\n    assert data[\"error\"][\"code\"] == \"AUTHENTICATION_ERROR\"\n{%- endif %}\n\n\n{%- if cookiecutter.use_api_key %}\n\n\n@pytest.mark.anyio\nasync def test_missing_api_key_returns_401(client: AsyncClient):\n    \"\"\"Test that missing API key returns 401.\"\"\"\n    # Health endpoint might not require auth, but we test the middleware\n    # For endpoints that require API key, they should return 401\n    await client.get(f\"{settings.API_V1_STR}/health\")\n\n\n@pytest.mark.anyio\nasync def test_invalid_api_key_returns_403(client: AsyncClient):\n    \"\"\"Test that invalid API key returns 403.\"\"\"\n    # Health endpoint might not require auth\n    await client.get(\n        f\"{settings.API_V1_STR}/health\",\n        headers={settings.API_KEY_HEADER: \"invalid-key\"},\n    )\n{%- endif %}\n","backend/tests/api/__init__.py":"\"\"\"API tests package.\"\"\"\n","backend/tests/api/test_items.py":"{%- if cookiecutter.include_example_crud and cookiecutter.use_database %}\n\"\"\"Tests for items CRUD routes.\n\nThis module demonstrates testing patterns for CRUD endpoints.\nYou can use it as a template for testing your own endpoints.\n\"\"\"\n\nfrom datetime import UTC, datetime\nfrom unittest.mock import AsyncMock, MagicMock\nfrom uuid import uuid4\n\nimport pytest\nfrom httpx import AsyncClient\n\nfrom app.core.config import settings\nfrom app.main import app\n\n\nclass MockItem:\n    \"\"\"Mock item for testing.\"\"\"\n\n    def __init__(\n        self,\n        id=None,\n        title=\"Test Item\",\n        description=\"Test Description\",\n        is_active=True,\n    ):\n{%- if cookiecutter.use_postgresql %}\n        self.id = id or uuid4()\n{%- else %}\n        self.id = id or str(uuid4())\n{%- endif %}\n        self.title = title\n        self.description = description\n        self.is_active = is_active\n        self.created_at = datetime.now(UTC)\n        self.updated_at = None\n\n\n@pytest.fixture\ndef mock_item() -> MockItem:\n    \"\"\"Create a mock item.\"\"\"\n    return MockItem()\n\n\n@pytest.fixture\ndef mock_items() -> list[MockItem]:\n    \"\"\"Create multiple mock items.\"\"\"\n    return [\n        MockItem(title=\"Item 1\", description=\"First item\"),\n        MockItem(title=\"Item 2\", description=\"Second item\"),\n        MockItem(title=\"Item 3\", description=\"Third item\"),\n    ]\n\n\n@pytest.fixture\ndef mock_item_service(mock_item: MockItem, mock_items: list[MockItem]) -> MagicMock:\n    \"\"\"Create a mock item service.\"\"\"\n    service = MagicMock()\n{%- if cookiecutter.use_postgresql or cookiecutter.use_mongodb %}\n    service.get_by_id = AsyncMock(return_value=mock_item)\n    service.get_multi = AsyncMock(return_value=mock_items)\n    service.create = AsyncMock(return_value=mock_item)\n    service.update = AsyncMock(return_value=mock_item)\n    service.delete = AsyncMock(return_value=mock_item)\n{%- elif cookiecutter.use_sqlite %}\n    service.get_by_id = MagicMock(return_value=mock_item)\n    service.get_multi = MagicMock(return_value=mock_items)\n    service.create = MagicMock(return_value=mock_item)\n    service.update = MagicMock(return_value=mock_item)\n    service.delete = MagicMock(return_value=mock_item)\n{%- endif %}\n    return service\n\n\n@pytest.fixture\nasync def client_with_mock_service(\n    mock_item_service: MagicMock,\n{%- if cookiecutter.use_database %}\n    mock_db_session,\n{%- endif %}\n) -> AsyncClient:\n    \"\"\"Client with mocked item service.\"\"\"\n    from httpx import ASGITransport\n\n    from app.api.deps import get_item_service\n{%- if cookiecutter.use_database %}\n    from app.db.session import get_db_session\n{%- endif %}\n\n    app.dependency_overrides[get_item_service] = lambda db=None: mock_item_service\n{%- if cookiecutter.use_database %}\n    app.dependency_overrides[get_db_session] = lambda: mock_db_session\n{%- endif %}\n\n    async with AsyncClient(\n        transport=ASGITransport(app=app),\n        base_url=\"http://test\",\n    ) as ac:\n        yield ac\n\n    app.dependency_overrides.clear()\n\n\n@pytest.mark.anyio\nasync def test_create_item_success(client_with_mock_service: AsyncClient):\n    \"\"\"Test successful item creation.\"\"\"\n    response = await client_with_mock_service.post(\n        f\"{settings.API_V1_STR}/items\",\n        json={\"title\": \"New Item\", \"description\": \"A new item\"},\n    )\n    assert response.status_code == 201\n    data = response.json()\n    assert data[\"title\"] == \"Test Item\"  # From mock\n\n\n@pytest.mark.anyio\nasync def test_create_item_minimal(client_with_mock_service: AsyncClient):\n    \"\"\"Test item creation with minimal data (only required fields).\"\"\"\n    response = await client_with_mock_service.post(\n        f\"{settings.API_V1_STR}/items\",\n        json={\"title\": \"Minimal Item\"},\n    )\n    assert response.status_code == 201\n\n\n@pytest.mark.anyio\nasync def test_create_item_validation_error(client_with_mock_service: AsyncClient):\n    \"\"\"Test item creation with invalid data.\"\"\"\n    response = await client_with_mock_service.post(\n        f\"{settings.API_V1_STR}/items\",\n        json={},  # Missing required 'title' field\n    )\n    assert response.status_code == 422\n\n\n@pytest.mark.anyio\nasync def test_get_item_success(\n    client_with_mock_service: AsyncClient,\n    mock_item: MockItem,\n):\n    \"\"\"Test successful item retrieval.\"\"\"\n    response = await client_with_mock_service.get(\n        f\"{settings.API_V1_STR}/items/{mock_item.id}\",\n    )\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"title\"] == mock_item.title\n    assert data[\"description\"] == mock_item.description\n\n\n@pytest.mark.anyio\nasync def test_get_item_not_found(\n    client_with_mock_service: AsyncClient,\n    mock_item_service: MagicMock,\n):\n    \"\"\"Test item retrieval when item doesn't exist.\"\"\"\n    from app.core.exceptions import NotFoundError\n\n{%- if cookiecutter.use_postgresql or cookiecutter.use_mongodb %}\n    mock_item_service.get_by_id = AsyncMock(\n        side_effect=NotFoundError(message=\"Item not found\")\n    )\n{%- elif cookiecutter.use_sqlite %}\n    mock_item_service.get_by_id = MagicMock(\n        side_effect=NotFoundError(message=\"Item not found\")\n    )\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\n    response = await client_with_mock_service.get(\n        f\"{settings.API_V1_STR}/items/{uuid4()}\",\n    )\n{%- else %}\n    response = await client_with_mock_service.get(\n        f\"{settings.API_V1_STR}/items/nonexistent-id\",\n    )\n{%- endif %}\n    assert response.status_code == 404\n\n\n{%- if not cookiecutter.enable_pagination %}\n\n\n@pytest.mark.anyio\nasync def test_list_items_success(\n    client_with_mock_service: AsyncClient,\n    mock_items: list[MockItem],\n):\n    \"\"\"Test successful item listing.\"\"\"\n    response = await client_with_mock_service.get(\n        f\"{settings.API_V1_STR}/items\",\n    )\n    assert response.status_code == 200\n    data = response.json()\n    assert len(data) == len(mock_items)\n\n\n@pytest.mark.anyio\nasync def test_list_items_pagination(client_with_mock_service: AsyncClient):\n    \"\"\"Test item listing with pagination parameters.\"\"\"\n    response = await client_with_mock_service.get(\n        f\"{settings.API_V1_STR}/items?skip=0&limit=10\",\n    )\n    assert response.status_code == 200\n{%- endif %}\n\n\n@pytest.mark.anyio\nasync def test_update_item_success(\n    client_with_mock_service: AsyncClient,\n    mock_item: MockItem,\n):\n    \"\"\"Test successful item update.\"\"\"\n    response = await client_with_mock_service.patch(\n        f\"{settings.API_V1_STR}/items/{mock_item.id}\",\n        json={\"title\": \"Updated Title\"},\n    )\n    assert response.status_code == 200\n\n\n@pytest.mark.anyio\nasync def test_update_item_partial(\n    client_with_mock_service: AsyncClient,\n    mock_item: MockItem,\n):\n    \"\"\"Test partial item update (only some fields).\"\"\"\n    response = await client_with_mock_service.patch(\n        f\"{settings.API_V1_STR}/items/{mock_item.id}\",\n        json={\"is_active\": False},\n    )\n    assert response.status_code == 200\n\n\n@pytest.mark.anyio\nasync def test_update_item_not_found(\n    client_with_mock_service: AsyncClient,\n    mock_item_service: MagicMock,\n):\n    \"\"\"Test item update when item doesn't exist.\"\"\"\n    from app.core.exceptions import NotFoundError\n\n{%- if cookiecutter.use_postgresql or cookiecutter.use_mongodb %}\n    mock_item_service.update = AsyncMock(\n        side_effect=NotFoundError(message=\"Item not found\")\n    )\n{%- elif cookiecutter.use_sqlite %}\n    mock_item_service.update = MagicMock(\n        side_effect=NotFoundError(message=\"Item not found\")\n    )\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\n    response = await client_with_mock_service.patch(\n        f\"{settings.API_V1_STR}/items/{uuid4()}\",\n        json={\"title\": \"Updated\"},\n    )\n{%- else %}\n    response = await client_with_mock_service.patch(\n        f\"{settings.API_V1_STR}/items/nonexistent-id\",\n        json={\"title\": \"Updated\"},\n    )\n{%- endif %}\n    assert response.status_code == 404\n\n\n@pytest.mark.anyio\nasync def test_delete_item_success(\n    client_with_mock_service: AsyncClient,\n    mock_item: MockItem,\n):\n    \"\"\"Test successful item deletion.\"\"\"\n    response = await client_with_mock_service.delete(\n        f\"{settings.API_V1_STR}/items/{mock_item.id}\",\n    )\n    assert response.status_code == 204\n\n\n@pytest.mark.anyio\nasync def test_delete_item_not_found(\n    client_with_mock_service: AsyncClient,\n    mock_item_service: MagicMock,\n):\n    \"\"\"Test item deletion when item doesn't exist.\"\"\"\n    from app.core.exceptions import NotFoundError\n\n{%- if cookiecutter.use_postgresql or cookiecutter.use_mongodb %}\n    mock_item_service.delete = AsyncMock(\n        side_effect=NotFoundError(message=\"Item not found\")\n    )\n{%- elif cookiecutter.use_sqlite %}\n    mock_item_service.delete = MagicMock(\n        side_effect=NotFoundError(message=\"Item not found\")\n    )\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\n    response = await client_with_mock_service.delete(\n        f\"{settings.API_V1_STR}/items/{uuid4()}\",\n    )\n{%- else %}\n    response = await client_with_mock_service.delete(\n        f\"{settings.API_V1_STR}/items/nonexistent-id\",\n    )\n{%- endif %}\n    assert response.status_code == 404\n{%- else %}\n\"\"\"Item tests - not configured (example CRUD disabled or no database).\"\"\"\n{%- endif %}\n","backend/tests/api/test_users.py":"{%- if cookiecutter.use_jwt %}\n\"\"\"Tests for user routes.\"\"\"\n{%- if cookiecutter.use_database or cookiecutter.enable_redis %}\n# ruff: noqa: I001 - Imports structured for Jinja2 template conditionals\n{%- endif %}\n\nfrom datetime import UTC, datetime\nfrom unittest.mock import AsyncMock, MagicMock\nfrom uuid import uuid4\n\nimport pytest\nfrom httpx import ASGITransport, AsyncClient\n\nfrom app.api.deps import get_current_active_superuser, get_current_user, get_user_service\n{%- if cookiecutter.use_database %}\nfrom app.api.deps import get_db_session\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\nfrom app.api.deps import get_redis\n{%- endif %}\nfrom app.core.config import settings\nfrom app.main import app\n\n\nclass MockUser:\n    \"\"\"Mock user for testing.\"\"\"\n\n    def __init__(\n        self,\n        id=None,\n        email=\"test@example.com\",\n        full_name=\"Test User\",\n        is_active=True,\n        is_superuser=False,\n        role=\"admin\",\n    ):\n{%- if cookiecutter.use_postgresql %}\n        self.id = id or uuid4()\n{%- else %}\n        self.id = id or str(uuid4())\n{%- endif %}\n        self.email = email\n        self.full_name = full_name\n        self.is_active = is_active\n        self.is_superuser = is_superuser\n        self.role = role\n        self.hashed_password = \"hashed\"\n        self.created_at = datetime.now(UTC)\n        self.updated_at = datetime.now(UTC)\n\n    def has_role(self, role) -> bool:\n        \"\"\"Check if user has the specified role.\"\"\"\n        if hasattr(role, \"value\"):\n            return self.role == role.value\n        return self.role == role\n\n\n@pytest.fixture\ndef mock_user() -> MockUser:\n    \"\"\"Create a mock regular user.\"\"\"\n    return MockUser()\n\n\n@pytest.fixture\ndef mock_superuser() -> MockUser:\n    \"\"\"Create a mock superuser.\"\"\"\n    return MockUser(is_superuser=True, email=\"admin@example.com\")\n\n\n@pytest.fixture\ndef mock_user_service(mock_user: MockUser) -> MagicMock:\n    \"\"\"Create a mock user service.\"\"\"\n    service = MagicMock()\n    service.get_by_id = AsyncMock(return_value=mock_user)\n    service.get_multi = AsyncMock(return_value=[mock_user])\n    service.update = AsyncMock(return_value=mock_user)\n    service.delete = AsyncMock(return_value=mock_user)\n    return service\n\n\n@pytest.fixture\nasync def auth_client(\n    mock_user: MockUser,\n    mock_user_service: MagicMock,\n{%- if cookiecutter.enable_redis %}\n    mock_redis: MagicMock,\n{%- endif %}\n{%- if cookiecutter.use_database %}\n    mock_db_session,\n{%- endif %}\n) -> AsyncClient:\n    \"\"\"Client with authenticated regular user.\"\"\"\n    app.dependency_overrides[get_current_user] = lambda: mock_user\n    app.dependency_overrides[get_user_service] = lambda: mock_user_service\n{%- if cookiecutter.enable_redis %}\n    app.dependency_overrides[get_redis] = lambda: mock_redis\n{%- endif %}\n{%- if cookiecutter.use_database %}\n    app.dependency_overrides[get_db_session] = lambda: mock_db_session\n{%- endif %}\n\n    async with AsyncClient(\n        transport=ASGITransport(app=app),\n        base_url=\"http://test\",\n    ) as ac:\n        yield ac\n\n    app.dependency_overrides.clear()\n\n\n@pytest.fixture\nasync def superuser_client(\n    mock_superuser: MockUser,\n    mock_user_service: MagicMock,\n{%- if cookiecutter.enable_redis %}\n    mock_redis: MagicMock,\n{%- endif %}\n{%- if cookiecutter.use_database %}\n    mock_db_session,\n{%- endif %}\n) -> AsyncClient:\n    \"\"\"Client with authenticated superuser.\"\"\"\n    app.dependency_overrides[get_current_user] = lambda: mock_superuser\n    app.dependency_overrides[get_current_active_superuser] = lambda: mock_superuser\n    app.dependency_overrides[get_user_service] = lambda: mock_user_service\n{%- if cookiecutter.enable_redis %}\n    app.dependency_overrides[get_redis] = lambda: mock_redis\n{%- endif %}\n{%- if cookiecutter.use_database %}\n    app.dependency_overrides[get_db_session] = lambda: mock_db_session\n{%- endif %}\n\n    async with AsyncClient(\n        transport=ASGITransport(app=app),\n        base_url=\"http://test\",\n    ) as ac:\n        yield ac\n\n    app.dependency_overrides.clear()\n\n\n@pytest.mark.anyio\nasync def test_read_current_user(auth_client: AsyncClient, mock_user: MockUser):\n    \"\"\"Test getting current user.\"\"\"\n    response = await auth_client.get(f\"{settings.API_V1_STR}/users/me\")\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"email\"] == mock_user.email\n\n\n@pytest.mark.anyio\nasync def test_update_current_user(auth_client: AsyncClient, mock_user_service: MagicMock):\n    \"\"\"Test updating current user.\"\"\"\n    response = await auth_client.patch(\n        f\"{settings.API_V1_STR}/users/me\",\n        json={\"full_name\": \"Updated Name\"},\n    )\n    assert response.status_code == 200\n    mock_user_service.update.assert_called_once()\n\n\n{%- if not cookiecutter.enable_pagination %}\n\n\n@pytest.mark.anyio\nasync def test_read_users_superuser(superuser_client: AsyncClient, mock_user_service: MagicMock):\n    \"\"\"Test getting all users as superuser.\"\"\"\n    response = await superuser_client.get(f\"{settings.API_V1_STR}/users\")\n    assert response.status_code == 200\n    data = response.json()\n    assert isinstance(data, list)\n{%- endif %}\n\n\n@pytest.mark.anyio\nasync def test_read_user_by_id(\n    superuser_client: AsyncClient,\n    mock_user: MockUser,\n    mock_user_service: MagicMock,\n):\n    \"\"\"Test getting user by ID as superuser.\"\"\"\n    response = await superuser_client.get(\n        f\"{settings.API_V1_STR}/users/{mock_user.id}\"\n    )\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"email\"] == mock_user.email\n\n\n@pytest.mark.anyio\nasync def test_read_user_by_id_not_found(\n    superuser_client: AsyncClient,\n    mock_user_service: MagicMock,\n):\n    \"\"\"Test getting non-existent user.\"\"\"\n    from app.core.exceptions import NotFoundError\n\n    mock_user_service.get_by_id = AsyncMock(\n        side_effect=NotFoundError(message=\"User not found\")\n    )\n\n    response = await superuser_client.get(\n        f\"{settings.API_V1_STR}/users/{uuid4()}\"\n    )\n    assert response.status_code == 404\n\n\n@pytest.mark.anyio\nasync def test_update_user_by_id(\n    superuser_client: AsyncClient,\n    mock_user: MockUser,\n    mock_user_service: MagicMock,\n):\n    \"\"\"Test updating user by ID as superuser.\"\"\"\n    response = await superuser_client.patch(\n        f\"{settings.API_V1_STR}/users/{mock_user.id}\",\n        json={\"full_name\": \"Admin Updated\"},\n    )\n    assert response.status_code == 200\n    mock_user_service.update.assert_called_once()\n\n\n@pytest.mark.anyio\nasync def test_delete_user_by_id(\n    superuser_client: AsyncClient,\n    mock_user: MockUser,\n    mock_user_service: MagicMock,\n):\n    \"\"\"Test deleting user by ID as superuser.\"\"\"\n    response = await superuser_client.delete(\n        f\"{settings.API_V1_STR}/users/{mock_user.id}\"\n    )\n    assert response.status_code == 204\n    mock_user_service.delete.assert_called_once()\n\n\n@pytest.mark.anyio\nasync def test_delete_user_by_id_not_found(\n    superuser_client: AsyncClient,\n    mock_user_service: MagicMock,\n):\n    \"\"\"Test deleting non-existent user.\"\"\"\n    from app.core.exceptions import NotFoundError\n\n    mock_user_service.delete = AsyncMock(\n        side_effect=NotFoundError(message=\"User not found\")\n    )\n\n    response = await superuser_client.delete(\n        f\"{settings.API_V1_STR}/users/{uuid4()}\"\n    )\n    assert response.status_code == 404\n{%- endif %}\n","backend/tests/api/test_health.py":"\"\"\"Health endpoint tests.\"\"\"\n{%- if cookiecutter.enable_redis or cookiecutter.use_postgresql or cookiecutter.use_mongodb %}\n\nfrom unittest.mock import AsyncMock\n{%- endif %}\n\nimport pytest\nfrom httpx import AsyncClient\n\nfrom app.core.config import settings\n\n\n@pytest.mark.anyio\nasync def test_health_check(client: AsyncClient):\n    \"\"\"Test liveness probe.\"\"\"\n    response = await client.get(f\"{settings.API_V1_STR}/health\")\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"status\"] == \"healthy\"\n\n\n@pytest.mark.anyio\nasync def test_readiness_check(client: AsyncClient):\n    \"\"\"Test readiness probe with mocked dependencies.\"\"\"\n    response = await client.get(f\"{settings.API_V1_STR}/ready\")\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"status\"] in [\"ready\", \"degraded\"]\n    assert \"checks\" in data\n\n\n{%- if cookiecutter.enable_redis %}\n\n\n@pytest.mark.anyio\nasync def test_readiness_check_redis_healthy(client: AsyncClient, mock_redis):\n    \"\"\"Test readiness when Redis is healthy.\"\"\"\n    mock_redis.ping = AsyncMock(return_value=True)\n\n    response = await client.get(f\"{settings.API_V1_STR}/ready\")\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"checks\"][\"redis\"] is True\n\n\n@pytest.mark.anyio\nasync def test_readiness_check_redis_unhealthy(client: AsyncClient, mock_redis):\n    \"\"\"Test readiness when Redis is unhealthy.\"\"\"\n    mock_redis.ping = AsyncMock(side_effect=Exception(\"Connection failed\"))\n\n    response = await client.get(f\"{settings.API_V1_STR}/ready\")\n    # Should return 503 when Redis is down\n    assert response.status_code == 503\n    data = response.json()\n    assert data[\"status\"] == \"degraded\"\n    assert data[\"checks\"][\"redis\"] is False\n{%- endif %}\n\n\n{%- if cookiecutter.use_postgresql %}\n\n\n@pytest.mark.anyio\nasync def test_readiness_check_db_healthy(client: AsyncClient, mock_db_session):\n    \"\"\"Test readiness when database is healthy.\"\"\"\n    # Mock successful DB query\n    mock_db_session.execute = AsyncMock()\n\n    response = await client.get(f\"{settings.API_V1_STR}/ready\")\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"checks\"][\"database\"][\"status\"] == \"healthy\"\n\n\n@pytest.mark.anyio\nasync def test_readiness_check_db_unhealthy(client: AsyncClient, mock_db_session):\n    \"\"\"Test readiness when database is unhealthy.\"\"\"\n    mock_db_session.execute = AsyncMock(side_effect=Exception(\"DB connection failed\"))\n\n    response = await client.get(f\"{settings.API_V1_STR}/ready\")\n    # Should return 503 when DB is down\n    assert response.status_code == 503\n    data = response.json()\n    assert data[\"status\"] == \"not_ready\"\n    assert data[\"checks\"][\"database\"][\"status\"] == \"unhealthy\"\n{%- endif %}\n\n\n{%- if cookiecutter.use_mongodb %}\n\n\n@pytest.mark.anyio\nasync def test_readiness_check_db_healthy(client: AsyncClient, mock_db_session):\n    \"\"\"Test readiness when MongoDB is healthy.\"\"\"\n    mock_db_session.command = AsyncMock(return_value={\"ok\": 1})\n\n    response = await client.get(f\"{settings.API_V1_STR}/ready\")\n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"checks\"][\"database\"] is True\n\n\n@pytest.mark.anyio\nasync def test_readiness_check_db_unhealthy(client: AsyncClient, mock_db_session):\n    \"\"\"Test readiness when MongoDB is unhealthy.\"\"\"\n    mock_db_session.command = AsyncMock(side_effect=Exception(\"MongoDB connection failed\"))\n\n    response = await client.get(f\"{settings.API_V1_STR}/ready\")\n    assert response.status_code == 503\n    data = response.json()\n    assert data[\"status\"] == \"degraded\"\n    assert data[\"checks\"][\"database\"] is False\n{%- endif %}\n","backend/tests/test_agents.py":"{%- if cookiecutter.enable_ai_agent and cookiecutter.use_pydantic_ai %}\n\"\"\"Tests for AI agent module (PydanticAI).\"\"\"\n\nfrom unittest.mock import MagicMock, patch\n\nimport pytest\n\nfrom app.agents.assistant import AssistantAgent, Deps, get_agent, run_agent\nfrom app.agents.tools.datetime_tool import get_current_datetime\n\n\nclass TestDeps:\n    \"\"\"Tests for Deps dataclass.\"\"\"\n\n    def test_deps_default_values(self):\n        \"\"\"Test Deps has correct default values.\"\"\"\n        deps = Deps()\n        assert deps.user_id is None\n        assert deps.user_name is None\n        assert deps.metadata == {}\n\n    def test_deps_with_values(self):\n        \"\"\"Test Deps with custom values.\"\"\"\n        deps = Deps(user_id=\"123\", user_name=\"Test User\", metadata={\"key\": \"value\"})\n        assert deps.user_id == \"123\"\n        assert deps.user_name == \"Test User\"\n        assert deps.metadata == {\"key\": \"value\"}\n\n\nclass TestGetCurrentDatetime:\n    \"\"\"Tests for get_current_datetime tool.\"\"\"\n\n    def test_returns_formatted_string(self):\n        \"\"\"Test get_current_datetime returns formatted string.\"\"\"\n        result = get_current_datetime()\n        assert isinstance(result, str)\n        # Should contain year, month, day\n        assert len(result) > 10\n\n\nclass TestAssistantAgent:\n    \"\"\"Tests for AssistantAgent class.\"\"\"\n\n    def test_init_with_defaults(self):\n        \"\"\"Test AssistantAgent initializes with defaults.\"\"\"\n        agent = AssistantAgent()\n        assert agent.system_prompt == \"You are a helpful assistant.\"\n        assert agent._agent is None\n\n    def test_init_with_custom_values(self):\n        \"\"\"Test AssistantAgent with custom configuration.\"\"\"\n        agent = AssistantAgent(\n            model_name=\"gpt-4\",\n            temperature=0.5,\n            system_prompt=\"Custom prompt\",\n        )\n        assert agent.model_name == \"gpt-4\"\n        assert agent.temperature == 0.5\n        assert agent.system_prompt == \"Custom prompt\"\n\n    @patch.dict(\"os.environ\", {\"OPENAI_API_KEY\": \"test-key\"})\n    @patch(\"app.agents.assistant.OpenAIProvider\")\n    @patch(\"app.agents.assistant.OpenAIChatModel\")\n    def test_agent_property_creates_agent(self, mock_model, mock_provider):\n        \"\"\"Test agent property creates agent on first access.\"\"\"\n        agent = AssistantAgent()\n        _ = agent.agent\n        assert agent._agent is not None\n        mock_model.assert_called_once()\n\n    @patch.dict(\"os.environ\", {\"OPENAI_API_KEY\": \"test-key\"})\n    @patch(\"app.agents.assistant.OpenAIProvider\")\n    @patch(\"app.agents.assistant.OpenAIChatModel\")\n    def test_agent_property_caches_agent(self, mock_model, mock_provider):\n        \"\"\"Test agent property caches the agent instance.\"\"\"\n        agent = AssistantAgent()\n        agent1 = agent.agent\n        agent2 = agent.agent\n        assert agent1 is agent2\n        mock_model.assert_called_once()\n\n\nclass TestGetAgent:\n    \"\"\"Tests for get_agent factory function.\"\"\"\n\n    def test_returns_assistant_agent(self):\n        \"\"\"Test get_agent returns AssistantAgent.\"\"\"\n        agent = get_agent()\n        assert isinstance(agent, AssistantAgent)\n\n\nclass TestAgentRoutes:\n    \"\"\"Tests for agent WebSocket routes.\"\"\"\n\n    @pytest.mark.anyio\n    async def test_agent_websocket_connection(self, client):\n        \"\"\"Test WebSocket connection to agent endpoint.\"\"\"\n        # This test verifies the WebSocket endpoint is accessible\n        # Actual agent testing would require mocking OpenAI\n        pass\n\n\nclass TestHistoryConversion:\n    \"\"\"Tests for conversation history conversion.\"\"\"\n\n    def test_empty_history(self):\n        \"\"\"Test with empty history.\"\"\"\n        _agent = AssistantAgent()  # noqa: F841\n        # History conversion happens inside run/iter methods\n        # We test the structure here\n        history = []\n        assert len(history) == 0\n\n    def test_history_roles(self):\n        \"\"\"Test history with different roles.\"\"\"\n        history = [\n            {\"role\": \"user\", \"content\": \"Hello\"},\n            {\"role\": \"assistant\", \"content\": \"Hi there!\"},\n            {\"role\": \"system\", \"content\": \"You are helpful\"},\n        ]\n        assert len(history) == 3\n        assert all(\"role\" in msg and \"content\" in msg for msg in history)\n{%- elif cookiecutter.enable_ai_agent and cookiecutter.use_langchain %}\n\"\"\"Tests for AI agent module (LangChain).\"\"\"\n\nfrom unittest.mock import MagicMock, patch\n\nimport pytest\n\nfrom app.agents.langchain_assistant import AgentContext, LangChainAssistant, get_agent, run_agent\nfrom app.agents.tools.datetime_tool import get_current_datetime\n\n\nclass TestAgentContext:\n    \"\"\"Tests for AgentContext TypedDict.\"\"\"\n\n    def test_context_empty(self):\n        \"\"\"Test AgentContext can be empty.\"\"\"\n        context: AgentContext = {}\n        assert \"user_id\" not in context\n        assert \"user_name\" not in context\n\n    def test_context_with_values(self):\n        \"\"\"Test AgentContext with values.\"\"\"\n        context: AgentContext = {\n            \"user_id\": \"123\",\n            \"user_name\": \"Test User\",\n            \"metadata\": {\"key\": \"value\"},\n        }\n        assert context[\"user_id\"] == \"123\"\n        assert context[\"user_name\"] == \"Test User\"\n        assert context[\"metadata\"] == {\"key\": \"value\"}\n\n\nclass TestGetCurrentDatetime:\n    \"\"\"Tests for get_current_datetime tool.\"\"\"\n\n    def test_returns_formatted_string(self):\n        \"\"\"Test get_current_datetime returns formatted string.\"\"\"\n        result = get_current_datetime()\n        assert isinstance(result, str)\n        # Should contain year, month, day\n        assert len(result) > 10\n\n\nclass TestLangChainAssistant:\n    \"\"\"Tests for LangChainAssistant class.\"\"\"\n\n    def test_init_with_defaults(self):\n        \"\"\"Test LangChainAssistant initializes with defaults.\"\"\"\n        agent = LangChainAssistant()\n        assert agent.system_prompt == \"You are a helpful assistant.\"\n        assert agent._agent is None\n\n    def test_init_with_custom_values(self):\n        \"\"\"Test LangChainAssistant with custom configuration.\"\"\"\n        agent = LangChainAssistant(\n            model_name=\"gpt-4\",\n            temperature=0.5,\n            system_prompt=\"Custom prompt\",\n        )\n        assert agent.model_name == \"gpt-4\"\n        assert agent.temperature == 0.5\n        assert agent.system_prompt == \"Custom prompt\"\n\n    @patch(\"app.agents.langchain_assistant.ChatOpenAI\")\n    @patch(\"app.agents.langchain_assistant.create_agent\")\n    def test_agent_property_creates_agent(self, mock_create_agent, mock_chat):\n        \"\"\"Test agent property creates agent on first access.\"\"\"\n        mock_create_agent.return_value = MagicMock()\n        agent = LangChainAssistant()\n        _ = agent.agent\n        assert agent._agent is not None\n        mock_create_agent.assert_called_once()\n\n    @patch(\"app.agents.langchain_assistant.ChatOpenAI\")\n    @patch(\"app.agents.langchain_assistant.create_agent\")\n    def test_agent_property_caches_agent(self, mock_create_agent, mock_chat):\n        \"\"\"Test agent property caches the agent instance.\"\"\"\n        mock_create_agent.return_value = MagicMock()\n        agent = LangChainAssistant()\n        agent1 = agent.agent\n        agent2 = agent.agent\n        assert agent1 is agent2\n        mock_create_agent.assert_called_once()\n\n\nclass TestGetAgent:\n    \"\"\"Tests for get_agent factory function.\"\"\"\n\n    def test_returns_langchain_assistant(self):\n        \"\"\"Test get_agent returns LangChainAssistant.\"\"\"\n        agent = get_agent()\n        assert isinstance(agent, LangChainAssistant)\n\n\nclass TestAgentRoutes:\n    \"\"\"Tests for agent WebSocket routes.\"\"\"\n\n    @pytest.mark.anyio\n    async def test_agent_websocket_connection(self, client):\n        \"\"\"Test WebSocket connection to agent endpoint.\"\"\"\n        # This test verifies the WebSocket endpoint is accessible\n        # Actual agent testing would require mocking OpenAI\n        pass\n\n\nclass TestHistoryConversion:\n    \"\"\"Tests for conversation history conversion.\"\"\"\n\n    def test_empty_history(self):\n        \"\"\"Test with empty history.\"\"\"\n        _agent = LangChainAssistant()  # noqa: F841\n        # History conversion happens inside run/stream methods\n        # We test the structure here\n        history = []\n        assert len(history) == 0\n\n    def test_history_roles(self):\n        \"\"\"Test history with different roles.\"\"\"\n        history = [\n            {\"role\": \"user\", \"content\": \"Hello\"},\n            {\"role\": \"assistant\", \"content\": \"Hi there!\"},\n            {\"role\": \"system\", \"content\": \"You are helpful\"},\n        ]\n        assert len(history) == 3\n        assert all(\"role\" in msg and \"content\" in msg for msg in history)\n\n    def test_convert_history(self):\n        \"\"\"Test _convert_history method.\"\"\"\n        agent = LangChainAssistant()\n        history = [\n            {\"role\": \"user\", \"content\": \"Hello\"},\n            {\"role\": \"assistant\", \"content\": \"Hi there!\"},\n            {\"role\": \"system\", \"content\": \"You are helpful\"},\n        ]\n        messages = agent._convert_history(history)\n        assert len(messages) == 3\n        from langchain.messages import AIMessage, HumanMessage, SystemMessage\n        assert isinstance(messages[0], HumanMessage)\n        assert isinstance(messages[1], AIMessage)\n        assert isinstance(messages[2], SystemMessage)\n{%- endif %}\n","backend/cli/__init__.py":"\"\"\"Project CLI module.\"\"\"\n","backend/cli/commands.py":"\"\"\"Project management CLI.\"\"\"\n# ruff: noqa: E402 - Import at bottom to avoid circular imports\n\nimport click\nfrom tabulate import tabulate\n\n\n@click.group()\n@click.version_option(version=\"0.1.0\", prog_name=\"{{ cookiecutter.project_slug }}\")\ndef cli():\n    \"\"\"{{ cookiecutter.project_name }} management CLI.\"\"\"\n    pass\n\n\n# === Server Commands ===\n@cli.group(\"server\")\ndef server_cli():\n    \"\"\"Server commands.\"\"\"\n    pass\n\n\n@server_cli.command(\"run\")\n@click.option(\"--host\", default=\"0.0.0.0\", help=\"Host to bind to\")\n@click.option(\"--port\", default=8000, type=int, help=\"Port to bind to\")\n@click.option(\"--reload\", is_flag=True, help=\"Enable auto-reload\")\ndef server_run(host: str, port: int, reload: bool):\n    \"\"\"Run the development server.\"\"\"\n    import uvicorn\n    uvicorn.run(\n        \"app.main:app\",\n        host=host,\n        port=port,\n        reload=reload,\n    )\n\n\n@server_cli.command(\"routes\")\ndef server_routes():\n    \"\"\"Show all registered routes.\"\"\"\n    from app.main import app\n\n    routes = []\n    for route in app.routes:\n        if hasattr(route, \"methods\"):\n            for method in route.methods - {\"HEAD\", \"OPTIONS\"}:\n                routes.append([method, route.path, getattr(route, \"name\", \"-\")])\n\n    click.echo(tabulate(routes, headers=[\"Method\", \"Path\", \"Name\"]))\n\n\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\n\n# === Database Commands ===\n@cli.group(\"db\")\ndef db_cli():\n    \"\"\"Database commands.\"\"\"\n    pass\n\n\n@db_cli.command(\"init\")\ndef db_init():\n    \"\"\"Initialize the database (run all migrations).\"\"\"\n    from alembic import command\n    from alembic.config import Config\n\n    click.echo(\"Initializing database...\")\n    alembic_cfg = Config(\"alembic.ini\")\n    command.upgrade(alembic_cfg, \"head\")\n    click.secho(\"Database initialized.\", fg=\"green\")\n\n\n@db_cli.command(\"migrate\")\n@click.option(\"-m\", \"--message\", required=True, help=\"Migration message\")\ndef db_migrate(message: str):\n    \"\"\"Create a new migration.\"\"\"\n    from alembic import command\n    from alembic.config import Config\n\n    alembic_cfg = Config(\"alembic.ini\")\n    command.revision(alembic_cfg, message=message, autogenerate=True)\n    click.secho(f\"Migration created: {message}\", fg=\"green\")\n\n\n@db_cli.command(\"upgrade\")\n@click.option(\"--revision\", default=\"head\", help=\"Revision to upgrade to\")\ndef db_upgrade(revision: str):\n    \"\"\"Run database migrations.\"\"\"\n    from alembic import command\n    from alembic.config import Config\n\n    alembic_cfg = Config(\"alembic.ini\")\n    command.upgrade(alembic_cfg, revision)\n    click.secho(f\"Upgraded to: {revision}\", fg=\"green\")\n\n\n@db_cli.command(\"downgrade\")\n@click.option(\"--revision\", default=\"-1\", help=\"Revision to downgrade to\")\ndef db_downgrade(revision: str):\n    \"\"\"Rollback database migrations.\"\"\"\n    from alembic import command\n    from alembic.config import Config\n\n    alembic_cfg = Config(\"alembic.ini\")\n    command.downgrade(alembic_cfg, revision)\n    click.secho(f\"Downgraded to: {revision}\", fg=\"green\")\n\n\n@db_cli.command(\"current\")\ndef db_current():\n    \"\"\"Show current migration revision.\"\"\"\n    from alembic import command\n    from alembic.config import Config\n\n    alembic_cfg = Config(\"alembic.ini\")\n    command.current(alembic_cfg)\n\n\n@db_cli.command(\"history\")\ndef db_history():\n    \"\"\"Show migration history.\"\"\"\n    from alembic import command\n    from alembic.config import Config\n\n    alembic_cfg = Config(\"alembic.ini\")\n    command.history(alembic_cfg)\n{%- endif %}\n\n\n{%- if cookiecutter.use_celery %}\n\n\n# === Celery Commands ===\n@cli.group(\"celery\")\ndef celery_cli():\n    \"\"\"Celery worker commands.\"\"\"\n    pass\n\n\n@celery_cli.command(\"worker\")\n@click.option(\"--loglevel\", default=\"info\", help=\"Log level (debug, info, warning, error)\")\n@click.option(\"--concurrency\", default=4, type=int, help=\"Number of concurrent workers\")\ndef celery_worker(loglevel: str, concurrency: int):\n    \"\"\"Start Celery worker.\"\"\"\n    import subprocess\n    subprocess.run([\n        \"celery\", \"-A\", \"app.worker.celery_app\", \"worker\",\n        f\"--loglevel={loglevel}\",\n        f\"--concurrency={concurrency}\",\n    ])\n\n\n@celery_cli.command(\"beat\")\n@click.option(\"--loglevel\", default=\"info\", help=\"Log level (debug, info, warning, error)\")\ndef celery_beat(loglevel: str):\n    \"\"\"Start Celery beat scheduler.\"\"\"\n    import subprocess\n    subprocess.run([\n        \"celery\", \"-A\", \"app.worker.celery_app\", \"beat\",\n        f\"--loglevel={loglevel}\",\n    ])\n\n\n@celery_cli.command(\"flower\")\n@click.option(\"--port\", default=5555, type=int, help=\"Flower web UI port\")\ndef celery_flower(port: int):\n    \"\"\"Start Flower monitoring UI.\"\"\"\n    import subprocess\n    subprocess.run([\n        \"celery\", \"-A\", \"app.worker.celery_app\", \"flower\",\n        f\"--port={port}\",\n    ])\n{%- endif %}\n\n{%- if cookiecutter.use_taskiq %}\n\n\n# === Taskiq Commands ===\n@cli.group(\"taskiq\")\ndef taskiq_cli():\n    \"\"\"Taskiq worker commands.\"\"\"\n    pass\n\n\n@taskiq_cli.command(\"worker\")\n@click.option(\"--workers\", default=2, type=int, help=\"Number of workers\")\n@click.option(\"--reload\", is_flag=True, help=\"Enable auto-reload for development\")\ndef taskiq_worker(workers: int, reload: bool):\n    \"\"\"Start Taskiq worker.\"\"\"\n    import subprocess\n    cmd = [\n        \"taskiq\", \"worker\", \"app.worker.taskiq_app:broker\",\n        f\"--workers={workers}\",\n    ]\n    if reload:\n        cmd.append(\"--reload\")\n    subprocess.run(cmd)\n\n\n@taskiq_cli.command(\"scheduler\")\ndef taskiq_scheduler():\n    \"\"\"Start Taskiq scheduler for periodic tasks.\"\"\"\n    import subprocess\n    subprocess.run([\n        \"taskiq\", \"scheduler\", \"app.worker.taskiq_app:scheduler\",\n    ])\n{%- endif %}\n\n{%- if cookiecutter.use_jwt %}\n\n\n# === User Commands ===\n@cli.group(\"user\")\ndef user_cli():\n    \"\"\"User management commands.\"\"\"\n    pass\n\n\n@user_cli.command(\"create\")\n@click.option(\"--email\", prompt=True, help=\"User email\")\n@click.option(\"--password\", prompt=True, hide_input=True, confirmation_prompt=True, help=\"User password\")\n@click.option(\"--role\", type=click.Choice([\"user\", \"admin\"]), default=\"user\", help=\"User role\")\n@click.option(\"--superuser\", is_flag=True, default=False, help=\"Create as superuser\")\ndef user_create(email: str, password: str, role: str, superuser: bool):\n    \"\"\"Create a new user.\"\"\"\n    import asyncio\n    from app.core.exceptions import AlreadyExistsError\n    from app.db.models.user import UserRole\n    from app.schemas.user import UserCreate\n    from app.services.user import UserService\n{%- if cookiecutter.use_postgresql %}\n    from app.db.session import async_session_maker\n\n    async def _create():\n        async with async_session_maker() as session:\n            user_service = UserService(session)\n            try:\n                user_in = UserCreate(email=email, password=password, role=UserRole(role))\n                user = await user_service.register(user_in)\n\n                if superuser:\n                    user.is_superuser = True\n                    session.add(user)\n\n                await session.commit()\n                return user\n            except AlreadyExistsError:\n                click.secho(f\"User already exists: {email}\", fg=\"red\")\n                return None\n{%- elif cookiecutter.use_sqlite %}\n    from app.db.session import SessionLocal\n\n    def _create():\n        with SessionLocal() as session:\n            user_service = UserService(session)\n            try:\n                user_in = UserCreate(email=email, password=password, role=UserRole(role))\n                user = user_service.register(user_in)\n\n                if superuser:\n                    user.is_superuser = True\n                    session.add(user)\n\n                session.commit()\n                return user\n            except AlreadyExistsError:\n                click.secho(f\"User already exists: {email}\", fg=\"red\")\n                return None\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\n    user = asyncio.run(_create())\n{%- else %}\n    user = _create()\n{%- endif %}\n    if user:\n        click.secho(f\"User created: {user.email} (role: {user.role})\", fg=\"green\")\n\n\n@user_cli.command(\"create-admin\")\n@click.option(\"--email\", prompt=True, help=\"Admin email\")\n@click.option(\"--password\", prompt=True, hide_input=True, confirmation_prompt=True, help=\"Admin password\")\ndef user_create_admin(email: str, password: str):\n    \"\"\"Create an admin user.\n\n    This is a shortcut for creating a user with admin role and superuser privileges.\n    Use this to create the initial admin account after setting up the database.\n    \"\"\"\n    import asyncio\n    from app.core.exceptions import AlreadyExistsError\n    from app.db.models.user import UserRole\n    from app.schemas.user import UserCreate\n    from app.services.user import UserService\n{%- if cookiecutter.use_postgresql %}\n    from app.db.session import async_session_maker\n\n    async def _create():\n        async with async_session_maker() as session:\n            user_service = UserService(session)\n            try:\n                user_in = UserCreate(email=email, password=password, role=UserRole.ADMIN)\n                user = await user_service.register(user_in)\n\n                # Admin users are also superusers\n                user.is_superuser = True\n                session.add(user)\n\n                await session.commit()\n                return user\n            except AlreadyExistsError:\n                click.secho(f\"User already exists: {email}\", fg=\"red\")\n                return None\n{%- elif cookiecutter.use_sqlite %}\n    from app.db.session import SessionLocal\n\n    def _create():\n        with SessionLocal() as session:\n            user_service = UserService(session)\n            try:\n                user_in = UserCreate(email=email, password=password, role=UserRole.ADMIN)\n                user = user_service.register(user_in)\n\n                # Admin users are also superusers\n                user.is_superuser = True\n                session.add(user)\n\n                session.commit()\n                return user\n            except AlreadyExistsError:\n                click.secho(f\"User already exists: {email}\", fg=\"red\")\n                return None\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\n    user = asyncio.run(_create())\n{%- else %}\n    user = _create()\n{%- endif %}\n    if user:\n        click.secho(f\"Admin user created: {user.email}\", fg=\"green\")\n        click.echo(\"This user has admin role and superuser privileges.\")\n\n\n@user_cli.command(\"set-role\")\n@click.argument(\"email\")\n@click.option(\"--role\", type=click.Choice([\"user\", \"admin\"]), required=True, help=\"New role\")\ndef user_set_role(email: str, role: str):\n    \"\"\"Change a user's role.\"\"\"\n    import asyncio\n    from app.core.exceptions import NotFoundError\n    from app.db.models.user import UserRole\n    from app.services.user import UserService\n{%- if cookiecutter.use_postgresql %}\n    from app.db.session import async_session_maker\n\n    async def _update():\n        async with async_session_maker() as session:\n            user_service = UserService(session)\n            try:\n                user = await user_service.get_by_email(email)\n                user.role = UserRole(role).value\n                session.add(user)\n                await session.commit()\n                return user\n            except NotFoundError:\n                click.secho(f\"User not found: {email}\", fg=\"red\")\n                return None\n\n    user = asyncio.run(_update())\n{%- elif cookiecutter.use_sqlite %}\n    from app.db.session import SessionLocal\n\n    with SessionLocal() as session:\n        user_service = UserService(session)\n        try:\n            user = user_service.get_by_email(email)\n            user.role = UserRole(role).value\n            session.add(user)\n            session.commit()\n        except NotFoundError:\n            click.secho(f\"User not found: {email}\", fg=\"red\")\n            user = None\n{%- endif %}\n    if user:\n        click.secho(f\"User {email} role updated to: {role}\", fg=\"green\")\n\n\n@user_cli.command(\"list\")\ndef user_list():\n    \"\"\"List all users.\"\"\"\n    import asyncio\n    from app.services.user import UserService\n{%- if cookiecutter.use_postgresql %}\n    from app.db.session import async_session_maker\n\n    async def _list():\n        async with async_session_maker() as session:\n            user_service = UserService(session)\n            return await user_service.get_multi()\n\n    users = asyncio.run(_list())\n{%- elif cookiecutter.use_sqlite %}\n    from app.db.session import SessionLocal\n\n    with SessionLocal() as session:\n        user_service = UserService(session)\n        users = user_service.get_multi()\n{%- endif %}\n\n    if not users:\n        click.echo(\"No users found.\")\n        return\n\n    table = [[u.id, u.email, u.role, u.is_active, u.is_superuser] for u in users]\n    click.echo(tabulate(table, headers=[\"ID\", \"Email\", \"Role\", \"Active\", \"Superuser\"]))\n{%- endif %}\n\n\n# === Custom Commands ===\n@cli.group(\"cmd\")\ndef cmd_cli():\n    \"\"\"Custom commands.\"\"\"\n    pass\n\n\n# Register all custom commands from app/commands/\nfrom app.commands import register_commands\n\nregister_commands(cmd_cli)\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    cli()\n\n\nif __name__ == \"__main__\":\n    main()\n","backend/.dockerignore":"{%- if cookiecutter.enable_docker %}\n# Git\n.git\n.gitignore\n\n# Python\n__pycache__\n*.py[cod]\n*$py.class\n*.so\n.Python\n.venv\nvenv/\nENV/\n\n# IDE\n.idea\n.vscode\n*.swp\n*.swo\n\n# Testing\n.pytest_cache\n.coverage\nhtmlcov/\n.tox\n.nox\n\n# Documentation\ndocs/_build/\n*.md\n!README.md\n\n# Build artifacts\ndist/\nbuild/\n*.egg-info/\n\n# Development files\n.env\n.env.local\n*.db\n*.sqlite\n\n# Docker\nDockerfile*\ndocker-compose*.yml\n.docker\n\n# CI/CD\n.github/\n.gitlab-ci.yml\n\n# Misc\n.DS_Store\nThumbs.db\n*.log\n{%- else %}\n# Docker is disabled\n{%- endif %}\n","backend/.env":"{%- if cookiecutter.generate_env -%}\n# {{ cookiecutter.project_name }} Environment Variables\n# Generated automatically - ready for local development\n\n# === Project ===\nPROJECT_NAME={{ cookiecutter.project_name }}\nDEBUG=true\nENVIRONMENT=development\n\n{%- if cookiecutter.enable_logfire %}\n\n# === Logfire ===\n# Get your token at https://logfire.pydantic.dev\nLOGFIRE_TOKEN=\nLOGFIRE_SERVICE_NAME={{ cookiecutter.project_slug }}\nLOGFIRE_ENVIRONMENT=development\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\n\n# === PostgreSQL ===\nPOSTGRES_HOST=localhost\nPOSTGRES_PORT=5432\nPOSTGRES_USER=postgres\nPOSTGRES_PASSWORD=postgres\nPOSTGRES_DB={{ cookiecutter.project_slug }}\n{%- endif %}\n\n{%- if cookiecutter.use_mongodb %}\n\n# === MongoDB ===\nMONGO_HOST=localhost\nMONGO_PORT=27017\nMONGO_DB={{ cookiecutter.project_slug }}\n{%- endif %}\n\n{%- if cookiecutter.use_sqlite %}\n\n# === SQLite ===\nSQLITE_PATH=./{{ cookiecutter.project_slug }}.db\n{%- endif %}\n\n{%- if cookiecutter.use_jwt %}\n\n# === JWT Auth ===\nSECRET_KEY=dev-secret-key-change-in-production\nACCESS_TOKEN_EXPIRE_MINUTES=10080\nALGORITHM=HS256\n{%- endif %}\n\n{%- if cookiecutter.use_api_key %}\n\n# === API Key Auth ===\nAPI_KEY=dev-api-key-change-in-production\nAPI_KEY_HEADER=X-API-Key\n{%- endif %}\n\n{%- if cookiecutter.enable_oauth_google %}\n\n# === OAuth2 (Google) ===\n# Get your credentials at https://console.cloud.google.com/apis/credentials\nGOOGLE_CLIENT_ID=\nGOOGLE_CLIENT_SECRET=\nGOOGLE_REDIRECT_URI=http://localhost:{{ cookiecutter.backend_port }}/api/v1/oauth/google/callback\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n\n# === Redis ===\nREDIS_HOST=localhost\nREDIS_PORT=6379\nREDIS_DB=0\n{%- endif %}\n\n{%- if cookiecutter.use_celery %}\n\n# === Celery ===\nCELERY_BROKER_URL=redis://localhost:6379/0\nCELERY_RESULT_BACKEND=redis://localhost:6379/0\n{%- endif %}\n\n{%- if cookiecutter.use_taskiq %}\n\n# === Taskiq ===\nTASKIQ_BROKER_URL=redis://localhost:6379/1\nTASKIQ_RESULT_BACKEND=redis://localhost:6379/1\n{%- endif %}\n\n{%- if cookiecutter.enable_sentry %}\n\n# === Sentry ===\nSENTRY_DSN=\n{%- endif %}\n\n{%- if cookiecutter.enable_file_storage %}\n\n# === S3/MinIO Storage ===\nS3_ENDPOINT=http://localhost:9000\nS3_ACCESS_KEY=minioadmin\nS3_SECRET_KEY=minioadmin\nS3_BUCKET={{ cookiecutter.project_slug }}\nS3_REGION=us-east-1\n{%- endif %}\n\n{%- if cookiecutter.enable_ai_agent %}\n\n# === AI Agent ({{ cookiecutter.ai_framework }}) ===\n{%- if cookiecutter.use_openai %}\nOPENAI_API_KEY=\nAI_MODEL=gpt-4o-mini\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\nANTHROPIC_API_KEY=\nAI_MODEL=claude-sonnet-4-5-20241022\n{%- endif %}\n{%- if cookiecutter.use_openrouter %}\nOPENROUTER_API_KEY=\nAI_MODEL=anthropic/claude-3.5-sonnet\n{%- endif %}\nAI_TEMPERATURE=0.7\n{%- if cookiecutter.use_langchain %}\n\n# === LangSmith (LangChain Observability) ===\n# Get your API key at https://smith.langchain.com\nLANGCHAIN_TRACING_V2=true\nLANGCHAIN_API_KEY=\nLANGCHAIN_PROJECT={{ cookiecutter.project_slug }}\nLANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n{%- endif %}\n{%- if cookiecutter.use_deepagents %}\n\n# === DeepAgents Configuration ===\n# Skills paths (comma-separated, relative paths)\nDEEPAGENTS_SKILLS_PATHS=\n# Enable/disable built-in tools\nDEEPAGENTS_ENABLE_FILESYSTEM=true\nDEEPAGENTS_ENABLE_EXECUTE=false\nDEEPAGENTS_ENABLE_TODOS=true\nDEEPAGENTS_ENABLE_SUBAGENTS=true\n# Human-in-the-loop: tools requiring approval (comma-separated, or \"all\")\n# e.g. \"write_file,edit_file,execute\" or leave empty to disable\nDEEPAGENTS_INTERRUPT_TOOLS=\n# Allowed decisions for interrupted tools\nDEEPAGENTS_ALLOWED_DECISIONS=approve,edit,reject\n{%- endif %}\n{%- endif %}\n\n{%- if cookiecutter.enable_cors %}\n\n# === CORS ===\nCORS_ORIGINS=[\"http://localhost:3000\",\"http://localhost:8080\"]\n{%- endif %}\n{% else -%}\n# .env file not generated - copy from .env.example\n# cp .env.example .env\n{%- endif %}\n","backend/scripts/.gitkeep":"","backend/alembic/script.py.mako":"{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\"\"\"${message}\n\nRevision ID: ${up_revision}\nRevises: ${down_revision | comma,n}\nCreate Date: ${create_date}\n\n\"\"\"\nfrom typing import Sequence, Union\n\nfrom alembic import op\nimport sqlalchemy as sa\n${imports if imports else \"\"}\n\n# revision identifiers, used by Alembic.\nrevision: str = ${repr(up_revision)}\ndown_revision: Union[str, None] = ${repr(down_revision)}\nbranch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}\ndepends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}\n\n\ndef upgrade() -> None:\n    ${upgrades if upgrades else \"pass\"}\n\n\ndef downgrade() -> None:\n    ${downgrades if downgrades else \"pass\"}\n{%- else %}\n# Alembic - not configured\n{%- endif %}\n","backend/alembic/env.py":"{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\"\"\"Alembic migration environment.\"\"\"\n# ruff: noqa: I001 - Imports structured for Jinja2 template conditionals\n\nfrom logging.config import fileConfig\n\nfrom alembic import context\nfrom sqlalchemy import engine_from_config, pool\n{%- if cookiecutter.use_sqlmodel %}\nfrom sqlmodel import SQLModel\n{%- endif %}\n\nfrom app.core.config import settings\n{%- if not cookiecutter.use_sqlmodel %}\nfrom app.db.base import Base\n{%- endif %}\n\n# Import all models here to ensure they are registered with metadata\n{%- if cookiecutter.use_jwt %}\nfrom app.db.models.user import User  # noqa: F401\n{%- endif %}\n\nconfig = context.config\n\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\n\n{%- if cookiecutter.use_sqlmodel %}\ntarget_metadata = SQLModel.metadata\n{%- else %}\ntarget_metadata = Base.metadata\n{%- endif %}\n\n\ndef get_url() -> str:\n    \"\"\"Get database URL from settings.\"\"\"\n{%- if cookiecutter.use_postgresql %}\n    return settings.DATABASE_URL_SYNC\n{%- else %}\n    return settings.DATABASE_URL\n{%- endif %}\n\n\ndef run_migrations_offline() -> None:\n    \"\"\"Run migrations in 'offline' mode.\"\"\"\n    url = get_url()\n    context.configure(\n        url=url,\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef run_migrations_online() -> None:\n    \"\"\"Run migrations in 'online' mode.\"\"\"\n    configuration = config.get_section(config.config_ini_section)\n    configuration[\"sqlalchemy.url\"] = get_url()\n\n    connectable = engine_from_config(\n        configuration,\n        prefix=\"sqlalchemy.\",\n        poolclass=pool.NullPool,\n    )\n\n    with connectable.connect() as connection:\n        context.configure(\n            connection=connection,\n            target_metadata=target_metadata,\n        )\n\n        with context.begin_transaction():\n            context.run_migrations()\n\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    run_migrations_online()\n{%- else %}\n# Alembic - not configured (no SQL database)\n{%- endif %}\n","backend/alembic/versions/.gitkeep":"","backend/.env.example":"# {{ cookiecutter.project_name }} Environment Variables\n\n# === Project ===\nPROJECT_NAME={{ cookiecutter.project_name }}\nDEBUG=true\nENVIRONMENT=local\n\n{%- if cookiecutter.enable_logfire %}\n\n# === Logfire ===\n# Get your token at https://logfire.pydantic.dev\nLOGFIRE_TOKEN=\nLOGFIRE_SERVICE_NAME={{ cookiecutter.project_slug }}\nLOGFIRE_ENVIRONMENT=development\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\n\n# === PostgreSQL ===\nPOSTGRES_HOST=localhost\nPOSTGRES_PORT=5432\nPOSTGRES_USER=postgres\nPOSTGRES_PASSWORD=postgres\nPOSTGRES_DB={{ cookiecutter.project_slug }}\n{%- endif %}\n\n{%- if cookiecutter.use_mongodb %}\n\n# === MongoDB ===\nMONGO_HOST=localhost\nMONGO_PORT=27017\nMONGO_DB={{ cookiecutter.project_slug }}\n# MONGO_USER=\n# MONGO_PASSWORD=\n{%- endif %}\n\n{%- if cookiecutter.use_sqlite %}\n\n# === SQLite ===\nSQLITE_PATH=./{{ cookiecutter.project_slug }}.db\n{%- endif %}\n\n{%- if cookiecutter.use_jwt %}\n\n# === JWT Auth ===\n# Generate with: openssl rand -hex 32\nSECRET_KEY=change-me-in-production-use-openssl-rand-hex-32\nACCESS_TOKEN_EXPIRE_MINUTES=10080\nALGORITHM=HS256\n{%- endif %}\n\n{%- if cookiecutter.use_api_key %}\n\n# === API Key Auth ===\nAPI_KEY=change-me-in-production\nAPI_KEY_HEADER=X-API-Key\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n\n# === Redis ===\nREDIS_HOST=localhost\nREDIS_PORT=6379\n# REDIS_PASSWORD=\nREDIS_DB=0\n{%- endif %}\n\n{%- if cookiecutter.use_celery %}\n\n# === Celery ===\nCELERY_BROKER_URL=redis://localhost:6379/0\nCELERY_RESULT_BACKEND=redis://localhost:6379/0\n{%- endif %}\n\n{%- if cookiecutter.use_taskiq %}\n\n# === Taskiq ===\nTASKIQ_BROKER_URL=redis://localhost:6379/1\nTASKIQ_RESULT_BACKEND=redis://localhost:6379/1\n{%- endif %}\n\n{%- if cookiecutter.use_arq %}\n\n# === ARQ (Async Redis Queue) ===\nARQ_REDIS_HOST=localhost\nARQ_REDIS_PORT=6379\n# ARQ_REDIS_PASSWORD=\nARQ_REDIS_DB=2\n{%- endif %}\n\n{%- if cookiecutter.enable_sentry %}\n\n# === Sentry ===\nSENTRY_DSN=\n{%- endif %}\n\n{%- if cookiecutter.enable_prometheus %}\n\n# === Prometheus ===\nPROMETHEUS_METRICS_PATH=/metrics\nPROMETHEUS_INCLUDE_IN_SCHEMA=false\n{%- endif %}\n\n{%- if cookiecutter.enable_file_storage %}\n\n# === S3/MinIO Storage ===\nS3_ENDPOINT=\nS3_ACCESS_KEY=\nS3_SECRET_KEY=\nS3_BUCKET={{ cookiecutter.project_slug }}\nS3_REGION=us-east-1\n{%- endif %}\n\n{%- if cookiecutter.enable_ai_agent %}\n\n# === AI Agent ({{ cookiecutter.ai_framework }}, {{ cookiecutter.llm_provider }}) ===\n{%- if cookiecutter.use_openai %}\nOPENAI_API_KEY=\nAI_MODEL=gpt-4o-mini\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\nANTHROPIC_API_KEY=\nAI_MODEL=claude-sonnet-4-5-20241022\n{%- endif %}\n{%- if cookiecutter.use_openrouter %}\nOPENROUTER_API_KEY=\nAI_MODEL=anthropic/claude-3.5-sonnet\n{%- endif %}\nAI_TEMPERATURE=0.7\n{%- if cookiecutter.use_langchain %}\n\n# === LangSmith (LangChain Observability) ===\n# Get your API key at https://smith.langchain.com\nLANGCHAIN_TRACING_V2=true\nLANGCHAIN_API_KEY=\nLANGCHAIN_PROJECT={{ cookiecutter.project_slug }}\nLANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n{%- endif %}\n{%- if cookiecutter.use_deepagents %}\n\n# === DeepAgents Configuration ===\n# Skills paths (comma-separated, relative paths e.g. \"/skills/user/,/skills/project/\")\nDEEPAGENTS_SKILLS_PATHS=\n# Enable/disable built-in tools\nDEEPAGENTS_ENABLE_FILESYSTEM=true\nDEEPAGENTS_ENABLE_EXECUTE=false\nDEEPAGENTS_ENABLE_TODOS=true\nDEEPAGENTS_ENABLE_SUBAGENTS=true\n# Human-in-the-loop: tools requiring approval (comma-separated, or \"all\")\n# e.g. \"write_file,edit_file,execute\" or leave empty to disable HITL\nDEEPAGENTS_INTERRUPT_TOOLS=\n# Allowed decisions for interrupted tools (approve, edit, reject)\nDEEPAGENTS_ALLOWED_DECISIONS=approve,edit,reject\n{%- endif %}\n{%- endif %}\n\n{%- if cookiecutter.enable_cors %}\n\n# === CORS ===\n# JSON list of allowed origins (default: localhost:3000, localhost:8080)\n# Note: \"*\" is blocked in production - specify explicit origins\nCORS_ORIGINS=[\"http://localhost:3000\",\"http://localhost:8080\"]\n{%- endif %}\n\n{%- if cookiecutter.enable_docker %}\n\n# === Docker Production (Traefik) ===\n# Domain for production deployment\nDOMAIN=example.com\n\n# Let's Encrypt email for SSL certificates\nACME_EMAIL=admin@example.com\n\n# Traefik dashboard auth (generate with: htpasswd -nb admin password)\n# TRAEFIK_DASHBOARD_AUTH=admin:$$apr1$$...\n\n{%- if cookiecutter.enable_redis %}\n# Redis password for production\nREDIS_PASSWORD=change-me-in-production\n{%- endif %}\n\n{%- if cookiecutter.use_celery %}\n# Flower monitoring credentials\nFLOWER_USER=admin\nFLOWER_PASSWORD=change-me-in-production\n{%- endif %}\n{%- endif %}\n","docker-compose.dev.yml":"{%- if cookiecutter.enable_docker %}\n# Development configuration (alias for docker-compose.yml)\n# Usage: docker-compose -f docker-compose.dev.yml up -d\n#\n# This file is identical to docker-compose.yml for explicit naming preference.\n# Use docker-compose.yml for default development.\n\nservices:\n  app:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_backend\n    ports:\n      - \"{{ cookiecutter.backend_port }}:{{ cookiecutter.backend_port }}\"\n    volumes:\n      - ./backend/app:/app/app:ro\n      - ./backend/cli:/app/cli:ro\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n      - ENVIRONMENT=local\n{%- if cookiecutter.use_postgresql %}\n      - POSTGRES_HOST=db\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n      - REDIS_HOST=redis\n{%- endif %}\n{%- if cookiecutter.use_celery %}\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/0\n{%- endif %}\n{%- if cookiecutter.use_taskiq %}\n      - TASKIQ_BROKER_URL=redis://redis:6379/1\n      - TASKIQ_RESULT_BACKEND=redis://redis:6379/1\n{%- endif %}\n    command: uvicorn app.main:app --host 0.0.0.0 --port {{ cookiecutter.backend_port }} --reload\n    networks:\n      - backend\n{%- if cookiecutter.use_postgresql or cookiecutter.enable_redis %}\n    depends_on:\n{%- if cookiecutter.use_postgresql %}\n      db:\n        condition: service_healthy\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n      redis:\n        condition: service_healthy\n{%- endif %}\n{%- endif %}\n    restart: unless-stopped\n{%- if cookiecutter.enable_prometheus %}\n    labels:\n      - \"prometheus.scrape=true\"\n      - \"prometheus.port={{ cookiecutter.backend_port }}\"\n      - \"prometheus.path=/metrics\"\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\n\n  db:\n    image: postgres:16-alpine\n    container_name: {{ cookiecutter.project_slug }}_db\n    environment:\n      - POSTGRES_USER=${POSTGRES_USER:-postgres}\n      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}\n      - POSTGRES_DB=${POSTGRES_DB:-{{ cookiecutter.project_slug }}}\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    ports:\n      - \"5432:5432\"\n    networks:\n      - backend\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${POSTGRES_USER:-postgres}\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    restart: unless-stopped\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n\n  redis:\n    image: redis:7-alpine\n    container_name: {{ cookiecutter.project_slug }}_redis\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n    networks:\n      - backend\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    restart: unless-stopped\n{%- endif %}\n\n{%- if cookiecutter.use_celery %}\n\n  celery_worker:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_celery_worker\n    volumes:\n      - ./backend/app:/app/app:ro\n    command: celery -A app.worker.celery_app worker --loglevel=debug\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n{%- if cookiecutter.use_postgresql %}\n      - POSTGRES_HOST=db\n{%- endif %}\n      - REDIS_HOST=redis\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/0\n    networks:\n      - backend\n    depends_on:\n      redis:\n        condition: service_healthy\n{%- if cookiecutter.use_postgresql %}\n      db:\n        condition: service_healthy\n{%- endif %}\n    restart: unless-stopped\n\n  celery_beat:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_celery_beat\n    volumes:\n      - ./backend/app:/app/app:ro\n    command: celery -A app.worker.celery_app beat --loglevel=debug\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n      - REDIS_HOST=redis\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/0\n    networks:\n      - backend\n    depends_on:\n      redis:\n        condition: service_healthy\n    restart: unless-stopped\n\n  flower:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_flower\n    command: celery -A app.worker.celery_app flower --port=5555\n    ports:\n      - \"5555:5555\"\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n      - REDIS_HOST=redis\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/0\n    networks:\n      - backend\n    depends_on:\n      redis:\n        condition: service_healthy\n    restart: unless-stopped\n{%- endif %}\n\n{%- if cookiecutter.use_taskiq %}\n\n  taskiq_worker:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_taskiq_worker\n    volumes:\n      - ./backend/app:/app/app:ro\n    command: taskiq worker app.worker.taskiq_app:broker --workers 1 --reload\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n{%- if cookiecutter.use_postgresql %}\n      - POSTGRES_HOST=db\n{%- endif %}\n      - REDIS_HOST=redis\n      - TASKIQ_BROKER_URL=redis://redis:6379/1\n      - TASKIQ_RESULT_BACKEND=redis://redis:6379/1\n    networks:\n      - backend\n    depends_on:\n      redis:\n        condition: service_healthy\n{%- if cookiecutter.use_postgresql %}\n      db:\n        condition: service_healthy\n{%- endif %}\n    restart: unless-stopped\n\n  taskiq_scheduler:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_taskiq_scheduler\n    volumes:\n      - ./backend/app:/app/app:ro\n    command: taskiq scheduler app.worker.taskiq_app:scheduler\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n      - REDIS_HOST=redis\n      - TASKIQ_BROKER_URL=redis://redis:6379/1\n      - TASKIQ_RESULT_BACKEND=redis://redis:6379/1\n    networks:\n      - backend\n    depends_on:\n      redis:\n        condition: service_healthy\n    restart: unless-stopped\n{%- endif %}\n\nnetworks:\n  backend:\n    driver: bridge\n\n{%- if cookiecutter.use_postgresql or cookiecutter.enable_redis %}\n\nvolumes:\n{%- if cookiecutter.use_postgresql %}\n  postgres_data:\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n  redis_data:\n{%- endif %}\n{%- endif %}\n{%- else %}\n# Docker is disabled for this project\n{%- endif %}\n","docs/adding_features.md":"# Adding New Features\n\n## Adding a New API Endpoint\n\n1. **Create schema** in `schemas/`\n   ```python\n   # schemas/item.py\n   class ItemCreate(BaseModel):\n       name: str\n       description: str | None = None\n\n   class ItemResponse(BaseModel):\n       id: UUID\n       name: str\n       created_at: datetime\n   ```\n\n2. **Create model** in `db/models/` (if new entity)\n   ```python\n   # db/models/item.py\n   class Item(Base):\n       __tablename__ = \"items\"\n       id: Mapped[UUID] = mapped_column(primary_key=True, default=uuid4)\n       name: Mapped[str] = mapped_column(String(255))\n   ```\n\n3. **Create repository** in `repositories/`\n   ```python\n   # repositories/item.py\n   class ItemRepository:\n       async def create(self, db: AsyncSession, **kwargs) -> Item:\n           item = Item(**kwargs)\n           db.add(item)\n           await db.flush()\n           await db.refresh(item)\n           return item\n   ```\n\n4. **Create service** in `services/`\n   ```python\n   # services/item.py\n   class ItemService:\n       def __init__(self, db: AsyncSession):\n           self.db = db\n           self.repo = ItemRepository()\n\n       async def create(self, item_in: ItemCreate) -> Item:\n           return await self.repo.create(self.db, **item_in.model_dump())\n   ```\n\n5. **Create route** in `api/routes/v1/`\n   ```python\n   # api/routes/v1/items.py\n   router = APIRouter(prefix=\"/items\", tags=[\"items\"])\n\n   @router.post(\"/\", response_model=ItemResponse, status_code=201)\n   async def create_item(\n       item_in: ItemCreate,\n       db: AsyncSession = Depends(get_db),\n   ):\n       service = ItemService(db)\n       return await service.create(item_in)\n   ```\n\n6. **Register route** in `api/routes/v1/__init__.py`\n   ```python\n   from .items import router as items_router\n   api_router.include_router(items_router)\n   ```\n\n## Adding a Custom CLI Command\n\nCommands are auto-discovered from `app/commands/`.\n\n```python\n# app/commands/my_command.py\nfrom app.commands import command, success, error\nimport click\n\n@command(\"my-command\", help=\"Description of what this does\")\n@click.option(\"--name\", \"-n\", required=True, help=\"Name parameter\")\ndef my_command(name: str):\n    # Your logic here\n    success(f\"Done: {name}\")\n```\n\nRun with: `uv run {{ cookiecutter.project_slug }} cmd my-command --name test`\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_pydantic_ai %}\n\n## Adding an AI Agent Tool (PydanticAI)\n\n```python\n# app/agents/assistant.py\n@agent.tool\nasync def my_tool(ctx: RunContext[Deps], param: str) -> dict:\n    \"\"\"Tool description for LLM - be specific about what it does.\"\"\"\n    # Access dependencies via ctx.deps\n    result = await some_operation(param)\n    return {\"result\": result}\n```\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_langchain %}\n\n## Adding an AI Agent Tool (LangChain)\n\n```python\n# app/agents/langchain_assistant.py\nfrom langchain.tools import tool\n\n@tool\ndef my_tool(param: str) -> dict:\n    \"\"\"Tool description for LLM - be specific about what it does.\"\"\"\n    result = some_operation(param)\n    return {\"result\": result}\n```\n{%- endif %}\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\n## Adding a Database Migration\n\n```bash\n# Create migration\nuv run alembic revision --autogenerate -m \"Add items table\"\n\n# Apply migration\nuv run alembic upgrade head\n\n# Or use CLI\nuv run {{ cookiecutter.project_slug }} db migrate -m \"Add items table\"\nuv run {{ cookiecutter.project_slug }} db upgrade\n```\n{%- endif %}\n","docs/architecture.md":"# Architecture Guide\n\nThis project follows a **Repository + Service** layered architecture.\n\n## Request Flow\n\n```\nHTTP Request ‚Üí API Route ‚Üí Service ‚Üí Repository ‚Üí Database\n                  ‚Üì\n              Response ‚Üê Service ‚Üê Repository ‚Üê\n```\n\n## Directory Structure (`backend/app/`)\n\n| Directory | Purpose |\n|-----------|---------|\n| `api/routes/v1/` | HTTP endpoints, request validation, auth |\n| `api/deps.py` | Dependency injection (db session, current user) |\n| `services/` | Business logic, orchestration |\n| `repositories/` | Data access layer, database queries |\n| `schemas/` | Pydantic models for request/response |\n| `db/models/` | SQLAlchemy/MongoDB models |\n| `core/config.py` | Settings via pydantic-settings |\n{%- if cookiecutter.use_auth %}\n| `core/security.py` | JWT/API key utilities |\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent %}\n| `agents/` | AI agents and tools |\n{%- endif %}\n| `commands/` | Django-style CLI commands |\n{%- if cookiecutter.use_celery or cookiecutter.use_taskiq %}\n| `worker/` | Background task definitions |\n{%- endif %}\n\n## Layer Responsibilities\n\n### API Routes (`api/routes/v1/`)\n- HTTP request/response handling\n- Input validation via Pydantic schemas\n- Authentication/authorization checks\n- Delegates to services for business logic\n\n### Services (`services/`)\n- Business logic and validation\n- Orchestrates repository calls\n- Raises domain exceptions (NotFoundError, etc.)\n- Transaction boundaries\n\n### Repositories (`repositories/`)\n- Database operations only\n- No business logic\n- Uses `db.flush()` not `commit()` (let dependency manage transactions)\n- Returns domain models\n\n## Key Files\n\n- Entry point: `app/main.py`\n- Configuration: `app/core/config.py`\n- Dependencies: `app/api/deps.py`\n{%- if cookiecutter.use_auth %}\n- Auth utilities: `app/core/security.py`\n{%- endif %}\n- Exception handlers: `app/api/exception_handlers.py`\n","docs/testing.md":"# Testing Guide\n\n## Running Tests\n\n```bash\ncd backend\n\n# Run all tests\npytest\n\n# Run with coverage\npytest --cov=app --cov-report=term-missing\n\n# Run specific test file\npytest tests/api/test_health.py -v\n\n# Run specific test\npytest tests/api/test_health.py::test_health_check -v\n\n# Run only unit tests\npytest tests/unit/\n\n# Run only integration tests\npytest tests/integration/\n\n# Run with verbose output\npytest -v\n\n# Stop on first failure\npytest -x\n```\n\n## Test Structure\n\n```\ntests/\n‚îú‚îÄ‚îÄ conftest.py          # Shared fixtures\n‚îú‚îÄ‚îÄ api/                 # API endpoint tests\n‚îÇ   ‚îú‚îÄ‚îÄ test_health.py\n‚îÇ   ‚îî‚îÄ‚îÄ test_auth.py\n‚îú‚îÄ‚îÄ unit/                # Unit tests (services, utils)\n‚îÇ   ‚îî‚îÄ‚îÄ test_services.py\n‚îî‚îÄ‚îÄ integration/         # Integration tests\n    ‚îî‚îÄ‚îÄ test_db.py\n```\n\n## Key Fixtures (`conftest.py`)\n\n```python\n# Database session for tests\n@pytest.fixture\nasync def db_session():\n    async with async_session() as session:\n        yield session\n        await session.rollback()\n\n# Test client\n@pytest.fixture\ndef client():\n    return TestClient(app)\n\n# Authenticated client\n@pytest.fixture\nasync def auth_client(client, test_user):\n    token = create_access_token(test_user.id)\n    client.headers[\"Authorization\"] = f\"Bearer {token}\"\n    return client\n```\n\n## Writing Tests\n\n### API Endpoint Test\n```python\ndef test_health_check(client):\n    response = client.get(\"/api/v1/health\")\n    assert response.status_code == 200\n    assert response.json()[\"status\"] == \"healthy\"\n```\n\n### Service Test\n```python\nasync def test_create_item(db_session):\n    service = ItemService(db_session)\n    item = await service.create(ItemCreate(name=\"Test\"))\n    assert item.name == \"Test\"\n```\n\n### Test with Authentication\n```python\ndef test_protected_endpoint(auth_client):\n    response = auth_client.get(\"/api/v1/users/me\")\n    assert response.status_code == 200\n```\n{%- if cookiecutter.use_frontend %}\n\n## Frontend Tests\n\n```bash\ncd frontend\n\n# Run unit tests\nbun test\n\n# Run with watch mode\nbun test --watch\n\n# Run E2E tests\nbun test:e2e\n\n# Run E2E in headed mode (see browser)\nbun test:e2e --headed\n```\n{%- endif %}\n\n## Test Database\n\nTests use a separate test database or SQLite in-memory:\n- Configuration in `tests/conftest.py`\n- Database is reset between tests\n- Use fixtures for test data\n","docs/patterns.md":"# Code Patterns\n\n## Dependency Injection\n\nUse FastAPI's `Depends()` for injecting dependencies:\n\n```python\nfrom app.api.deps import get_db, get_current_user\n\n@router.get(\"/items\")\nasync def list_items(\n    db: AsyncSession = Depends(get_db),\n    current_user: User = Depends(get_current_user),\n):\n    service = ItemService(db)\n    return await service.get_multi()\n```\n\nAvailable dependencies in `app/api/deps.py`:\n- `get_db` - Database session\n{%- if cookiecutter.use_auth %}\n- `get_current_user` - Authenticated user (raises 401 if not authenticated)\n- `get_current_user_optional` - User or None\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n- `get_redis` - Redis connection\n{%- endif %}\n\n## Service Layer Pattern\n\nServices contain business logic:\n\n```python\nclass ItemService:\n    def __init__(self, db: AsyncSession):\n        self.db = db\n        self.repo = ItemRepository()\n\n    async def create(self, item_in: ItemCreate) -> Item:\n        # Business validation\n        if await self.repo.exists_by_name(self.db, item_in.name):\n            raise AlreadyExistsError(message=\"Item already exists\")\n\n        # Create via repository\n        return await self.repo.create(self.db, **item_in.model_dump())\n\n    async def get_or_raise(self, id: UUID) -> Item:\n        item = await self.repo.get_by_id(self.db, id)\n        if not item:\n            raise NotFoundError(message=\"Item not found\", details={\"id\": str(id)})\n        return item\n```\n\n## Repository Layer Pattern\n\nRepositories handle data access only:\n\n```python\nclass ItemRepository:\n    async def get_by_id(self, db: AsyncSession, id: UUID) -> Item | None:\n        return await db.get(Item, id)\n\n    async def create(self, db: AsyncSession, **kwargs) -> Item:\n        item = Item(**kwargs)\n        db.add(item)\n        await db.flush()  # Not commit! Let dependency manage transaction\n        await db.refresh(item)\n        return item\n\n    async def get_multi(\n        self, db: AsyncSession, skip: int = 0, limit: int = 100\n    ) -> list[Item]:\n        result = await db.execute(\n            select(Item).offset(skip).limit(limit)\n        )\n        return list(result.scalars().all())\n```\n\n## Exception Handling\n\nUse domain exceptions in services:\n\n```python\nfrom app.core.exceptions import NotFoundError, AlreadyExistsError, ValidationError\n\n# In service\nif not item:\n    raise NotFoundError(\n        message=\"Item not found\",\n        details={\"id\": str(id)}\n    )\n\nif await self.repo.exists_by_email(self.db, email):\n    raise AlreadyExistsError(\n        message=\"User with this email already exists\"\n    )\n```\n\nException handlers convert to HTTP responses automatically.\n\n## Schema Patterns\n\nSeparate schemas for different operations:\n\n```python\n# Base with shared fields\nclass ItemBase(BaseModel):\n    name: str\n    description: str | None = None\n\n# For creation (input)\nclass ItemCreate(ItemBase):\n    pass\n\n# For updates (all optional)\nclass ItemUpdate(BaseModel):\n    name: str | None = None\n    description: str | None = None\n\n# For responses (with DB fields)\nclass ItemResponse(ItemBase):\n    id: UUID\n    created_at: datetime\n    updated_at: datetime | None\n\n    model_config = ConfigDict(from_attributes=True)\n```\n{%- if cookiecutter.use_frontend %}\n\n## Frontend Patterns\n\n### Authentication (HTTP-only cookies)\n\n```typescript\nimport { useAuth } from '@/hooks/use-auth';\n\nfunction Component() {\n    const { user, isAuthenticated, login, logout } = useAuth();\n}\n```\n\n### State Management (Zustand)\n\n```typescript\nimport { useAuthStore } from '@/stores/auth-store';\n\nconst { user, setUser, logout } = useAuthStore();\n```\n{%- if cookiecutter.enable_ai_agent %}\n\n### WebSocket Chat\n\n```typescript\nimport { useChat } from '@/hooks/use-chat';\n\nfunction ChatPage() {\n    const { messages, sendMessage, isStreaming } = useChat();\n}\n```\n{%- endif %}\n{%- endif %}\n","README.md":"# Full-Stack FastAPI + Next.js Template for AI/LLM Applications\n\n<p align=\"center\">\n  <a href=\"https://github.com/vstorm-co/full-stack-ai-agent-template/stargazers\"><img src=\"https://img.shields.io/github/stars/vstorm-co/full-stack-ai-agent-template?style=flat&logo=github&color=yellow\" alt=\"GitHub Stars\"></a>\n  <a href=\"https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/LICENSE\"><img src=\"https://img.shields.io/github/license/vstorm-co/full-stack-ai-agent-template?color=blue\" alt=\"License\"></a>\n  <a href=\"https://www.python.org/\"><img src=\"https://img.shields.io/badge/python-3.11%20%7C%203.12%20%7C%203.13-blue?logo=python&logoColor=white\" alt=\"Python\"></a>\n  <a href=\"https://pypi.org/project/fastapi-fullstack/\"><img src=\"https://img.shields.io/pypi/v/fastapi-fullstack?color=green&logo=pypi&logoColor=white\" alt=\"PyPI\"></a>\n  <img src=\"https://img.shields.io/badge/coverage-100%25-brightgreen\" alt=\"Coverage\">\n  <img src=\"https://img.shields.io/badge/integrations-20%2B-brightgreen\" alt=\"20+ Integrations\">\n</p>\n\n<p align=\"center\">\n  <b>Production-ready project generator for AI/LLM applications with 20+ enterprise integrations.</b><br>\n  <sub>Built with FastAPI, Next.js 15, PydanticAI/LangChain, and everything you need for professional business applications.</sub>\n</p>\n\n<p align=\"center\">\n  <a href=\"#-why-this-template\">Why This Template</a> ‚Ä¢\n  <a href=\"#-features\">Features</a> ‚Ä¢\n  <a href=\"#-demo\">Demo</a> ‚Ä¢\n  <a href=\"#-quick-start\">Quick Start</a> ‚Ä¢\n  <a href=\"#-architecture\">Architecture</a> ‚Ä¢\n  <a href=\"#-ai-agent\">AI Agent</a> ‚Ä¢\n  <a href=\"#-observability-with-logfire\">Logfire</a> ‚Ä¢\n  <a href=\"#-documentation\">Documentation</a>\n</p>\n\n## Related Projects\n\n> **Building advanced AI agents?** Check out [pydantic-deep](https://github.com/vstorm-co/pydantic-deepagents) - a deep agent framework built on pydantic-ai with planning, filesystem, and subagent capabilities.\n\n---\n\n## üéØ Why This Template\n\nBuilding AI/LLM applications requires more than just an API wrapper. You need:\n\n- **Type-safe AI agents** with tool/function calling\n- **Real-time streaming** responses via WebSocket\n- **Conversation persistence** and history management\n- **Production infrastructure** - auth, rate limiting, observability\n- **Enterprise integrations** - background tasks, webhooks, admin panels\n\nThis template gives you all of that out of the box, with **20+ configurable integrations** so you can focus on building your AI product, not boilerplate.\n\n### Perfect For\n\n- ü§ñ **AI Chatbots & Assistants** - PydanticAI or LangChain agents with streaming responses\n- üìä **ML Applications** - Background task processing with Celery/Taskiq\n- üè¢ **Enterprise SaaS** - Full auth, admin panel, webhooks, and more\n- üöÄ **Startups** - Ship fast with production-ready infrastructure\n\n---\n\n## ‚ú® Features\n\n### ü§ñ AI/LLM First\n\n- **[PydanticAI](https://ai.pydantic.dev)** or **[LangChain](https://python.langchain.com)** - Choose your preferred AI framework\n- **WebSocket Streaming** - Real-time responses with full event access\n- **Conversation Persistence** - Save chat history to database\n- **Custom Tools** - Easily extend agent capabilities\n- **Multi-model Support** - OpenAI, Anthropic, and more\n- **Observability** - Logfire for PydanticAI, LangSmith for LangChain\n\n### ‚ö° Backend (FastAPI)\n\n- **[FastAPI](https://fastapi.tiangolo.com)** + **[Pydantic v2](https://docs.pydantic.dev)** - High-performance async API\n- **Multiple Databases** - PostgreSQL (async), MongoDB (async), SQLite\n- **Authentication** - JWT + Refresh tokens, API Keys, OAuth2 (Google)\n- **Background Tasks** - Celery, Taskiq, or ARQ\n- **Django-style CLI** - Custom management commands with auto-discovery\n\n### üé® Frontend (Next.js 15)\n\n- **React 19** + **TypeScript** + **Tailwind CSS v4**\n- **AI Chat Interface** - WebSocket streaming, tool call visualization\n- **Authentication** - HTTP-only cookies, auto-refresh\n- **Dark Mode** + **i18n** (optional)\n\n### üîå 20+ Enterprise Integrations\n\n| Category | Integrations |\n|----------|-------------|\n| **AI Frameworks** | PydanticAI, LangChain |\n| **Caching & State** | Redis, fastapi-cache2 |\n| **Security** | Rate limiting, CORS, CSRF protection |\n| **Observability** | Logfire, LangSmith, Sentry, Prometheus |\n| **Admin** | SQLAdmin panel with auth |\n| **Events** | Webhooks, WebSockets |\n| **DevOps** | Docker, GitHub Actions, GitLab CI, Kubernetes |\n\n---\n\n## üé¨ Demo\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/app_start.gif\" alt=\"FastAPI Fullstack Generator Demo\">\n</p>\n\n---\n\n## üöÄ Quick Start\n\n### Installation\n\n```bash\n# pip\npip install fastapi-fullstack\n\n# uv (recommended)\nuv tool install fastapi-fullstack\n\n# pipx\npipx install fastapi-fullstack\n```\n\n### Create Your Project\n\n```bash\n# Interactive wizard (recommended)\nfastapi-fullstack new\n\n# Quick mode with options\nfastapi-fullstack create my_ai_app \\\n  --database postgresql \\\n  --auth jwt \\\n  --frontend nextjs\n\n# Use presets for common setups\nfastapi-fullstack create my_ai_app --preset production   # Full production setup\nfastapi-fullstack create my_ai_app --preset ai-agent     # AI agent with streaming\n\n# Minimal project (no extras)\nfastapi-fullstack create my_ai_app --minimal\n```\n\n### Start Development\n\n#### Step 1: Install Dependencies\n\n```bash\ncd my_ai_app\nmake install\n```\n\n> **Windows Users:** The `make` command requires GNU Make which is not available by default on Windows.\n> You can either install Make via [Chocolatey](https://chocolatey.org/) (`choco install make`),\n> use WSL (Windows Subsystem for Linux), or use the raw commands from the\n> [Manual Commands Reference](#-manual-commands-reference-windows--no-make) section below.\n\n#### Step 2: Start the Database\n{%- if cookiecutter.use_postgresql %}\n\n```bash\n# Start PostgreSQL with Docker\nmake docker-db\n\n# Wait a few seconds for the database to be ready\n```\n{%- elif cookiecutter.use_mongodb %}\n\n```bash\n# Start MongoDB with Docker\ndocker-compose up -d mongo\n```\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\n#### Step 3: Create and Apply Database Migrations\n\nThe project uses Alembic for database migrations. After generating a new project, you need to create the initial migration:\n\n```bash\n# Create the initial migration (generates migration file based on your models)\nmake db-migrate\n# When prompted, enter a message like: \"Initial migration\"\n\n# Apply the migration to create tables\nmake db-upgrade\n```\n\n> **Note:** Run `make db-migrate` whenever you modify database models to generate new migrations.\n{%- endif %}\n\n{%- if cookiecutter.use_jwt %}\n\n#### Step 4: Create Admin User\n\n```bash\n# Create an admin user (required for SQLAdmin panel access)\nmake create-admin\n# Enter email and password when prompted\n```\n{%- endif %}\n\n#### Step 5: Start the Backend\n\n```bash\nmake run\n```\n\nThe API will be available at:\n- API: http://localhost:{{ cookiecutter.backend_port }}\n- Docs: http://localhost:{{ cookiecutter.backend_port }}/docs\n{%- if cookiecutter.enable_admin_panel %}\n- Admin Panel: http://localhost:{{ cookiecutter.backend_port }}/admin\n{%- endif %}\n\n{%- if cookiecutter.use_frontend %}\n\n#### Step 6: Start the Frontend (separate terminal)\n\n```bash\ncd frontend\nbun install\nbun dev\n```\n\nFrontend: http://localhost:{{ cookiecutter.frontend_port }}\n{%- endif %}\n\n---\n\n### Quick Start with Docker\n\nAlternatively, run everything with Docker:\n\n```bash\n# Start all backend services (API, database, Redis, etc.)\nmake docker-up\n\n{%- if cookiecutter.use_frontend %}\n# Start frontend (separate command)\nmake docker-frontend\n{%- endif %}\n```\n\n---\n\n### Using the Project CLI\n\nEach generated project includes a CLI tool named `{{ cookiecutter.project_slug }}`. Run commands from the `backend/` directory:\n\n```bash\ncd backend\n\n# Server commands\nuv run {{ cookiecutter.project_slug }} server run --reload     # Start dev server\nuv run {{ cookiecutter.project_slug }} server routes           # Show all routes\n\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n# Database commands\nuv run {{ cookiecutter.project_slug }} db migrate -m \"message\" # Create migration\nuv run {{ cookiecutter.project_slug }} db upgrade              # Apply migrations\nuv run {{ cookiecutter.project_slug }} db downgrade            # Rollback migration\n{%- endif %}\n\n{%- if cookiecutter.use_jwt %}\n# User commands\nuv run {{ cookiecutter.project_slug }} user create-admin       # Create admin user\nuv run {{ cookiecutter.project_slug }} user create             # Create regular user\nuv run {{ cookiecutter.project_slug }} user list               # List all users\n{%- endif %}\n```\n\nOr use Makefile shortcuts from the project root:\n\n```bash\nmake help          # Show all available commands\nmake run           # Start dev server\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\nmake db-migrate    # Create new migration\nmake db-upgrade    # Apply migrations\n{%- endif %}\n{%- if cookiecutter.use_jwt %}\nmake create-admin  # Create admin user\n{%- endif %}\n```\n\n**Access:**\n- API: http://localhost:8000\n- Docs: http://localhost:8000/docs\n- Admin Panel: http://localhost:8000/admin\n- Frontend: http://localhost:3000\n\n---\n\n## üì∏ Screenshots\n\n### Chat Interface\n| Light Mode | Dark Mode |\n|:---:|:---:|\n| ![Chat Light](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/new_chat_light.png) | ![Chat Dark](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/new_chat_dark.png) |\n\n### Authentication\n| Register | Login |\n|:---:|:---:|\n| ![Register](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/new_register.png) | ![Login](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/new_login.png) |\n\n### Observability\n| Logfire (PydanticAI) | LangSmith (LangChain) |\n|:---:|:---:|\n| ![Logfire](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/logfire.png) | ![LangSmith](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/langsmith.png) |\n\n### Admin, Monitoring & API\n| Celery Flower | SQLAdmin Panel |\n|:---:|:---:|\n| ![Flower](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/flower.png) | ![Admin](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/admin.png) |\n\n| API Documentation |\n|:---:|\n| ![API Docs](https://raw.githubusercontent.com/vstorm-co/full-stack-ai-agent-template/main/assets/docs_2.png) |\n\n---\n\n## üèóÔ∏è Architecture\n\n```mermaid\ngraph TB\n    subgraph Frontend[\"Frontend (Next.js 15)\"]\n        UI[React Components]\n        WS[WebSocket Client]\n        Store[Zustand Stores]\n    end\n\n    subgraph Backend[\"Backend (FastAPI)\"]\n        API[API Routes]\n        Services[Services Layer]\n        Repos[Repositories]\n        Agent[AI Agent]\n    end\n\n    subgraph Infrastructure\n        DB[(PostgreSQL/MongoDB)]\n        Redis[(Redis)]\n        Queue[Celery/Taskiq]\n    end\n\n    subgraph External\n        LLM[OpenAI/Anthropic]\n        Webhook[Webhook Endpoints]\n    end\n\n    UI --> API\n    WS <--> Agent\n    API --> Services\n    Services --> Repos\n    Services --> Agent\n    Repos --> DB\n    Agent --> LLM\n    Services --> Redis\n    Services --> Queue\n    Services --> Webhook\n```\n\n### Layered Architecture\n\nThe backend follows a clean **Repository + Service** pattern:\n\n```mermaid\ngraph LR\n    A[API Routes] --> B[Services]\n    B --> C[Repositories]\n    C --> D[(Database)]\n\n    B --> E[External APIs]\n    B --> F[AI Agents]\n```\n\n| Layer | Responsibility |\n|-------|---------------|\n| **Routes** | HTTP handling, validation, auth |\n| **Services** | Business logic, orchestration |\n| **Repositories** | Data access, queries |\n\nSee [Architecture Documentation](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/architecture.md) for details.\n\n---\n\n## ü§ñ AI Agent\n\nChoose between **PydanticAI** or **LangChain** when generating your project, with support for multiple LLM providers:\n\n```bash\n# PydanticAI with OpenAI (default)\nfastapi-fullstack create my_app --ai-agent --ai-framework pydantic_ai\n\n# PydanticAI with Anthropic\nfastapi-fullstack create my_app --ai-agent --ai-framework pydantic_ai --llm-provider anthropic\n\n# PydanticAI with OpenRouter\nfastapi-fullstack create my_app --ai-agent --ai-framework pydantic_ai --llm-provider openrouter\n\n# LangChain with OpenAI\nfastapi-fullstack create my_app --ai-agent --ai-framework langchain\n\n# LangChain with Anthropic\nfastapi-fullstack create my_app --ai-agent --ai-framework langchain --llm-provider anthropic\n```\n\n### Supported LLM Providers\n\n| Framework | OpenAI | Anthropic | OpenRouter |\n|-----------|:------:|:---------:|:----------:|\n| **PydanticAI** | ‚úì | ‚úì | ‚úì |\n| **LangChain** | ‚úì | ‚úì | - |\n\n### PydanticAI Integration\n\nType-safe agents with full dependency injection:\n\n```python\n# app/agents/assistant.py\nfrom pydantic_ai import Agent, RunContext\n\n@dataclass\nclass Deps:\n    user_id: str | None = None\n    db: AsyncSession | None = None\n\nagent = Agent[Deps, str](\n    model=\"openai:gpt-4o-mini\",\n    system_prompt=\"You are a helpful assistant.\",\n)\n\n@agent.tool\nasync def search_database(ctx: RunContext[Deps], query: str) -> list[dict]:\n    \"\"\"Search the database for relevant information.\"\"\"\n    # Access user context and database via ctx.deps\n    ...\n```\n\n### LangChain Integration\n\nFlexible agents with LangGraph:\n\n```python\n# app/agents/langchain_assistant.py\nfrom langchain.tools import tool\nfrom langgraph.prebuilt import create_react_agent\n\n@tool\ndef search_database(query: str) -> list[dict]:\n    \"\"\"Search the database for relevant information.\"\"\"\n    ...\n\nagent = create_react_agent(\n    model=ChatOpenAI(model=\"gpt-4o-mini\"),\n    tools=[search_database],\n    prompt=\"You are a helpful assistant.\",\n)\n```\n\n### WebSocket Streaming\n\nBoth frameworks use the same WebSocket endpoint with real-time streaming:\n\n```python\n@router.websocket(\"/ws\")\nasync def agent_ws(websocket: WebSocket):\n    await websocket.accept()\n\n    # Works with both PydanticAI and LangChain\n    async for event in agent.stream(user_input):\n        await websocket.send_json({\n            \"type\": \"text_delta\",\n            \"content\": event.content\n        })\n```\n\n### Observability\n\nEach framework has its own observability solution:\n\n| Framework | Observability | Dashboard |\n|-----------|--------------|-----------|\n| **PydanticAI** | [Logfire](https://logfire.pydantic.dev) | Agent runs, tool calls, token usage |\n| **LangChain** | [LangSmith](https://smith.langchain.com) | Traces, feedback, datasets |\n\nSee [AI Agent Documentation](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/ai-agent.md) for more.\n\n---\n\n## üìä Observability\n\n### Logfire (for PydanticAI)\n\n[Logfire](https://logfire.pydantic.dev) provides complete observability for your application - from AI agents to database queries. Built by the Pydantic team, it offers first-class support for the entire Python ecosystem.\n\n```mermaid\ngraph LR\n    subgraph Your App\n        API[FastAPI]\n        Agent[PydanticAI]\n        DB[(Database)]\n        Cache[(Redis)]\n        Queue[Celery/Taskiq]\n        HTTP[HTTPX]\n    end\n\n    subgraph Logfire\n        Traces[Traces]\n        Metrics[Metrics]\n        Logs[Logs]\n    end\n\n    API --> Traces\n    Agent --> Traces\n    DB --> Traces\n    Cache --> Traces\n    Queue --> Traces\n    HTTP --> Traces\n```\n\n| Component | What You See |\n|-----------|-------------|\n| **PydanticAI** | Agent runs, tool calls, LLM requests, token usage, streaming events |\n| **FastAPI** | Request/response traces, latency, status codes, route performance |\n| **PostgreSQL/MongoDB** | Query execution time, slow queries, connection pool stats |\n| **Redis** | Cache hits/misses, command latency, key patterns |\n| **Celery/Taskiq** | Task execution, queue depth, worker performance |\n| **HTTPX** | External API calls, response times, error rates |\n\n### LangSmith (for LangChain)\n\n[LangSmith](https://smith.langchain.com) provides observability specifically designed for LangChain applications:\n\n| Feature | Description |\n|---------|-------------|\n| **Traces** | Full execution traces for agent runs and chains |\n| **Feedback** | Collect user feedback on agent responses |\n| **Datasets** | Build evaluation datasets from production data |\n| **Monitoring** | Track latency, errors, and token usage |\n\nLangSmith is automatically configured when you choose LangChain:\n\n```bash\n# .env\nLANGCHAIN_TRACING_V2=true\nLANGCHAIN_API_KEY=your-api-key\nLANGCHAIN_PROJECT=my_project\n```\n\n### Configuration\n\nEnable Logfire and select which components to instrument:\n\n```bash\nfastapi-fullstack new\n# ‚úì Enable Logfire observability\n#   ‚úì Instrument FastAPI\n#   ‚úì Instrument Database\n#   ‚úì Instrument Redis\n#   ‚úì Instrument Celery\n#   ‚úì Instrument HTTPX\n```\n\n### Usage\n\n```python\n# Automatic instrumentation in app/main.py\nimport logfire\n\nlogfire.configure()\nlogfire.instrument_fastapi(app)\nlogfire.instrument_asyncpg()\nlogfire.instrument_redis()\nlogfire.instrument_httpx()\n```\n\n```python\n# Manual spans for custom logic\nwith logfire.span(\"process_order\", order_id=order.id):\n    await validate_order(order)\n    await charge_payment(order)\n    await send_confirmation(order)\n```\n\nFor more details, see [Logfire Documentation](https://logfire.pydantic.dev/docs/integrations/).\n\n{%- if cookiecutter.enable_prometheus %}\n\n---\n\n## üìà Prometheus Metrics\n\nThis project includes Prometheus metrics for monitoring and alerting.\n\n### Accessing Metrics\n\nMetrics are exposed at the `/metrics` endpoint:\n\n```bash\ncurl http://localhost:{{ cookiecutter.backend_port }}/metrics\n```\n\n### Available Metrics\n\n| Metric | Type | Description |\n|--------|------|-------------|\n| `http_requests_total` | Counter | Total HTTP requests by method, path, status |\n| `http_request_duration_seconds` | Histogram | Request latency distribution |\n| `http_requests_inprogress` | Gauge | Currently in-flight requests |\n| `http_request_size_bytes` | Histogram | Request body size |\n| `http_response_size_bytes` | Histogram | Response body size |\n\n### Prometheus Configuration\n\nAdd to your `prometheus.yml`:\n\n```yaml\nscrape_configs:\n  - job_name: '{{ cookiecutter.project_slug }}'\n    static_configs:\n      - targets: ['localhost:{{ cookiecutter.backend_port }}']\n    metrics_path: /metrics\n    scrape_interval: 15s\n```\n\n### Docker Labels\n\nWhen running with Docker, the service includes labels for Prometheus service discovery:\n\n```yaml\nlabels:\n  - \"prometheus.scrape=true\"\n  - \"prometheus.port={{ cookiecutter.backend_port }}\"\n  - \"prometheus.path=/metrics\"\n```\n\n### Environment Variables\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `PROMETHEUS_METRICS_PATH` | `/metrics` | Endpoint path for metrics |\n| `PROMETHEUS_INCLUDE_IN_SCHEMA` | `false` | Include in OpenAPI schema |\n{%- endif %}\n\n{%- if cookiecutter.use_arq %}\n\n---\n\n## ‚ö° Background Tasks (ARQ)\n\nThis project uses [ARQ](https://arq-docs.helpmanual.io/) (Async Redis Queue) for background task processing.\n\n### Starting the Worker\n\n```bash\n# Using the CLI\ncd backend\narq app.worker.arq_app.WorkerSettings\n\n# Using Docker\ndocker-compose up -d arq_worker\n```\n\n### Enqueueing Tasks\n\n```python\nfrom arq.connections import ArqRedis, create_pool\nfrom app.core.config import settings\n\n# Create a connection pool\nredis = await create_pool(RedisSettings(\n    host=settings.ARQ_REDIS_HOST,\n    port=settings.ARQ_REDIS_PORT,\n    database=settings.ARQ_REDIS_DB,\n))\n\n# Enqueue a task\nawait redis.enqueue_job('example_task', 'Hello, World!')\n\n# Enqueue with delay\nfrom datetime import timedelta\nawait redis.enqueue_job('example_task', 'Delayed message', _defer_by=timedelta(minutes=5))\n```\n\n### Creating New Tasks\n\nAdd tasks to `app/worker/arq_app.py`:\n\n```python\nasync def my_task(ctx: dict, arg1: str, arg2: int) -> dict:\n    \"\"\"My custom background task.\"\"\"\n    # ctx contains: redis connection, job_id, job_try, etc.\n    result = await do_something(arg1, arg2)\n    return {\"status\": \"completed\", \"result\": result}\n\n# Register in WorkerSettings.functions list\nclass WorkerSettings:\n    functions = [\n        example_task,\n        my_task,  # Add your task here\n    ]\n```\n\n### Scheduled Tasks (Cron)\n\n```python\nfrom arq import cron\n\nclass WorkerSettings:\n    cron_jobs = [\n        cron(my_scheduled_task, minute=0, hour=0),  # Daily at midnight\n        cron(my_scheduled_task, minute={0, 30}),     # Every 30 minutes\n    ]\n```\n\n### Environment Variables\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `ARQ_REDIS_HOST` | `localhost` | Redis host |\n| `ARQ_REDIS_PORT` | `6379` | Redis port |\n| `ARQ_REDIS_PASSWORD` | `None` | Redis password |\n| `ARQ_REDIS_DB` | `2` | Redis database number |\n{%- endif %}\n\n{%- if cookiecutter.enable_kubernetes %}\n\n---\n\n## ‚ò∏Ô∏è Kubernetes Deployment\n\nThis project includes Kubernetes manifests for production deployment.\n\n### Quick Deploy\n\n```bash\n# Using kustomize (recommended)\nkubectl apply -k kubernetes/\n\n# Or apply individually\nkubectl apply -f kubernetes/namespace.yaml\nkubectl apply -f kubernetes/configmap.yaml\nkubectl apply -f kubernetes/secret.yaml\nkubectl apply -f kubernetes/deployment.yaml\nkubectl apply -f kubernetes/service.yaml\nkubectl apply -f kubernetes/ingress.yaml\n```\n\n### Manifest Files\n\n| File | Description |\n|------|-------------|\n| `namespace.yaml` | Creates dedicated namespace |\n| `configmap.yaml` | Non-sensitive configuration |\n| `secret.yaml` | Sensitive data (passwords, API keys) |\n| `deployment.yaml` | Backend + worker deployments |\n| `service.yaml` | ClusterIP service for backend |\n| `ingress.yaml` | External access with nginx ingress |\n| `kustomization.yaml` | Kustomize configuration |\n\n### Before Deploying\n\n1. **Update secrets** in `kubernetes/secret.yaml`:\n   ```bash\n   # Generate a secure SECRET_KEY\n   openssl rand -hex 32\n   ```\n\n2. **Configure ingress** in `kubernetes/ingress.yaml`:\n   - Replace `api.example.com` with your domain\n   - Uncomment TLS section for HTTPS\n\n3. **Build and push Docker image**:\n   ```bash\n   docker build -t your-registry/{{ cookiecutter.project_slug }}:latest ./backend\n   docker push your-registry/{{ cookiecutter.project_slug }}:latest\n   ```\n\n4. **Update image** in `kubernetes/kustomization.yaml`:\n   ```yaml\n   images:\n     - name: {{ cookiecutter.project_slug }}\n       newName: your-registry/{{ cookiecutter.project_slug }}\n       newTag: latest\n   ```\n\n### Scaling\n\n```bash\n# Scale backend replicas\nkubectl scale deployment {{ cookiecutter.project_slug }}-backend -n {{ cookiecutter.project_slug }} --replicas=3\n\n# View pods\nkubectl get pods -n {{ cookiecutter.project_slug }}\n\n# View logs\nkubectl logs -f deployment/{{ cookiecutter.project_slug }}-backend -n {{ cookiecutter.project_slug }}\n```\n\n### Using with Helm (optional)\n\nFor more advanced deployments, consider creating a Helm chart based on these manifests.\n{%- endif %}\n\n---\n\n## üõ†Ô∏è Django-style CLI\n\nEach generated project includes a powerful CLI inspired by Django's management commands. The CLI name matches your project slug (e.g., if your project is `my_app`, the CLI command is `uv run my_app`).\n\n### Built-in Commands\n\n```bash\n# Run commands from the backend directory:\ncd backend\n\n# Server\nuv run {{ cookiecutter.project_slug }} server run --reload\nuv run {{ cookiecutter.project_slug }} server routes\n\n# Database (Alembic wrapper)\nuv run {{ cookiecutter.project_slug }} db init\nuv run {{ cookiecutter.project_slug }} db migrate -m \"Add users\"\nuv run {{ cookiecutter.project_slug }} db upgrade\n\n# Users\nuv run {{ cookiecutter.project_slug }} user create-admin       # Create admin (interactive)\nuv run {{ cookiecutter.project_slug }} user create             # Create user (interactive)\nuv run {{ cookiecutter.project_slug }} user list               # List all users\n```\n\n> **Tip:** Use `make` commands as shortcuts - they handle the `uv run` prefix and directory automatically. Run `make help` to see all available commands.\n\n### Custom Commands\n\nCreate your own commands with auto-discovery:\n\n```python\n# app/commands/seed.py\nfrom app.commands import command, success, error\nimport click\n\n@command(\"seed\", help=\"Seed database with test data\")\n@click.option(\"--count\", \"-c\", default=10, type=int)\n@click.option(\"--dry-run\", is_flag=True)\ndef seed_database(count: int, dry_run: bool):\n    \"\"\"Seed the database with sample data.\"\"\"\n    if dry_run:\n        info(f\"[DRY RUN] Would create {count} records\")\n        return\n\n    # Your logic here\n    success(f\"Created {count} records!\")\n```\n\nCommands are **automatically discovered** from `app/commands/` - just create a file and use the `@command` decorator.\n\n```bash\nuv run {{ cookiecutter.project_slug }} cmd seed --count 100\nuv run {{ cookiecutter.project_slug }} cmd seed --dry-run\n```\n\n---\n\n## üñ•Ô∏è Manual Commands Reference (Windows / No Make)\n\nIf you don't have `make` installed (common on Windows), use these commands directly.\nAll commands should be run from the project root directory.\n\n### Setup & Development\n\n| Task | Command |\n|------|---------|\n| Install dependencies | `uv sync --directory backend --dev` |\n| Start dev server | `uv run --directory backend {{ cookiecutter.project_slug }} server run --reload` |\n| Start prod server | `uv run --directory backend {{ cookiecutter.project_slug }} server run --host 0.0.0.0 --port {{ cookiecutter.backend_port }}` |\n| Show routes | `uv run --directory backend {{ cookiecutter.project_slug }} server routes` |\n\n### Code Quality\n\n| Task | Command |\n|------|---------|\n| Format code | `uv run --directory backend ruff format app tests cli` |\n| Fix lint issues | `uv run --directory backend ruff check app tests cli --fix` |\n| Check linting | `uv run --directory backend ruff check app tests cli` |\n| Type check | `uv run --directory backend mypy app` |\n\n### Testing\n\n| Task | Command |\n|------|---------|\n| Run tests | `uv run --directory backend pytest tests/ -v` |\n| Run with coverage | `uv run --directory backend pytest tests/ -v --cov=app --cov-report=term-missing` |\n\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\n### Database\n\n| Task | Command |\n|------|---------|\n| Create migration | `uv run --directory backend {{ cookiecutter.project_slug }} db migrate -m \"message\"` |\n| Apply migrations | `uv run --directory backend {{ cookiecutter.project_slug }} db upgrade` |\n| Rollback migration | `uv run --directory backend {{ cookiecutter.project_slug }} db downgrade` |\n| Show current | `uv run --directory backend {{ cookiecutter.project_slug }} db current` |\n| Show history | `uv run --directory backend {{ cookiecutter.project_slug }} db history` |\n{%- endif %}\n\n{%- if cookiecutter.use_jwt %}\n\n### Users\n\n| Task | Command |\n|------|---------|\n| Create admin | `uv run --directory backend {{ cookiecutter.project_slug }} user create-admin` |\n| Create user | `uv run --directory backend {{ cookiecutter.project_slug }} user create` |\n| List users | `uv run --directory backend {{ cookiecutter.project_slug }} user list` |\n{%- endif %}\n\n{%- if cookiecutter.use_celery %}\n\n### Celery\n\n| Task | Command |\n|------|---------|\n| Start worker | `uv run --directory backend {{ cookiecutter.project_slug }} celery worker` |\n| Start beat | `uv run --directory backend {{ cookiecutter.project_slug }} celery beat` |\n| Start flower | `uv run --directory backend {{ cookiecutter.project_slug }} celery flower` |\n{%- endif %}\n\n{%- if cookiecutter.use_taskiq %}\n\n### Taskiq\n\n| Task | Command |\n|------|---------|\n| Start worker | `uv run --directory backend {{ cookiecutter.project_slug }} taskiq worker` |\n| Start scheduler | `uv run --directory backend {{ cookiecutter.project_slug }} taskiq scheduler` |\n{%- endif %}\n\n{%- if cookiecutter.use_arq %}\n\n### ARQ\n\n| Task | Command |\n|------|---------|\n| Start worker | `arq app.worker.arq_app.WorkerSettings` (from backend/) |\n{%- endif %}\n\n{%- if cookiecutter.enable_docker %}\n\n### Docker\n\n| Task | Command |\n|------|---------|\n| Start all services | `docker-compose up -d` |\n| Stop all services | `docker-compose down` |\n| View logs | `docker-compose logs -f` |\n| Build images | `docker-compose build` |\n{%- if cookiecutter.use_postgresql %}\n| Start PostgreSQL only | `docker-compose up -d db` |\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n| Start Redis only | `docker-compose up -d redis` |\n{%- endif %}\n| Start production | `docker-compose -f docker-compose.prod.yml up -d` |\n{%- endif %}\n\n### Cleanup\n\n| Task | Command (Unix) | Command (Windows PowerShell) |\n|------|----------------|------------------------------|\n| Clean cache | `find . -type d -name __pycache__ -exec rm -rf {} +` | `Get-ChildItem -Recurse -Directory -Filter __pycache__ \\| Remove-Item -Recurse -Force` |\n\n---\n\n## üìÅ Generated Project Structure\n\n```\nmy_project/\n‚îú‚îÄ‚îÄ backend/\n‚îÇ   ‚îú‚îÄ‚îÄ app/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py              # FastAPI app with lifespan\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/v1/       # Versioned API endpoints\n‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deps.py          # Dependency injection\n‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ router.py        # Route aggregation\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/                # Config, security, middleware\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db/models/           # SQLAlchemy/MongoDB models\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/             # Pydantic schemas\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repositories/        # Data access layer\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/            # Business logic\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agents/              # AI agents with centralized prompts\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commands/            # Django-style CLI commands\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ worker/              # Background tasks\n‚îÇ   ‚îú‚îÄ‚îÄ cli/                     # Project CLI\n‚îÇ   ‚îú‚îÄ‚îÄ tests/                   # pytest test suite\n‚îÇ   ‚îî‚îÄ‚îÄ alembic/                 # Database migrations\n‚îú‚îÄ‚îÄ frontend/\n‚îÇ   ‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/                 # Next.js App Router\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/          # React components\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/               # useChat, useWebSocket, etc.\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stores/              # Zustand state management\n‚îÇ   ‚îî‚îÄ‚îÄ e2e/                     # Playwright tests\n‚îú‚îÄ‚îÄ docker-compose.yml\n‚îú‚îÄ‚îÄ Makefile\n‚îî‚îÄ‚îÄ README.md\n```\n\nGenerated projects include version metadata in `pyproject.toml` for tracking:\n\n```toml\n[tool.fastapi-fullstack]\ngenerator_version = \"0.1.5\"\ngenerated_at = \"2024-12-21T10:30:00+00:00\"\n```\n\n---\n\n## ‚öôÔ∏è Configuration Options\n\n### Core Options\n\n| Option | Values | Description |\n|--------|--------|-------------|\n| **Database** | `postgresql`, `mongodb`, `sqlite`, `none` | Async by default |\n| **Auth** | `jwt`, `api_key`, `both`, `none` | JWT includes user management |\n| **OAuth** | `none`, `google` | Social login |\n| **AI Framework** | `pydantic_ai`, `langchain` | Choose your AI agent framework |\n| **LLM Provider** | `openai`, `anthropic`, `openrouter` | OpenRouter only with PydanticAI |\n| **Background Tasks** | `none`, `celery`, `taskiq`, `arq` | Distributed queues |\n| **Frontend** | `none`, `nextjs` | Next.js 15 + React 19 |\n\n### Presets\n\n| Preset | Description |\n|--------|-------------|\n| `--preset production` | Full production setup with Redis, Sentry, Kubernetes, Prometheus |\n| `--preset ai-agent` | AI agent with WebSocket streaming and conversation persistence |\n| `--minimal` | Minimal project with no extras |\n\n### Integrations\n\nSelect what you need:\n\n```bash\nfastapi-fullstack new\n# ‚úì Redis (caching/sessions)\n# ‚úì Rate limiting (slowapi)\n# ‚úì Pagination (fastapi-pagination)\n# ‚úì Admin Panel (SQLAdmin)\n# ‚úì AI Agent (PydanticAI or LangChain)\n# ‚úì Webhooks\n# ‚úì Sentry\n# ‚úì Logfire / LangSmith\n# ‚úì Prometheus\n# ... and more\n```\n\n---\n\n## üìö Documentation\n\n| Document | Description |\n|----------|-------------|\n| [Architecture](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/architecture.md) | Repository + Service pattern, layered design |\n| [Frontend](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/frontend.md) | Next.js setup, auth, state management |\n| [AI Agent](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/ai-agent.md) | PydanticAI, tools, WebSocket streaming |\n| [Observability](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/observability.md) | Logfire integration, tracing, metrics |\n| [Deployment](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/deployment.md) | Docker, Kubernetes, production setup |\n| [Development](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/docs/development.md) | Local setup, testing, debugging |\n\n---\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=vstorm-co/full-stack-ai-agent-template&type=date&legend=top-left)](https://www.star-history.com/#vstorm-co/full-stack-ai-agent-template&type=date&legend=top-left)\n\n---\n\n## üôè Inspiration\n\nThis project is inspired by:\n\n- [full-stack-fastapi-template](https://github.com/fastapi/full-stack-fastapi-template) by @tiangolo\n- [fastapi-template](https://github.com/s3rius/fastapi-template) by @s3rius\n- [FastAPI Best Practices](https://github.com/zhanymkanov/fastapi-best-practices) by @zhanymkanov\n- Django's management commands system\n\n---\n\n## ü§ù Contributing\n\nContributions are welcome! Please read our [Contributing Guide](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/CONTRIBUTING.md) for details.\n\n---\n\n## üìÑ License\n\nMIT License - see [LICENSE](https://github.com/vstorm-co/full-stack-ai-agent-template/blob/main/LICENSE) for details.\n\n---\n\n<p align=\"center\">\n  Made with ‚ù§Ô∏è by <a href=\"https://github.com/vstorm-co\">VStorm</a>\n</p>\n",".gitignore":"# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\n# Python lib directories (but not frontend src/lib)\n/lib/\n/lib64/\nparts/\nsdist/\nvar/\nwheels/\n*.egg-info/\n.installed.cfg\n*.egg\n\n# PyInstaller\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Environments\n.env\n.env.local\n.env.*.local\n.env.prod\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# IDE\n.idea/\n.vscode/\n*.swp\n*.swo\n*~\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# ruff\n.ruff_cache/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# pytype\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# Local development\n*.db\n*.sqlite\n*.sqlite3\n\n# Logs\n*.log\nlogs/\n\n# Docker\n.docker/\n\n# OS\n.DS_Store\nThumbs.db\n\n# Project specific\n{%- if cookiecutter.use_sqlite %}\n{{ cookiecutter.project_slug }}.db\n{%- endif %}\n","nginx/ssl/.gitkeep":"# SSL Certificates Directory\n#\n# Place your SSL certificates here:\n# - cert.pem (certificate chain)\n# - key.pem (private key)\n#\n# For Let's Encrypt with certbot:\n# certbot certonly --standalone -d api.yourdomain.com -d yourdomain.com\n#\n# Then copy certificates:\n# cp /etc/letsencrypt/live/yourdomain.com/fullchain.pem nginx/ssl/cert.pem\n# cp /etc/letsencrypt/live/yourdomain.com/privkey.pem nginx/ssl/key.pem\n#\n# For development, you can generate self-signed certificates:\n# openssl req -x509 -nodes -days 365 -newkey rsa:2048 \\\n#   -keyout nginx/ssl/key.pem \\\n#   -out nginx/ssl/cert.pem \\\n#   -subj \"/CN=localhost\"\n","nginx/nginx.conf":"# =============================================================================\n# Nginx Configuration for {{ cookiecutter.project_name }}\n# Generated by fastapi-fullstack\n# =============================================================================\n#\n# This configuration provides:\n# - Reverse proxy for backend API (api.DOMAIN)\n{% if cookiecutter.use_frontend %}\n# - Reverse proxy for frontend (DOMAIN)\n{% endif %}\n{% if cookiecutter.use_celery %}\n# - Reverse proxy for Flower dashboard (flower.DOMAIN)\n{% endif %}\n# - WebSocket support for /ws endpoint\n# - Security headers\n# - HTTP to HTTPS redirect\n#\n# SSL Certificates:\n# Place your SSL certificates in the nginx/ssl/ directory:\n# - nginx/ssl/cert.pem (certificate)\n# - nginx/ssl/key.pem (private key)\n#\n# For Let's Encrypt with certbot:\n# certbot certonly --webroot -w /var/www/certbot -d api.yourdomain.com -d yourdomain.com\n# =============================================================================\n\n# Upstream definitions\nupstream backend {\n    server backend:{{ cookiecutter.backend_port }};\n}\n\n{% if cookiecutter.use_frontend %}\nupstream frontend {\n    server frontend:{{ cookiecutter.frontend_port }};\n}\n\n{% endif %}\n{% if cookiecutter.use_celery %}\nupstream flower {\n    server flower:5555;\n}\n\n{% endif %}\n# =============================================================================\n# HTTP Server - Redirect to HTTPS\n# =============================================================================\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name _;\n\n    # Let's Encrypt ACME challenge\n    location /.well-known/acme-challenge/ {\n        root /var/www/certbot;\n    }\n\n    # Redirect all other HTTP traffic to HTTPS\n    location / {\n        return 301 https://$host$request_uri;\n    }\n}\n\n# =============================================================================\n# HTTPS Server - Backend API (api.DOMAIN)\n# =============================================================================\nserver {\n    listen 443 ssl;\n    listen [::]:443 ssl;\n    http2 on;\n    server_name api.${DOMAIN:-localhost};\n\n    # SSL Configuration\n    ssl_certificate /etc/nginx/ssl/cert.pem;\n    ssl_certificate_key /etc/nginx/ssl/key.pem;\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;\n    ssl_prefer_server_ciphers off;\n    ssl_session_timeout 1d;\n    ssl_session_cache shared:SSL:50m;\n    ssl_stapling on;\n    ssl_stapling_verify on;\n\n    # Security Headers\n    add_header X-Frame-Options \"SAMEORIGIN\" always;\n    add_header X-Content-Type-Options \"nosniff\" always;\n    add_header X-XSS-Protection \"1; mode=block\" always;\n    add_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\n    add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always;\n\n    # Proxy settings\n    proxy_http_version 1.1;\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_set_header X-Forwarded-Host $host;\n    proxy_set_header X-Forwarded-Port $server_port;\n\n    # WebSocket support for /ws endpoint\n    location /ws {\n        proxy_pass http://backend;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_read_timeout 86400;\n        proxy_send_timeout 86400;\n    }\n\n    # API endpoints\n    location / {\n        proxy_pass http://backend;\n        proxy_buffering off;\n        proxy_request_buffering off;\n\n        # Timeouts\n        proxy_connect_timeout 60s;\n        proxy_send_timeout 60s;\n        proxy_read_timeout 60s;\n    }\n}\n\n{% if cookiecutter.use_frontend %}\n# =============================================================================\n# HTTPS Server - Frontend (DOMAIN)\n# =============================================================================\nserver {\n    listen 443 ssl;\n    listen [::]:443 ssl;\n    http2 on;\n    server_name ${DOMAIN:-localhost};\n\n    # SSL Configuration\n    ssl_certificate /etc/nginx/ssl/cert.pem;\n    ssl_certificate_key /etc/nginx/ssl/key.pem;\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;\n    ssl_prefer_server_ciphers off;\n    ssl_session_timeout 1d;\n    ssl_session_cache shared:SSL:50m;\n\n    # Security Headers\n    add_header X-Frame-Options \"SAMEORIGIN\" always;\n    add_header X-Content-Type-Options \"nosniff\" always;\n    add_header X-XSS-Protection \"1; mode=block\" always;\n    add_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\n    add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always;\n\n    # Proxy settings\n    proxy_http_version 1.1;\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n\n    # Frontend application\n    location / {\n        proxy_pass http://frontend;\n        proxy_buffering off;\n\n        # Timeouts\n        proxy_connect_timeout 60s;\n        proxy_send_timeout 60s;\n        proxy_read_timeout 60s;\n    }\n\n    # Next.js HMR WebSocket (development)\n    location /_next/webpack-hmr {\n        proxy_pass http://frontend;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n    }\n}\n\n{% endif %}\n{% if cookiecutter.use_celery %}\n# =============================================================================\n# HTTPS Server - Flower Dashboard (flower.DOMAIN)\n# =============================================================================\nserver {\n    listen 443 ssl;\n    listen [::]:443 ssl;\n    http2 on;\n    server_name flower.${DOMAIN:-localhost};\n\n    # SSL Configuration\n    ssl_certificate /etc/nginx/ssl/cert.pem;\n    ssl_certificate_key /etc/nginx/ssl/key.pem;\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;\n    ssl_prefer_server_ciphers off;\n    ssl_session_timeout 1d;\n    ssl_session_cache shared:SSL:50m;\n\n    # Security Headers\n    add_header X-Frame-Options \"SAMEORIGIN\" always;\n    add_header X-Content-Type-Options \"nosniff\" always;\n    add_header X-XSS-Protection \"1; mode=block\" always;\n    add_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\n    add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always;\n\n    # Proxy settings\n    proxy_http_version 1.1;\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n\n    # Flower dashboard\n    location / {\n        proxy_pass http://flower;\n        proxy_buffering off;\n\n        # Timeouts\n        proxy_connect_timeout 60s;\n        proxy_send_timeout 60s;\n        proxy_read_timeout 60s;\n    }\n}\n\n{% endif %}\n",".env.prod.example":"{%- if cookiecutter.enable_docker %}\n# {{ cookiecutter.project_name }} - Production Environment\n# Generated by fastapi-fullstack v{{ cookiecutter.generator_version }}\n#\n# IMPORTANT: Copy this file to .env.prod before deploying\n#   cp .env.prod.example .env.prod\n#\n# WARNING: Never commit .env.prod to version control!\n\n# === Container Prefix (must be unique per server) ===\nCONTAINER_PREFIX={{ cookiecutter.project_slug }}\n\n{%- if cookiecutter.include_traefik_labels %}\n\n# === Domain Configuration ===\nDOMAIN=example.com\nACME_EMAIL=admin@example.com\n{%- endif %}\n\n{%- if cookiecutter.use_nginx %}\n\n# === Domain Configuration ===\nDOMAIN=example.com\n# Note: Place SSL certificates in nginx/ssl/ directory:\n#   - nginx/ssl/cert.pem (certificate chain)\n#   - nginx/ssl/key.pem (private key)\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\n\n# === PostgreSQL ===\nPOSTGRES_USER=postgres\nPOSTGRES_PASSWORD=  # Generate: openssl rand -base64 32\nPOSTGRES_DB={{ cookiecutter.project_slug }}\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n\n# === Redis ===\nREDIS_PASSWORD=  # Generate: openssl rand -base64 32\n{%- endif %}\n\n{%- if cookiecutter.use_jwt %}\n\n# === JWT Secret ===\nSECRET_KEY=  # Generate: openssl rand -hex 32\n{%- endif %}\n\n{%- if cookiecutter.include_traefik_service %}\n\n# === Traefik Dashboard ===\n# Generate with: htpasswd -nb admin yourpassword\n# Example: admin:$apr1$xyz$hash\nTRAEFIK_DASHBOARD_AUTH=\n{%- endif %}\n\n{%- if cookiecutter.use_celery %}\n\n# === Flower Monitoring ===\nFLOWER_USER=admin\nFLOWER_PASSWORD=  # Generate: openssl rand -base64 16\n{%- endif %}\n{%- else %}\n# Docker is disabled for this project\n{%- endif %}\n",".github/workflows/ci.yml":"{%- if cookiecutter.use_github_actions %}\nname: CI\n\non:\n  push:\n    branches: [main, master]\n  pull_request:\n    branches: [main, master]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v4\n        with:\n          version: \"latest\"\n\n      - name: Set up Python\n        run: uv python install {{ cookiecutter.python_version }}\n\n      - name: Install dependencies\n        run: uv sync --directory backend --dev\n\n      - name: Run ruff check\n        run: uv run --directory backend ruff check app tests cli\n\n      - name: Run ruff format check\n        run: uv run --directory backend ruff format app tests cli --check\n\n      - name: Run mypy\n        run: uv run --directory backend mypy app\n\n  test:\n    runs-on: ubuntu-latest\n{%- if cookiecutter.use_postgresql or cookiecutter.enable_redis %}\n    services:\n{%- if cookiecutter.use_postgresql %}\n      postgres:\n        image: postgres:16-alpine\n        env:\n          POSTGRES_USER: postgres\n          POSTGRES_PASSWORD: postgres\n          POSTGRES_DB: test_db\n        ports:\n          - 5432:5432\n        options: >-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n      redis:\n        image: redis:7-alpine\n        ports:\n          - 6379:6379\n        options: >-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n{%- endif %}\n{%- endif %}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v4\n        with:\n          version: \"latest\"\n\n      - name: Set up Python\n        run: uv python install {{ cookiecutter.python_version }}\n\n      - name: Install dependencies\n        run: uv sync --directory backend --dev\n\n      - name: Run tests\n        run: uv run --directory backend pytest tests/ -v --cov=app --cov-report=xml\n        env:\n{%- if cookiecutter.use_postgresql %}\n          POSTGRES_HOST: localhost\n          POSTGRES_PORT: 5432\n          POSTGRES_USER: postgres\n          POSTGRES_PASSWORD: postgres\n          POSTGRES_DB: test_db\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n          REDIS_HOST: localhost\n          REDIS_PORT: 6379\n{%- endif %}\n\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v4\n        with:\n          files: ./backend/coverage.xml\n          fail_ci_if_error: false\n\n  security:\n    name: Security Scan\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install uv\n        uses: astral-sh/setup-uv@v4\n        with:\n          version: \"latest\"\n\n      - name: Set up Python\n        run: uv python install {{ cookiecutter.python_version }}\n\n      - name: Install dependencies\n        run: uv sync --directory backend --dev\n\n      - name: Install pip-audit\n        run: uv pip install pip-audit\n\n      - name: Run pip-audit\n        run: uv run pip-audit --require-hashes=false --progress-spinner=off\n        working-directory: backend\n\n{%- if cookiecutter.enable_docker %}\n\n  docker:\n    runs-on: ubuntu-latest\n    needs: [lint, test]\n    if: github.event_name == 'push' && github.ref == 'refs/heads/main'\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Build Docker image\n        uses: docker/build-push-action@v6\n        with:\n          context: ./backend\n          push: false\n          tags: {{ cookiecutter.project_slug }}:latest\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n{%- endif %}\n{%- else %}\n# GitHub Actions CI is disabled for this project\n{%- endif %}\n","docker-compose.yml":"{%- if cookiecutter.enable_docker %}\n# Backend development configuration\n# Usage: docker-compose up -d\n\nservices:\n  app:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_backend\n    ports:\n      - \"{{ cookiecutter.backend_port }}:{{ cookiecutter.backend_port }}\"\n    volumes:\n      - ./backend/app:/app/app:ro\n      - ./backend/cli:/app/cli:ro\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n      - ENVIRONMENT=local\n{%- if cookiecutter.use_postgresql %}\n      - POSTGRES_HOST=db\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n      - REDIS_HOST=redis\n{%- endif %}\n{%- if cookiecutter.use_celery %}\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/0\n{%- endif %}\n{%- if cookiecutter.use_taskiq %}\n      - TASKIQ_BROKER_URL=redis://redis:6379/1\n      - TASKIQ_RESULT_BACKEND=redis://redis:6379/1\n{%- endif %}\n    command: uvicorn app.main:app --host 0.0.0.0 --port {{ cookiecutter.backend_port }} --reload\n    networks:\n      - backend\n{%- if cookiecutter.use_postgresql or cookiecutter.enable_redis %}\n    depends_on:\n{%- if cookiecutter.use_postgresql %}\n      db:\n        condition: service_healthy\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n      redis:\n        condition: service_healthy\n{%- endif %}\n{%- endif %}\n    restart: unless-stopped\n{%- if cookiecutter.enable_prometheus %}\n    labels:\n      - \"prometheus.scrape=true\"\n      - \"prometheus.port={{ cookiecutter.backend_port }}\"\n      - \"prometheus.path=/metrics\"\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\n\n  db:\n    image: postgres:16-alpine\n    container_name: {{ cookiecutter.project_slug }}_db\n    environment:\n      - POSTGRES_USER=${POSTGRES_USER:-postgres}\n      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}\n      - POSTGRES_DB=${POSTGRES_DB:-{{ cookiecutter.project_slug }}}\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    # Port exposed only for local development - remove in production\n    ports:\n      - \"5432:5432\"\n    networks:\n      - backend\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${POSTGRES_USER:-postgres}\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    restart: unless-stopped\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n\n  redis:\n    image: redis:7-alpine\n    container_name: {{ cookiecutter.project_slug }}_redis\n    # Port exposed only for local development - remove in production\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n    networks:\n      - backend\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    restart: unless-stopped\n{%- endif %}\n\n{%- if cookiecutter.use_celery %}\n\n  celery_worker:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_celery_worker\n    volumes:\n      - ./backend/app:/app/app:ro\n    command: celery -A app.worker.celery_app worker --loglevel=debug\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n{%- if cookiecutter.use_postgresql %}\n      - POSTGRES_HOST=db\n{%- endif %}\n      - REDIS_HOST=redis\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/0\n    networks:\n      - backend\n    depends_on:\n      redis:\n        condition: service_healthy\n{%- if cookiecutter.use_postgresql %}\n      db:\n        condition: service_healthy\n{%- endif %}\n    restart: unless-stopped\n\n  celery_beat:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_celery_beat\n    volumes:\n      - ./backend/app:/app/app:ro\n    command: celery -A app.worker.celery_app beat --loglevel=debug\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n      - REDIS_HOST=redis\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/0\n    networks:\n      - backend\n    depends_on:\n      redis:\n        condition: service_healthy\n    restart: unless-stopped\n\n  flower:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_flower\n    command: celery -A app.worker.celery_app flower --port=5555\n    ports:\n      - \"5555:5555\"\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n      - REDIS_HOST=redis\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/0\n    networks:\n      - backend\n    depends_on:\n      redis:\n        condition: service_healthy\n    restart: unless-stopped\n{%- endif %}\n\n{%- if cookiecutter.use_taskiq %}\n\n  taskiq_worker:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_taskiq_worker\n    volumes:\n      - ./backend/app:/app/app:ro\n    command: taskiq worker app.worker.taskiq_app:broker --workers 1 --reload\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n{%- if cookiecutter.use_postgresql %}\n      - POSTGRES_HOST=db\n{%- endif %}\n      - REDIS_HOST=redis\n      - TASKIQ_BROKER_URL=redis://redis:6379/1\n      - TASKIQ_RESULT_BACKEND=redis://redis:6379/1\n    networks:\n      - backend\n    depends_on:\n      redis:\n        condition: service_healthy\n{%- if cookiecutter.use_postgresql %}\n      db:\n        condition: service_healthy\n{%- endif %}\n    restart: unless-stopped\n\n  taskiq_scheduler:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_taskiq_scheduler\n    volumes:\n      - ./backend/app:/app/app:ro\n    command: taskiq scheduler app.worker.taskiq_app:scheduler\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n      - REDIS_HOST=redis\n      - TASKIQ_BROKER_URL=redis://redis:6379/1\n      - TASKIQ_RESULT_BACKEND=redis://redis:6379/1\n    networks:\n      - backend\n    depends_on:\n      redis:\n        condition: service_healthy\n    restart: unless-stopped\n{%- endif %}\n\n{%- if cookiecutter.use_arq %}\n\n  arq_worker:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_arq_worker\n    volumes:\n      - ./backend/app:/app/app:ro\n    command: arq app.worker.arq_app.WorkerSettings\n    env_file:\n      - ./backend/.env\n    environment:\n      - DEBUG=true\n{%- if cookiecutter.use_postgresql %}\n      - POSTGRES_HOST=db\n{%- endif %}\n      - REDIS_HOST=redis\n      - ARQ_REDIS_HOST=redis\n      - ARQ_REDIS_PORT=6379\n      - ARQ_REDIS_DB=2\n    networks:\n      - backend\n    depends_on:\n      redis:\n        condition: service_healthy\n{%- if cookiecutter.use_postgresql %}\n      db:\n        condition: service_healthy\n{%- endif %}\n    restart: unless-stopped\n{%- endif %}\n\nnetworks:\n  backend:\n    driver: bridge\n\n{%- if cookiecutter.use_postgresql or cookiecutter.enable_redis %}\n\nvolumes:\n{%- if cookiecutter.use_postgresql %}\n  postgres_data:\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n  redis_data:\n{%- endif %}\n{%- endif %}\n{%- else %}\n# Docker is disabled for this project\n{%- endif %}\n","docker-compose.prod.yml":"{%- if cookiecutter.enable_docker %}\n# Production configuration\n{%- if cookiecutter.include_traefik_service %}\n# with Traefik reverse proxy\n{%- elif cookiecutter.include_traefik_labels %}\n# with external Traefik (connect to traefik-public network)\n{%- elif cookiecutter.include_nginx_service %}\n# with Nginx reverse proxy\n{%- elif cookiecutter.include_nginx_config %}\n# with external Nginx (config template provided)\n{%- else %}\n# without reverse proxy (ports exposed directly)\n{%- endif %}\n#\n# Usage:\n#   1. Copy .env.prod.example to .env.prod and fill in values:\n#      cp .env.prod.example .env.prod\n#   2. Run: docker-compose -f docker-compose.prod.yml up -d\n{%- if cookiecutter.include_traefik_service %}\n#\n# Prerequisites:\n#   1. Configure .env.prod with DOMAIN and ACME_EMAIL\n#   2. Ensure ports 80 and 443 are available\n#   3. Generate passwords: openssl rand -base64 32\n{%- elif cookiecutter.include_traefik_labels %}\n#\n# Prerequisites:\n#   1. Create external traefik-public network: docker network create traefik-public\n#   2. Run your Traefik instance connected to traefik-public network\n#   3. Configure .env.prod with DOMAIN\n{%- elif cookiecutter.include_nginx_service %}\n#\n# Prerequisites:\n#   1. Place SSL certificates in nginx/ssl/ directory:\n#      - nginx/ssl/cert.pem (certificate)\n#      - nginx/ssl/key.pem (private key)\n#   2. Configure .env.prod with DOMAIN\n#   3. Ensure ports 80 and 443 are available\n{%- elif cookiecutter.include_nginx_config %}\n#\n# Prerequisites:\n#   1. Configure your external Nginx using nginx/nginx.conf as reference\n#   2. Configure .env.prod with DOMAIN\n{%- endif %}\n\nservices:\n{%- if cookiecutter.include_traefik_service %}\n  traefik:\n    image: traefik:v3.2\n    container_name: {{ cookiecutter.project_slug }}_traefik\n    command:\n      - \"--api.dashboard=true\"\n      - \"--providers.docker=true\"\n      - \"--providers.docker.exposedbydefault=false\"\n      - \"--providers.docker.network=traefik-public\"\n      - \"--entrypoints.web.address=:80\"\n      - \"--entrypoints.websecure.address=:443\"\n      # Redirect HTTP to HTTPS\n      - \"--entrypoints.web.http.redirections.entrypoint.to=websecure\"\n      - \"--entrypoints.web.http.redirections.entrypoint.scheme=https\"\n      # Let's Encrypt\n      - \"--certificatesresolvers.letsencrypt.acme.httpchallenge=true\"\n      - \"--certificatesresolvers.letsencrypt.acme.httpchallenge.entrypoint=web\"\n      - \"--certificatesresolvers.letsencrypt.acme.email=${ACME_EMAIL:-admin@example.com}\"\n      - \"--certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json\"\n      # Access logs\n      - \"--accesslog=true\"\n      - \"--accesslog.bufferingsize=100\"\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      - traefik_letsencrypt:/letsencrypt\n    networks:\n      - traefik-public\n    labels:\n      # Dashboard\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-traefik.rule=Host(`traefik.${DOMAIN:-localhost}`)\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-traefik.entrypoints=websecure\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-traefik.tls.certresolver=letsencrypt\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-traefik.service=api@internal\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-traefik.middlewares={{ cookiecutter.project_slug }}-auth\"\n      - \"traefik.http.middlewares.{{ cookiecutter.project_slug }}-auth.basicauth.users=${TRAEFIK_DASHBOARD_AUTH:-admin:$$apr1$$xyz$$hash}\"\n      # Security headers middleware\n      - \"traefik.http.middlewares.{{ cookiecutter.project_slug }}-security-headers.headers.stsSeconds=31536000\"\n      - \"traefik.http.middlewares.{{ cookiecutter.project_slug }}-security-headers.headers.stsIncludeSubdomains=true\"\n      - \"traefik.http.middlewares.{{ cookiecutter.project_slug }}-security-headers.headers.stsPreload=true\"\n      - \"traefik.http.middlewares.{{ cookiecutter.project_slug }}-security-headers.headers.contentTypeNosniff=true\"\n      - \"traefik.http.middlewares.{{ cookiecutter.project_slug }}-security-headers.headers.browserXssFilter=true\"\n      - \"traefik.http.middlewares.{{ cookiecutter.project_slug }}-security-headers.headers.referrerPolicy=strict-origin-when-cross-origin\"\n      - \"traefik.http.middlewares.{{ cookiecutter.project_slug }}-security-headers.headers.frameDeny=true\"\n    restart: unless-stopped\n    deploy:\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 256M\n{%- endif %}\n\n{%- if cookiecutter.include_nginx_service %}\n  nginx:\n    image: nginx:alpine\n    container_name: {{ cookiecutter.project_slug }}_nginx\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/ssl:/etc/nginx/ssl:ro\n    networks:\n      - backend-internal\n    depends_on:\n      - app\n{%- if cookiecutter.use_frontend %}\n      - frontend\n{%- endif %}\n    healthcheck:\n      test: [\"CMD\", \"nginx\", \"-t\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    restart: unless-stopped\n    deploy:\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 128M\n{%- endif %}\n\n  app:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_backend\n    env_file:\n      - .env.prod\n      - ./backend/.env\n    environment:\n      - DEBUG=false\n      - ENVIRONMENT=production\n{%- if cookiecutter.use_postgresql %}\n      - POSTGRES_HOST=db\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n      - REDIS_HOST=redis\n{%- endif %}\n{%- if cookiecutter.use_celery %}\n      - CELERY_BROKER_URL=redis://redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://redis:6379/0\n{%- endif %}\n{%- if cookiecutter.use_taskiq %}\n      - TASKIQ_BROKER_URL=redis://redis:6379/1\n      - TASKIQ_RESULT_BACKEND=redis://redis:6379/1\n{%- endif %}\n    command: uvicorn app.main:app --host 0.0.0.0 --port {{ cookiecutter.backend_port }} --workers 4\n{%- if cookiecutter.include_traefik_labels %}\n    networks:\n      - traefik-public\n      - backend-internal\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-api.rule=Host(`api.${DOMAIN:-localhost}`)\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-api.entrypoints=websecure\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-api.tls.certresolver=letsencrypt\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-api.middlewares={{ cookiecutter.project_slug }}-security-headers@docker\"\n      - \"traefik.http.services.{{ cookiecutter.project_slug }}-api.loadbalancer.server.port={{ cookiecutter.backend_port }}\"\n      - \"traefik.docker.network=traefik-public\"\n{%- elif cookiecutter.include_nginx_service %}\n    networks:\n      - backend-internal\n    # No ports exposed - nginx handles external traffic\n{%- else %}\n    networks:\n      - backend-internal\n    ports:\n      - \"{{ cookiecutter.backend_port }}:{{ cookiecutter.backend_port }}\"\n{%- endif %}\n{%- if cookiecutter.use_postgresql or cookiecutter.enable_redis %}\n    depends_on:\n{%- if cookiecutter.use_postgresql %}\n      db:\n        condition: service_healthy\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n      redis:\n        condition: service_healthy\n{%- endif %}\n{%- endif %}\n    restart: unless-stopped\n    deploy:\n      resources:\n        limits:\n          cpus: '1'\n          memory: 512M\n        reservations:\n          cpus: '0.5'\n          memory: 256M\n\n{%- if cookiecutter.use_postgresql %}\n\n  db:\n    image: postgres:16-alpine\n    container_name: {{ cookiecutter.project_slug }}_db\n    environment:\n      - POSTGRES_USER=${POSTGRES_USER:-postgres}\n      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}\n      - POSTGRES_DB=${POSTGRES_DB:-{{ cookiecutter.project_slug }}}\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    # NO external ports - only accessible within backend-internal network\n    networks:\n      - backend-internal\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${POSTGRES_USER:-postgres}\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    restart: unless-stopped\n    deploy:\n      resources:\n        limits:\n          cpus: '1'\n          memory: 512M\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n\n  redis:\n    image: redis:7-alpine\n    container_name: {{ cookiecutter.project_slug }}_redis\n    command: redis-server --requirepass ${REDIS_PASSWORD:?REDIS_PASSWORD is required}\n    # NO external ports - only accessible within backend-internal network\n    volumes:\n      - redis_data:/data\n    networks:\n      - backend-internal\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"-a\", \"${REDIS_PASSWORD}\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    restart: unless-stopped\n    deploy:\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 256M\n{%- endif %}\n\n{%- if cookiecutter.use_celery %}\n\n  celery_worker:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_celery_worker\n    command: celery -A app.worker.celery_app worker --loglevel=warning --concurrency=4\n    env_file:\n      - .env.prod\n      - ./backend/.env\n    environment:\n      - DEBUG=false\n{%- if cookiecutter.use_postgresql %}\n      - POSTGRES_HOST=db\n{%- endif %}\n      - REDIS_HOST=redis\n      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/0\n    networks:\n      - backend-internal\n    depends_on:\n      redis:\n        condition: service_healthy\n{%- if cookiecutter.use_postgresql %}\n      db:\n        condition: service_healthy\n{%- endif %}\n    restart: unless-stopped\n    deploy:\n      replicas: 2\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 512M\n        reservations:\n          cpus: '0.25'\n          memory: 256M\n\n  celery_beat:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_celery_beat\n    command: celery -A app.worker.celery_app beat --loglevel=warning\n    env_file:\n      - .env.prod\n      - ./backend/.env\n    environment:\n      - DEBUG=false\n      - REDIS_HOST=redis\n      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/0\n    networks:\n      - backend-internal\n    depends_on:\n      redis:\n        condition: service_healthy\n    restart: unless-stopped\n    deploy:\n      resources:\n        limits:\n          cpus: '0.25'\n          memory: 128M\n\n  flower:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_flower\n    command: celery -A app.worker.celery_app flower --port=5555\n    env_file:\n      - .env.prod\n      - ./backend/.env\n    environment:\n      - DEBUG=false\n      - REDIS_HOST=redis\n      - CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0\n      - CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/0\n      - FLOWER_BASIC_AUTH=${FLOWER_USER:-admin}:${FLOWER_PASSWORD:?FLOWER_PASSWORD is required}\n{%- if cookiecutter.include_traefik_labels %}\n    networks:\n      - traefik-public\n      - backend-internal\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-flower.rule=Host(`flower.${DOMAIN:-localhost}`)\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-flower.entrypoints=websecure\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-flower.tls.certresolver=letsencrypt\"\n      - \"traefik.http.services.{{ cookiecutter.project_slug }}-flower.loadbalancer.server.port=5555\"\n      - \"traefik.docker.network=traefik-public\"\n{%- elif cookiecutter.include_nginx_service %}\n    networks:\n      - backend-internal\n    # No ports exposed - nginx handles external traffic\n{%- else %}\n    networks:\n      - backend-internal\n    ports:\n      - \"5555:5555\"\n{%- endif %}\n    depends_on:\n      redis:\n        condition: service_healthy\n    restart: unless-stopped\n    deploy:\n      resources:\n        limits:\n          cpus: '0.25'\n          memory: 128M\n{%- endif %}\n\n{%- if cookiecutter.use_taskiq %}\n\n  taskiq_worker:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_taskiq_worker\n    command: taskiq worker app.worker.taskiq_app:broker --workers 4\n    env_file:\n      - .env.prod\n      - ./backend/.env\n    environment:\n      - DEBUG=false\n{%- if cookiecutter.use_postgresql %}\n      - POSTGRES_HOST=db\n{%- endif %}\n      - REDIS_HOST=redis\n      - TASKIQ_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/1\n      - TASKIQ_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/1\n    networks:\n      - backend-internal\n    depends_on:\n      redis:\n        condition: service_healthy\n{%- if cookiecutter.use_postgresql %}\n      db:\n        condition: service_healthy\n{%- endif %}\n    restart: unless-stopped\n    deploy:\n      replicas: 2\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 512M\n        reservations:\n          cpus: '0.25'\n          memory: 256M\n\n  taskiq_scheduler:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_taskiq_scheduler\n    command: taskiq scheduler app.worker.taskiq_app:scheduler\n    env_file:\n      - .env.prod\n      - ./backend/.env\n    environment:\n      - DEBUG=false\n      - REDIS_HOST=redis\n      - TASKIQ_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/1\n      - TASKIQ_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/1\n    networks:\n      - backend-internal\n    depends_on:\n      redis:\n        condition: service_healthy\n    restart: unless-stopped\n    deploy:\n      resources:\n        limits:\n          cpus: '0.25'\n          memory: 128M\n{%- endif %}\n\n{%- if cookiecutter.use_arq %}\n\n  arq_worker:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_arq_worker\n    command: arq app.worker.arq_app.WorkerSettings\n    env_file:\n      - .env.prod\n      - ./backend/.env\n    environment:\n      - DEBUG=false\n{%- if cookiecutter.use_postgresql %}\n      - POSTGRES_HOST=db\n      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}\n{%- endif %}\n      - REDIS_HOST=redis\n      - REDIS_PASSWORD=${REDIS_PASSWORD}\n      - ARQ_REDIS_HOST=redis\n      - ARQ_REDIS_PORT=6379\n      - ARQ_REDIS_DB=2\n    networks:\n      - backend-internal\n    depends_on:\n      redis:\n        condition: service_healthy\n{%- if cookiecutter.use_postgresql %}\n      db:\n        condition: service_healthy\n{%- endif %}\n    restart: unless-stopped\n    deploy:\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 256M\n{%- endif %}\n\n{%- if cookiecutter.use_frontend %}\n\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_frontend\n    environment:\n      - NODE_ENV=production\n      - BACKEND_URL=http://app:{{ cookiecutter.backend_port }}\n      - BACKEND_WS_URL=ws://app:{{ cookiecutter.backend_port }}\n{%- if cookiecutter.include_traefik_labels %}\n    networks:\n      - traefik-public\n    labels:\n      - \"traefik.enable=true\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-frontend.rule=Host(`${DOMAIN:-localhost}`)\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-frontend.entrypoints=websecure\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-frontend.tls.certresolver=letsencrypt\"\n      - \"traefik.http.routers.{{ cookiecutter.project_slug }}-frontend.middlewares={{ cookiecutter.project_slug }}-security-headers@docker\"\n      - \"traefik.http.services.{{ cookiecutter.project_slug }}-frontend.loadbalancer.server.port={{ cookiecutter.frontend_port }}\"\n      - \"traefik.docker.network=traefik-public\"\n{%- elif cookiecutter.include_nginx_service %}\n    networks:\n      - backend-internal\n    # No ports exposed - nginx handles external traffic\n{%- else %}\n    networks:\n      - backend-internal\n    ports:\n      - \"{{ cookiecutter.frontend_port }}:{{ cookiecutter.frontend_port }}\"\n{%- endif %}\n    depends_on:\n      - app\n    restart: unless-stopped\n    deploy:\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 256M\n{%- endif %}\n\nnetworks:\n{%- if cookiecutter.include_traefik_service %}\n  traefik-public:\n    driver: bridge\n{%- elif cookiecutter.include_traefik_labels %}\n  traefik-public:\n    external: true\n{%- endif %}\n  backend-internal:\n    driver: bridge\n    internal: true\n\nvolumes:\n{%- if cookiecutter.include_traefik_service %}\n  traefik_letsencrypt:\n{%- endif %}\n{%- if cookiecutter.use_postgresql %}\n  postgres_data:\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n  redis_data:\n{%- endif %}\n{%- else %}\n# Docker is disabled for this project\n{%- endif %}\n",".gitlab-ci.yml":"{%- if cookiecutter.use_gitlab_ci %}\n# GitLab CI/CD Pipeline for {{ cookiecutter.project_name }}\n\nstages:\n  - lint\n  - test\n  - security\n{%- if cookiecutter.enable_docker %}\n  - build\n{%- endif %}\n\nvariables:\n  PYTHON_VERSION: \"{{ cookiecutter.python_version }}\"\n  PIP_CACHE_DIR: \"$CI_PROJECT_DIR/.cache/pip\"\n  UV_CACHE_DIR: \"$CI_PROJECT_DIR/.cache/uv\"\n\n# Cache configuration\n.cache_config: &cache_config\n  cache:\n    key: \"$CI_COMMIT_REF_SLUG\"\n    paths:\n      - .cache/pip\n      - .cache/uv\n      - backend/.venv\n\n# Base Python job template\n.python_base:\n  image: python:${PYTHON_VERSION}-slim\n  before_script:\n    - pip install uv\n    - cd backend\n    - uv sync --dev\n  <<: *cache_config\n\n# =============================================================================\n# Lint Stage\n# =============================================================================\n\nruff-check:\n  stage: lint\n  extends: .python_base\n  script:\n    - uv run ruff check app tests cli\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\nruff-format:\n  stage: lint\n  extends: .python_base\n  script:\n    - uv run ruff format app tests cli --check\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\nmypy:\n  stage: lint\n  extends: .python_base\n  script:\n    - uv run mypy app\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\n# =============================================================================\n# Test Stage\n# =============================================================================\n\ntest:\n  stage: test\n  image: python:${PYTHON_VERSION}-slim\n{%- if cookiecutter.use_postgresql or cookiecutter.enable_redis %}\n  services:\n{%- if cookiecutter.use_postgresql %}\n    - name: postgres:16-alpine\n      alias: postgres\n      variables:\n        POSTGRES_USER: postgres\n        POSTGRES_PASSWORD: postgres\n        POSTGRES_DB: test_db\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n    - name: redis:7-alpine\n      alias: redis\n{%- endif %}\n{%- endif %}\n  variables:\n{%- if cookiecutter.use_postgresql %}\n    POSTGRES_HOST: postgres\n    POSTGRES_PORT: \"5432\"\n    POSTGRES_USER: postgres\n    POSTGRES_PASSWORD: postgres\n    POSTGRES_DB: test_db\n{%- endif %}\n{%- if cookiecutter.enable_redis %}\n    REDIS_HOST: redis\n    REDIS_PORT: \"6379\"\n{%- endif %}\n  before_script:\n    - pip install uv\n    - cd backend\n    - uv sync --dev\n  script:\n    - uv run pytest tests/ -v --cov=app --cov-report=xml --cov-report=term-missing\n  coverage: '/(?i)total.*? (100(?:\\.0+)?\\%|[1-9]?\\d(?:\\.\\d+)?\\%)$/'\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: backend/coverage.xml\n    expire_in: 1 week\n  <<: *cache_config\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\n# =============================================================================\n# Security Stage\n# =============================================================================\n\nsecurity-scan:\n  stage: security\n  extends: .python_base\n  script:\n    - uv pip install pip-audit\n    - uv run pip-audit --require-hashes=false --progress-spinner=off\n  allow_failure: true\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\n{%- if cookiecutter.enable_docker %}\n\n# =============================================================================\n# Build Stage\n# =============================================================================\n\ndocker-build:\n  stage: build\n  image: docker:24\n  services:\n    - docker:24-dind\n  variables:\n    DOCKER_TLS_CERTDIR: \"/certs\"\n  before_script:\n    - docker info\n  script:\n    - docker build -t {{ cookiecutter.project_slug }}:$CI_COMMIT_SHORT_SHA ./backend\n    - docker tag {{ cookiecutter.project_slug }}:$CI_COMMIT_SHORT_SHA {{ cookiecutter.project_slug }}:latest\n  rules:\n    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n\n# Optional: Push to GitLab Container Registry\n# Uncomment and configure as needed\n#\n# docker-push:\n#   stage: build\n#   image: docker:24\n#   services:\n#     - docker:24-dind\n#   variables:\n#     DOCKER_TLS_CERTDIR: \"/certs\"\n#   before_script:\n#     - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n#   script:\n#     - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA ./backend\n#     - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA\n#     - docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA $CI_REGISTRY_IMAGE:latest\n#     - docker push $CI_REGISTRY_IMAGE:latest\n#   rules:\n#     - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH\n#   needs:\n#     - docker-build\n{%- endif %}\n{%- else %}\n# GitLab CI is disabled for this project\n{%- endif %}\n","AGENTS.md":"# AGENTS.md\n\nThis file provides guidance for AI coding agents (Codex, Copilot, Cursor, Zed, OpenCode).\n\n## Project Overview\n\n**{{ cookiecutter.project_name }}** - FastAPI application.\n\n**Stack:** FastAPI + Pydantic v2\n{%- if cookiecutter.use_postgresql %}, PostgreSQL{%- endif %}\n{%- if cookiecutter.use_mongodb %}, MongoDB{%- endif %}\n{%- if cookiecutter.use_jwt %}, JWT auth{%- endif %}\n{%- if cookiecutter.enable_redis %}, Redis{%- endif %}\n{%- if cookiecutter.use_frontend %}, Next.js 15{%- endif %}\n\n## Commands\n\n```bash\n# Run server\ncd backend && uv run uvicorn app.main:app --reload\n\n# Tests & lint\npytest\nruff check . --fix && ruff format .\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\n# Migrations\nuv run alembic upgrade head\n{%- endif %}\n```\n\n## Project Structure\n\n```\nbackend/app/\n‚îú‚îÄ‚îÄ api/routes/v1/    # Endpoints\n‚îú‚îÄ‚îÄ services/         # Business logic\n‚îú‚îÄ‚îÄ repositories/     # Data access\n‚îú‚îÄ‚îÄ schemas/          # Pydantic models\n‚îú‚îÄ‚îÄ db/models/        # DB models\n‚îî‚îÄ‚îÄ commands/         # CLI commands\n```\n\n## Key Conventions\n\n- `db.flush()` in repositories, not `commit()`\n- Services raise `NotFoundError`, `AlreadyExistsError`\n- Separate `Create`, `Update`, `Response` schemas\n\n## More Info\n\n- `docs/architecture.md` - Architecture details\n- `docs/adding_features.md` - How to add features\n- `docs/testing.md` - Testing guide\n- `docs/patterns.md` - Code patterns\n","kubernetes/deployment.yaml":"{%- if cookiecutter.enable_kubernetes %}\n# Deployment for {{ cookiecutter.project_name }} Backend\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ cookiecutter.project_slug }}-backend\n  namespace: {{ cookiecutter.project_slug }}\n  labels:\n    app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n    app.kubernetes.io/component: backend\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n      app.kubernetes.io/component: backend\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n        app.kubernetes.io/component: backend\n{%- if cookiecutter.enable_prometheus %}\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"{{ cookiecutter.backend_port }}\"\n        prometheus.io/path: \"/metrics\"\n{%- endif %}\n    spec:\n      containers:\n        - name: backend\n          image: {{ cookiecutter.project_slug }}:latest\n          imagePullPolicy: Always\n          ports:\n            - containerPort: {{ cookiecutter.backend_port }}\n              name: http\n          envFrom:\n            - configMapRef:\n                name: {{ cookiecutter.project_slug }}-config\n            - secretRef:\n                name: {{ cookiecutter.project_slug }}-secrets\n          resources:\n            requests:\n              memory: \"256Mi\"\n              cpu: \"100m\"\n            limits:\n              memory: \"512Mi\"\n              cpu: \"500m\"\n          livenessProbe:\n            httpGet:\n              path: /api/v1/health\n              port: {{ cookiecutter.backend_port }}\n            initialDelaySeconds: 10\n            periodSeconds: 30\n            timeoutSeconds: 5\n            failureThreshold: 3\n          readinessProbe:\n            httpGet:\n              path: /api/v1/ready\n              port: {{ cookiecutter.backend_port }}\n            initialDelaySeconds: 5\n            periodSeconds: 10\n            timeoutSeconds: 5\n            failureThreshold: 3\n          securityContext:\n            runAsNonRoot: true\n            runAsUser: 1000\n            allowPrivilegeEscalation: false\n            readOnlyRootFilesystem: true\n      restartPolicy: Always\n\n---\n{%- if cookiecutter.use_celery %}\n# Celery Worker Deployment\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ cookiecutter.project_slug }}-celery-worker\n  namespace: {{ cookiecutter.project_slug }}\n  labels:\n    app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n    app.kubernetes.io/component: celery-worker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n      app.kubernetes.io/component: celery-worker\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n        app.kubernetes.io/component: celery-worker\n    spec:\n      containers:\n        - name: celery-worker\n          image: {{ cookiecutter.project_slug }}:latest\n          imagePullPolicy: Always\n          command: [\"celery\", \"-A\", \"app.worker.celery_app\", \"worker\", \"--loglevel=info\"]\n          envFrom:\n            - configMapRef:\n                name: {{ cookiecutter.project_slug }}-config\n            - secretRef:\n                name: {{ cookiecutter.project_slug }}-secrets\n          resources:\n            requests:\n              memory: \"256Mi\"\n              cpu: \"100m\"\n            limits:\n              memory: \"512Mi\"\n              cpu: \"500m\"\n      restartPolicy: Always\n\n---\n# Celery Beat Deployment\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ cookiecutter.project_slug }}-celery-beat\n  namespace: {{ cookiecutter.project_slug }}\n  labels:\n    app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n    app.kubernetes.io/component: celery-beat\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n      app.kubernetes.io/component: celery-beat\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n        app.kubernetes.io/component: celery-beat\n    spec:\n      containers:\n        - name: celery-beat\n          image: {{ cookiecutter.project_slug }}:latest\n          imagePullPolicy: Always\n          command: [\"celery\", \"-A\", \"app.worker.celery_app\", \"beat\", \"--loglevel=info\"]\n          envFrom:\n            - configMapRef:\n                name: {{ cookiecutter.project_slug }}-config\n            - secretRef:\n                name: {{ cookiecutter.project_slug }}-secrets\n          resources:\n            requests:\n              memory: \"128Mi\"\n              cpu: \"50m\"\n            limits:\n              memory: \"256Mi\"\n              cpu: \"200m\"\n      restartPolicy: Always\n{%- endif %}\n\n{%- if cookiecutter.use_taskiq %}\n---\n# Taskiq Worker Deployment\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ cookiecutter.project_slug }}-taskiq-worker\n  namespace: {{ cookiecutter.project_slug }}\n  labels:\n    app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n    app.kubernetes.io/component: taskiq-worker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n      app.kubernetes.io/component: taskiq-worker\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n        app.kubernetes.io/component: taskiq-worker\n    spec:\n      containers:\n        - name: taskiq-worker\n          image: {{ cookiecutter.project_slug }}:latest\n          imagePullPolicy: Always\n          command: [\"taskiq\", \"worker\", \"app.worker.taskiq_app:broker\", \"--workers\", \"2\"]\n          envFrom:\n            - configMapRef:\n                name: {{ cookiecutter.project_slug }}-config\n            - secretRef:\n                name: {{ cookiecutter.project_slug }}-secrets\n          resources:\n            requests:\n              memory: \"256Mi\"\n              cpu: \"100m\"\n            limits:\n              memory: \"512Mi\"\n              cpu: \"500m\"\n      restartPolicy: Always\n{%- endif %}\n\n{%- if cookiecutter.use_arq %}\n---\n# ARQ Worker Deployment\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: {{ cookiecutter.project_slug }}-arq-worker\n  namespace: {{ cookiecutter.project_slug }}\n  labels:\n    app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n    app.kubernetes.io/component: arq-worker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n      app.kubernetes.io/component: arq-worker\n  template:\n    metadata:\n      labels:\n        app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n        app.kubernetes.io/component: arq-worker\n    spec:\n      containers:\n        - name: arq-worker\n          image: {{ cookiecutter.project_slug }}:latest\n          imagePullPolicy: Always\n          command: [\"arq\", \"app.worker.arq_app.WorkerSettings\"]\n          envFrom:\n            - configMapRef:\n                name: {{ cookiecutter.project_slug }}-config\n            - secretRef:\n                name: {{ cookiecutter.project_slug }}-secrets\n          resources:\n            requests:\n              memory: \"256Mi\"\n              cpu: \"100m\"\n            limits:\n              memory: \"512Mi\"\n              cpu: \"500m\"\n      restartPolicy: Always\n{%- endif %}\n{%- else %}\n# Kubernetes is disabled for this project\n{%- endif %}\n","kubernetes/ingress.yaml":"{%- if cookiecutter.enable_kubernetes %}\n# Ingress for {{ cookiecutter.project_name }}\n# Configure your domain and TLS settings before deploying\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: {{ cookiecutter.project_slug }}-ingress\n  namespace: {{ cookiecutter.project_slug }}\n  labels:\n    app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n    app.kubernetes.io/component: ingress\n  annotations:\n    # Nginx Ingress Controller annotations\n    nginx.ingress.kubernetes.io/proxy-body-size: \"10m\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"60\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"60\"\n{%- if cookiecutter.enable_rate_limiting %}\n    # Rate limiting (adjust as needed)\n    nginx.ingress.kubernetes.io/limit-rps: \"100\"\n    nginx.ingress.kubernetes.io/limit-connections: \"50\"\n{%- endif %}\n    # Uncomment for Let's Encrypt with cert-manager\n    # cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\nspec:\n  ingressClassName: nginx\n  # Uncomment for TLS\n  # tls:\n  #   - hosts:\n  #       - api.example.com\n  #     secretName: {{ cookiecutter.project_slug }}-tls\n  rules:\n    - host: api.example.com  # Replace with your domain\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: {{ cookiecutter.project_slug }}-backend\n                port:\n                  number: {{ cookiecutter.backend_port }}\n{%- else %}\n# Kubernetes is disabled for this project\n{%- endif %}\n","kubernetes/kustomization.yaml":"{%- if cookiecutter.enable_kubernetes %}\n# Kustomization for {{ cookiecutter.project_name }}\n# Deploy with: kubectl apply -k kubernetes/\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nnamespace: {{ cookiecutter.project_slug }}\n\nresources:\n  - namespace.yaml\n  - configmap.yaml\n  - secret.yaml\n  - deployment.yaml\n  - service.yaml\n  - ingress.yaml\n\ncommonLabels:\n  app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n  app.kubernetes.io/version: \"0.1.0\"\n  app.kubernetes.io/managed-by: kustomize\n\n# Image customization (override in overlays)\nimages:\n  - name: {{ cookiecutter.project_slug }}\n    newTag: latest\n{%- else %}\n# Kubernetes is disabled for this project\n{%- endif %}\n","kubernetes/service.yaml":"{%- if cookiecutter.enable_kubernetes %}\n# Service for {{ cookiecutter.project_name }} Backend\napiVersion: v1\nkind: Service\nmetadata:\n  name: {{ cookiecutter.project_slug }}-backend\n  namespace: {{ cookiecutter.project_slug }}\n  labels:\n    app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n    app.kubernetes.io/component: backend\nspec:\n  type: ClusterIP\n  ports:\n    - port: {{ cookiecutter.backend_port }}\n      targetPort: {{ cookiecutter.backend_port }}\n      protocol: TCP\n      name: http\n  selector:\n    app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n    app.kubernetes.io/component: backend\n{%- else %}\n# Kubernetes is disabled for this project\n{%- endif %}\n","kubernetes/namespace.yaml":"{%- if cookiecutter.enable_kubernetes %}\n# Kubernetes Namespace for {{ cookiecutter.project_name }}\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: {{ cookiecutter.project_slug }}\n  labels:\n    app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n    app.kubernetes.io/managed-by: kubectl\n{%- else %}\n# Kubernetes is disabled for this project\n{%- endif %}\n","kubernetes/configmap.yaml":"{%- if cookiecutter.enable_kubernetes %}\n# ConfigMap for {{ cookiecutter.project_name }}\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: {{ cookiecutter.project_slug }}-config\n  namespace: {{ cookiecutter.project_slug }}\n  labels:\n    app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n    app.kubernetes.io/component: backend\ndata:\n  # Application settings\n  ENVIRONMENT: \"production\"\n  DEBUG: \"false\"\n  PROJECT_NAME: \"{{ cookiecutter.project_name }}\"\n  API_V1_STR: \"/api/v1\"\n\n{%- if cookiecutter.use_postgresql %}\n  # PostgreSQL settings\n  POSTGRES_HOST: \"postgres-service\"\n  POSTGRES_PORT: \"5432\"\n  POSTGRES_DB: \"{{ cookiecutter.project_slug }}\"\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n  # Redis settings\n  REDIS_HOST: \"redis-service\"\n  REDIS_PORT: \"6379\"\n  REDIS_DB: \"0\"\n{%- endif %}\n\n{%- if cookiecutter.use_celery %}\n  # Celery settings\n  CELERY_BROKER_URL: \"redis://redis-service:6379/0\"\n  CELERY_RESULT_BACKEND: \"redis://redis-service:6379/0\"\n{%- endif %}\n\n{%- if cookiecutter.use_taskiq %}\n  # Taskiq settings\n  TASKIQ_BROKER_URL: \"redis://redis-service:6379/1\"\n  TASKIQ_RESULT_BACKEND: \"redis://redis-service:6379/1\"\n{%- endif %}\n\n{%- if cookiecutter.use_arq %}\n  # ARQ settings\n  ARQ_REDIS_HOST: \"redis-service\"\n  ARQ_REDIS_PORT: \"6379\"\n  ARQ_REDIS_DB: \"2\"\n{%- endif %}\n\n{%- if cookiecutter.enable_logfire %}\n  # Logfire settings\n  LOGFIRE_SERVICE_NAME: \"{{ cookiecutter.project_slug }}\"\n  LOGFIRE_ENVIRONMENT: \"production\"\n{%- endif %}\n\n{%- if cookiecutter.enable_cors %}\n  # CORS settings (adjust for your domain)\n  CORS_ORIGINS: '[\"https://{{ cookiecutter.project_slug }}.example.com\"]'\n{%- endif %}\n{%- else %}\n# Kubernetes is disabled for this project\n{%- endif %}\n","kubernetes/secret.yaml":"{%- if cookiecutter.enable_kubernetes %}\n# Secret for {{ cookiecutter.project_name }}\n# WARNING: Replace placeholder values before deploying!\n# Consider using external secrets management (Vault, AWS Secrets Manager, etc.)\napiVersion: v1\nkind: Secret\nmetadata:\n  name: {{ cookiecutter.project_slug }}-secrets\n  namespace: {{ cookiecutter.project_slug }}\n  labels:\n    app.kubernetes.io/name: {{ cookiecutter.project_slug }}\n    app.kubernetes.io/component: backend\ntype: Opaque\nstringData:\n{%- if cookiecutter.use_jwt %}\n  # Generate with: openssl rand -hex 32\n  SECRET_KEY: \"CHANGE_ME_IN_PRODUCTION\"\n{%- endif %}\n\n{%- if cookiecutter.use_api_key %}\n  API_KEY: \"CHANGE_ME_IN_PRODUCTION\"\n{%- endif %}\n\n{%- if cookiecutter.use_postgresql %}\n  POSTGRES_USER: \"postgres\"\n  POSTGRES_PASSWORD: \"CHANGE_ME_IN_PRODUCTION\"\n{%- endif %}\n\n{%- if cookiecutter.enable_redis %}\n  REDIS_PASSWORD: \"\"\n{%- endif %}\n\n{%- if cookiecutter.enable_logfire %}\n  LOGFIRE_TOKEN: \"\"\n{%- endif %}\n\n{%- if cookiecutter.enable_sentry %}\n  SENTRY_DSN: \"\"\n{%- endif %}\n\n{%- if cookiecutter.enable_ai_agent %}\n{%- if cookiecutter.use_openai %}\n  OPENAI_API_KEY: \"\"\n{%- endif %}\n{%- if cookiecutter.use_anthropic %}\n  ANTHROPIC_API_KEY: \"\"\n{%- endif %}\n{%- if cookiecutter.use_openrouter %}\n  OPENROUTER_API_KEY: \"\"\n{%- endif %}\n{%- endif %}\n\n{%- if cookiecutter.enable_oauth_google %}\n  GOOGLE_CLIENT_ID: \"\"\n  GOOGLE_CLIENT_SECRET: \"\"\n{%- endif %}\n{%- else %}\n# Kubernetes is disabled for this project\n{%- endif %}\n","docker-compose.frontend.yml":"{%- if cookiecutter.enable_docker and cookiecutter.use_frontend %}\n# Frontend development configuration\n# Usage: docker-compose -f docker-compose.frontend.yml up -d\n#\n# Note: Backend must be running first (docker-compose up -d)\n# Frontend connects to backend via host network\n\nservices:\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n    container_name: {{ cookiecutter.project_slug }}_frontend\n    ports:\n      - \"{{ cookiecutter.frontend_port }}:{{ cookiecutter.frontend_port }}\"\n    environment:\n      - NODE_ENV=development\n      - BACKEND_URL=http://host.docker.internal:{{ cookiecutter.backend_port }}\n      - BACKEND_WS_URL=ws://host.docker.internal:{{ cookiecutter.backend_port }}\n    extra_hosts:\n      - \"host.docker.internal:host-gateway\"\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:{{ cookiecutter.frontend_port }}/api/health\"]\n      interval: 30s\n      timeout: 10s\n      start_period: 40s\n      retries: 3\n{%- else %}\n# Frontend is disabled for this project\n{%- endif %}\n","CLAUDE.md":"# CLAUDE.md\n\n## Project Overview\n\n**{{ cookiecutter.project_name }}** - FastAPI application generated with [Full-Stack FastAPI + Next.js Template](https://github.com/vstorm-co/full-stack-ai-agent-template).\n\n**Stack:** FastAPI + Pydantic v2\n{%- if cookiecutter.use_postgresql %}, PostgreSQL (async){%- endif %}\n{%- if cookiecutter.use_mongodb %}, MongoDB (async){%- endif %}\n{%- if cookiecutter.use_sqlite %}, SQLite{%- endif %}\n{%- if cookiecutter.use_jwt %}, JWT auth{%- endif %}\n{%- if cookiecutter.enable_redis %}, Redis{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_pydantic_ai %}, PydanticAI{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_langchain %}, LangChain{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_langgraph %}, LangGraph{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_crewai %}, CrewAI{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_deepagents %}, DeepAgents{%- endif %}\n{%- if cookiecutter.use_celery %}, Celery{%- endif %}\n{%- if cookiecutter.use_taskiq %}, Taskiq{%- endif %}\n{%- if cookiecutter.use_frontend %}, Next.js 15{%- endif %}\n\n## Commands\n\n```bash\n# Backend\ncd backend\nuv run uvicorn app.main:app --reload --port {{ cookiecutter.backend_port }}\npytest\nruff check . --fix && ruff format .\n{%- if cookiecutter.use_postgresql or cookiecutter.use_sqlite %}\n\n# Database\nuv run alembic upgrade head\nuv run alembic revision --autogenerate -m \"Description\"\n{%- endif %}\n{%- if cookiecutter.use_frontend %}\n\n# Frontend\ncd frontend\nbun dev\nbun test\n{%- endif %}\n{%- if cookiecutter.enable_docker %}\n\n# Docker\ndocker compose up -d\n{%- endif %}\n```\n\n## Project Structure\n\n```\nbackend/app/\n‚îú‚îÄ‚îÄ api/routes/v1/    # HTTP endpoints\n‚îú‚îÄ‚îÄ services/         # Business logic\n‚îú‚îÄ‚îÄ repositories/     # Data access\n‚îú‚îÄ‚îÄ schemas/          # Pydantic models\n‚îú‚îÄ‚îÄ db/models/        # Database models\n‚îú‚îÄ‚îÄ core/config.py    # Settings\n{%- if cookiecutter.enable_ai_agent %}\n‚îú‚îÄ‚îÄ agents/           # AI agents\n{%- endif %}\n‚îî‚îÄ‚îÄ commands/         # CLI commands\n```\n\n## Key Conventions\n\n- Use `db.flush()` in repositories (not `commit`)\n- Services raise domain exceptions (`NotFoundError`, `AlreadyExistsError`)\n- Schemas: separate `Create`, `Update`, `Response` models\n- Commands auto-discovered from `app/commands/`\n\n## Where to Find More Info\n\nBefore starting complex tasks, read relevant docs:\n- **Architecture details:** `docs/architecture.md`\n- **Adding features:** `docs/adding_features.md`\n- **Testing guide:** `docs/testing.md`\n- **Code patterns:** `docs/patterns.md`\n\n## Environment Variables\n\nKey variables in `.env`:\n```bash\nENVIRONMENT=local\n{%- if cookiecutter.use_postgresql %}\nPOSTGRES_HOST=localhost\nPOSTGRES_PASSWORD=secret\n{%- endif %}\n{%- if cookiecutter.use_jwt %}\nSECRET_KEY=change-me-use-openssl-rand-hex-32\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_openai %}\nOPENAI_API_KEY=sk-...\n{%- endif %}\n{%- if cookiecutter.enable_ai_agent and cookiecutter.use_anthropic %}\nANTHROPIC_API_KEY=sk-ant-...\n{%- endif %}\n{%- if cookiecutter.enable_logfire %}\nLOGFIRE_TOKEN=your-token\n{%- endif %}\n```\n"}}